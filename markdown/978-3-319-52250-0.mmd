[MISSING_PAGE_EMPTY:7936]

**Springer Texts in Statistics**

**Series editors**

R. DeVeaux

S.E. Fienberg

I. Olkin

More information about this series at [http://www.springer.com/series/417](http://www.springer.com/series/417)Angela Dean. Daniel Voss

Daniel Draguljic

Design and Analysis

of Experiments

Second Edition

[MISSING_PAGE_EMPTY:7939]

### Preface to the Second Edition

Since writing the first edition of _Design and Analysis of Experiments_, there have been a number of additions to the research investigator's toolbox. In this second edition, we have incorporated a few of these modern topics.

Small screening designs are now becoming prevalent in industry for aiding the search for a few influential factors from amongst a large pool of factors of potential interest. In Chap. 15, we have expanded the material on saturated designs and introduced the topic of _supersaturated designs_ which have fewer observations than the number of factors being investigated. We have illustrated that useful information can be gleaned about influential factors through the use of supersaturated designs even though their contrast estimators are correlated. When curvature is of interest, we have described _definitive screening designs_ which have only recently been introduced in the literature, and which allow second order effects to be measured while retaining independence of linear main effects and requiring barely more than twice as many observations as factors.

Another modern set of tools, now used widely in areas such as biomedical and materials engineering, the physical sciences, and the life sciences, is that of _computer experiments_. To give a flavor of this topic, a new Chap. 20 has been added. Computer experiments are typically used when a mathematical description of a physical process is available, but a physical experiment cannot be run for ethical or cost reasons. We have discussed the major issues in both the design and analysis of computer experiments. While the complete treatment of the theoretical background for the analysis is beyond the scope of this book, we have provided enough technical details of the statistical model, as well as an intuitive explanation, to make the analysis accessible to the intended reader. We have also provided computer code needed for both design and analysis.

Chapter 19 has been expanded to include two new experiments involving split-plot designs from the discipline of human factors engineering. In one case, imbalance due to lost data, coupled with a mixed model, motivates introduction of restricted-maximum-likelihood-based methods implemented in the computer software sections, including a comparison of these methods to those based on least squares estimation.

It is now the case that analysis of variance and computation of confidence intervals is almost exclusively done by computer and rarely by hand. However, we have retained the basic material on these topics since it isfundamental to the understanding of computer output. We have removed some of the more specialized details of least squares estimates from Chaps. 10-12 and canonical analysis details in Chap. 16, relying on the computer software sections to illustrate these.

SAS(r) software is still used widely in industry, but many university departments now teach the analysis of data using R (R Development Core Team, 2017). This is a command line software for statistical computing and graphics that is freely available on the web. Consequently, we have made a major addition to the book by including sections illustrating the use of R software for each chapter. These sections run parallel to the "Using SAS Software" sections, retained from the first edition.

A few additions have been made to the "Using SAS Software" sections. For example, in Chap. 11, PROC OPTEX has been included for generation of efficient block designs. PROC MIXED is utilized in Chap. 5 to implement Satterthwaite's method, and also in Chaps. 17-19 to estimate standard errors involving composite variance estimates, and in Chap. 19 to implement _restricted maximum likelihood estimation_ given imbalanced data and mixed models.

We have updated the SAS output1, showing this as reproductions of PC output windows generated by each program. The SAS programs presented can be run on a PC or in a command line environment such as unix, although the latter would use PROC PLOT rather than the graphics PROC SGPLOT.

Footnote 1: The output in our “Using SAS Software” sections was generated using SAS software Version 9.3 of the SAS System for PC. Copyright © SAS 2012 SAS Institute Inc. SAS and all other SAS Institute Inc. product or service names are registered trademarks or trademarks of SAS Institute Inc., Cary, NC, USA.

Some minor modifications have been made to a few other chapters from the first edition. For example, for assessing which contrasts are non-negligible in single replicate or fractional factorial experiments, we have replaced normal probability plots by _half-normal probability plots_ (Chaps. 7, 13 and 15). The reason for this change is that contrast signs are dependent upon which level of the factor is labeled as the high level and which is labeled as the low level. Half-normal plots remove this potential arbitrariness by plotting the absolute values of the contrast estimates against "half-normal scores".

Section 7.6 in the first edition on the control of noise variability and Taguchi experiments has been removed, while the corresponding material in Chap. 15 has been expanded. On teaching the material, we found it preferable to have information on mixed arrays, product arrays, and their analysis, in one location. The selection of multiple comparison methods in Chap. 4 has been shortened to include only those methods that were used constantly throughout the book. Thus, we removed the method of multiple comparisons with the best, which was not illustrated often; however, this method remains appropriate and valid for many situations in practice.

Some of the worked examples in Chap. 10 have been replaced with newer experiments, and new worked examples added to Chaps. 15 and 19. Some new exercises have been added to many chapters. These either replace exercises from the first edition or have been added at the end of the exercise list. All other first edition exercises retain their same numbers in this second edition.

A new website [http://www.wright.edu/~dan.voss/DeanVossDraguljic.html](http://www.wright.edu/~dan.voss/DeanVossDraguljic.html) has been set up for the second edition. This contains material similar to that on the website for the first edition, including datasets for examples and exercises, SAS and R programs, and any corrections.

We continue to owe a debt of gratitude to many. We extend our thanks to all the many students at The Ohio State University and Wright State University who provided imaginative and interesting experiments and gave us permission to include their projects. We thank all the readers who notified us of errors in the first edition and we hope that we have remembered to include all the corrections. We will be equally grateful to readers of the second edition for notifying us of any newly introduced errors. We are indebted to Russell Lenth for updating the R package lsmeans to encompass all the multiple comparisons procedures used in this book. We are grateful to the editorial staff at Springer, especially Rebekah McClure and Hannah Bracken, who were always available to give advice and answer our questions quickly and in detail.

Finally, we extend our love and gratitude to Jeff, Nancy, Tom, Jimmy, Linda, Luka, Nikola, Marija and Anika.

Columbus, USA Angela Dean

Dayton, USA Daniel Voss

Lancaster, USA Daniel DraguljicPreface to the First Edition

The initial motivation for writing this book was the observation from various students that the subject of design and analysis of experiments can seem like "a bunch of miscellaneous topics." We believe that the identification of the objectives of the experiment and the practical considerations governing the design form the heart of the subject matter and serve as the link between the various analytical techniques. We also believe that learning about design and analysis of experiments is best achieved by the planning, running, and analyzing of a simple experiment.

With these considerations in mind, we have included throughout the book the details of the planning stage of several experiments that were run in the course of teaching our classes. The experiments were run by students in statistics and the applied sciences and are sufficiently simple that it is possible to discuss the planning of the entire experiment in a few pages, and the procedures can be reproduced by readers of the book. In each of these experiments, we had access to the investigators' actual report, including the difficulties they came across and how they decided on the treatment factors, the needed number of observations, and the layout of the design. In the later chapters, we have included details of a number of published experiments. The outlines of many other student and published experiments appear as exercises at the ends of the chapters.

Complementing the practical aspects of the design are the statistical aspects of the analysis. We have developed the theory of estimable functions and analysis of variance with some care, but at a low mathematical level. Formulae are provided for almost all analyses so that the statistical methods can be well understood, related design issues can be discussed, and computations can be done by hand in order to check computer output.

We recommend the use of a sophisticated statistical package in conjunction with the book. Use of software helps to focus attention on the statistical issues rather than the calculation. Our particular preference is for the SAS software, and we have included the elementary use of this package at the end of most chapters. Many of the SAS program files and data sets used in the book can be found at www.springer-ny.com. However, the book can equally well be used with any other statistical package. Availability of statistical software has also helped shape the book in that we can discuss more complicated analyses--the analysis of unbalanced designs, for example.

The level of presentation of material is intended to make the book accessible to a wide audience. Standard linear models under normality are used for all analyses. We have avoided using calculus, except in a few optional sections where least squares estimators are obtained. We have also avoided using linear algebra, except in an optional section on the canonical analysis of second-order response surface designs. Contrast coefficients are listed in the form of a vector, but these are interpreted merely as a list of coefficients.

This book reflects a number of personal preferences. First and foremost, we have not put side conditions on the parameters in our models. The reason for this is threefold. Firstly, when side conditions are added to the model, all the parameters appear to be estimable. Consequently, one loses the perspective that in factorial experiments, main effects can be interpreted only as averages over any interactions that happen to be present. Secondly, the side conditions that are the most useful for hand calculation do not coincide with those used by the SAS software. Thirdly, if one feeds a nonestimable parametric function into a computer program such as PROC GLM in SAS, the program will declare the function to be "nonestimable," and the user needs to be able to interpret this statement. A consequence is that the traditional solutions to the normal equations do not arise naturally. Since the traditional solutions are for nonestimable parameters, we have tried to avoid giving these, and instead have focused on the estimation of functions of \(E[Y]\), all of which are estimable.

We have concentrated on the use of prespecified models and preplanned analyses rather than exploratory data analysis. We have emphasized the experimentwise control of error rates and confidence levels rather than individual error rates and confidence levels.

We rely upon residual plots rather than formal tests to assess model assumptions. This is because of the additional information provided by residual plots when model assumption violations are indicated. For example, plots to check homogeneity of variance also indicate when a variance-stabilizing transformation should be effective. Likewise, nonlinear patterns in a normal probability plot may indicate whether inferences under normality are likely to be liberal or conservative. Except for some tests for lack of fit, we have, in fact, omitted all details of formal testing for model assumptions, even though they are readily available in many computer packages.

The book starts with basic principles and techniques of experimental design and analysis of experiments. It provides a checklist for the planning of experiments, and covers analysis of variance, inferences for treatment contrasts, regression, and analysis of covariance. These basics are then applied in a wide variety of settings. Designs covered include completely randomized designs, complete and incomplete block designs, row-column designs, single replicate designs with confounding, fractional factorial designs, response surface designs, and designs involving nested factors and factors with random effects, including split-plot designs.

In the last few years, "Taguchi methods" have become very popular for industrial experimentation, and we have incorporated some of these ideas. Rather than separating Taguchi methods as special topics, we have interspersedthem throughout the chapters via the notion of including "noise factors" in an experiment and analyzing the variability of the response as the noise factors vary.

We have introduced factorial experiments as early as Chapter 3, but analyzed them as one-way layouts (i.e., using a cell means model). The purpose is to avoid introducing factorial experiments halfway through the book as a totally new topic, and to emphasize that many factorial experiments are run as completely randomized designs. We have analyzed contrasts in a two-factor experiment both via the usual two-way analysis of variance model (where the contrasts are in terms of the main effect and interaction parameters) and also via a cell-means model (where the contrasts are in terms of the treatment combination parameters). The purpose of this is to lay the groundwork for Chapters 13-15, where these contrasts are used in confounding and fractions. It is also the traditional notation used in conjunction with Taguchi methods.

The book is not all-inclusive. For example, we do not cover recovery of interblock information for incomplete block designs with random block effects. We do not provide extensive tables of incomplete block designs. Also, careful coverage of unbalanced models involving random effects is beyond our scope. Finally, inclusion of SAS graphics is limited to low-resolution plots.

The book has been classroom tested successfully over the past five years at The Ohio State University, Wright State University, and Kenyon College, for junior and senior undergraduate students majoring in a variety of fields, first-year graduate students in statistics, and senior graduate students in the applied sciences. These three institutions are somewhat different. The Ohio State University is a large land-grant university offering degrees through the Ph.D., Wright State University is a mid-sized university with few Ph.D. programs, and Kenyon College is a liberal arts undergraduate college. Below we describe typical syllabi that have been used.

At OSU, classes meet for five hours per week for ten weeks. A typical class is composed of 35 students, about a third of whom are graduate students in the applied statistics master's program. The remaining students are undergraduates in the mathematical sciences or graduate students in industrial engineering, biomedical engineering, and various applied sciences. The somewhat ambitious syllabus covers Chapters 1-7 and 10, Sections 11.1-11.4, and Chapters 13, 15, and 17. Students taking these classes plan, run, and analyze their own experiments, usually in a team of four or five students from several different departments. This project serves the function of giving statisticians the opportunity of working with scientists and of seeing the experimental procedure firsthand, and gives the scientists access to colleagues with a broader statistical training. The experience is usually highly rated by the student participants.

Classes at WSU meet four hours per week for ten weeks. A typical class involves about 10 students who are either in the applied statistics master's degree program or who are undergraduates majoring in mathematics with a statistics concentration. Originally, two quarters (20 weeks) of probability and statistics formed the prerequisite, and the course covered much of Chapters 1-4, 6, 7, 10, 11, and 13, with Chapters 3 and 4 being primarily review material. Currently, students enter with two additional quarters in applied linear models, including regression, analysis of variance, and methods of multiple comparisons, and the course covers Chapters 1 and 2, Sections 3.2, 6.7, and 7.5, Chapters 10, 11, and 13, Sections 15.1-15.2, and perhaps Chapter 16. As at OSU, both of these syllabi are ambitious. During the second half of the course, the students plan, run, and analyze their own experiments, working in groups of one to three. The students provide written and oral reports on the projects, and the discussions during the oral reports are of mutual enjoyment and benefit. A leisurely topics course has also been offered as a sequel, covering the rest of Chapters 14-17.

At Kenyon College, classes meet for three hours a week for 15 weeks. A typical class is composed of about 10 junior and senior undergraduates majoring in various fields. The syllabus covers Chapters 1-7, 10, and 17.

For some areas of application, random effects, nested models, and split-plot designs, which are covered in Chapters 17-19, are important topics. It is possible to design a syllabus that reaches these chapters fairly rapidly by covering Chapters 1-4, 6, 7, 17, 18, 10, 19.

We owe a debt of gratitude to many. For reading of, and comments on, prior drafts, we thank Bradley Hartlaub, Jeffrey Nunemacher, Mark Irwin, an anonymous reviewer, and the many students who suffered through the early drafts. We thank Baoshe An, James Clark, and Dionne Pratt for checking a large number of exercises, and Paul Burte, Kathryn Collins, Yuming Deng, Joseph Mesaros, Dionne Pratt, Joseph Whitmore, and many others for catching numerous typing errors. We are grateful to Peg Steigerwald, Terry England, Dolores Wills, Jill McClane, and Brian J. Williams for supplying hours of typing skills. We extend our thanks to all the many students in classes at The Ohio State University, Wright State University, and the University of Wisconsin at Madison whose imagination and diligence produced so many wonderful experiments; also to Brian H. Williams and Bob Wardrop for supplying data sets; to Nathan Buurma, Colleen Brensinger, and James Colton for library searches; and to the publishers and journal editors who gave us permission to use data and descriptions of experiments. We are especially grateful to the SAS Institute for permission to reproduce portions of SAS programs and corresponding output, and to John Kimmel for his enduring patience and encouragement throughout this endeavor.

This book has been ten years in the making. In the view of the authors, it is "a work in progress temporarily cast in stone"--or in print, as it were. We are wholly responsible for any errors and omissions, and we would be most grateful for comments, corrections, and suggestions from readers so that we can improve any future editions.

Finally, we extend our love and gratitude to Jeff, Nancy, Tommy, and Jimmy, often neglected during this endeavor, for their enduring patience, love, and support.

Columbus, Ohio

Dayton, Ohio

Angela Dean Daniel Voss

###### Contents

* 1 Principles and Techniques
	* 1.1 Design: Basic Principles and Techniques
		* 1.1.1 The Art of Experimentation
		* 1.1.2 Replication
		* 1.1.3 Blocking
		* 1.1.4 Randomization
	* 1.2 Analysis: Basic Principles and Techniques
* 2 Planning Experiments
	* 2.1 Introduction
	* 2.2 A Checklist for Planning Experiments
	* 2.3 A Real Experiment--Cotton-Spinning Experiment
	* 2.4 Some Standard Experimental Designs
		* 2.4.1 Completely Randomized Designs
		* 2.4.2 Block Designs
		* 2.4.3 Designs with Two or More Blocking Factors
		* 2.4.4 Split-Plot Designs
	* 2.5 More Real Experiments
		* 2.5.1 Soap Experiment
		* 2.5.2 Battery Experiment
		* 2.5.3 Cake-Baking Experiment
		* 2.5.4 Exercises
* 3 Designs with One Source of Variation
	* 3.1 Introduction
	* 3.2 Randomization
	* 3.3 Model for a Completely Randomized Design
	* 3.4 Estimation of Parameters
		* 3.4.1 Estimable Functions of Parameters
		* 3.4.2 Notation
		* 3.4.3 Obtaining Least Squares Estimates
		* 3.4.4 Properties of Least Squares Estimators
		* 3.4.5 Estimation of \(\sigma^{2}\)
		* 3.4.6 Confidence Bound for \(\sigma^{2}\)
	* 3.5 One-Way Analysis of Variance
		* 3.5.1 Testing Equality of Treatment Effects
		* 3.5.2 Use of \(p\)-Values
* 43.6 Sample Sizes * 3.6.1 Expected Mean Squares for Treatments * 3.6.2 Sample Sizes Using Power of a Test * 3.7 A Real Experiment--Soap Experiment, Continued * 3.7.1 Checklist, Continued * 3.7.2 Data Collection and Analysis * 3.7.3 Discussion by the Experimenter * 3.7.4 Further Observations by the Experimenter * 3.8 Using SAS Software * 3.8.1 Randomization * 3.8.2 Analysis of Variance * 3.8.3 Calculating Sample Size Using Power of a Test * 3.9 Using R Software * 3.9.1 Randomization * 3.9.2 Reading and Plotting Data * 3.9.3 Analysis of Variance * 3.9.4 Calculating Sample Size Using Power of a Test * Exercises * 4 Inferences for Contrasts and Treatment Means * 4.1 Introduction * 4.2 Contrasts * 4.2.1 Pairwise Comparisons * 4.2.2 Treatment Versus Control * 4.2.3 Difference of Averages * 4.2.4 Trends * 4.3 Individual Contrasts and Treatment Means * 4.3.1 Confidence Interval for a Single Contrast * 4.3.2 Confidence Interval for a Single Treatment Mean * 4.3.3 Hypothesis Test for a Single Contrast or Treatment Mean * 4.3.4 Equivalence of Tests and Confidence Intervals (Optional) * 4.4 Methods of Multiple Comparisons * 4.4.1 Multiple Confidence Intervals * 4.4.2 Bonferroni Method for Preplanned Comparisons * 4.4.3 Scheffe Method of Multiple Comparisons * 4.4.4 Tukey Method for All Pairwise Comparisons * 4.4.5 Dunnett Method for Treatment-Versus-Control Comparisons * 4.4.6 Combination of Methods * 4.4.7 Methods Not Controlling Experimentwise Error Rate * 4.5 Sample Sizes * 4.5

[MISSING_PAGE_EMPTY:7949]

[MISSING_PAGE_FAIL:15]

[MISSING_PAGE_EMPTY:7951]

	* 9.5 Treatment Contrasts and Confidence Intervals. 293
		* 9.5.1 Individual Confidence Intervals 293
		* 9.5.2 Multiple Comparisons 294
	* 9.6 Using SAS Software 296
	* 9.7 Using R Software 299
* 10 Complete Block Designs 305
	* 10.1 Introduction 305
	* 10.2 Blocks, Noise Factors or Covariates? 305
	* 10.3 Design Issues 306
		* 10.3.1 Block Sizes. 306
		* 10.3.2 Complete Block Design Definitions 307
		* 10.3.3 The Randomized Complete Block Design 308
		* 10.3.4 The General Complete Block Design 309
		* 10.3.5 How Many Observations?. 309
	* 10.4 Analysis of Randomized Complete Block Designs 310
		* 10.4.1 Model and Analysis of Variance 310
		* 10.4.2 Multiple Comparisons 313
	* 10.5 A Real Experiment--Cotton-Spinning Experiment 314
		* 10.5.1 Design Details. 315
		* 10.5.2 Sample-Size Calculation 315
		* 10.5.3 Analysis of the Cotton-Spinning Experiment. 315
	* 10.6 Analysis of General Complete Block Designs. 318
		* 10.6.1 Model and Analysis of Variance 318
		* 10.6.2 Multiple Comparisons for the General Complete Block Design 320
		* 10.6.3 Sample-Size Calculations 322
	* 10.7 Checking Model Assumptions 323
	* 10.8 Factorial Experiments 324
	* 10.9 Using SAS Software 327
* 10.10 Using R Software 331
* 10.10 Services. 336
* 11 Incomplete Block Designs 349
	* 11.1 Introduction 349
	* 11.2 Design Issues 349
		* 11.2.1 Block Sizes. 349
		* 11.2.2 Design Plans and Randomization. 350
		* 11.2.3 Estimation of Contrasts 351
	* 11.3 Some Special Incomplete Block Designs 352
		* 11.3.1 Balanced Incomplete Block Designs 354
		* 11.3.3 Cyclic Designs 356
	* 11.4 Analysis of General Incomplete Block Designs 356
		* 11.4.1 Contrast Estimators and Multiple Comparisons 356
		* 11.4.2 Analysis of Variance 358

###### Contents

		* 11.4.3 Analysis of Balanced Incomplete Block Designs.
		* 11.4.4 A Real Experiment--Dedergent Experiment.
		* 11.4.5 Analysis of Group Divisible Designs
		* 11.4.6 Analysis of Cyclic Designs
	* 11.5 A Real Experiment--Plasma Experiment
	* 11.6 Sample Sizes
	* 11.7 Factorial Experiments
		* 11.7.1 Factorial Structure
	* 11.8 Using SAS Software
		* 11.8.1 Generation of Efficient Block Designs
		* 11.8.2 Analysis of Variance, Contrasts, and Multiple Comparisons
		* 11.8.3 Plots
	* 11.9 Using R Software
		* 11.9.1 Generating Efficient Incomplete Block Designs
		* 11.9.2 Analysis of Variance, Contrasts, and Multiple Comparisons
		* 11.9.3 Plots
* 12 Designs with Two Blocking Factors
	* 12.1 Introduction
	* 12.2 Design Issues
		* 12.2.1 Selection and Randomization of Row-Column Designs
		* 12.2.2 Latin Square Designs
		* 12.2.3 Youden Designs
		* 12.2.4 Cyclic and Other Row-Column Designs
	* 12.3 Analysis of Row-Column Designs
		* 12.3.1 Model for a Row-Column Design
		* 12.3.2 Analysis of Variance for a Row-Column Design
		* 12.3.3 Confidence Intervals and Multiple Comparisons
	* 12.4 Analysis of Latin Square Designs
		* 12.4.1 Analysis of Variance for Latin Square Designs
		* 12.4.2 Confidence Intervals for Latin Square Designs
		* 12.4.3 How Many Observations?.
	* 12.5 Analysis of Youden Designs
		* 12.5.1 Analysis of Variance for Youden Designs
		* 12.5.2 Confidence Intervals for Youden Designs
		* 12.5.3 How Many Observations?.
	* 12.6 Checking the Assumptions on the Model
	* 12.7 Factorial Experiments in Row-Column Designs
* 12.8 Using SAS Software 416 12.8.1 Factorial Model 417 12.8.2 Plots 419 12.9 Using R Software 420 12.9.1 Factorial Model 423 12.9.2 Plots Exercises.
* 13 Confounded Two-Level Factorial Experiments 13.1 Introduction 433 13.2 Single Replicate Factorial Experiments 13.2.1 Coding and Notation 433 13.2.2 Confounding 434 13.2.3 Analysis 434 13.3 Confounding Using Contrasts 435 13.3.1 Contrasts 435 13.3.2 Experiments in Two Blocks 436 13.3.3 Experiments in Four Blocks 441 13.3.4 Experiments in Eight Blocks 443 13.3.5 Experiments in More Than Eight Blocks 443 13.4 Confounding Using Equations 444 13.4.1 Experiments in Two Blocks 445 13.4.2 Experiments in More Than Two Blocks 447 13.5 A Real Experiment--Mangold Experiment. 447 13.6 Plans for Confounded 2\({}^{p}\) Experiments 451 13.7 Multireplicate Designs 451 13.8 Complete Confounding: Repeated Single-Replicate Designs 452 13.8.1 A Real Experiment--Decontamination Experiment 452 13.9 Partial Confounding 455 13.10 Comparing the Multireplicate Designs 458 13.11 Using SAS Software 461 13.12 Using R Software 463 Exercises.
* 14 Confounding in General Factorial Experiments 473 14.1 Introduction 473 14.2 Confounding with Factors at Three Levels 473 14.2.1 Contrasts 473 14.2.2 Confounding Using Contrasts 474 14.2.3 Confounding Using Equations 475 14.2.4 A Real Experiment--Dye Experiment 478 14.2.5 Plans for Confounded 3\({}^{p}\) Experiments 481 14.3 Designing Using Pseudofactors 482 14.3.1 Confounding in 4\({}^{p}\) Experiments. 482 14.3.2 Confounding in 2\({}^{p}\times 4^{q}\) Experiments 483 14.4 Designing Confounded Asymmetric Experiments 483

\begin{tabular}{l l}  & 14.5 & Using SAS Software \\  & 14.6 & Using R Software \\  & 14.6 & Using R Software \\  & 15.2.1 & Half-Fractions of \(2^{p}\) Experiments; \\  & 2\({}^{p-1}\) Experiments. \\  & 15.2.2 & Resolution and Notation \\  & 15.2.3 & A Real Experiment--Soup Experiment. \\  & 15.2.4 & Quarter-Fractions of \(2^{p}\) Experiments; \\  & 2\({}^{p-2}\) Experiments. \\  & 15.2.5 & Smaller Fractions of \(2^{p}\) Experiments \\
15.3 & Fractions from Block Designs; Factors \\  & with 3 Levels \\  & 15.3.1 & One-Third Fractions of \(3^{p}\) Experiments; \\  & 3\({}^{p-1}\) Experiments. \\  & 15.3.2 & One-Ninth Fractions of \(3^{p}\) Experiments; \\  & 3\({}^{p-2}\) Experiments. \\
15.4 & Fractions from Block Designs; Other Experiments. \\  & 15.4.1 & \(2^{p}\times 4^{q}\) Experiments \\  & 15.4.2 & \(2^{p}\times 3^{q}\) Experiments \\
15.5 & Blocked Fractional Factorial Experiments. \\
15.6 & Fractions from Orthogonal Arrays \\  & 15.6.1 & \(2^{p}\) Orthogonal Arrays \\  & 15.6.2 & \(2^{p}\times 4^{q}\) Orthogonal Arrays \\  & 15.6.3 & \(3^{p}\) Orthogonal Arrays \\
15.7 & Design for the Control of Noise Variability \\  & 15.7.1 & A Real Experiment--Inclinometer \\  & Experiment. \\
15.8 & Small Screening Designs: Orthogonal Main \\  & Effect Plans \\  & 15.8.1 & Saturated Designs \\  & 15.8.2 & Supersaturated Designs. \\  & 15.8.3 & Saturated Orthogonal Main Effect Plans \\  & Plus Interactions \\  & 15.8.4 & Definitive Screening Designs \\
15.9 & Using SAS Software \\  & 15.9.1 & Fractional Factorials. \\  & 15.9.2 & Design for the Control of Noise Variability. \\  & 15.9.3 & Analysis of Small Screening Designs \\
15.10 & Using R Software \\  & 15.10.1 & Fractional Factorials. \\  & 15.10.2 & Design for the Control of Noise Variability. \\  & 15.10.3 & Analysis of Small Screening Designs \\  & 15.10.4 & Analysis of Small Screening Designs \\ \end{tabular}

Response Surface Methodology
* 16.1 Introduction
	* 16.2 First-Order Designs and Analysis
		* 16.2.1 Models.
		* 16.2.2 Standard First-Order Designs
		* 16.2.3 Least Squares Estimation
		* 16.2.4 Checking Model Assumptions.
		* 16.2.5 Analysis of Variance
		* 16.2.6 Tests for Lack of Fit
		* 16.2.7 Path of Steepest Ascent
	* 16.3 Second-Order Designs and Analysis
		* 16.3.1 Models and Designs.
		* 16.3.2 Central Composite Designs
		* 16.3.3 Generic Test for Lack of Fit of the Second-Order Model.
		* 16.3.4 Analysis of Variance for a Second-Order Model
		* 16.3.5 Canonical Analysis of a Second-Order Model
	* 16.4 Properties of Second-Order Designs: CCDs
		* 16.4.1 Rotatability
		* 16.4.2 Orthogonality
		* 16.4.3 Orthogonal Blocking
	* 16.5 A Real Experiment: Flour Production Experiment, Continued
	* 16.6 Box-Behnken Designs.
	* 16.7 Using SAS Software
		* 16.7.1 Analysis of a Standard First-Order Design
		* 16.7.2 Analysis of a Second-Order Design
	* 16.8 Using R Software
		* 16.8.1 Analysis of a Standard First-Order Design
		* 16.8.2 Analysis of a Second-Order Design
		* 16.8.3 Generating Designs
		* 16.8.4 Exercises.
* 17 Random Effects and Variance Components
	* 17.1 Introduction
	* 17.2 Some Examples
	* 17.3 One Random Effect.
		* 17.3.1 The Random-Effects One-Way Model
		* 17.3.2 Estimation of \(\sigma^{2}\)
		* 17.3.3 Estimation of \(\sigma^{2}_{T}\)
		* 17.3.4 Testing Equality of Treatment Effects
		* 17.3.5 Confidence Intervals for Variance Components
	* 17.4 Sample Sizes for an Experiment with One Random Effect
	* 17.5 Checking Assumptions on the Model

###### Contents

	* 17.6 Two or More Random Effects
		* 17.6.1 Models and Examples
		* 17.6.2 Checking Model Assumptions
		* 17.6.3 Estimation of \(\sigma^{2}\)
		* 17.6.4 Estimation of Variance Components
		* 17.6.5 Confidence Intervals for Variance Components
		* 17.6.6 Hypothesis Tests for Variance Components
		* 17.6.7 Sample Sizes
	* 17.7 Mixed Models
		* 17.7.1 Expected Mean Squares and Hypothesis Tests
		* 17.7.2 Confidence Intervals in Mixed Models
	* 17.8 Rules for Analysis of Random-Effects and Mixed Models
		* 17.8.1 Rules--Equal Sample Sizes
		* 17.8.2 Controversy (Optional)
	* 17.9 Block Designs and Random Block Effects
* 17.10 Using SAS Software
* 17.10.1 Checking Assumptions on the Model
* 17.10.2 Estimation and Hypothesis Testing
* 17.10.3 Sample Size Calculations
* 17.11 Using R Software
* 17.11.1 Checking Assumptions on the Model
* 17.11.2 Estimation and Hypothesis Testing
* 17.11.3 Sample Size Calculations
* 18 Nested Models
	* 18.1 Introduction
	* 18.2 Examples and Models
	* 18.3 Analysis of Nested Fixed Effects
		* 18.3.1 Least Squares Estimates
		* 18.3.2 Estimation of \(\sigma^{2}\)
		* 18.3.3 Confidence Intervals
		* 18.3.4 Hypothesis Testing
	* 18.4 Analysis of Nested Random Effects
		* 18.4.1 Expected Mean Squares
		* 18.4.2 Estimation of Variance Components
		* 18.4.3 Hypothesis Testing
		* 18.4.4 Some Examples.
	* 18.5 Using SAS Software
		* 18.5.1 Voltage Experiment
18.6 Using R Software 691 18.6.1 Voltage Experiment 692 18.6.2 Analysis Using Least Squares Estimates and aov. 694 18.6.3 Analysis Using Restricted Maximum Likelihood Estimation 695 Exercises.
19 **Split-Plot Designs** 703 19.1 Introduction 703 19.2 Designs and Models 703 19.3 Analysis of a Split-Plot Design with Complete Blocks 705 19.3.1 Split-Plot Analysis 706 19.3.2 Whole-Plot Analysis 707 19.3.3 Contrasts Within and Between Whole Plots 708 19.3.4 A Real Experiment--Oats Experiment 709 19.4 Split-Split-Plot Designs 711 19.5 Split-Plot Confounding 713 19.6 A Real Experiment--UAV Experiment 713 19.6.1 Analysis of Variance 715 19.6.2 Multiple Comparisons 716 19.7 A Real Experiment--Mobile Computing Field Study. 717 19.7.1 Analysis of Variance 719 19.7.2 Multiple Comparisons 721 19.7.3 Analysis as a Split-Split-Plot Design 721 19.7.4 Design Construction. 724 727 19.8 Using SAS Software 727 19.8.1 The Analysis of Variance Approach. 727 19.8.2 Simple Contrasts 732 19.8.3 The Restricted Maximum Likelihood Approach 733 19.8.4 Recovery of Inter-block Information 736 19.8.5 ReML and Unbalanced Data. 742 745 745 19.9.1 The Analysis of Variance Approach. 745 19.9.2 Simple Contrasts 746 19.9.3 The Restricted Maximum Likelihood Approach 747 19.9.4 Recovery of Inter-block Information 753 19.9.5 ReML and Unbalanced Data. 756 Exercises.
20 **Computer Experiments**. 765 20.1 Introduction 765 20.2 Models for Computer Experiments 767 20.3 Gaussian Stochastic Process Model 768

[MISSING_PAGE_EMPTY:7959]

### 1.1 Design: Basic Principles and Techniques

#### The Art of Experimentation

One of the first questions facing an experimenter is, "How many observations do I need to take?" or alternatively, "Given my limited budget, how can I gain as much information as possible?" These are not questions that can be answered in a couple of sentences. They are, however, questions that are central to the material in this book. As a first step towards obtaining an answer, the experimenter must ask further questions, such as, "What is the main purpose of running this experiment?" and "What do I hope to be able to show?"

Typically, an experiment may be run for one or more of the following reasons:

1. to determine the principal causes of variation in a measured response,
2. to find the conditions that give rise to a maximum or minimum response,
3. to compare the responses achieved at different settings of controllable variables,
4. to obtain a mathematical model in order to predict future responses.

Observations can be collected from _observational studies_ as well as from _experiments_, but only an experiment allows conclusions to be drawn about cause and effect. For example, consider the following situation:

The output from each machine on a factory floor is constantly monitored by any successful manufacturing company. Suppose that in a particular factory, the output from a particular machine is consistently of low quality. What should the managers do? They could conclude that the machine needs replacing and pay out a large sum of money for a new one. They could decide that the machine operator is at fault and dismiss him or her. They could conclude that the humidity in that part of the factory is too high and install a new air conditioning system. In other words, the machine output has been observed under the current operating conditions (an observational study), and although it has been very effective in showing the management that a problem exists, it has given them very little idea about the _cause_ of the poor quality.

It would actually be a simple matter to determine or rule out some of the potential causes. For example, the question about the operator could be answered by moving all the operators from machine to machine over several days. If the poor output follows the operator, then it is safe to conclude that the operator is the cause. If the poor output remains with the original machine, then the operator isblameless, and the machine itself or the factory humidity is the most likely cause of the poor quality. This is an "experiment." The experimenter has control over a possible cause in the difference in output quality between machines. If this particular cause is ruled out, then the experimenter can begin to vary other factors such as humidity or machine settings.

It is more efficient to examine all possible causes of variation simultaneously rather than one at a time. Fewer observations are usually needed, and one gains more information about the system being investigated. This simultaneous study is known as a "factorial experiment." In the early stages of a project, a list of all factors that conceivably could have an important effect on the response of interest is drawn up. This may yield a large number of factors to be studied, in which case special techniques are needed to gain as much information as possible from examining only a subset of possible factor settings.

The art of designing an experiment and the art of analyzing an experiment are closely intertwined and need to be studied side by side. In designing an experiment, one must take into account the analysis that will be performed. In turn, the efficiency of the analysis will depend upon the particular experimental design that is used to collect the data. Without these considerations, it is possible to invest much time, effort, and expense in the collection of data which seem relevant to the purpose at hand but which, in fact, contribute little to the research questions being asked. A guiding principle of experimental design is to "keep it simple." Interpretation and presentation of the results of experiments are generally clearer for simpler experiments.

Three basic techniques fundamental to experimental design are replication, blocking, and randomization. The first two help to increase precision in the experiment; the last is used to decrease bias. These techniques are discussed briefly below and in more detail throughout the book.

#### Replication

Replication is the repetition of experimental conditions so that the effects of interest can be estimated with greater precision and the associated variability can be estimated.

There is a difference between "replication" and "repeated measurements." For example, suppose four subjects are each assigned to a drug and a measurement is taken on each subject. The result is four independent observations on the drug. This is "replication." On the other hand, if one subject is assigned to a drug and then measured four times, the measurements are not independent. We call them "repeated measurements." The variation recorded in repeated measurements taken at the same time reflects the variation in the measurement process, while the variation recorded in repeated measurements taken over a time interval reflects the variation in the single subject's response to the drug over time. Neither reflects the variation in independent subjects' responses to the drug. We need to know about the latter variation in order to generalize any conclusion about the drug so that it is relevant to all similar subjects.

#### Blocking

A designed experiment involves the application of treatments to experimental units to assess the effects of the treatments on some response. The "experimental units," which may be subjects, materials, conditions, points in time, or some combination of these, will be variable and induce variation in the response. Such variation in experimental units may be intentional, as the experimental conditions under which an experiment is run should be representative of those to which the conclusions of the experiment are to be applied. For inferences to be broad in scope, the experimental conditions should be appropriately varied. Blocking is a technique that can often be used to control and adjust for some of the variation in experimental units.

To block an experiment is to divide, or partition, the experimental units into groups called blocks in such a way that the experimental units in each block are intended to be relatively similar, so that treatments assigned to experimental units in the same block can be compared under relatively similar experimental conditions. If blocking is done well, then comparisons of two or more treatments are made more precisely in the experiment than similar comparisons from an unblocked design. For example, in an experiment to compare the effects of two skin ointments for rash, the two treatments can be compared more precisely on two arms of the same person than on the arms of two different people. Either circumstance can be replicated, ideally using subjects randomly sampled from or at least representative of the population of interest.

#### Randomization

The purpose of randomization is to prevent systematic and personal biases from being introduced into the experiment by the experimenter. A random assignment of subjects or experimental material to treatments prior to the start of the experiment ensures that observations that are favored or adversely affected by unknown sources of variation are observations "selected in the luck of the draw" and not systematically selected.

Lack of a random assignment of experimental material or subjects leaves the experimental procedure open to _experimenter bias_. For example, a horticulturalist may assign his or her favorite variety of experimental crop to the parts of the field that look the most fertile, or a medical practitioner may assign his or her preferred drug to the patients most likely to respond well. The preferred variety or drug may then appear to give better results no matter how good or bad it actually is.

Lack of random assignment can also leave the procedure open to _systematic bias_. Consider, for example, an experiment involving drying time of three paints applied to sections of a wooden board, where each paint is to be observed four times. If no random assignment of order of observation is made, many experimenters would take the four observations on paint 1, followed by those on paint 2, followed by those on paint 3. This order might be perfectly satisfactory, but it could equally well prove to be disastrous. Observations taken over time could be affected by differences in atmospheric conditions, fatigue of the experimenter, systematic differences in the wooden board sections, etc. These could all conspire to ensure that any measurements taken during the last part of the experiment are, say, underrecorded, with the result that paint 3 appears to dry faster than the other paints when, in fact, it may be less good. The order 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3 helps to solve the problem, but it does not remove it completely (especially if the experimenter takes a break after every three observations).

There are also analytical reasons to support the use of a random assignment. It will be seen in Chaps. 3 and 4 that common forms of analysis of the data depend on the \(F\) and \(t\) distributions. It can be shown that a random assignment ensures that these distributions are the correct ones to use. The interested reader is referred to Kempthorne (1977).

To understand the meaning of randomization, consider an experiment to compare the effects on blood pressure of three exercise programs, where each program is observed four times, giving a total of 12 observations. Now, given 12 subjects, imagine making a list of all possible assignments of the 12 subjects to the three exercise programs so that 4 subjects are assigned to each program. (There are 12!/(4!4!4!), or 34,650 ways to do this.) If the assignment of subjects to programs is done in such a way that every possible assignment has the same chance of occurring, then the assignment is said to be a _completely random assignment_. Completely randomized designs, discussed in Chaps. 3-7 of this book, are randomized in this way. It is, of course, possible that a random assignment itself could lead to the order 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3. If the experimenter expressly wishes to avoid certain assignments, then a different type of design should be used. An experimenter should not look at the resulting assignment, decide that it does not look very random, and change it.

Without the aid of an objective randomizing device, it is not possible for an experimenter to make a random assignment. In fact, it is not even possible to select a single number at random. This is borne out by a study run at the University of Delaware and reported by Professor Hoerl in the _Royal Statistical Society News and Notes_ (January 1988). The study, which was run over several years, asked students to pick a number at random between 0 and 9. The numbers 3 and 7 were selected by about 40% of the students. This is twice as many as would be expected if the numbers were truly selected at random.

The most frequently used objective mechanism for achieving a random assignment in experimental design is a random number generator. A random number generator is a computer program that gives as output a very long string of digits that are integers between 0 and 9 inclusive and that have the following properties. All integers between 0 and 9 occur approximately the same number of times, as do all pairs of integers, all triples, and so on. Furthermore, there is no discernible pattern in the string of digits, and hence the name "random" numbers.

The random numbers in Appendix Table A.1 are part of a string of digits produced by a random number generator (in SAS(r) version 6.09 on a DEC Model 4000 MODEL 610 computer at Wright State University). Many experimenters and statistical consultants will have direct access to their own random number generator on a computer or calculator and will not need to use the table. The table is divided into six sections (pages), each section containing six groups of six rows and six groups of six columns. The grouping is merely a device to aid in reading the table. To use the table, a random starting place must be found. An experimenter who always starts reading the table at the same place always has the same set of digits, and these could not be regarded as random. The grouping of the digits by six rows and columns allows a random starting place to be obtained using five rolls of a fair die. For example, the five rolls giving 3, 1, 3, 5, 2 tells the experimenter to find the digit that is in Sect. 3 of the table, row group 1, column group 3, row 5, column 2. Then the digits can be read singly, or in pairs, or triples, etc. from the starting point across the rows.

The most common random number generators on computers or calculators generate \(n\)-digit real numbers between zero and one. Single digit random numbers can be obtained from an \(n\)-digit real number by reading the first digit after the decimal point. Pairs of digits can be obtained by reading the first two digits after the decimal point, and so on. The use of random numbers for randomization is shown in Sects. 3.2, 3.8.1 and 3.9.1.

### Analysis: Basic Principles and Techniques

In the analysis of data, it is desirable to provide both graphical and statistical analyses. Plots that illustrate the relative responses of the factor settings under study allow the experimenter to gain a feel for the practical implications of the statistical results and to communicate effectively the results of the experiment to others. In addition, data plots allow the proposed model to be checked and aid in the identification of unusual observations, as discussed in Chap. 5. Statistical analysis quantifies the relative responses of the factors, thus clarifying conclusions that might be misleading or not at all apparent in plots of the data.

The purpose of an experiment can range from exploratory (discovering new important sources of variability) to confirmatory (confirming that previously discovered sources of variability are sufficiently major to warrant further study), and the philosophy of the analysis depends on the purpose of the experiment. In the early stages of experimentation the analysis may be exploratory, and one would plot and analyze the data in any way that assists in the identification of important sources of variation. Inlater stages of experimentation, analysis is usually confirmatory in nature. A mathematical model of the response is postulated and hypotheses are tested and confidence intervals are calculated.

In this book, we use _linear models_ to model our response and the _method of least squares_ for obtaining estimates of the parameters in the model. These are described in Chap. 3. We also use restricted maximum likelihood estimation of parameters in Chap. 19. Our models include random "error variables" that encompass all the sources of variability not explicitly present in the model. We operate under the assumption that the error terms are normally distributed. However, most of the procedures in this book are generally fairly robust to nonnormality, provided that there are no extreme observations among the data.

It is rare nowadays for experimental data to be analyzed by hand. Most experimenters and statisticians have access to a computer package that is capable of producing, at the very least, a basic analysis of data for the simplest experiments. To the extent possible, for each design discussed, we shall present useful plots and methods of analysis that can be obtained from most statistical software packages. We will also develop many of the mathematical formulas that lie behind the computer analysis. This will enable the reader more easily to appreciate and interpret statistical computer package output and the associated manuals. Computer packages vary in sophistication, flexibility, and the statistical knowledge required of the user. The SAS software (see SAS Institute Inc., 2004) is one of the better commercial statistical packages for analyzing experimental data. The R software (see R Core Team, 2017) is a command line software for statistical computing and graphics which is freely available on the web. Both packages can handle every model discussed in this book, and although they require some knowledge of experimental design on the part of the user, neither is difficult to learn. We provide some basic SAS and R statements and resulting output at the end of most chapters to illustrate data analysis. A reader who wishes to use a different computer package can run the equivalent analyses on his or her own package and compare the output with those shown. It is important that every user know exactly the capabilities of his or her own package and also the likely size of rounding errors.

It is not our intent to teach the best use of SAS and R software, and readers may find better ways of achieving the same analyses. SAS software, being a commercial package, requires purchase of a license, but many universities and companies already have site licenses. R is a free software environment for statistical computing and graphics. Links for downloading and installing R are provided in Sect. 3.9.

### 2.1 Introduction

Although planning an experiment is an exciting process, it is extremely time-consuming. This creates a temptation to begin collecting data without giving the experimental design sufficient thought. Rarely will this approach yield data that have been collected in exactly the right way and in sufficient quantity to allow a good analysis with the required precision. This chapter gives a step by step guide to the experimental planning process. The steps are discussed in Sect. 2.2 and illustrated via real experiments in Sects. 2.3 and 2.5. Some standard experimental designs are described briefly in Sect. 2.4.

### 2.2 A Checklist for Planning Experiments

The steps in the following checklist summarize a very large number of decisions that need to be made at each stage of the experimental planning process. The steps are not independent, and at any stage, it may be necessary to go back and revise some of the decisions made at an earlier stage.

#### Checklist

1. Define the objectives of the experiment.
2. Identify all sources of variation, including: 1. treatment factors and their levels, 2. experimental units, 3. blocking factors, noise factors, and covariates.
3. Choose a rule for assigning the experimental units to the treatments.
4. Specify the measurements to be made, the experimental procedure, and the anticipated difficulties.
5. Run a pilot experiment.
6. Specify the model.
7. Outline the analysis.
8. Calculate the number of observations that need to be taken.
9. Review the above decisions. Revise, if necessary.

A short description of the decisions that need to be made at each stage of the checklist is given below. Only after all of these decisions have been made should the data be collected.

1. **Define the objectives of the experiment**. A list should be made of the precise questions that are to be addressed by the experiment. It is this list that helps to determine the decisions required at the subsequent stages of the checklist. It is advisable to list only the essential questions, since side issues will unnecessarily complicate the experiment, increasing both the cost and the likelihood of mistakes. On the other hand, questions that are inadvertently omitted may be unanswerable from the data. In compiling the list of objectives, it can often be helpful to outline the conclusions expected from the analysis of the data. The objectives may need to be refined as the remaining steps of the checklist are completed.
2. **Identify all sources of variation**. A source of variation is _anything_ that could cause an observation to have a different numerical value from another observation. Some sources of variation are minor, producing only small differences in the data. Others are major and need to be planned for in the experiment. It is good practice to make a list of every conceivable source of variation and then label each as either major or minor. Major sources of variation can be divided into two types: those that are of particular interest to the experimenter, called "treatment factors," and those that are not of interest, called "nuisance factors." (i) Treatment factors and their levels. Although the term _treatment factor_ might suggest a drug in a medical experiment, it is used to mean any substance or item whose effect on the data is to be studied. At this stage in the checklist, the treatment factors and their _levels_ should be selected. The levels are the specific types or amounts of the treatment factor that will actually be used in the experiment. For example, a treatment factor might be a drug or a chemical additive or temperature or teaching method, etc. The levels of such treatment factors might be the different amounts of the drug to be studied, different types of chemical additives to be considered, selected temperature settings in the range of interest, different teaching methods to be compared, etc. Few experiments involve more than four levels per treatment factor. If the levels of a treatment factor are quantitative (i.e., can be measured), then they are usually chosen to be equally spaced. Two levels are needed to model a linear trend, three levels for a quadratic trend, and so forth. If the response or log(response) should be well modeled by a rather simple function of the log of the factor level, then one may choose the factor levels to be equally spaced on a log scale. For convenience, treatment factor levels can be coded. For example, temperature levels 60, 70, 80\({}^{\circ}\),... might be coded as 1, 2, 3,... in the plan of the experiment, or as 0, 1, 2,... With the latter coding, level 0 does not necessarily signify the absence of the treatment factor. It is merely a label. Provided that the experimenter keeps a clear record of the original choice of levels, no information is lost by working with the codes. When an experiment involves more than one treatment factor, every observation is a measurement on some combination of levels of the various treatment factors. For example, if there are two treatment factors, temperature and pressure, whenever an observation is taken at a certain pressure, it must necessarily be taken at some temperature, and vice versa. Suppose there are four levels of temperature coded 1, 2, 3, 4 and three levels of pressure coded 1, 2, 3. Then there are twelve combinations of levels coded 11, 12,..., 43, where the first digit of each pair refers to the level of temperature and the second digit to the level of pressure. Treatment factors are often labeled \(F_{1}\), \(F_{2}\), \(F_{3}\), \(\ldots\) or \(A\), \(B\), \(C\), \(\ldots\). The combinations of their levels are called _treatment combinations_ and an experiment involving two or more treatment factors is called a _factorial experiment_.

We will use the term _treatment_ to mean a level of a treatment factor in a single factor experiment, or to mean a treatment combination in a factorial experiment.

(ii) Experimental units.

_Experimental units_ are the "material" to which the levels of the treatment factor(s) are applied. For example, in agriculture these would be individual plots of land, in medicine they would be human or animal subjects, in industry they might be batches of raw material, factory workers, etc. If an experiment has to be run over a period of time, with the observations being collected sequentially, then the times of day can also be regarded as experimental units.

Experimental units should be representative of the material and conditions to which the conclusions of the experiment will be applied. For example, the conclusions of an experiment that uses university students as experimental units may not apply to all adults in the country. The results of a chemical experiment run in an 80\({}^{\circ}\) laboratory may not apply in a 60\({}^{\circ}\) factory. Thus it is important to consider carefully the scope of the experiment in listing the objectives in step (a).

It is important to distinguish experimental units from _observational units_--namely, what is measured to obtain observations. For example, in an experiment involving the feeding of animals in a pen to assess the effects of diet on weight gain, it may be that pens of animals fed together are the experimental units while the individual animals are the observational units. In most experiments, the experimental units and observational units are one and the same. However, when there is a distinction, it is important that the data analysis reflect it. Otherwise, mistakenly treating the observational units as experimental units would give the appearance that the experiment provides more data or replication than is indeed present.

(iii) Blocking factors, noise factors, and covariates.

An important part of designing an experiment is to enable the effects of the nuisance factors to be distinguished from those of the treatment factors. There are several ways of dealing with nuisance factors, depending on their nature.

It may be desirable to limit the scope of the experiment and to fix the level of the nuisance factor. This action may necessitate a revision of the objectives listed in step (a) since the conclusions of the experiment will not be so widely applicable. Alternatively, it may be possible to hold the level of a nuisance factor constant for one group of experimental units, change it to a different fixed value for a second group, change it again for a third, and so on. Such a nuisance factor is called a _blocking factor_, and experimental units measured under the same level of the blocking factor are said to be in the same _block_ (see Chap. 10). For example, suppose that temperature was expected to have an effect on the observations in an experiment, but it was not itself a factor of interest. The entire experiment could be run at a single temperature, thus limiting the conclusions to that particular temperature. Alternatively, the experimental units could be divided into blocks with each block of units being measured at a different fixed temperature.

Even when the nuisance variation is not measured, it is still often possible to divide the experimental units into blocks of like units. For example, plots of land or times of day that are close together are more likely to be similar than those far apart. Subjects with similar characteristics are more likely to respond in similar ways to a drug than subjects with different characteristics. Observations made in the same factory are more likely to be similar than observations made in different factories.

Sometimes nuisance variation is a property of the experimental units and can be measured before the experiment takes place, (e.g., the blood pressure of a patient in a medical experiment, the I.Q. of a pupil in an educational experiment, the acidity of a plot of land in an agricultural experiment). Such a measurement is called a _covariate_ and can play a major role in the analysis (see Chap. 9). Alternatively, the experimental units can be grouped into blocks, each block having a similar value of the covariate. The covariate would then be regarded as a blocking factor. If the experimenter is interested in the variability of the response as the experimental conditions are varied, then nuisance factors are deliberately included in the experiment and not removed via blocking. Such nuisance factors are called _noise factors_, and experiments involving noise factors form the subject of _robust design_, discussed in Chap. 15.
* **Choose a rule by which to assign the experimental units to the levels of the treatment factors**. The assignment rule, or the _experimental design,_ specifies which experimental units are to be observed under which treatments. The choice of design, which may or may not involve blocking factors, depends upon all the decisions made so far in the checklist. There are several standard designs that are used often in practice, and these are introduced in Sect. 2.4. Further details and more complicated designs are discussed later in the book. The actual assignment of experimental units to treatments should be done at random, subject to restrictions imposed by the chosen design. The importance of a random assignment was discussed in Sect. 1.1.4. Methods of randomization are given in Sect. 3.2. There are some studies in which it appears to be impossible to assign the experimental units to the treatments either at random or indeed by any method. For example, if the study is to investigate the effects of smoking on cancer with human subjects as the experimental units, it is neither ethical nor possible to assign a person to smoke a given number of cigarettes per day. Such a study would therefore need to be done by observing people who have themselves chosen to be light, heavy, or nonsmokers throughout their lives. This type of study is an _observational study_ and not an experiment. Although many of the analysis techniques discussed in this book could be used for observational studies, cause and effect conclusions are not valid, and such studies will not be discussed further.
* **Specify the measurements to be made, the experimental procedure, and the anticipated difficulties**. The data (or observations) collected from an experiment are measurements of a response variable (e.g., the yield of a crop, the time taken for the occurrence of a chemical reaction, the output of a machine). The units in which the measurements are to be made should be specified, and these should reflect the objectives of the experiment. For example, if the experimenter is interested in detecting a difference of 0.5 gram in the response variable arising from two different treatments, it would not be sensible to take measurements to the nearest gram. On the other hand, it would be unnecessary to take measurements to the nearest 0.01 gram. Measurements to the nearest 0.1 gram would be sufficiently sensitive to detect the required difference, if it exists. There are usually unforeseen difficulties in collecting data, but these can often be identified by taking a few practice measurements or by running a pilot experiment (see step (e)). Listing the anticipated difficulties helps to identify sources of variation required by step (b) of the checklist, and also gives the opportunity of simplifying the experimental procedure before the experiment begins.

Precise directions should be listed as to how the measurements are to be made. This might include details of the measuring instruments to be used, the time at which the measurements are to be made, the way in which the measurements are to be recorded. It is important that everyone involved in running the experiment follow these directions exactly. It is advisable to draw up a data collection sheet that shows the order in which the observations are to be made and also the units of measurement.
* **Run a pilot experiment**. A pilot experiment is a mini experiment involving only a few observations. No conclusions are necessarily expected from such an experiment. It is run to aid in the completion of the checklist. It provides an opportunity to practice the experimental technique and to identify unsuspected problems in the data collection. If the pilot experiment is large enough, it can also help in the selection of a suitable model for the main experiment. The observed experimental error in the pilot experiment can help in the calculation of the number of observations required by the main experiment (step (h)). At this stage, steps (a)-(d) of the checklist should be reevaluated and changes made as necessary.
* **Specify the model**. The model must indicate explicitly the relationship that is believed to exist between the response variable and the major sources of variation that were identified at step (b). The techniques used in the analysis of the experimental data will depend upon the form of the model. It is important, therefore, that the model represent the true relationship reasonably accurately. The most common type of model is the linear model, which shows the response variable set equal to a linear combination of terms representing the major sources of variation plus an error term representing all the minor sources of variation taken together. A pilot experiment (step (e)) can help to show whether or not the data are reasonably well described by the model. There are two different types of treatment or block factors that need to be distinguished, since they lead to somewhat different analyses. The effect of a factor is said to be a _fixed effect_ if the factor levels have been specifically selected by the experimenter and if the experimenter is interested in comparing the effects on the response variable of these specific levels. This is the most common type of factor and is the type considered in the early chapters. A model containing only fixed-effect factors (apart from the response and error random variables) is called a _fixed-effects model_. Occasionally, however, a factor has an extremely large number of possible levels, and the levels included in the experiment are a random sample from the population of all possible levels. The effect of such a factor is said to be a _random effect_. Since the levels are not specifically chosen, the experimenter has little interest in comparing the effects on the response variable of the particular levels used in the experiment. Instead, it is the variability of the response due to the entire population of levels that is of interest. Models for which all factors are random effects are called _random-effects models_. Models for which some factors are random effects and others are fixed effects are called _mixed models_. Experiments involving random effects will be considered in Chaps. 17 and 18.
* **Outline the analysis**. The type of analysis that will be performed on the experimental data depends on the objectives determined in step (a), the design selected in step (c), and its associated model specified in step (f).

The entire analysis should be outlined (including hypotheses to be tested and confidence intervals to be calculated). The analysis not only determines the calculations at step (h), but also verifies that the design is suitable for achieving the objectives of the experiment.
2. **Calculate the number of observations needed**. At this stage in the checklist, a calculation should be done for the number of observations that are needed in order to achieve the objectives of the experiment. If too few observations are taken, then the experiment may be inconclusive. If too many are taken, then time, energy, and money are needlessly expended. Formulae for calculating the number of observations are discussed in Sects.3.6 and 4.5 for the completely randomized design, and in later chapters for more complex designs. The formulae require a knowledge of the size of the experimental variability. This is the amount of variability in the data caused by the sources of variation designated as minor in step (b) (plus those sources that were forgotten!). Estimating the size of the experimental error prior to the experiment is not easy, and it is advisable to err on the large side. Methods of estimation include the calculation of the experimental error in a pilot experiment (step (e)) and previous experience of working with similar experiments.
3. **Review the above decisions**. **Revise if necessary**. Revision is necessary when the number of observations calculated at step (h) exceeds the number that can reasonably be taken within the time or budget available. Revision must begin at step (a), since the scope of the experiment usually has to be narrowed. If revisions are not necessary, then the data collection may commence.

It should now be obvious that a considerable amount of thought needs to precede the running of an experiment. The data collection is usually the most costly and the most time-consuming part of the experimental procedure. Spending a little extra time in planning helps to ensure that the data can be used to maximum advantage. No method of analysis can save a badly designed experiment.

Although an experimental scientist well trained in the principles of design and analysis of experiments may not need to consult a statistician, it usually helps to talk over the checklist with someone not connected with the experiment. Step (a) in the checklist is often the most difficult to complete. A consulting statistician's first question to a client is usually, "Tell me _exactly_ why you are running the experiment. _Exactly_ what do you want to show?" If these questions cannot be answered, it is not sensible for the experimenter to go away, collect some data, and worry about it later. Similarly, it is essential that a consulting statistician understand reasonably well not only the purpose of the experiment but also the experimental technique. It is not helpful to tell an experimenter to run a pilot experiment that eats up most of the budget.

The experimenter needs to give clear directions concerning the experimental procedure to all persons involved in running the experiment and in collecting the data. It is also necessary to check that these directions are being followed exactly as prescribed. An amusing anecdote told by Salvadori (1980) in his book _Why Buildings Stand Up_ illustrates this point. The story concerns a quality control study of concrete. Concrete consists of cement, sand, pebbles, and water and is mixed in strictly controlled proportions in a concrete plant. It is then carried to a building site in a revolving drum on a large truck. A sample of concrete is taken from each truckload and, after seven days, is tested for compressive strength. Its strength depends partly upon the ratio of water to cement, and decreases as the proportion of water increases. The anecdote concerns a problem that occurred during construction of an airport terminal in New York. Although the concrete reaching the site before noon showed good strength, some of the concrete arriving shortly after noon did not. The supervisor investigated the most plausible causes until he decided to follow the trucks as they went from the plant to the site. He spotted a truck driver regularly stopping for beer and a sandwich at noon, and to prevent the concrete hardening, he added extra water into the drums. Thus, Salvadori concludes "the prudent engineer must not only be cautious about material properties, but be aware, most of all, of human behavior."

This applies to prudent experimenters, too! In the chapters that follow, most of the emphasis falls on the statistical analysis of well-designed experiments. It is crucial to keep in mind the ideas in these first sections while reading the rest of the book. Unfortunately, there are no nice formulae to summarize everything. Both the experimenter and the statistical consultant should use the checklist and lots of common sense!

### A Real Experiment--Cotton-Spinning Experiment

The experiment to be described was reported in the November 1953 issue of the journal _Applied Statistics_ by Robert Peake, of the British Cotton Industry Research Association. Although the experiment was run many years ago, the types of decisions involved in planning experiments have changed very little. The original report was not written in checklist form, but all of the relevant details were provided by the author in the article.

#### Checklist

1. **Define the objectives of the experiment**. At an intermediate stage of the cotton-spinning process, a strand of cotton (known as "roving") thicker than the final thread is produced. Roving is twisted just before it is wound onto a bobbin. As the degree of twist increases, so does the strength of the cotton, but unfortunately, so does the production time and hence, the cost. The twist is introduced by means of a rotary guide called a "flyer." The purpose of the experiment was twofold; first, to investigate the way in which different degrees of twist (measured in turns per inch) affected the breakage rate of the roving, and secondly, to compare the ordinary flyer with the newly devised special flyer.
2. **Identify all sources of variation**. (i) Treatment factors and their levels. There are two treatment factors, namely "type of flyer" and "degree of twist." The first treatment factor, flyer, has two levels, "ordinary" and "special." We code these as 1 and 2, respectively. The levels of the second treatment factor, twist, had to be chosen within a feasible range. A pilot experiment was run to determine this range, and four non equally spaced levels were selected, 1.63, 1.69, 1.78, and 1.90 turns per inch. Coding these levels as 1, 2, 3, and 4, there are eight possible treatment combinations, as shown in Table 2.1. The two treatment combinations 11 and 24 were omitted from the experiment, since the pilot experiment showed that these did not produce satisfactory roving. The experiment was run with the six treatment combinations 12, 13, 14, 21, 22, 23.

(ii) Experimental units.

An experimental unit consisted of the thread on the set of full bobbins in a machine on a given day. It was not possible to assign different bobbins in a machine to different treatment combinations. The bobbins needed to be fully wound, since the tension, and therefore the breakage rate, changed as the bobbin filled. It took nearly one day to wind each set of bobbins completely.

(iii) Blocking factors, noise factors, and covariates.

Apart from the treatment factors, the following sources of variation were identified: the different machines, the different operators, the experimental material (cotton), and the atmospheric conditions.

There was some discussion among the experimenters over the designation of the blocking factors. Although similar material was fed to the machines and the humidity in the factory was controlled as far as possible, it was still thought that the experimental conditions might change over time. A blocking factor representing the day of the experiment was contemplated. However, the experimenters finally decided to ignore the day-to-day variability and to include just one blocking factor, each of whose levels represented a machine with a single operator. The number of experimental units per block was limited to six to keep the experimental conditions fairly similar within a block.
* **Choose a rule by which to assign the experimental units to the treatments**.

A randomized complete block design, which is discussed in detail in Chap. 10, was selected. The six experimental units in each block were randomly assigned to the six treatment combinations. The design of the final experiment was similar to that shown in Table 2.2.
* **Specify the measurements to be made, the experimental procedure, and the anticipated difficulties**.

It was decided that a suitable measurement for comparing the effects of the treatment combinations was the number of breaks per hundred pounds of material. Since the job of machine operator included mending every break in the roving, it was easy for the operator to keep a record of every break that occurred.

The experiment was to take place in the factory during the normal routine. The major difficulties were the length of time involved for each observation, the loss of production time caused by changing the flyers, and the fact that it was not known in advance how many machines would be available for the experiment.

\begin{table}
\begin{tabular}{c c c c c}  & & \multicolumn{3}{c}{Twist} \\  & Flyer & 1.63 & 1.69 & 1.78 & 1.90 \\ Ordinary & (11) & 12 & 13 & 14 \\ Special & 21 & 22 & 23 & (24) \\ \end{tabular}
\end{table}
Table 2.1: Treatment combinations for the cotton-spinning experiment * **Run a pilot experiment**. The experimental procedure was already well known. However, a pilot experiment was run in order to identify suitable levels of the treatment factor "degree of twist" for each of the flyers; see step (b).
* **Specify the model**. The model was of the form \[\text{Breakage rate}= \text{ constant }+\text{ effect of treatment combination}+\text{ effect of block }+\text{ error }.\] Models of this form and the associated analyses are discussed in Chap. 10.
* **Outline the analysis**. The analysis was planned to compare differences in the breakage rates caused by the six flyer/twist combinations. Further, the trend in breakage rates as the degree of twist was increased was of interest for each flyer separately.
* **Calculate the number of observations that need to be taken**. The experimental variability was estimated from a previous experiment of a somewhat different nature. This allowed a calculation of the required number of blocks to be done (see Sect. 10.5.2). The calculation was based on the fact that the experimenters wished to detect a true difference in breakage rates of at least 2 breaks per 100 pounds with high probability. The calculation suggested that 56 blocks should be observed (a total of 336 observations!).
* **Review the above decisions. Revise, if necessary**. Since each block would take about a week to observe, it was decided that 56 blocks would not be possible. The experimenters decided to analyze the data after the first 13 blocks had been run. The effect of decreasing the number of observations from the number calculated is that the requirements stated in step (h) would not be met. The probability of detecting differences of 2 breaks per 100 lbs was substantially reduced.

\begin{table}
\begin{tabular}{c c c c c c c} \hline  & & & \multicolumn{4}{c}{Time order} \\  & & & 2 & 3 & 4 & 5 & 6 \\ \hline I & 22 & 12 & 14 & 21 & 13 & 23 \\ II & 21 & 14 & 12 & 13 & 22 & 23 \\ III & 23 & 21 & 14 & 12 & 13 & 22 \\ IV & 23 & 21 & 12 &... &... &... \\ \(\vdots\) & \(\vdots\) & \(\vdots\) & \(\vdots\) & \(\vdots\) & \(\vdots\) & \(\vdots\) \\ \hline \end{tabular}
\end{table}
Table 2.2: Part of the design for the cotton-spinning experiment The results from the 13 blocks are shown in Table 3, and the data from five of these are plotted in Fig. 1. The data show that there are certainly differences in blocks. For example, results in block 5 are consistently above those for block 1. The breakage rate appears to be somewhat higher for treatment combinations 12 and 13 than for 23. However, the observed differences may not be any larger than the inherent variability in the data. Therefore, it is important to subject these data to a careful statistical analysis. This will be done in Sect. 0.5.

### Some Standard Experimental Designs

An experimental design is a rule that determines the assignment of the experimental units to the treatments. Although experiments differ from each other greatly in most respects, there are some standard designs that are used frequently. These are described briefly in this section.

\begin{table}
\begin{tabular}{c c c c c c c} \hline Treatment combination & \multicolumn{6}{c}{Block number} \\  & 1 & 2 & 3 & 4 & 5 & 6 \\ \hline
12 & 6.0 & 9.7 & 7.4 & 11.5 & 17.9 & 11.9 \\
13 & 6.4 & 8.3 & 7.9 & 8.8 & 10.1 & 11.5 \\
14 & 2.3 & 3.3 & 7.3 & 10.6 & 7.9 & 5.5 \\
21 & 3.3 & 6.4 & 4.1 & 6.9 & 6.0 & 7.4 \\
22 & 3.7 & 6.4 & 8.3 & 3.3 & 7.8 & 5.9 \\
23 & 4.2 & 4.6 & 5.0 & 4.1 & 5.5 & 3.2 \\ \hline Treatment combination & \multicolumn{6}{c}{Block number} \\  & 7 & 8 & 9 & 10 & 11 & 12 & 13 \\ \hline
12 & 10.2 & 7.8 & 10.6 & 17.5 & 10.6 & 10.6 & 8.7 \\
13 & 8.7 & 9.7 & 8.3 & 9.2 & 9.2 & 10.1 & 12.4 \\
14 & 7.8 & 5.0 & 7.8 & 6.4 & 8.3 & 9.2 & 12.0 \\
21 & 6.0 & 7.3 & 7.8 & 7.4 & 7.3 & 10.1 & 7.8 \\
22 & 8.3 & 5.1 & 6.0 & 3.7 & 11.5 & 13.8 & 8.3 \\
23 & 10.1 & 4.2 & 5.1 & 4.6 & 11.5 & 5.0 & 6.4 \\ \hline \end{tabular}
\end{table}
Table 3: Data from the cotton-spinning experiment

Figure 1: A subset of the data for the cotton-spinning experiment

#### Completely Randomized Designs

A _completely randomized design_ is the name given to a design in which the experimenter assigns the experimental units to the treatments completely at random, subject only to the number of observations to be taken on each treatment. Completely randomized designs are used for experiments that involve no blocking factors. They are discussed in depth in Chaps. 3-9 and again in some of the later chapters. The mechanics of the randomization procedure are illustrated in Sect. 3.2. The statistical properties of the design are completely determined by specification of \(r_{1}\), \(r_{2}\),..., \(r_{v}\), where \(r_{i}\) denotes the number of observations on the \(i\)th treatment, \(i=1\),..., \(v\).

The model is of the form

\[\text{Response}\;=\;\text{constant}\;+\;\text{effect of treatment}\;+\;\text{error}\,.\]

Factorial experiments often have a large number of treatments. This number can even exceed the number of available experimental units, so that only a subset of the treatment combinations can be observed. Special methods of design and analysis are needed for such experiments, and these are discussed in Chap. 15.

#### Block Designs

A _block design_ is a design in which the experimenter partitions the experimental units into blocks, determines the allocation of treatments to blocks, and assigns the experimental units within each block to the treatments completely at random. Block designs are discussed in depth in Chaps. 10-14.

In the analysis of a block design, the blocks are treated as the levels of a single blocking factor even though they may be defined by a combination of levels of more than one nuisance factor. For example, the cotton-spinning experiment of Sect. 2.3 is a block design with each block corresponding to a combination of a machine and an operator. The model is of the form

\[\text{Response}\;= \;\text{constant}\;+\;\text{effect of block}\] \[+\;\text{effect of treatment}\;+\;\text{error}\,\,.\]

The simplest block design is the _complete block design_, in which each treatment is observed the same number of times in each block. Complete block designs are easy to analyze. A complete block design whose blocks contain a single observation on each treatment is called a _randomized complete block design_ or, simply, a _randomized block design_.

When the block size is smaller than the number of treatments, so that it is not possible to observe every treatment in every block, a block design is called an _incomplete block design_. The precision with which treatment effects can be compared and the methods of analysis that are applicable depend on the choice of the design. Some standard design choices, and appropriate methods of randomization, are covered in Chap. 11. Incomplete block designs for factorial experiments are discussed in Chap. 13.

#### Designs with Two or More Blocking Factors

When an experiment involves two major sources of variation that have each been designated as blocking factors, these blocking factors are said to be either _crossed_ or _nested_. The difference between these is illustrated in Table 2.4. Each experimental unit occurs at some combination of levels of the two blocking

[MISSING_PAGE_FAIL:41]

As an example, consider an experiment to compare the effects of a number of diets (the treatments) on the weight (the response variable) of piglets (the experimental units). Piglets vary in their metabolism, as do human beings. Therefore, the experimental units are extremely variable. However, some of this variability can be controlled by noting that piglets from the same litter are more likely to be similar than piglets from different litters. Also, litters from the same sow are more likely to be similar than litters from different sows. The different sows can be regarded as blocks, the litters regarded as subblocks, and the piglets as the experimental units within the subblocks. A piglet belongs only to one litter (piglets are nested within litters), and a litter belongs only to one sow (litters are nested within sows). The random assignment of piglets to diets would be done separately litter by litter in exactly the same way as for any block design.

In the industrial setting, the experimental units may be samples of some experimental material (e.g., cotton) taken from several different batches that have been obtained from several different suppliers. The samples, which are to be assigned to the treatments, are "nested within batches," and the batches are "nested within suppliers." The random assignment of samples to treatment factor levels is done separately batch by batch.

In an ordinary block design, the experimental units can be thought of as being nested within blocks. In the above two examples, an extra "layer" of nesting is apparent. Experimental units are nested within subblocks, subblocks are nested within blocks. The subblocks can be assigned at random to the levels of a further treatment factor. When this is done, the design is often known as a _split-plot design_ (see Sect. 2.4.4).

#### Split-Plot Designs

A _split-plot design_ is a design with at least one blocking factor where the experimental units within each block are assigned to the treatment factor levels as usual, and _in addition,_ the blocks are assigned at random to the levels of a further treatment factor. This type of design is used when the levels of one (or more) treatment factors are easy to change, while the alteration of levels of other treatment factors are costly, or time-consuming. For example, this type of situation occurred in the cotton-spinning experiment of Sect. 2.3. Setting the degree of twist involved little more than a turn of a dial, but changing the flyers involved stripping down the machines. The experiment was, in fact, run as a randomized complete block design, as shown in Table 2.2. However, it could have been run as a split-plot design, as shown in Table 2.6. The time slots have been grouped into blocks, which have been assigned at random to the two flyers. The three experimental units within each cell have been assigned at random to degrees of twist.

\begin{table}
\begin{tabular}{c c c c c c c} \hline Machine with operator & & & Days & & & \\  & 1 & 2 & 3 & 4 & 5 & 6 \\ \hline
1 & 12 & 13 & 14 & 21 & 22 & 23 \\
2 & 13 & 14 & 21 & 22 & 23 & 12 \\
3 & 14 & 21 & 22 & 23 & 12 & 13 \\
4 & 22 & 23 & 12 & 13 & 14 & 21 \\
5 & 23 & 12 & 13 & 14 & 21 & 22 \\
6 & 21 & 22 & 23 & 12 & 13 & 14 \\ \hline \end{tabular}
\end{table}
Table 2.5: A Latin square for the cotton-spinning experiment Split-plot designs also occur in medical and psychological experiments. For example, suppose that several subjects are assigned at random to the levels of a drug. In each time-slot each subject is asked to perform one of a number of tasks, and some response variable is measured. The subjects can be regarded as blocks, and the time-slots for each subject can be regarded as experimental units within the blocks. The blocks and the experimental units are each assigned to the levels of the treatment factors--the subject to drugs and the time-slots to tasks. Split-plot designs are discussed in detail in Chap. 19.

In a split-plot design, the effect of a treatment factor whose levels are assigned to the experimental units is generally estimated more precisely than a treatment factor whose levels are assigned to the blocks. It was this reason that led the experimenters of the cotton-spinning experiment to select the randomized complete block design in Table 2 rather than the split-plot design of Table 6. They preferred to take the extra time in running the experiment rather than risk losing precision in the comparison of the flyers.

### More Real Experiments

Three experiments are described in this section. The first, called the "soap experiment," was run as a class project by Suyapa Silvia in 1985. The second, called the "battery experiment," was run by one of the authors. Both of these experiments are designed as completely randomized designs. The first has one treatment factor at three levels while the second has two treatment factors, each at two levels. The soap and battery experiments are included here to illustrate the large number of decisions that need to be made in running even the simplest investigations. Their data are used in Chaps. 3-5 to illustrate methods of analysis. The third experiment, called the "cake-baking experiment," includes some of the more complicated features of the designs discussed in Sect. 4.

#### Soap Experiment

The checklist for this experiment has been obtained from the experimenter's report. Our comments are in parentheses. The reader is invited to critically appraise the decisions made by this experimenter and to devise alternative ways of running her experiment.

\begin{table}
\begin{tabular}{c c c c c c c} \hline \hline  & & \multicolumn{4}{c}{Time order} \\  & 1 & 2 & 3 & 4 & 5 & 6 \\ \cline{2-7}  & & Block I & & & Block II & \\ \cline{2-7}  & & Flyer 2 & & & Flyer 1 & \\ Machine I & & Twist 2 & Twist 1 & Twist 3 & Twist 2 & Twist 4 & Twist 3 \\ \cline{2-7}  & & Flyer 2 & & & Flyer 1 & \\ Machine II & & Twist 1 & Twist 2 & Twist 3 & Twist 4 & Twist 2 & Twist 3 \\ \cline{2-7}  & & Flyer 1 & & & Flyer 2 & \\ Machine III & & Twist 4 & Twist 2 & Twist 3 & Twist 3 & Twist 1 & Twist 2 \\ ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ \\ \hline \hline \end{tabular}
\end{table}
Table 6: A split-plot design for the cotton-spinning experiment 

#### Checklist (Suyapa Silvia, 1985)

1. **Define the objectives of the experiment**. The purpose of this experiment is to compare the extent to which three particular types of soap dissolve in water. It is expected that the experiment will answer the following questions: Are there any differences in weight loss due to dissolution among the three soaps when allowed to soak in water for the same length of time? What are these differences? Generalizations to other soaps advertised to be of the same type as the three used for this experiment cannot be made, as each soap differs in terms of composition, i.e., has different mixtures of ingredients. Also, because of limited laboratory equipment, the experimental conditions imposed upon these soaps cannot be expected to mimic the usual treatment of soaps, i.e., use of friction, running water, etc. Conclusions drawn can only be discussed in terms of the conditions posed in this experiment, although they could give indications of what the results might be under more normal conditions. (We have deleted the details of the actual soaps used).
2. **Identify all sources of variation**. (i) Treatment factors and their levels The treatment factor, soap, has been chosen to have three levels: regular, deodorant, and moisturizing brands, all from the same manufacturer. The particular brands used in the experiment are of special interest to this experimenter. The soap will be purchased at local stores and cut into cubes of similar weight and size--about 1\({}^{\prime\prime}\) cubes. The cubes will be cut out of each bar of soap using a sharp hacksaw so that all sides of the cube will be smooth. They will then be weighed on a digital laboratory scale showing a precision of 10 mg. The weight of each cube will be made approximately equal to the weight of the smallest cube by carefully shaving thin slices from it. A record of the preexperimental weight of each cube will be made. (Note that the experimenter has no control over the age of the soap used in the experiment. She is assuming that the bars of soap purchased will be typical of the population of soap bars available in the stores. If this assumption is not true, then the results of the experiment will not be applicable in general. Each cube should be cut from a different bar of soap purchased from a random sample of stores in order for the experiment to be as representative as possible of the populations of soap bars.) (ii) Experimental units The experiment will be carried out using identical metal muffin pans. Water will be heated to 100\({}^{\circ}\)F (approximate hot bath temperature), and each section will be quickly filled with 1/4 cup of water. A pilot study indicated that this amount of water is enough to cover the tops of the soaps. The water-filled sections of the muffin pans are the experimental units, and these will be assigned to the different soaps as described in step (c). (iii) Blocking factors, noise factors, and covariates (Apart from the differences in the composition of the soaps themselves, the initial sizes of the cubes were not identical, and the sections of the muffin pan were not necessarily all exposed to thesame amount of heat. The initial sizes of the cubes were measured by weight. These could have been used as covariates, but the experimenter chose instead to measure the weight changes, that is, "final weight minus initial weight." The sections of the muffin pan could have been grouped into blocks with levels such as "outside sections," "inside sections," or such as "center of heating vent" and "off-center of heating vent." However, the experimenter did not feel that the experimental units would be sufficiently variable to warrant blocking. Other sources of variation include inaccuracies of measuring initial weights, final weights, amounts and temperature of water. All of these were designated as minor. No noise factors were incorporated into the experiment.)
3. **Choose a rule by which to assign the experimental units to the levels of the treatment factors**. An equal number of observations will be made on each of the three treatment factor levels. Therefore, \(r\) cubes of each type of soap will be prepared. These cubes will be randomly matched to the experimental units (muffin pan sections) using a random-number table. (This assignment rule defines a completely randomized design with \(r\) observations on each treatment factor level, see Chap. 3).
4. **Specify the measurements to be made, the experimental procedure, and the anticipated difficulties**. The cubes will be carefully placed in the water according to the assignment rule described in paragraph (c). The pans will be immediately sealed with aluminum foil in order to prevent excessive moisture loss. The pans will be positioned over a heating vent to keep the water at room temperature. Since the sections will be assigned randomly to the cubes, it is hoped that if water temperature differences do exist, these will be randomly distributed among the three treatment factor levels. After 24 hours, the contents of the pans will be inverted onto a screen and left to drain and dry for a period of 4 days in order to ensure that the water that was absorbed by each cube has been removed thoroughly. The screen will be labeled with the appropriate soap numbers to keep track of the individual soap cubes. After the cubes have dried, each will be carefully weighed. These weights will be recorded next to the corresponding preexperimental weights to study the changes, if any, that may have occurred. The analysis will be carried out on the differences between the post- and preexperimental weights.

**Expected Difficulties**

1. The length of time required for a cube of soap to dissolve noticeably may be longer than is practical or assumed. Therefore, the data may not show any differences in weights.
2. Measuring the partially dissolved cubes may be difficult with the softer soaps (e.g., moisturizing soap), since they are likely to lose their shape.
3. The drying time required may be longer than assumed and may vary with the soaps, making it difficult to know when they are completely dry.
4. The heating vent may cause the pan sections to dry out prematurely. (After the experiment was run, Suyapa made a list of the actual difficulties encountered. They are reproduced below. Although she had run a pilot experiment, it failed to alert her to these difficulties ahead of time, since not all levels of the treatment factor had been observed.)

## Difficulties Encountered

1. When the cubes were placed in the warm water, it became apparent that some soaps absorbed water very quickly compared to others, causing the tops of these cubes to become exposed eventually. Since this had not been anticipated, no additional water was added to these chambers in order to keep the experiment as designed. This created a problem, since the cubes of soap were not all completely covered with water for the 24-hour period.
2. The drying time required was also different for the regular soap compared with the other two. The regular soap was still moist, and even looked bigger, when the other two were beginning to crack and separate. This posed a real dilemma, since the loss of weight due to dissolution could not be judged unless all the water was removed from the cubes. The soaps were observed for two more days after the data was collected and the regular soap did lose part of the water it had retained.
3. When the contents of the pans were deposited on the screen, it became apparent that the dissolved portion of the soap had become a semisolid gel, and a decision had to be made to regard this as "nonusable" and not allow it to solidify along with the cubes (which did not lose their shape).

(The remainder of the checklist together with the analysis is given in Sect. 3.7. The calculations at step (h) showed that four observations should be taken on each soap type. The data were collected and are shown in Table 2.7. A plot of the data is shown in Fig. 2.2.)

The weightloss for each cube of soap measured in grams to the nearest 0.01 gm is the difference between the initial weight of the cube (pre-weight) and the weight of the same cube at the end of the experiment (post-weight). Negative values indicate a weight gain, while positive values indicate a weight loss (a large value being a greater loss). As can be seen, the regular soap cubes experienced the smallest changes in weight, and in fact, appear to have retained some of the water. Possible reasons for this will be examined in the discussion section (see Sect. 3.7.3). The data show a clear difference in the weight loss of the different soap types. This will be verified by a statistical hypothesis test (Sect. 3.7.2).

\begin{table}
\begin{tabular}{c c c c c} \hline Soap (Level) & Cube & Pre-weight (grams) & Post-weight (grams) & Weightloss (grams) \\ \hline Regular (1) & 1 & 13.14 & 13.44 & \(-\)0.30 \\  & 2 & 13.17 & 13.27 & \(-\)0.10 \\  & 3 & 13.17 & 13.31 & \(-\)0.14 \\  & 4 & 13.17 & 12.77 & 0.40 \\ Deodorant (2) & 5 & 13.03 & 10.40 & 2.63 \\  & 6 & 13.18 & 10.57 & 2.61 \\  & 7 & 13.12 & 10.71 & 2.41 \\  & 8 & 13.19 & 10.04 & 3.15 \\ Moisturizing (3) & 9 & 13.14 & 11.28 & 1.86 \\  & 10 & 13.19 & 11.16 & 2.03 \\  & 11 & 13.06 & 10.80 & 2.26 \\  & 12 & 13.00 & 11.18 & 1.82 \\ \hline \end{tabular}
\end{table}
Table 2.7: Weight loss for soaps in the soap experiment

#### Battery Experiment

##### Checklist

1. **Define the objectives of the experiment**. Due to the frequency with which his family needed to purchase flashlight batteries, one of the authors (Dan Voss) was interested in finding out which type of nonrechargeable battery was the most economical. In particular, Dan was interested in comparing the lifetime per unit cost of the particular name brand that he most often purchased with the store brand where he usually shopped. He also wanted to know whether it was worthwhile paying the extra money for alkaline batteries over heavy duty batteries. A further objective was to compare the lifetimes of the different types of battery regardless of cost. This was due to the fact that whenever there was a power cut, all the available flashlights appeared to have dead batteries! (Only the first objective will be discussed in Chaps. 3 and 4. The second objective will be addressed in Chap. 5.)
2. **Identify all sources of variation**. There are several sources of variation that are easy to identify in this experiment. Clearly, different duty batteries such as alkaline and heavy duty could well be an important factor in the lifetime per unit cost, as could the brand of the battery. These two sources of variation are the ones of most interest in the experiment and form the levels of the two treatment factors "duty" and "brand." Dan decided not to include regular duty batteries in the experiment. Other possible sources of variation include the date of manufacture of the purchased battery, and whether the lifetime was monitored under continuous running conditions or under the more usual setting with the flashlight being turned on and off, the temperature of the environment, the age and variability of the flashlight bulbs. The first of these could not be controlled in the experiment. The batteries used in the experiment were purchased at different times and in different locations in order to give a wide representation of dates of manufacture. The variability caused by this factor would be measured as part of the natural variability (error variability) in the experiment along with measurement error. Had the dates been marked on the packets, they could have been included in the analysis of the experiment as covariates. However, the dates were not available.

Figure 2: Weight loss for the soap experimentThe second of these possible sources of variation (running conditions) was fixed. All the measurements were to be made under constant running conditions. Although this did not mimic the usual operating conditions of flashlight batteries, Dan thought that the relative ordering of the different battery types in terms of life per unit cost would be the same. The continuous running setting was much easier to handle in an experiment since each observation was expected to take several hours and no sophisticated equipment was available.

The third source of variation (temperature) was also fixed. Since the family living quarters are kept at a temperature of about 68\({}^{\circ}\) in the winter, Dan decided to run his experiment at this usual temperature. Small fluctuations in temperature were not expected to be important.

The variability due to the age of the flashlight bulb was more difficult to handle. A decision had to be made whether to use a new bulb for each observation and risk muddling the effect of the battery with that of the bulb, or whether to use the same bulb throughout the experiment and risk an effect of the bulb age from biasing the data. A third possibility was to divide the observations into blocks and to use a single bulb throughout a block, but to change bulbs between blocks. Since the lifetime of a bulb is considerably longer than that of a battery, Dan decided to use the same bulb throughout the experiment.

(i) Treatment factors and their levels

There are two treatment factors each having two levels. These are battery "duty" (level 1 = alkaline, level 2 = heavy duty) and "brand" (level 1 = name brand, level 2 = store brand). This gives four treatment combinations coded 11, 12, 21, 22. In Chaps. 3-5, we will recode these treatment combinations as 1, 2, 3, 4, and we will often refer to them as the four different treatments or the four different levels of the factor "battery type." Thus, the levels of battery type are:

(ii) Experimental units

The experimental units in this experiment are the time slots. These were assigned at random to the battery types so as to determine the order in which the batteries were to be observed. Any fluctuations in temperature during the experiment form part of the variability between the time slots and are included in the error variability.

(iii) Blocking factors, noise factors, and covariates

As mentioned above, it was decided not to include a blocking factor representing different flashlight bulbs. Also, the date of manufacture of each battery was not available, and small fluctuations in room temperature were not thought to be important. Consequently, there were no covariates in the experiment, and no noise factors were incorporated.

3. **Choose a rule by which to assign the experimental units to the levels of the treatment factor**. Since there were to be no blocking factors, a completely randomized design was selected, and the time slots were assigned at random to the four different battery types.
4. **Specify the measurements to be made, the experimental procedure, and the anticipated difficulties**. The first difficulty was in deciding exactly how to measure lifetime of a flashlight battery. First, a flashlight requires two batteries. In order to keep the cost of the experiment low, Dan decided to wire a circuit linking just one battery to a flashlight bulb. Although this does not mimic the actual use of a flashlight, Dan thought that as with the constant running conditions, the relative lifetimes per unit cost of the four battery types would be preserved. Secondly, there was the difficulty in determining when the battery had run down. Each observation took several hours, and it was not possible to monitor the experiment constantly. Also, a bulb dims slowly as the battery runs down, and it is a judgment call as to when the battery is flat. Dan decided to deal with both of these problems by including a small clock in the circuit. The clock stopped before the bulb had completely dimmed, and the elapsed time on the clock was taken as a measurement of the battery life. The cost of a battery was computed as half of the cost of a two-pack, and the lifetime per unit cost was measured in minutes per dollar (min/$).
5. **Run a pilot experiment**. A few observations were run as a pilot experiment. This ensured that the circuit did indeed work properly. It was discovered that the clock and the bulb had to be wired in parallel and not in series, as Dan had first thought! The pilot experiment also gave a rough idea of the length of time each observation would take (at least four hours), and provided a very rough estimate of the error variability that was used at step (h) to calculate that four observations were needed on each treatment combination.

##### Difficulties Encountered

The only difficulty encountered in running the main experiment was that during the fourth observation, it was discovered that the clock was running but the bulb was out. This was due to a loose connection. The connection was repaired, a new battery inserted into the circuit, and the clock reset.

##### Data

The data collected in the main experiment are shown in Table 2.8 and plotted in Fig. 2.3. The experiment was run in 1993.

#### 2.5.3 Cake-Baking Experiment

The following factorial experiment was run in 1979 by the baking company Spillers Ltd. (in the U.K.) and was reported in the _Bulletin in Applied Statistics_ in 1980 by S.M. Lewis and A.M. Dean.

\begin{table}
\begin{tabular}{c c c c c} \hline Battery type & Life (min) & Unit cost (\$) & Life per unit cost & Time order \\ \hline
1 & 602 & 0.985 & 611 & 1 \\
2 & 863 & 0.935 & 923 & 2 \\
1 & 529 & 0.985 & 537 & 3 \\
4 & 235 & 0.495 & 476 & 4 \\
1 & 534 & 0.985 & 542 & 5 \\
1 & 585 & 0.985 & 593 & 6 \\
2 & 743 & 0.935 & 794 & 7 \\
3 & 232 & 0.520 & 445 & 8 \\
4 & 282 & 0.495 & 569 & 9 \\
2 & 773 & 0.935 & 827 & 10 \\
2 & 840 & 0.935 & 898 & 11 \\
3 & 255 & 0.520 & 490 & 12 \\
4 & 238 & 0.495 & 480 & 13 \\
3 & 200 & 0.520 & 384 & 14 \\
4 & 228 & 0.495 & 460 & 15 \\
3 & 215 & 0.520 & 413 & 16 \\ \hline \end{tabular}
\end{table}
Table 2.8: Data for the battery experiment

Figure 2.3: Battery life per unit cost versus battery

#### Checklist

1. **Define the objectives of the experiment**. The experimenters at Spillers, Ltd. wanted to know how "cake quality" was affected by adding different amounts of glycerine and tartaric acid to the cake mix.
2. **Identify all sources of variation**. (i) Treatment factors and their levels The two treatment factors of interest were glycerine and tartaric acid. Glycerine was called the "first treatment factor" and labeled \(F_{1}\), while tartaric acid was called the "second treatment factor" and labeled \(F_{2}\). The experimenters were very familiar with the problems of cake baking and determinations of cake quality. They knew exactly which amounts of the two treatment factors they wanted to compare. They selected four equally spaced amounts of glycerine and three equally spaced amounts of tartaric acid. These were coded as 1, 2, 3, 4 for glycerine and 1, 2, 3 for tartaric acid. Therefore, the twelve coded treatment combinations were 11, 12, 13, 21, 22, 23, 31, 32, 33, 41, 42, 43. (ii) Identify the experimental units Before the experimental units can be identified, it is necessary to think about the experimental procedure. One batch of cake-mix was divided into portions. One of the twelve treatment combinations (i.e., a certain amount of glycerine and a certain amount of tartaric acid) was added to each portion. Each portion was then thoroughly mixed and put into a container for baking. The containers were placed on a tray in an oven at a given temperature for the required length of time. The experimenters required an entire tray of cakes to make one measurement of cake quality. Only one tray would fit on any one shelf of an oven. An experimental unit was, therefore, "an oven shelf with a tray of containers of cake-mix," and these were assigned at random to the twelve treatment combinations. (iii) Blocking factors, noise factors, and covariates There were two crossed blocking factors. The first was time of day with two levels (morning and afternoon). The second was oven, which had three levels, one level for each of the three ovens that were available on the day of the experiment. Each cell (defined by oven and time of day) contained six experimental units, since an oven contained six shelves (see Table 2.9). Each set of six experimental units was assigned at random to six of the twelve treatment combinations, and it

\begin{table}
\begin{tabular}{c c c c c c c c c c c c c c} \hline \multicolumn{2}{c}{Oven codes} & \multicolumn{8}{c}{Time of day codes} \\  & & & 1 & & & & & & & & 2 & & & \\ \hline
1 & 11 & 13 & 22 & 24 & 32 & 34 & 12 & 14 & 21 & 23 & 31 & 33 \\
2 & 12 & 14 & 21 & 23 & 32 & 34 & 11 & 13 & 22 & 24 & 31 & 33 \\
3 & 12 & 14 & 22 & 24 & 31 & 33 & 11 & 13 & 21 & 23 & 32 & 34 \\ \hline \end{tabular}
\end{table}
Table 2.9: Basic design for the baking experimentwas decided in advance which six treatment combinations should be observed together in a cell (see step (c) of the checklist). Although the experimenters expected differences in the ovens and in different runs of the same oven, their experience showed that differences between the shelves of their industrial ovens were very minor. Otherwise, a third blocking factor representing oven shelf would have been needed. It was possible to control carefully the amount of cake mix put into each container, and the experimenters did not think it was necessary to monitor the precooked weight of each cake. Small differences in these weights would not affect the measurement of the quality. Therefore, no covariates were used in the analysis.
3. **Choose a rule by which to assign the experimental units to the levels of the treatment factors**. Since there were two crossed blocking factors, a row-column design with six experimental units per cell was required. It was not possible to observe every treatment combination in every cell. However, it was thought advisable to observe all twelve treatment combinations in each oven, either in the morning or the afternoon. This precaution was taken so that if one of the ovens failed on the day of the experiment, the treatment combinations could still all be observed twice each. The basic design (before randomization) that was used by Spillers is shown in Table 9. The experimental units (the trays of containers on the six oven shelves) need to be assigned at random to the 6 treatment combinations cell by cell. The oven codes need to be assigned to the actual ovens at random, and the time of day codes 1 and 2 to morning and afternoon.

## Exercises

### Exercises 1-7 refer to the list of experiments in Table 10.

1. Table 10 gives a list of experiments that can be run as class projects. Select a simple experiment of interest to you, but preferably not on the list. Complete steps (a)-(c) of the checklist with the intention of actually running the experiment when the checklist is complete.
2. For experiments 1 and 7 in Table 10, complete steps (a) and (b) of the checklist. There may be more than one treatment factor. Give precise definitions of their levels.
3. For experiment 2, complete steps (a)-(c) of the checklist.
4. For experiment 3, complete steps (a)-(c) of the checklist.
5. For experiment 4, list sources of variation. Decide which sources can be controlled by limiting the scope of the experiment or by specifying the exact experimental procedure to be followed. Of the

\begin{table}
\begin{tabular}{p{34.1pt} p{34.1pt}}
1. & Compare the growth rate of bean seeds under different watering and lighting schedules. \\
2. & Does the boiling point of water differ with different concentrations of salt? \\
3. & Compare the strengths of different brands of paper towel. \\
4. & Do different makes of popcorn give different proportions of unpopped kernels? What about cooking methods? \\
5. & Compare the effects of different locations of an observer on the speed at which subjects locate the occurrences of the letter “e” in a written passage. \\
6. & Do different colored candles burn at different speeds? \\
7. & Compare the proportions of words remembered from lists of related or unrelated words, and under various conditions such as silence and distraction. \\
8. & Compare the effects of different colors of exam paper on students’ performance in an examination. \\ \end{tabular}
\end{table}
Table 10: Some simple experimentsremaining sources of variation, decide which are minor and which are major. Are there any blocking factors in this experiment?
6. For experiment 6, specify what measurements should be made, how they should be made, and list any difficulties that might be expected.
7. For experiment 8, write down all the possible sources of variation. In your opinion, should this experiment be run as a completely randomized design, a block design, or a design with more than one blocking factor? Justify your answer.
8. Read critically through the checklists in Sect. 2.5. Would you suggest any changes? Would you have done anything differently? If you had to criticize these experiments, which points would you address?
9. The following description was given by Clifford Pugh in the 1953 volume of _Applied Statistics_. "The widespread use of detergents for domestic dish washing makes it desirable for manufacturers to carry out tests to evaluate the performance of their products. \(\ldots\) Since foaming is regarded as the main criterion of performance, the measure adopted is the number of plates washed before the foam is reduced to a thin surface layer. The five main factors which may affect the number of plates washed by a given product are (i) the concentration of detergent, (ii) the temperature of the water, (iii) the hardness of the water, (iv) the type of "soil" on the plates, and (v) the method of washing used by the operator. \(\ldots\) The difficulty of standardizing the soil is overcome by using the plates from a works canteen (cafeteria) for the test and adopting a randomized complete block technique in which plates from any one course form a block \(\ldots\) One practical limitation is the number of plates available in any one block. This permits only four \(\ldots\) tests to be completed (in a block)." Draw up steps (a)-(d) of a checklist for an experiment of the above type and give an example of a design that fits the requirements of your checklist.

## 3.1 Introduction

In working through the checklist in Chap. 2, the experimenter must choose an experimental design at step (c). A design is the rule that determines the assignment of the experimental units to treatments. The simplest possible design is the _completely randomized design_, where the experimental units are assigned to the treatments completely at random, subject to the number of observations to be taken on each treatment. Completely randomized designs involve no blocking factors.

Two ways of calculating the required number of observations (sample sizes) on each treatment are presented in Sects. 3.6 and 4.5. The first method chooses sample sizes to obtain desired powers of hypothesis tests, and the second chooses sample sizes to achieve desired lengths of confidence intervals. We sometimes refer to the list of treatments and the corresponding sample sizes as the design, with the understanding that the assignment of experimental units to treatments is to be done completely at random.

In this chapter, we discuss the random assignment procedure for the completely randomized design, we introduce the method of least squares for estimating model parameters, and we develop a procedure for testing equality of the treatment parameters. Analyses by the SAS and R software are described at the end of the chapter.

### 3.2 Randomization

In this section we provide a procedure for randomization that is very easily applied using a computer, but can equally well be done by hand. On a computer, the procedure requires the availability of software that stores data in rows and columns (like spreadsheet software, a SAS data set, or a data.frame or matrix in R), that includes a function that randomly generates real numbers between zero and one, and that includes the capacity to sort rows by the values in one column.

We use \(r_{i}\) to denote the number of observations to be taken on the \(i\)th treatment, and \(n=\Sigma r_{i}\) to denote the total number of observations (and hence the required number of experimental units). We code the treatments from 1 to \(v\) and label the experimental units 1 to \(n\).

* Enter into one column \(r_{1}\) 1's, then \(r_{2}\) 2's,..., and finally \(r_{v}\)\(v\)'s, giving a total of \(n=\Sigma r_{i}\) entries. These represent the treatment labels.
* Enter into another column \(n=\Sigma r_{i}\) random numbers, including enough digits to avoid ties. (The random numbers can be generated by a computer program or read from Table A.1).

[MISSING_PAGE_FAIL:55]

\[Y_{it}=\mu_{i}+\epsilon_{it},\ \ \ t=1,\ldots,r_{i},\ \ \ i=1,\ldots,v,\]

where \(v\) is the number of treatments and \(r_{i}\) is the number of observations to be taken on the \(i\)th treatment. An alternative way of writing this model is to replace the parameter \(\mu_{i}\) by \(\mu+\tau_{i}\), so that the model becomes

\[Y_{it}=\mu+\tau_{i}+\epsilon_{it},\ \ \ t=1,\ldots,r_{i},\ \ \ i=1,\ldots,v.\]

In this model, \(\mu\,+\,\tau_{i}\) denotes the true mean response for the \(i\)th treatment, and examination of differences between the parameters \(\mu_{i}\) in the first model is equivalent to examination of differences between the parameters \(\tau_{i}\) in the second model.

It will be seen in Sect. 3.4 that unique estimates of the parameters in the second formulation of the model cannot be obtained. Nevertheless, many experimenters prefer this model. The parameter \(\mu\) is a constant, and the parameter \(\tau_{i}\) represents the positive or negative deviation of the response from this constant when the \(i\)th treatment is observed. This deviation is called the "effect" on the response of the \(i\)th treatment.

The above models are _linear models_, that is, the response variable is written as a linear function of the parameters. Any model that is not, or cannot, be transformed into a linear model cannot be treated by the methods in this book. Linear models often provide reasonably good approximations to more complicated models, and they are used extensively in practice.

The specific forms of the distributions of the random variables in a model need to be identified before any statistical analyses can be done. The error variables represent all the minor sources of variation taken together, including all the measurement errors. In many experiments, it is reasonable to assume that the error variables are independent and that they have a normal distribution with zero mean and unknown variance \(\sigma^{2}\), which must be estimated. We call these assumptions the _error assumptions_. It will be shown in Chap. 5 that plots of the experimental data give good indications of whether or not the error assumptions are likely to be true. Proceeding with the analysis when the constant variance, normality, or independence assumptions are violated can result in a totally incorrect analysis.

A complete statement of the model for any experiment should include the list of error assumptions. Thus, for a completely randomized design with \(v\) specifically selected treatments (fixed effects), the model is

\[\begin{array}{l}Y_{it}=\mu+\tau_{i}+\epsilon_{it}\,,\\ \epsilon_{it}\sim N(0,\sigma^{2})\,,\\ \epsilon_{it}{}^{\prime}\mbox{s are mutually independent,}\\ t=1,\ldots,r_{i},\ \ \ i=1,\ldots,v,\end{array} \tag{3.3.1}\]

where "\(\sim N(0,\sigma^{2})\)" denotes "has a normal distribution with mean 0 and variance \(\sigma^{2}\)." This is sometimes called a _one-way analysis of variance model_, since the model includes only one major source of variation, namely the treatment effect, and because the standard analysis of data using this model involves a comparison of measures of variation.

Notice that it is unnecessary to specify the distribution of \(Y_{it}\) in the model, as it is possible to deduce this from the stated information. Since \(Y_{it}\) is modeled as the sum of a treatment mean \(\mu+\tau_{i}\) and a normally distributed random variable \(\epsilon_{it}\), it follows that

\[Y_{it}\sim N(\mu+\tau_{i},\sigma^{2}).\]

Also, since the \(\epsilon_{it}\)'s are mutually independent, the \(Y_{it}\)'s must also be mutually independent. Therefore, if the model is a true representation of the behavior of the response variable, then the data values \(y_{it}\) for the \(i\)th treatment form a random sample from a \(N(\mu+\tau_{i},\sigma^{2})\) distribution.

### Estimation of Parameters

#### Estimable Functions of Parameters

A function of the parameters of any linear model is said to be _estimable_ if and only if it can be written as the expected value of a linear combination of the response variables. Only estimable functions of the parameters have unique linear unbiased estimates. Since it makes no sense to work with functions that have an infinite possible number of values, it is important that the analysis of the experiment involve only the estimable functions. For the one-way analysis of variance model (3.3.1), every estimable function is of the form

\[E\left[\sum_{i}\sum_{t}a_{it}Y_{it}\right] =\sum_{i}\sum_{t}a_{it}E[Y_{it}]\] \[=\sum_{i}\sum_{t}a_{it}(\mu+\tau_{i})\ \ =\ \ \sum_{i}b_{i}(\mu+ \tau_{i})\,,\]

where \(b_{i}=\Sigma_{t}a_{it}\) and the \(a_{it}\)'s are real numbers. Any function not of this form is _nonestimable_.

Clearly, \(\mu+\tau_{1}\) is estimable, since it can be obtained by setting \(b_{1}=1\) and \(b_{2}=b_{3}=\cdots=b_{v}=0\). Similarly, each \(\mu+\tau_{i}\) is estimable. If we choose \(b_{i}=c_{i}\) where \(\sum c_{i}=0\), we see that \(\sum c_{i}\tau_{i}\) is estimable. Any such function \(\sum c_{i}\tau_{i}\) for which \(\sum_{i}c_{i}=0\) is called a _contrast_, so all contrasts are estimable in the one-way analysis of variance model. For example, setting \(b_{1}=1\), \(b_{2}=-1\), \(b_{3}=\cdots=b_{v}=0\) shows that \(\tau_{1}-\tau_{2}\) is estimable. Similarly, each \(\tau_{i}-\tau_{s}\), \(i\neq s\), is estimable. Notice that there are no values of \(b_{i}\) that give \(\mu\), \(\tau_{1}\), \(\tau_{2}\), \(\ldots\), or \(\tau_{v}\) separately as the expected value. Therefore, these parameters are not individually estimable.

#### Notation

We write the \(i\)th treatment sample mean as

\[\overline{Y}_{i.}=\frac{1}{r_{i}}\left(\sum_{t=1}^{r_{i}}Y_{it}\right)\]

and the corresponding observed sample mean as \(\overline{y}_{i.}\). The "dot" notation means "add over all values of the subscript replaced with a dot," and the "bar" means "divide by the number of terms that have been added up." This notation will be extremely useful throughout this book. For example, in the next subsection we write

\[\frac{1}{n}\sum_{i=1}^{v}\sum_{t=1}^{r_{i}}y_{it}=\frac{1}{n}\sum_{i=1}^{v}y_{i.}=\frac{1}{n}y_{..}=\overline{y}_{..},\ \text{where}\ n=\sum_{i=1}^{v}r_{i}=r.\,,\]

so that \(\overline{y}_{..}\) is the average of all of the observations. Note that if the summation applies to a subscript on two variables, the dot notation cannot be used. For example, \(\sum r_{i}\hat{\tau}_{i}\) cannot be written as \(r.\hat{\tau}.\), since \(r.\hat{\tau}\) denotes \((\sum r_{i})(\sum\hat{\tau}_{i})\). Also note that when notation involves both a sum and a square, such as \(y_{..}^{2}\) or \(\hat{y}_{l}^{2}\), the sum is taken first and then the sum is squared.

#### Obtaining Least Squares Estimates

The _method of least squares_ is used to obtain estimates and estimators for estimable functions of parameters in linear models. We shall show that the \(i\)th treatment sample mean \(\overline{Y}_{i.}\) and its observed value \(\overline{y}_{i.}\) are the "least squares estimator" and "least squares estimate," respectively, of \(\mu+\tau_{i}\). Least squares solutions for the parameters \(\mu,\,\tau_{1},\,\ldots,\tau_{v}\) are any set of corresponding values \(\hat{\mu},\,\hat{\tau}_{1},\,\ldots,\,\hat{\tau}_{v}\) that minimize the sum of squared errors

\[\sum_{i=1}^{v}\sum_{l=1}^{r_{l}}e_{it}^{2}=\sum_{i=1}^{v}\sum_{t=1}^{r_{l}}(y_{ it}-\mu-\tau_{l})^{2}. \tag{3.4.2}\]

The estimated model \(\hat{y}_{it}=\hat{\mu}+\hat{\tau}_{i}\) is the model that best fits the data in the sense of minimizing (3.4.2).

Finding least squares solutions is a standard problem in calculus.1 The sum of squared errors (3.4.2) is differentiated with respect to each of the parameters \(\mu,\,\tau_{1},\,\ldots,\,\tau_{v}\) in turn. Then each of the \(v+1\) resulting derivatives is set equal to zero, yielding a set of \(v+1\) equations. These \(v+1\) equations are called the _normal equations_. Any solution to the normal equations gives a minimum value of the sum of squared errors (3.4.2) and provides a set of least squares solutions for the parameters.

Footnote 1: Readers without a background in calculus may note that the least squares solutions for the parameters, individually, are not unique and then may skip forward to Sect. 3.4.4.

The reader is asked to verify in Exercise 6 that the normal equations for the one-way analysis of variance model (3.3.1) are those shown in (3.4.3). The first equation in (3.4.3) is obtained by setting the derivative of the sum of squared errors of (3.4.2) with respect to \(\mu\) equal to zero, and the other \(v\) equations are obtained by setting the derivatives with respect to each \(\tau_{i}\) in turn equal to zero. We put "hats" on the parameters at this stage to denote solutions. The \(v+1\) normal equations are

\[y_{\ldots}-n\hat{\mu}-\sum_{i}r_{i}\hat{\tau}_{i} = 0, \tag{3.4.3}\] \[y_{i.}-r_{i}\hat{\mu}-r_{i}\hat{\tau}_{i} = 0,\quad i=1,\ldots,\,v,\]

and include \(v+1\) unknown parameters. From the last \(v\) equations, we obtain

\[\hat{\mu}+\hat{\tau}_{i}=\overline{y}_{i.},\quad i=1,\ldots,\,v,\]

so the least squares solution for the \(i\)th treatment mean \(\mu+\tau_{i}\) is the corresponding sample mean \(\overline{y}_{i.}\).

There is a problem in solving the normal equations to obtain least squares solutions for each parameter \(\mu,\,\tau_{1},\,\ldots,\,\tau_{v}\) individually. If the last \(v\) normal equations (3.4.3) are added together, the first equation results. This means that the \(v+1\) equations are not distinct (not linearly independent). The last \(v\) normal equations _are_ distinct, since they each contain a different \(\tau_{i}\). Thus, there are exactly \(v\) distinct normal equations in \(v+1\) unknown parameters, and there is no unique solution for the parameters. This is not surprising, in view of the fact that we have already seen in Sect. 3.4.1 that these parameters are not individually estimable. For practical purposes, any one of the infinite number of solutions will be satisfactory, since they lead to identical solutions for the estimable parameters. To obtain any one of these solutions, it is necessary to add a further equation to the set of normal equations. _Any_ extra equation can be added, provided that it is not a linear combination of the equations already present. The trick is to add whichever equation will aid most in solving the entire set of equations.

One obvious possibility is to add the equation \(\hat{\mu}=0\), in which case the normal equations become

\[\hat{\mu} =0\,,\] \[y_{..}-\sum_{i}r_{i}\hat{\tau}_{i} =0\,,\] \[y_{i..}-r_{i}\hat{\tau}_{i} =0,\quad i=1,\ldots,v.\]

It is then a simple matter to solve the last \(v\) equations for the \(\hat{\tau}_{i}\)'s, yielding \(\hat{\tau}_{i}=y_{i..}/r_{i}=\overline{y}_{i..}\). Thus, one solution to the normal equations is

\[\hat{\mu} =0\,,\] \[\hat{\tau}_{i} =\overline{y}_{i..},\quad i=1,\ldots,v.\]

A more common solution is obtained by adding the extra equation \(\sum_{i}r_{i}\hat{\tau}_{i}=0\) to (3.4.3). In this case, the normal equations become

\[\sum_{i}r_{i}\hat{\tau}_{i} =0\,,\] \[y_{..}-n\hat{\mu} =0\,,\] \[y_{i..}-r_{i}\hat{\mu}-r_{i}\hat{\tau}_{i} =0,\quad i=1,\ldots,v,\]

from which we obtain the least squares solutions

\[\hat{\mu} =\overline{y}_{..}\,,\] \[\hat{\tau}_{i} =\overline{y}_{i..}-\overline{y}_{..},\quad i=1,\ldots,v.\]

Still another solution, used, for example, by the SAS software, is obtained by adding the equation \(\hat{\tau}_{v}=0\). Then the solutions to the normal equations are

\[\hat{\mu} =\overline{y}_{v..}\,,\] \[\hat{\tau}_{i} =\overline{y}_{i..}-\overline{y}_{v..},\quad i=1,\ldots,v.\]

The default solution for the R software is similar and obtained by adding the equation \(\hat{\tau}_{1}=0\). In each of the sets of solutions just obtained, it is always true that

\[\hat{\mu}+\hat{\tau}_{i}=\overline{y}_{i..}.\]

_No matter which_ extra equation is added to the normal equations, \(\overline{y}_{i..}\) will _always_ be the least squares solution for \(\mu+\tau_{i}\). Thus, although it is not possible to obtain unique least squares solutions for \(\mu\) and \(\tau_{i}\) separately, the least squares solution for the estimable true treatment mean \(\mu+\tau_{i}\)\(is\) unique. We call \(\overline{y}_{i..}\) the _least squares estimate_ and \(\overline{Y}_{i..}\) the _least squares estimator_ of \(\mu+\tau_{i}\). The notation \(\hat{\mu}+\hat{\tau}_{i}\) is used somewhat ambiguously to mean both the least squares estimator and estimate. It should be clear from the context which of these is meant.

#### Properties of Least Squares Estimators

An important property of a least squares estimator is that

the least squares estimator of any estimable function of the parameters is the unique best linear unbiased estimator.

This statement, called the _Gauss-Markov Theorem_, is true for all linear models whose error variables are independent and have common variance \(\sigma^{2}\). The theorem tells us that for the one-way analysis of variance model (3.3.1), the least squares estimator \(\sum b_{i}\overline{Y}_{i.}\) of the estimable function \(\sum b_{i}(\mu+\tau_{i})\) is unique, is unbiased and has smallest variance. The theorem also tells us that \(\tau_{i}\) cannot be estimable, since we have three different solutions for \(\tau_{i}\) and none of the corresponding estimators has expected value equal to \(\tau_{i}\).

For the one-way analysis of variance model, \(Y_{it}\) has a normal distribution with mean \(\mu+\tau_{i}\) and variance \(\sigma^{2}\) (see Sect. 3.3), so \(E[\overline{Y}_{i.}]=\mu+\tau_{i}\) and \(\text{Var}(\overline{Y}_{i.})=\sigma^{2}/r_{i}\). Therefore, the distribution of the least squares estimator \(\overline{Y}_{i.}\) of \(\mu+\tau_{i}\) is

\[\overline{Y}_{i.}\sim N(\mu+\tau_{i}\,\ \sigma^{2}/r_{i})\,.\]

The \(\overline{Y}_{i.}\)'s are independent, since they are based on different \(Y_{it}\)'s. Consequently, the distribution of the least squares estimator \(\sum c_{i}\overline{Y}_{i.}\) of the contrast \(\sum c_{i}\tau_{i}\), with \(\sum c_{i}=0\), is

\[\sum c_{i}\overline{Y}_{i.}\sim N(\Sigma c_{i}\tau_{i},\ \ \Sigma\frac{c_{i}^{2}} {r_{i}}\sigma^{2}).\]

##### 3.4.1 Heart-lung pump experiment

The following experiment was run by Richard Davis at The Ohio State University in 1987 to determine the effect of the number of revolutions per minute (rpm) of the rotary pump head of an Olson heart-lung pump on the fluid flow rate. The rpm was set directly on the tachometer of the pump console and PVC tubing of size 3/8" by 3/32" was used. The flow rate was measured in liters per minute. Five equally spaced levels of the treatment factor "rpm" were selected, namely, 50, 75, 100, 125, and 150 rpm, and these were coded as 1, 2, 3, 4, 5, respectively. The experimental design was a completely randomized design with \(r_{1}=r_{3}=r_{5}=5\), \(r_{2}=3\), and \(r_{4}=2\). The data, in the order collected, are given in Table 3.2, and the summary information is

\[\begin{array}{rll}y_{1.}=&5.676,&r_{1}=5,&\overline{y}_{1.}=1.1352,\\ y_{2.}=&5.166,&r_{2}=3,&\overline{y}_{2.}=1.7220,\\ y_{3.}=&11.634,&r_{3}=5,&\overline{y}_{3.}=2.3268,\\ y_{4.}=&5.850,&r_{4}=2,&\overline{y}_{4.}=2.9250,\\ y_{5.}=&17.646,&r_{5}=5,&\overline{y}_{5.}=3.5292.\end{array}\]

The least squares estimate of the mean fluid flow rate when the pump is operating at 150 rpm is

\[(\hat{\mu}+\hat{\tau}_{5})=\overline{y}_{5.}=3.5292\]

liters per minute. The other mean fluid flow rates are estimated in a similar way. The experimenter expected the flow rate to increase as the rpm of the pump head was increased. Figure 3.1 supports this expectation.

Since the variance of the least squares estimator \(\overline{Y}_{i.}\) of \(\mu+\tau_{i}\) is \(\sigma^{2}/r_{i}\), the first, third, and fifth treatment means are more precisely measured than the second and fourth.

The least squares estimate of the difference in fluid flow rate between 50 and 150 rpm is

\[(\hat{\tau}_{5}-\hat{\tau}_{1})=(\hat{\mu}+\hat{\tau}_{5})-(\hat{\mu}+\hat{\tau }_{1})=\overline{y}_{5.}-\overline{y}_{1.}=2.394\]

liters per minute. The associated variance is

\[\sum_{i=1}^{5}\frac{c_{i}^{2}}{r_{i}}\sigma^{2}=\left(\frac{1}{5}+\frac{1}{5} \right)\sigma^{2}=0.4\;\sigma^{2}.\]

\begin{table}
\begin{tabular}{c c c c} \hline Observation & rpm & Level & Liters/minute \\ \hline
1 & 150 & 5 & 3.540 \\ pump head of an Olson & 2 & 50 & 1 & 1.158 \\ heart–lung pump & 3 & 50 & 1 & 1.128 \\

[MISSING_PAGE_POST]

 \hline \end{tabular}
\end{table}
Table 3.2: Fluid flow obtained from the rotary pump head of an Olson heart–lung pump

Figure 3.1: Plot of data for the heart–lung pump experiment

#### Estimation of \(\sigma^{2}\)

The least squares estimates \(\hat{\mu}+\hat{\tau}_{i}=\overline{y}_{i.}\) of \(\mu+\tau_{i}\) (\(i=1,\ldots,v\)) minimize the sum of squared errors. Therefore, for the one-way analysis of variance model (3.3.1), the minimum possible value of the sum of squared errors (3.4.2), which we write as \(s\!s\!E\), is equal to

\[s\!s\!E=\sum_{i}\sum_{t}\hat{\epsilon}_{it}^{2}=\sum_{i}\sum_{t}(y_{it}-\hat{ \mu}-\hat{\tau}_{i})^{2}.\]

Here, \(\hat{\epsilon}_{it}=(y_{it}-\hat{\mu}-\hat{\tau}_{i})\) is the deviation of the \(t\)th observation on the \(i\)th treatment from the estimated \(i\)th treatment mean. This is called the (\(it\))th _residual_. Substituting the least squares estimates \(\hat{\mu}+\hat{\tau}_{i}=\overline{y}_{i.}\) into the formula for s\(\!s\!E\), we have

\[s\!s\!E=\sum_{i}\sum_{t}(y_{it}-\overline{y}_{i.})^{2}. \tag{3.4.4}\]

The minimum sum of squared errors, s\(\!s\!E\), is called the _sum of squares for error_ or the _error sum of squares_, and is used below to find an unbiased estimate of the error variance \(\sigma^{2}\). A useful computational formula for \(s\!s\!E\) is obtained by multiplying out the quantity in parentheses in (3.4.4); that is,

\[s\!s\!E=\sum_{i}\sum_{t}y_{it}^{2}-\sum_{i}r_{i}\overline{y}_{i.}^{2} \tag{3.4.5}\]

Now, the random variable \(\!SSE\) corresponding to the minimum sum of squared errors s\(\!s\!E\) in (3.4.4) is

\[SSE=\sum_{i}\sum_{t}(Y_{it}-\overline{Y}_{i.})^{2}=\sum_{i}(r_{i}-1)S_{i}^{2}\, \tag{3.4.6}\]

where \(S_{i}^{2}=\sum_{t=1}^{r_{i}}(Y_{it}-\overline{Y}_{i.})^{2}/(r_{i}-1))\) is the sample variance for the \(i\)th treatment. In Exercise 3.11, the reader is asked to verify that \(S_{i}^{2}\) is an unbiased estimator of the error variance \(\sigma^{2}\). Then, the expected value of \(SSE\) is

\[E(SSE)=\sum_{i}(r_{i}-1)E(S_{i}^{2})=(n-v)\sigma^{2}\,\]

giving an unbiased estimator of \(\sigma^{2}\) as

\[\hat{\sigma}^{2}=SSE/(n-v)=MSE. \tag{3.4.7}\]

The corresponding unbiased estimate of \(\sigma^{2}\) is the observed value of \(MSE\), namely \(ms\!E=s\!s\!E/(n-v)\). Both \(\!MSE\) and \(\!ms\!E\) are called the _mean square for error_ or _error mean square_. The estimate \(\!ms\!E\) is sometimes called the "within groups (or within treatments) variation."

#### Confidence Bound for \(\sigma^{2}\)

If an experiment were to be repeated in the future, the estimated value of \(\sigma^{2}\) obtained from the current experiment could be used at step (h) of the checklist to help calculate the number of observations that should be taken in the new experiment (see Sects. 3.6.2 and 4.5). However, the error variance in thenew experiment is unlikely to be exactly the same as that in the current experiment, and in order not to underestimate the number of observations needed, it is advisable to use a larger value of \(\sigma^{2}\) in the sample size calculation. One possibility is to use the upper limit of a one-sided confidence interval for \(\sigma^{2}\).

It can be shown that the distribution of \(SSE/\sigma^{2}\) is chi-squared with \(n-v\) degrees of freedom, denoted by \(\chi^{2}_{n-v}\). Consequently,

\[P\left(\frac{SSE}{\sigma^{2}}\geq\chi^{2}_{n-v,\,1-\alpha}\right)=1-\alpha\,, \tag{3.4.8}\]

where \(\chi^{2}_{n-v,\,1-\alpha}\) is the percentile of the chi-squared distribution with \(n-v\) degrees of freedom and with probability of \(1-\alpha\) in the right-hand tail.

Manipulating the inequalities in (3.4.8), and replacing SSE by its observed value ssE, gives a one-sided 100(\(1-\alpha\))% confidence bound for \(\sigma^{2}\) as

\[\sigma^{2}\leq\frac{ssE}{\chi^{2}_{n-v,\,1-\alpha}}\,. \tag{3.4.9}\]

This upper bound is called a 100(\(1-\alpha\))% upper confidence limit for \(\sigma^{2}\).

Example 3.4.2: Battery experiment, continued

The data of the battery experiment (Sect. 2.5.2, p. 24) are summarized in Table 3.3. The sum of squares for error is obtained from (3.4.5); that is,

\[ssE = \sum_{i}\sum_{t}y^{2}_{it}-\sum_{i}r_{i}\overline{y}^{2}_{i.}\] \[= 6,028,288-4(570.75^{2}+860.50^{2}+433.00^{2}+496.25^{2})\] \[= 28,412.5.\]

An unbiased estimate of the error variance is then obtained as

\[msE=ssE/(n-v)=28,412.5/(16-4)=2367.71\,.\]

A 95% upper confidence limit for \(\sigma^{2}\) is given by

\[\sigma^{2} \leq \frac{ssE}{\chi^{2}_{12,\,0.95}} = \frac{28,412.5}{5.23} = 5432.60\,,\]

and taking the square root of the confidence limit, a 95% upper confidence limit for \(\sigma\) is 73.71 minutes per dollar. If the experiment were to be repeated in the future, the calculation for the number of observations at step (h) of the checklist might take the largest likely value for \(\sigma\) to be around 70-75 minutes per dollar.

### One-Way Analysis of Variance

#### Testing Equality of Treatment Effects

In an experiment involving \(v\) treatments, an obvious question is whether or not the treatments differ at all in terms of their effects on the response variable. Thus one may wish to test the null hypothesis

\[H_{0}:\{\tau_{1}=\tau_{2}=\cdots=\tau_{v}\}\]

that the treatment effects are all equal against the alternative hypothesis

\[H_{A}:\{\text{at least two of the $\tau_{l}$'s differ}\}.\]

At first glance, the null hypothesis appears to involve nonestimable parameters. However, we can easily rewrite it in terms of \(v-1\) estimable contrasts, as follows:

\[H_{0}:\{\tau_{1}-\tau_{2}=0\;\;\text{and}\;\;\tau_{1}-\tau_{3}=0\;\;\text{and} \;\;\cdots\;\;\text{and}\;\;\tau_{1}-\tau_{v}=0\}.\]

This is not the only way to rewrite \(H_{0}\) in terms of estimable contrasts. For example, we could use the contrasts \(\tau_{i}-\overline{\tau}\). (where \(\overline{\tau}\). \(=\sum\tau_{i}/v\)) and write the null hypothesis as follows:

\[H_{0}:\{\tau_{1}-\overline{\tau}.=0\;\text{and}\;\;\tau_{2}-\overline{\tau}.=0 \;\;\text{and}\;\;\;\cdots\;\;\text{and}\;\;\tau_{v}-\overline{\tau}.=0\}\,.\]

Now \(\overline{\tau}\). is the average of the \(\tau_{i}\)'s, so the \(\tau_{i}-\overline{\tau}\).'s add to zero. Consequently, if \(\tau_{i}-\overline{\tau}.=0\) for \(i=1,\,\ldots,\,v-1\), then \(\tau_{v}-\overline{\tau}\). must also be zero. Thus, this form of the null hypothesis could be written in terms of just the first \(v-1\) estimable functions \(\tau_{1}-\overline{\tau}\).,..., \(\tau_{v-1}-\overline{\tau}\).

Any way that we rewrite \(H_{0}\) in terms of estimable functions of the parameters, it will always depend on \(v-1\) distinct contrasts. The number \(v-1\) is called the _treatment degrees of freedom_.

The basic idea behind an analysis of variance test is that the sum of squares for error measures how well the model fits the data. Consequently, a way of testing \(H_{0}\) is to compare the sum of squares for error under the original one-way analysis of variance model (3.3.1), known as the _full model_, with that obtained from the modified model, which assumes that the null hypothesis is true. This modified model is called the _reduced model_.

Under \(H_{0}\), the \(\tau_{l}\)'s are equal, and we can write the common value of \(\tau_{1},\,\ldots,\,\tau_{v}\) as \(\tau\). If we incorporate this into the one-way analysis of variance model, we obtain the reduced model

\begin{table}
\begin{tabular}{c c c c c} \hline Battery type & \multicolumn{3}{c}{Life per unit cost (minutes per dollar)} & \(\overline{y}_{i}\). \\ \hline
1 & 611 & 537 & 542 & 593 & 570.75 \\
2 & 923 & 794 & 827 & 898 & 860.50 \\
3 & 445 & 490 & 384 & 413 & 433.00 \\
4 & 476 & 569 & 480 & 460 & 496.25 \\ \hline \end{tabular}
\end{table}
Table 3.3: Data for the battery experiment\[Y_{it} =\mu+\tau+\epsilon_{it}^{0}\,,\] \[\epsilon_{it}^{0}\sim N(0,\sigma^{2})\,,\] \[\epsilon_{it}^{0}{}^{\prime}\text{s are mutually independent}\,,\] \[t=1,\ldots,r_{i},\quad i=1,\ldots,v\,,\]

where we write \(\epsilon_{it}^{0}\) for the \((it)\)th error variable in the reduced model. To calculate the sum of squares for error, \(ssE_{0}\), we need to determine the value of \(\mu+\tau\) that minimizes the sum of squared errors

\[\sum_{i}\sum_{t}(y_{it}-\mu-\tau)^{2}\.\]

Using calculus, the reader is asked to show in Exercise 7 that the unique least squares estimate of \(\mu+\tau\) is the sample mean of all the observations; that is, \(\hat{\mu}+\hat{\tau}=\overline{y}_{\ldots}\). Therefore, the error sum of squares for the reduced model is

\[ssE_{0} =\sum_{i}\sum_{t}(y_{it}-\overline{y}_{\ldots})^{2}\] \[=\sum_{i}\sum_{t}y_{it}^{2}-n\overline{y}_{\ldots}^{2}. \tag{3.5.10}\]

If the null hypothesis \(H_{0}:\{\tau_{1}=\tau_{i}=\cdots=\tau_{v}\}\) is false, and the treatment effects differ, the sum of squares for error \(ssE\) under the full model (3.3.1) is considerably smaller than the sum of squares for error \(ssE_{0}\) for the reduced model. This is depicted in Fig. 3.2. On the other hand, if the null hypothesis is true, then \(ssE_{0}\) and \(ssE\) will be very similar. The analysis of variance test is based on the difference \(ssE_{0}-ssE\), relative to the size of \(ssE\); that is, the test is based on \((ssE_{0}-ssE)/ssE\). We would want to reject \(H_{0}\) if this quantity is large.

We call \(ssT=ssE_{0}-ssE\) the _sum of squares for treatments_ or the _treatment sum of squares_, since its value depends on the differences between the treatment effects. Using formulas (3.5.10) and (3.4.5) for \(ssE_{0}\) and \(ssE\), the treatment sum of squares is \[ssT = ssE_{0}-ssE \tag{3.5.11}\] \[= \left(\sum_{i}\sum_{t}y_{it}^{2}-n\overline{y}_{..}^{2}\right)- \left(\sum_{i}\sum_{t}y_{it}^{2}-\sum_{i}r_{i}\overline{y}_{i.}^{2}\right)\] \[= \sum_{i}r_{i}\overline{y}_{i.}^{2}-n\overline{y}_{..}^{2}\,. \tag{3.5.12}\]

An equivalent formulation is

\[ssT=\sum_{i}r_{i}(\overline{y}_{i.}-\overline{y}_{..})^{2}\,. \tag{3.5.13}\]

The reader is invited to multiply out the parentheses in (3.5.13) and verify that (3.5.12) is obtained. There is a shortcut method of expanding (3.5.13) to obtain (3.5.12). First write down each term in \(y\) and square it. Then associate with each squared term the signs in (3.5.13). Finally, precede each term with the summations and constant outside the parentheses in (3.5.13). This quick expansion will work for all terms like (3.5.13) in this book. Formula (3.5.13) is probably the easier form of ssT to remember, while (3.5.12) is easier to manipulate for theoretical work and use for computations.

Since we will reject \(H_{0}\) if ssT/ssE is large, we need to know what "large" means. This in turn means that we need to know the distribution of the corresponding random variable SST/SSE when \(H_{0}\) is true, where

\[SST=\sum_{i}r_{i}(\overline{Y}_{i.}-\overline{Y}_{..})^{2}\quad\text{and} \quad SSE=\sum_{i}\sum_{t}(Y_{it}-\overline{Y}_{i.})^{2}\,. \tag{3.5.14}\]

Now, as mentioned in Sect. 3.4.6, it can be shown that \(SSE/\sigma^{2}\) has a chi-squared distribution with \(n-v\) degrees of freedom, denoted by \(\chi_{n-v}^{2}\). Similarly, it can be shown that when \(H_{0}\) is true, SST/\(\sigma^{2}\) has a \(\chi_{v-1}^{2}\) distribution, and that SST and SSE are independent. The ratio of two independent chi-squared random variables, each divided by their degrees of freedom, has an \(F\) distribution. Therefore, if \(H_{0}\) is true, we have

\[\frac{SST/\sigma^{2}(v-1)}{SSE/\sigma^{2}(n-v)}\sim F_{v-1,n-v}\,.\]

We now know the distribution of SST/SSE multiplied by the constant \((n-v)/(v-1)\), and we want to reject the null hypothesis \(H_{0}:\{\tau_{1}=\cdots=\tau_{v}\}\) in favor of the alternative hypothesis \(H_{A}:\{\)at least two of the treatment effects differ\(\}\) if this ratio is large. Thus, if we write msT = ssT/\((v-1)\), msE = ssE/\((n-v)\), where ssT and ssE are the observed values of the treatment sum of squares and error sum of squares, respectively, our decision rule is to

\[\text{reject }H_{0}\quad\text{if}\quad\frac{msT}{msE}>F_{v-1,n-v,\alpha}\,, \tag{3.5.15}\]

where \(F_{v-1,n-v,\alpha}\) is the critical value from the \(F\) distribution with \(v-1\) and \(n-v\) degrees of freedom with \(\alpha\) in the right-hand tail. The probability \(\alpha\) is often called the _significance level_ of the test and is the probability of rejecting \(H_{0}\) when in fact it is true (a Type I error). Thus, \(\alpha\) should be selected to be small if it is important not to make a Type I error (\(\alpha=0.01\) and \(0.001\) are typical choices); otherwise, \(\alpha\) can be chosen to be a little larger (\(\alpha=0.10\) and \(0.05\) are typical choices). Critical values \(F_{v-1,n-v,\alpha}\) for the \(F\) distribution are given in Table A.6. Due to lack of space, only a few typical values of \(\alpha\) have been tabulated.

The calculations involved in the test of the hypothesis \(H_{0}\) against \(H_{A}\) are usually written as an _analysis of variance table_ as shown in Table 4. The last line shows the _total sum of squares_ and _total degrees of freedom_. The total sum of squares, sstot, is (\(n-1\)) times the sample variance of all of the data values. Thus,

\[sstot=\sum_{i}\sum_{t}(y_{it}-\overline{y}_{..})^{2}=\sum_{i}\sum_{t}y_{it}^{2} -n\overline{y}_{..}^{2}. \tag{3.5.16}\]

From (3.5.10), we see that _sstot_ happens to be equal to \(ssE_{0}\) for the one-way analysis of variance model, and from (3.5.11) we see that

\[sstot=ssT+ssE.\]

Thus, the total sum of squares consists of a part \(ssT\) that is explained by differences between the treatment effects and a part \(ssE\) that is not explained by any of the parameters in the model.

#### _Example 3.5.1_ Battery experiment, continued

Consider the battery experiment introduced in Sect. 2.5.2, p. 24. The sum of squares for error was calculated in Example 3.4.2, p. 40, to be \(ssE=28,412.5\). The life per unit cost responses and treatment averages are given in Table 3.3, p. 41. From these, we have \(\Sigma\,\Sigma y_{it}^{2}=6,028,288\), \(\overline{y}_{..}=590.125\), and \(r_{i}=4\). Hence, the sums of squares \(ssT\) (3.5.12) and sstot (3.5.16) are

\[ssT =\sum r_{i}\overline{y}_{i..}^{2}-n\overline{y}_{..}^{2}\] \[=4(570.75^{2}+860.50^{2}+433.00^{2}+496.25^{2})-16(590.125)^{2}\] \[=427,915.25,\] \[sstot =ssE_{0}\ \ =\ \ \sum\sum y_{it}^{2}-n\overline{y}_{..}^{2}\] \[=6,028,288-16(590.125)^{2}\ \ =\ \ 456,327.75,\]

and we can verify that \(sstot=ssT+ssE\).

The decision rule for testing the null hypothesis \(H_{0}:\{\tau_{1}=\tau_{2}=\tau_{3}=\tau_{4}\}\) that the four battery types have the same average life per unit cost against the alternative hypothesis that at least two of the battery types differ, at significance level \(\alpha\), is

\[\text{reject }H_{0}\text{ if }msT/msE=60.24>F_{3,12,\alpha}.\]

\begin{table}
\begin{tabular}{l c c c c c} \hline Source of variation & Degrees of freedom & Sum of squares & Mean square & Ratio & Expected mean square \\ \hline Treatments & \(v\)-1 & \(ssT\) & \(\frac{ssT}{v-1}\) & \(\frac{msT}{msE}\) & \(\sigma^{2}+Q(\tau_{i})\) \\ Error & \(n\)-\(v\) & \(ssE\) & \(\frac{ssE}{n-v}\) & & \(\sigma^{2}\) \\ Total & \(n\)-1 & \(sstot\) & & & \\ \hline \multicolumn{6}{c}{Computational formulae} \\ \(ssT=\sum_{i}r_{i}\overline{y}_{i..}^{2}-n\overline{y}_{..}^{2}\) & & & & \\ \(sstot=\sum_{i}\sum_{t}y_{it}^{2}-n\overline{y}_{..}^{2}\) & & & & \\ \hline \(Q(\tau_{i})=\sum_{i}r_{i}(\tau_{i}-\sum_{h}r_{h}\tau_{h}/n)^{2}/(v-1)\) & & & & \\ \hline \end{tabular}
\end{table}
Table 4: One-way analysis of variance table From Table A.6, it can be seen that \(60.24>F_{3,12,\alpha}\) for any of the tabulated values of \(\alpha\). For example, if \(\alpha\) is chosen to be 0.01, then \(F_{3,12,0.01}=5.95\). Thus, for any tabulated choice of \(\alpha\), the null hypothesis is rejected, and it is concluded that at least two of the battery types differ in mean life per unit cost. In order to investigate which particular pairs of battery types differ, we would need to calculate confidence intervals. This will be done in Chap. 4. 

#### Use of _p_-Values

The _p-value_ of a test is the smallest choice of \(\alpha\) that would allow the null hypothesis to be rejected. For convenience, computer packages usually print the _p_-value as well as the ratio msT/msE. Having information about the _p_-value saves looking up \(F_{v-1,n-v,\alpha}\) in Table A.6. All we need to do is to compare the _p_-value with our selected value of \(\alpha\). Therefore, the decision rule for testing \(H_{0}:\{\tau_{1}=\cdots\tau_{v}\}\) against \(H_{A}:\{\)not all of \(\tau_{l}\)'s are equal\(\}\) can be written as

\[\text{reject }H_{0}\text{ if }p<\alpha.\]

_Example 3.5.2_ Battery experiment, continued

In the battery experiment of Example 3.5.1, the null hypothesis \(H_{0}:\{\tau_{1}=\tau_{2}=\tau_{3}=\tau_{4}\}\) that the four battery types have the same average life per unit cost was tested against the alternative hypothesis that they do not. The _p_-value generated by SAS software for the test is shown in Table 3.5 as \(p=0.0001\). A value of 0.0001 in the SAS computer output indicates that the _p_-value is less than or equal to 0.0001. Smaller values are not printed explicitly. If \(\alpha\) were chosen to be 0.01, then the null hypothesis would be rejected, since \(p<\alpha\). 

### Sample Sizes

Before an experiment can be run, it is necessary to determine the number of observations that should be taken on each treatment. This forms step (h) of the checklist in Sect. 2.2. In order to make this determination, the experimenter must first ascertain the approximate cost, in both time and money, of taking each observation and whether the cost differs for different levels of the treatment factor(s). There will probably be a fixed budget for the entire experiment. Therefore, remembering to set aside sufficient resources for the analysis of the experimental data, a rough calculation can be made of the maximum number, \(N\), of observations that can be afforded. After having worked through steps (a)-(g) of the checklist, the experimenter will have identified the objectives of the experiment and the type of analysis required. It must now be ascertained whether or not the objectives of the experiment can be achieved within the budget. The calculations at step (h) may show that it is unnecessary to take as many as \(N\) observations, in which case valuable resources can be saved. Alternatively, and unfortunately

\begin{table}
\begin{tabular}{l c c c c c} \hline Source of variation & Degrees of freedom & Sum of squares & Mean square & Ratio & _p_-value \\ \hline Type & 3 & 427,915.25 & 142,638.42 & 60.24 & 0.0001 \\ Error & 12 & 28,412.50 & 2,367.71 & & \\ Total & 15 & 456,327.75 & & & \\ \hline \end{tabular}
\end{table}
Table 3.5: One-way analysis of variance table for the battery experiment the more likely, it may be found that more than \(N\) observations are needed in order to fulfill all the experimenter's requirements of the experiment. In this case, the experimenter needs to go back and review the decisions made so far in order to try to relax some of the requirements. Otherwise, an increase in budget needs to be obtained. There is little point in running the experiment with smaller sample sizes than those required without finding out what effect this will have on the analysis. The following quotation from J. N. R. Jeffers in his article "Acid rain and tree roots: an analysis" in _The Statistical Consultant in Action_ (1987) is worth careful consideration:

There is a quite strongly held view among experimenters that statisticians always ask for more replication than can be provided, and hence jeopardize the research by suggesting that it is not worth doing unless sufficient replication can be provided. There is, of course, some truth in this allegation, and equally, some truth in the view that, unless an experiment can be done with adequate replication, and with due regard to the size of the difference which it is important to be able to detect, the research may indeed not be worth doing.

We will consider two methods of determining the number of observations on each treatment (the sample sizes). One method, which involves specifying the desired length of confidence intervals, will be presented in Sect. 4.5. The other method, which involves specifying the power required of the analysis of variance, is the topic of this section. Since the method uses the expected value of the mean square for treatments, we calculate this first.

#### Expected Mean Squares for Treatments

The formula for SST, the treatment sum of squares, was given in (3.5.14) on p. 43. Its expected value is

\[E[SST] = E[\sum r_{i}(\overline{Y}_{i.}-\overline{Y}_{.})^{2}]\] \[= E[\sum r_{i}\overline{Y}_{i.}^{2}-n\overline{Y}_{.}^{2}]\] \[= \sum r_{i}E[\overline{Y}_{i.}^{2}]-nE[\overline{Y}_{.}^{2}]\.\]

From the definition of the variance of a random variable, we know that \(\text{Var}(X)=E[X^{2}]-(E[X])^{2}\), so we can write \(E[SST]\) as

\[E[SST]=\Sigma r_{i}[\text{Var}(\overline{Y}_{i.})+(E[\overline{Y}_{i.}])^{2}] -n[\text{Var}(\overline{Y}_{.})+(E[\overline{Y}_{.}])^{2}]\,.\]

For the one-way analysis of variance model (3.3.1), the response variables \(Y_{it}\) are independent, and each has a normal distribution with mean \(\mu+\tau_{i}\) and variance \(\sigma^{2}\). So,

\[E[SST] = \sum r_{i}\left(\sigma^{2}/r_{i}+(\mu+\tau_{i})^{2}\right)\] \[-n\left(\sigma^{2}/n+\left(\mu+\sum r_{i}\tau_{i}/n\right)^{2}\right)\] \[= v\sigma^{2}+n\mu^{2}+2\mu\sum r_{i}\tau_{i}+\sum r_{i}\tau_{i}^ {2}\] \[-\sigma^{2}-n\mu^{2}-2\mu\sum r_{i}\tau_{i}-(\sum r_{i}\tau_{i})^ {2}/n\] \[= (v-1)[\sigma^{2}+Q(\tau_{i})]\,,\]where

\[Q(\tau_{i})=\Sigma_{i}r_{i}\left(\tau_{i}-\Sigma_{h}r_{h}\tau_{h}/n\right)^{2}/(v- 1)\,, \tag{3.6.17}\]

which reduces to \(Q(\tau_{i})=r\sum_{i}(\tau_{i}-\overline{\tau}.)^{2}/(v-1)\) when \(r_{1}=r_{2}=\ldots r_{v}=r\). The expected value of the mean square for treatments \(MST=SST/(v-1)\) is

\[E[MST]=\sigma^{2}+Q(\tau_{i})\,,\]

which is the quantity we listed in the analysis of variance table, Table 3.4. We note that when the treatment effects are all equal, \(Q(\tau_{i})=0\), and \(E[MST]=\sigma^{2}\).

#### Sample Sizes Using Power of a Test

Suppose that one of the major objectives of an experiment is to examine whether or not the treatments all have a similar effect on the response. The null hypothesis is actually somewhat unrealistic. The effects of the treatments are almost certainly not _exactly_ equal, and even if they were, the nuisance variability in the experimental data would mask this fact. In any case, if the different levels produce only a very small difference in the response variable, the experimenter may not be interested in discovering this fact. For example, a difference of 5 minutes in life per dollar in two different batteries would probably not be noticed by most users. However, a larger difference such as 60 minutes may well be noticed. Thus the experimenter might require \(H_{0}\) to be rejected with high probability if \(\tau_{i}-\tau_{s}>60\) minutes per dollar for some \(i\neq s\) but may not be concerned about rejecting the null hypothesis if \(\tau_{i}-\tau_{s}\leq 5\) minutes per dollar for all \(i\neq s\). In most experiments, there is some value \(\Delta\) such that if the difference in the effects of any two of the treatments exceeds \(\Delta\), the experimenter would like to reject the null hypothesis in favor of the alternative hypothesis with high probability.

The _power_ of the test at \(\Delta\), denoted by \(\pi(\Delta)\), is the probability of rejecting \(H_{0}\) when the effects of at least two of the treatments differ by \(\Delta\). The power of the test \(\pi(\Delta)\) is a function of \(\Delta\) and also of the sample sizes, the number of treatments, the significance level \(\alpha\), and the error variance \(\sigma^{2}\). Consequently, the sample sizes can be determined if \(\pi(\Delta)\), \(v\), \(\alpha\), and \(\sigma^{2}\) are known. The values of \(\Delta\), \(\pi(\Delta)\), \(v\), and \(\alpha\) are chosen by the experimenter, but the error variance has to be guessed using data from a pilot study or another similar experiment. In general, the largest likely value of \(\sigma^{2}\) should be used. If the guess for \(\sigma^{2}\) is too small, then the power of the test will be lower than the specified \(\pi(\Delta)\). If the guess for \(\sigma^{2}\) is too high, then the power will be higher than needed, and differences in the \(\tau_{i}\)'s smaller than \(\Delta\) will cause \(H_{0}\) to be rejected with high probability.

The rule for testing the null hypothesis \(H_{0}:\{\tau_{1}=\cdots=\tau_{v}\}\) against \(H_{A}\): {at least two of the \(\tau_{i}\)'s differ}, given in (3.5.15), on p. 43, is

\[\text{reject }\ H_{0}\ \ \text{if}\ \ \frac{msT}{msE}>F_{v-1,n-v,\alpha}\,.\]

As stated in Sect. 3.5.1, the test statistic MST/MSE has an \(F\) distribution if the null hypothesis is correct. But if the null hypothesis is false, then MST/MSE has a related distribution called a noncentral \(F\) distribution. The noncentral \(F\) distribution is denoted by \(F_{v-1,n-v,\delta^{2}}\), where \(\delta^{2}\) is called the _noncentrality parameter_ and is defined to be

\[\delta^{2}=(v-1)Q(\tau_{i})/\sigma^{2}\,, \tag{3.6.18}\]where \(Q(\tau_{i})\) was calculated in (3.6.17). When \(Q(\tau_{i})=0\), then \(\delta^{2}=0\), and the distribution of _MST_/_MSE_ becomes the usual \(F\)-distribution. Otherwise, \(\delta^{2}\) is greater than zero, and the mean and spread of the distribution of MST/_MSE_ are larger than those of the usual \(F\)-distribution. For equal sample sizes \(r_{1}=r_{2}=\cdots=r_{v}=r\), we see that \(\delta^{2}\) is

\[\delta^{2}=r\sum_{i}(\tau_{i}-\overline{\tau}.)^{2}/\sigma^{2}.\]

The calculation of the sample size \(r\) required to achieve a power \(\pi(\Delta)\) at \(\Delta\) for given \(v\), \(\alpha\), and \(\sigma^{2}\) rests on the fact that the hardest situation to detect is that in which the effects of two of the factor levels (say, the first and last) differ by \(\Delta\), and the others are all equal and midway between; that is,

\[\mu+\tau_{2}=\mu+\tau_{3}=\cdots=\mu+\tau_{v-1}=c\,\]

\[\mu+\tau_{1}=c+\Delta/2\,\ \ \ \text{and}\ \ \ \mu+\tau_{v}=c-\Delta/2\,\]

for some constant \(c\). In this case,

\[\delta^{2}=r\sum_{i}\frac{(\tau_{i}-\overline{\tau}.)^{2}}{\sigma^{2}}=\frac{ r\Delta^{2}}{2\sigma^{2}}. \tag{3.6.19}\]

The power of the test depends on the sample size \(r\) through the distribution of _MST_/_MSE_, which depends on \(\delta^{2}\). Since the power of the test is the probability of rejecting \(H_{0}\), we have

\[\pi(\Delta)=P\left(\frac{MST}{MSE}>F_{v-1,n-v,\alpha}\right)\.\]

The noncentral \(F\) distribution is tabulated in Table A.7, with power \(\pi\) given as a function of \(\phi=\delta/\sqrt{v}\) for various values of \(\nu_{1}=v-1\), \(\nu_{2}=n-v\), and \(\alpha\). Using (3.6.19),

\[\phi^{2}=\frac{\delta^{2}}{v}=\frac{r\Delta^{2}}{2v\sigma^{2}}\,\]

so

\[r=\frac{2v\sigma^{2}\phi^{2}}{\Delta^{2}}. \tag{3.6.20}\]

Hence, given \(\alpha\), \(\Delta\), \(v\), and \(\sigma^{2}\), the value of \(r\) can be determined from Table A.7 to achieve a specified power \(\pi(\Delta)\). The determination has to be done iteratively, since the denominator degrees of freedom, \(\nu_{2}=n-v=v(r-1)\), depend on the unknown \(r\). The procedure is as follows:

1. Find the section of Table A.7 for the numerator degrees of freedom \(\nu_{1}=v-1\) and the specified \(\alpha\) (only \(\alpha=0.05\) is shown).
2. Calculate the denominator degrees of freedom using \(\nu_{2}=1000\) in the first iteration and \(\nu_{2}=n-v=v(r-1)\) in the following iterations, and locate the appropriate row of the table, taking the smaller listed value of \(\nu_{2}\) if necessary.
3. For the required power \(\pi(\Delta)\), use interpolation to determine the corresponding value of \(\phi\), or take the larger listed value if necessary.

4. Calculate \(r=2v\sigma^{2}\phi^{2}/\Delta^{2}\), rounding up to the nearest integer. (The first iteration gives a lower bound for \(r\).)
5. Repeat steps (b)-(d) until the value of \(r\) is unchanged or alternates between two values. Select the larger of alternating values.

#### 3.6.1 Soap experiment, continued

The first part of the checklist for the soap experiment is given in Sect. 2.5.1, p. 20, and is continued in Sect. 3.7, below. At step (h), the experimenter calculated the number of observations needed on each type of soap as follows.

The error variance was estimated to be about 0.007 grams squared from the pilot experiment. In testing the hypothesis \(H_{0}:\{\tau_{1}=\tau_{2}=\tau_{3}\}\), the experimenter deemed it important to be able to detect a difference in weight loss of at least \(\Delta=0.25\,\mathrm{g}\) between any two soap types, with a probability 0.90 of correctly doing so, and a probability 0.05 of a Type I error. This difference was considered to be the smallest discrepancy in the weight loss of soaps that would be noticeable.

Using a one-way analysis of variance model, for \(v=3\) treatments, with \(\Delta=0.25\), \(r=2v\sigma^{2}\phi^{2}/\Delta^{2}=0.672\phi^{2}\), and \(\nu_{2}=v(r-1)=3(r-1)\), \(r\) was calculated as follows. Using Table 7 for \(\nu_{1}=v-1=2\), \(\alpha=0.05\), and \(\pi(\Delta)=0.90\):

\[\begin{array}{ccccc}r&\nu_{2}=3(r-1)&\phi&r=0.672\phi^{2}&\text{Action}\\ \hline&1000&2.25&3.40&\text{Round up to $r=4$}\\ 4&9&2.50&4.20&\text{Round up to $r=5$}\\ 5&12&2.50&4.20&\text{Stop, and use $r=4$ or 5$}.\\ \end{array}\]

The experimenter decided to take \(r=4\) observations on each soap type. Sections 3.8.3 and 3.9.4 show how to make these calculations using the SAS and R software, respectively. 

### A Real Experiment--Soap Experiment, Continued

The objective of the soap experiment described in Sect. 2.5.1, p. xx, was to compare the extent to which three different types of soap dissolve in water. The three soaps selected for the experiment were a regular soap, a deodorant soap, and a moisturizing soap from a single manufacturer, and the weight-loss after 24 h of soaking and 4 days drying is reproduced in Table 3.6. Steps (a)-(d) of the checklist were given in Sect. 2.5.1. The remaining steps and part of the analysis of the experimental data are described below. The first part of the description is based on the written report of the experimenter, Suyapa Silvia.

\begin{table}
\begin{tabular}{c c c c c c} \hline \hline Soap & \multicolumn{3}{c}{Weight-loss (grams)} & \multicolumn{3}{c}{\(\overline{y}_{i}\)} \\ \hline
1 & \(-0.30\) & \(-0.10\) & \(-0.14\) & \(0.40\) & \(-0.0350\) \\
2 & 2.63 & 2.61 & 2.41 & 3.15 & 2.7000 \\
3 & 1.86 & 2.03 & 2.26 & 1.82 & 1.9925 \\ \hline \hline \end{tabular}
\end{table}
Table 3.6: Data for the soap experiment 

#### Checklist, Continued

(e) **Run a pilot experiment**.

A pilot experiment was run and used for two purposes. First, it helped to identify the difficulties listed at step (d) of the checklist. Secondly, it provided an estimate of \(\sigma^{2}\) for step (h). The error variance was estimated to be about 0.007 g\({}^{2}\). The value 0.007 gm\({}^{2}\) was the value of msE in the pilot experiment. In fact, this is an underestimate, and it would have been better to have used the one-sided confidence bound (3.4.9) for \(\sigma^{2}\). (f) **Specify the model**.

Since care will be taken to control all extraneous sources of variation, it is assumed that the following model will be a reasonable approximation to the true model.

\[\begin{array}{c}Y_{it}=\mu+\tau_{i}+\epsilon_{it}\,,\\ \epsilon_{it}\sim N(0,\,\sigma^{2})\,,\\ \epsilon_{it}\prime\text{s are mutually independent}\\ i=1,2,3;\quad t=1,\ldots r_{i};\end{array}\]

where \(\tau_{i}\) is the (fixed) effect on the response of the \(i\)th soap, \(\mu\) is a constant, \(Y_{it}\) is the weight loss of the \(t\)th cube of the \(i\)th soap, and \(\epsilon_{it}\) is a random error. Before analyzing the experimental data, the assumptions concerning the distribution of the error variables will be checked using graphical methods. (Assumption checking will be discussed in Chap. 5). (g) **Outline the analysis**.

In order to address the question of differences in weights, a one-way analysis of variance will be computed at \(\alpha=0.05\) to test

\[\begin{array}{c}H_{0}:\{\tau_{1}=\tau_{2}=\tau_{3}\}\\ H_{A}:\{\text{ the effects of at least two pairs of soap types differ}\}.\end{array}\]

To find out more about the differences among pairs of treatments, 95% confidence intervals for the pairwise differences of the \(\tau_{i}\) will be calculated using Tukey's method (Tukey's method will be discussed in Sect. 4.4.4). (h) **Calculate the number of observations that need to be taken**.

Four observations will be taken on each soap type. (See Example 3.6.1, p. 49, for the calculation.) (i) **Review the above decisions. Revise if necessary**.

It is not difficult to obtain 4 observations on each of 3 soaps, and therefore the checklist does not need revising. Small adjustments to the experimental procedure that were found necessary during the pilot experiment have already been incorporated into the checklist.

#### Data Collection and Analysis

The data collected by the experimenter are plotted in Fig. 2.2, p. 24, and reproduced in Table 3.6. The assumptions that the error variables are independent and have a normal distribution with constantvariance were checked (using methods to be described in Chap. 5) and appear to be satisfied. The least squares estimates, \(\hat{\mu}+\hat{\tau}_{i}=\overline{y}_{i.}\), of the average weight loss values (in grams) are

\[\overline{y}_{1.}=-0.0350\,,\qquad\overline{y}_{2.}=2.7000\,,\qquad\overline{y} _{3.}=1.9925.\]

The hypothesis of no differences in weight loss due to the different soap types is tested below using an analysis of variance test.

Using the values \(\overline{y}_{i.}\) given above, together with \(\sum\sum y_{it}^{2}=45.7397\) and \(r_{1}=r_{2}=r_{3}=4\), the sums of squares for Soap and Total are calculated using (3.5.12) and (3.5.16), pp. 43 and 44, as

\[sST = \sum r_{i}\overline{y}_{i.}^{2}-n\overline{y}_{..}^{2}\] \[= \left[4(-0.0350)^{2}+4(2.7000)^{2}+4(1.9925)^{2}\right]-\left[12 (1.5525)^{2}\right]=16.1220\,,\] \[sstot = s\kappa E_{0}=\sum\sum y_{it}^{2}-n\overline{y}_{..}^{2}\] \[= 45.7397-12(1.5525)^{2}=16.8166.\]

The sum of squares for error can be calculated by subtraction, giving \(s\kappa E=sstot-s\kappa T=0.6946\), or directly from (3.4.5), p. 39, as

\[s\kappa E = \sum\sum y_{it}^{2}-\sum r_{i}\overline{y}_{i.}^{2}\] \[= 45.7397-\left[4(-0.0350)^{2}+4(2.7000)^{2}+4(1.9925)^{2}\right]= 0.6946\,.\]

The estimate of error variability is then

\[\hat{\sigma}^{2}=msE=s\kappa E/(n-v)=0.6945/(12-3)=0.0772\,.\]

The sums of squares and mean squares are shown in the analysis of variance table, Table 3.7. Notice that the estimate of \(\sigma^{2}\) is ten times larger than the estimate of \(0.007\,\mathrm{g}^{2}\) provided by the pilot experiment. This suggests that the pilot experiment was not sufficiently representative of the main experiment. As a consequence, the actual power of detecting a difference of \(\Delta=0.25\,\mathrm{g}\) between the weight losses of the soaps is, in fact, somewhat below the desired probability of \(0.90\).

The decision rule for testing \(H_{0}:\{\tau_{1}=\tau_{2}=\tau_{3}\}\) against the alternative hypothesis, that at least two of the soap types differ in weight loss, using a significance level of \(\alpha=0.05\), is to reject \(H_{0}\) if \(msT/msE=104.45>F_{2.9,0.05}\). From Table A.6, \(F_{2.9,0.05}=4.26\). Consequently, the null hypothesis is rejected, and it is concluded that at least two of the soap types do differ in their weight loss after \(24\,\mathrm{h}\) in water (and \(4\) days drying time). This null hypothesis would have been rejected for most practical choices of \(\alpha\). If \(\alpha\) had been chosen to be as small as \(0.005\), \(F_{2.9,\alpha}\) is still only \(10.1\). Alternatively, if the

\begin{table}
\begin{tabular}{c c c c c c} \hline Source of variation & Degrees of freedom & Sum of squares & Mean square & Ratio & \(p\)-value \\ \hline Soap & 2 & 16.1220 & 8.0610 & 104.45 & 0.0001 \\ Error & 9 & 0.6946 & 0.0772 & & \\ Total & 11 & 16.8166 & & & \\ \hline \end{tabular}
\end{table}
Table 3.7: One-way analysis of variance table for the soap experiment analysis is done by computer, the \(p\)-value would be printed in the computer output. Here the \(p\)-value is less than 0.0001, and \(H_{0}\) would be rejected for any choice of \(\alpha\) above this value.

The experimenter was interested in estimating the contrasts \(\tau_{i}-\tau_{u}\) for all \(i\neq u\), that is, she was interested in comparing the effects on weight loss of the different types of soaps. For the one-way analysis of variance model (3.3.1) and a completely randomized design, all contrasts are estimable, and the least squares estimate of \(\tau_{i}-\tau_{u}\) is

\[\hat{\tau}_{i}-\hat{\tau}_{u}=(\hat{\mu}+\hat{\tau}_{i})-(\hat{\mu}+\hat{\tau}_ {u})=\overline{y}_{i.}-\overline{y}_{u.}\,.\]

Hence, the least square estimates of the differences in the treatment effects are

\[\hat{\tau}_{2}-\hat{\tau}_{3}=0.7075\,,\hskip 14.226378pt\hat{\tau}_{2}-\hat{ \tau}_{1}=2.7350\,,\hskip 14.226378pt\hat{\tau}_{3}-\hat{\tau}_{1}=2.0275\,.\]

Confidence intervals for the differences will be evaluated in Example 4.4.5.

#### Discussion by the Experimenter

The results of this experiment were unexpected in that the soaps reacted with the water in very different ways, each according to its ingredients. An examination of the soap packages showed that for the deodorant soap and the moisturizing soap, water is listed as the third ingredient, whereas the regular soap claims to be 99.44% pure soap. Information on the chemical composition of soaps revealed that soaps are sodium and/or potassium salts of oleic, palmitic, and coconut oils and therefore in their pure form (without water) should float as the regular soap bars do. The other two soaps under discussion contain water and therefore are more dense and do not float.

One possible reason for the regular soap's actual increase in weight is that this "dry" soap absorbed and retained the water and dissolved to a lesser extent during the soaking period. The deodorant soap and the moisturizing soap, on the other hand, already contained water and did not absorb as much as the regular soap. They dissolved more easily during the soaking phase as a consequence. This is somewhat supported by the observation that the dissolved soap gel that formed extensively around the deodorant soap and the moisturizing soap did not form as much around the regular soap. Furthermore, the regular soap appeared to increase in size and remain larger, even at the end of the drying period.

#### Further Observations by the Experimenter

The soaps were weighed every day for one week after the experimental data had been collected in order to see what changes continued to occur. The regular soap eventually lost most of the water it retained, and the average loss of weight (due to dissolution) was less than that for the other two soaps.

If this study were repeated, with a drying period of at least one week, I believe that the results would indicate that regular soap loses less weight due to dissolution than either of the deodorant soap or the moisturizing soap

### Using SAS Software

#### Randomization

A simple procedure for randomizing a completely randomized design was given in Sect. 3.2, p. 31. This procedure is easily implemented using the SAS software, as we now illustrate. Consider a completely randomized design for two treatments and \(r=3\) observations on each, giving a total of \(n=6\) observations. The following SAS statements create and print a data set named DESIGN, which includes the lists of values of the two variables TRTMT and RANNO as required by steps 1 and 2 of the randomization procedure in Sect. 3.2. The statements INPUT and LINES are instructions to SAS that the values of TRTMT are being input on the lines that follow rather than from an external data file. Inclusion of "@" in the INPUT statement allows the levels of TRTMT to be entered on one line as opposed to one per line. For each treatment label entered for the variable TRTMT, a corresponding value of RANNO is generated using the SAS random number generating function RANUNI which generates uniform random numbers between 0 and 1.

 DATA DESIGN;  INPUT TRTMT @e;  RANNO=RANUNI(0);  LINES;  1 1 1 2 2 2  ;  PROC PRINT; RUN; The statement PROC PRINT then prints the following output. The column labeled OBS (observation number) is generated by the SAS software for reference.

 The SAS System  Obs TRTMT RANNO  1 1 0.74865  2 1 0.62288  3 1 0.87913  4 2 0.32869  5 2 0.47360  6 2 0.72967 The following additional statements sort the data set by the values of RANNO, as required by step 3 of the randomization procedure, and print the randomized design along with the ordered experimental unit labels 1-6 under the heading OBS.

 PROC SORT; BY RANNO;  PROC PRINT; RUN; The resulting output is as follows.

 The SAS System  Obs TRTMT RANNO  1 2 0.32869  2 2 0.47360  3 1 0.62288  4 2 0.72967  5 1 0.74865  6 1 0.87913 Experimental units 3, 5, and 6 are assigned to treatment 1, and experimental units 1, 2, and 4 are assigned to treatment 2.

#### Analysis of Variance

In this section we illustrate how SAS software can be used to conduct a one-way analysis of variance test for equality of the treatment effects, assuming that model (3.3.1) is appropriate. We use the data in Table 2.7, p. 23, from the soap experiment.

A sample SAS program to analyze the data is given in Table 3.8. Line numbers have been included for reference, but the line numbers are not part of the SAS program and if included would cause SAS software to generate error messages. SAS programs and data files for this edition are available at the following website.

[http://www.wright.edu/~dan.voss/DeanVossDraguljic.html](http://www.wright.edu/~dan.voss/DeanVossDraguljic.html)

The option LINESIZE = 72 in the OPTIONS statement in line 1 of the program causes all list output generated by the program to be restricted to 72 characters per line, which is convenient for printing list output on 8.5 by 11 inch paper in the portrait orientation. This option has no effect on the standard html output, however, so can be ignored by readers running the SAS software in a windows environment, which is most likely to be the norm. Some of our SAS programs, including those using PROC SGPLOT for example, assume the user is running SAS in a windows environment, whereas PROC PLOT might be used instead if running SAS in a command line mode. All SAS statements are ended by a semicolon.

Lines 2-10 of the program create a SAS data set named SOAP that includes as variables the response variable WTLOSS and the corresponding level of the treatment factor SOAP. The LINES statement indicates that subsequent lines contain data to be read directly from the program, until data entry is

\begin{table}
\begin{tabular}{r c} Line & SAS Program \\  & 1 & OPTIONS LINESIZE = 72; \\  & 2 & DATA SOAP; \\  & 3 & INPUT WTLOSS SOAP; \\  & 4 & LINES; \\  & 5 & -0.30 1 \\  & 6 & -0.10 1 \\  & 7 & -0.14 1 \\  & 8 & : \\  & 9 & 1.82 3 \\  & 10 & ; \\  & 11 & PROC PRINT; \\  & 12 & PROC SGPLOT; \\  & 13 & SCATTER X = SOAP Y = WTLOSS; \\  & 14 & XAXIS TYPE = DISCRETE LABEL = ‘Soap’; \\  & 15 & YAXIS LABEL = ‘Weight Loss (grams)’; \\  & 16 & PROC GLM; \\  & 17 & CLASS SOAP; \\  & 18 & MODEL WTLOSS = SOAP; \\  & 19 & LSMEANS SOAP; \\  & 20 & RUN; QUIT; \\ \end{tabular}
\end{table}
Table 3.8: SAS program for the soap experimentstopped by the next semicolon (line 10). Line 8 must be replaced by the additional data not shown here.

Alternatively, the same data could be read from a file, soap.txt say, by replacing lines 2-10 with the following code, including a correct file path.

INFILE 'c:\path\soap.txt' FIRSTOBS = 2; INPUT WTLOSS SOAP;

Include the option FIRSTOBS = 2 if the data file contains headers on line one then data starting on line two, but delete it if the data starts on line one with no headers.

The PRINT procedure (line 11) prints the data. While this is good practice to verify that the data were read correctly, the PRINT procedure will not routinely be shown in subsequent programs.

The SGPLOT procedure (lines 12-15) generates a scatterplot of WTLOSS versus SOAP like that shown in Fig. 3. The \(x\)-axis option TYPE = DISCRETE instructs the SAS software to use integer values for \(x\)-axis tick marks. The LABEL option sets the desired label for each axis.

The resulting scatterplot is displayed in a SAS output window, by default (on a PC). Alternatively, one could redirect the scatterplot to be saved in the file ch3soap.pdf in pdf format, for example, as illustrated by the following code.

ODS GRAPHICS / RESET IMAGENAME ='ch3soap' IMAGEFMT = PDF HEIGHT = 1.5in WIDTH = 2in; ODS LISTING GPATH ='c:\path\figs'; * insert PROC SGPLOT and its subcommands here; RUN; * Run PROC SGPLOT before closing output to pdf file; ODS GRAPHICS / RESET;

The statements beginning "*" and ending ";" are comments which are not executed by the SAS software. The first ODS GRAPHICS command redirects graphics output to the file ch3soap.pdf using pdf as the image format, and specifies the dimension of the graphic image to be saved. The ODS LISTING command then specifies the directory where the SAS software is to store the file, so the user must replace "c:\path\figs" with an existing path and directory on the user's computer. Following PROC SGPLOT and its statements, the second ODS GRAPHICS command resets the graphics defaults, so graphics output reverts again to the SAS output window. However, before doing so, the RUN command causes SGPLOT to execute while output is still directed to the file ch3soap.pdf.

The General Linear Models procedure PROC GLM (lines 16-19) generates an analysis of variance table. The CLASS statement identifies SOAP as a major source of variation to be modeled as a _classification variable_, so a parameter is associated with each of its levels. The MODEL statement defines the response variable as WTLOSS, and the only source of variation included in the model is SOAP. The

Figure 3.3: Data plot from the SAS software for the soap experiment

parameter \(\mu\) and the error variables are automatically included in the model. The MODEL statement causes the analysis of variance table shown in Fig. 3.4 to be calculated. The F Value is the value of the ratio msT/msE for testing the null hypothesis that the three treatment effects are all equal. The value \(\text{Pr}\ >\ \text{F}\) is the \(p\)-value of the test to be compared with the chosen significance level. When the \(p\)-value is listed as \(<\).0001, the null hypothesis would be rejected for any chosen significance level larger than 0.0001.

The LSMEANS statement (line 19 of Table 3.8), which is part of the GLM procedure, causes the least squares means, \(\hat{\mu}+\hat{\tau}_{l}=\overline{y}_{i.}\), to be printed. The output from this statement is shown in Fig. 3.5.

The RUN statement in line 20 is needed to cause the last procedure to be executed when the program is run in an interactive line mode, typical of a PC Windows environment for example, and the QUIT statement ends the procedure. Though necessary for interactive program processing, the RUN and QUIT statements will not be shown from now on in any programs.

#### Calculating Sample Size Using Power of a Test

In Table 3.9, we show a sample SAS program which calculates the power of the test of the null hypothesis \(H_{0}:\{\tau_{1}=\cdots=\tau_{v}\}\) against \(H_{A}\): {at least two of the \(\tau_{i}\)'s differ}. The program uses a DO statement, which allows the calculation to be done for a selected range of sample sizes \(r\), using the formulae in Sect. 3.6.2. The line DO R = 3 TO 6 BY 1; asks the SAS software to do the calculations for each value of \(r\) between 3 and 6, increasing \(r\) by 1 each time.

The code shown is for the soap experiment in Example 3.6.1, but is easily modified for other experiments by changing the values of the number of levels of the treatment factor (V), the difference

Figure 3.4: Sample SAS output from PROC GLM for the soap experiment

Figure 3.5: Output from the LSMEANS statement for the SOLP experiment

(DEL) to be detected (i.e. \(\Delta\)), the assumed largest value of the error variance (SIGMA2), the significance level of the test (ALPHA), and the range of values of \(r\) to be investigated.

In Table 9, the degrees of freedom \(\nu_{1}=v-1\) and \(\nu_{2}=n-v=v(r-1)\) for the \(F\)-distribution are donated by NU1 and NU2. The "left-hand tail probability" \(1-\alpha\) is called LHTPB, and is used in calculating the critical value \(F_{v-1,n-v,\alpha}\), called FVALUE. From (3.6.20), the value of \(\phi\), labelled PHI is calculated as \(\sqrt{r\,\Delta^{2}/(2v\sigma^{2})}\). The "non-centrality parameter" NONCN is \(\delta^{2}=v\phi^{2}\) and this is needed by the non-central \(F\) distribution in the calculation of the power for the range of values of \(r\) specified. The output, generated by the PROC PRINT statement is

Obs R POWER

2 3 0.70934

3 4 0.89565

4 5 0.96715

5 6 0.99058

and we can see that, just as in Example 3.6.1, to achieve a power of approximately 0.9, the number of observations needed is \(r=4\) per level of the treatment factor. To see the values of all the variables calculated at each step, remove the line VAR R POWER; which restricts which variables are printed.

### Using R Software

#### Preliminaries

R is a free software environment for statistical computing and graphics, used extensively in this book. Readers can install the R software after downloading it from [http://cran.us.r-project.org](http://cran.us.r-project.org), for example, choosing the appropriate version for the computer and operating system. RStudio is free software providing an enhanced environment for running R. After installing R, readers are recommended to also download and install RStudio; it can be downloaded from [http://www.rstudio.com](http://www.rstudio.com), choosing

\begin{table}
\begin{tabular}{c c} DATA POWER; & \\ V = 3; & \\ DEL = 0.25; & \\ SIGMA2 = 0.007; & \\ ALPHA = 0.05; & \\ NU1 = V - 1; & \\ LHTPB = 1 - ALPHA; & \\ DO R = 3 TO 6 BY 1; & \\ NU2 = V*(R - 1); & \\ PHI = (SQRT(R / (2*V*SIGMA2)))*DEL; & \\ FVALUE = FINV(LHTPB, NU1, NU2); & \\ NONCN = V*PHI**2; & \\ POWER = 1 - PROBF(FVALUE, NU1, NU2, NONCN); & \\ OUTPUT; & \\ END; & \\ PROC PRINT; & \\ VAR R POWER; & \\ \end{tabular}
\end{table}
Table 9: Calculating sample sizes using power of the test again the appropriate version for the computer and operating system. Run either R or RStudio, as RStudio invokes R.

Throughout the book, we shall assume that the reader has set up a working directory for R called RCode and that R program files are either in the working directory or in specified subdirectories of the working directory. For example, we assume that RCode includes a subdirectory called data containing any data set that is to be read by R and a subdirectory called figs in which R will store any plots generated. R programs and data files for this edition are available at the following website.

[http://www.wright.edu/~dan.voss/DeanVossDraguljic.html](http://www.wright.edu/~dan.voss/DeanVossDraguljic.html)

We shall assume that the user will execute the following commands or similar each time that R (or RStudio) is started.

 rm(list = ls()) # Remove all objects (start with clean slate)  opar = par() # Save default graphics parameters as opar  setwd("/RCode") # Set the working directory  getwd() # Confirm working directory  options(show.signif.stars = FALSE) # Show no stars for significance tests  options(width = 72, digits = 5, scipen = 2) # Control printed output  ooptions = options(width = 72, digits = 5, scipen = 2) # Save print options

The first command removes all existing R objects created previously by the user, clearing the slate for a new session. The symbol "#" starts a line comment, used for program documentation. The second command assigns R's current graphics parameters par()--initially the default graphics parameter values--to the object opar, saving them so they can be restored later via the command par(opar) if desired. We will routinely use "=" for assignment, though use of "<-" is more traditional in R. The setwd command in the third line sets /RCode as the _working directory_, where the software reads and writes files by default. If RCode is not in the root directory, then use setwd("/path/RCode") but specify the correct directory path to RCode. The getwd() command in the fourth line displays the working directory, to confirm it is now /RCode. For functions that conduct hypothesis tests, the options command in the fifth line suppresses printing of stars for various levels of significance. The options command in line six controls printed output, restricting it to be at most 72 columns wide with five significant digits, and penalizing use of scientific notation. We have initialized R in this way or similarly when running our programs, though these commands will generally not be shown in our subsequent program code. The last line saves these print options as ooptions, so if changed they can be restored by the command options(ooptions).

While the above commands can be typed into the R Console and executed one by one, it is more convenient to save them in a file, startup.r say, in the working directory. Then the single command

 source("/RCode/startup.r")

will execute the commands in the startup.r file. We routinely executed this code line each time we started R (or RStudio) to produce R program output in this book, though we do not show this code line in our programs.

As will be seen in the following sections, when R is waiting for the next command, a prompt > is displayed, and if the user command is not complete when a line is entered (for example if the final parenthesis is missing), the prompt will change to + on the next line, prodding the user to enter the rest of the command. To end an R session, type q().

It is prudent to use the latest production version of R. On a Windows operating system, the updateR command of the installr package will detect if there is a new R version available, and if so it will download and install it and update previously installed add-on packages. The following commands, when executed from within R, install and load the installr package and execute the updateR command.

install.packages("installr"); library(installr); updateR() Assuming the user has installed and set up R as noted above, we are ready to use the software.

#### Randomization

A simple procedure for randomizing a completely randomized design was given in Sect. 3.2, p. 31. This procedure is easily implemented using the R software, as we now illustrate. Consider a completely randomized design for two treatments and \(r=3\) observations on each, giving a total of \(n=6\) observations.

The following R statements create and display a data frame named design, a _data frame_ being a data set consisting of equal-length columns of information. Here, the columns of design are the lists of values of the two variables trtmt and ranno as required by steps 1 and 2 of the randomization procedure in Sect. 3.2. In particular, the first statement creates the column trtmt of treatment labels. The second statement creates the column ranno consisting of six uniform random numbers between 0 and 1, six being the length of the column trtmt. The third statement puts the columns trtmt and ranno into a data frame, and assigns this object the name design. Then the fourth statement displays design. The R output is shown immediately following the R statements:

 > trtmt = c(1, 1, 1, 2, 2, 2) # Create column trtmt = (1, 1, 1, 2, 2, 2) > ranno = runif(length(trtmt)) # Create column of 6 unif(0, 1) RVs > design = data.frame(trtmt, ranno) # Create data.frame "design" > design # Display the data.frame design

 trtmt ranno  1 1 0.447827  2 1 0.494462  3 1 0.174414  4 2 0.894132  5 2 0.473540  6 2 0.010771 We digress to provide additional information about R, before finishing the randomization process in the next paragraph. The command trtmt = rep(c(1, 2), each = 3) would yield the same column trtmt, but by replicating 1 and 2 three times each--a more convenient approach for larger designs. Each time the above R commands are run, a different set of random numbers will result. Typing the command design causes the entire data frame design to be displayed. One could display only what is in column 1 named trtmt, for example, by typing design$trtmt, design[, 1], or design[, "trtmt"]. The column trtmt also still exists as a separate object, that can be displayed simply by typing trtmt. One could remove this redundant object by the command rm(trtmt). Note that R is "case-sensitive", so if the column name is trtmt, then R will not be able to locate a column called, say, Trtmt with a capital T. The details about any of the commands used can be found by typing?commandName, for example typing?runif will bring up the command help file containing many details about the use of runif.

The following additional statements sort the trtmt column of the data frame design by the values of ranno, as required by step 3 of the randomization procedure. Specifically, the statement order(ranno) yields the order 6 3 1 5 2 4, since the smallest random variate is in row 6, the second smallest is in row 3, etc. So, the first statement below redefines the data frame design to have its rows reordered accordingly, effectively sorting the rows based on the values of the random numbers (RNs). The second statement below defines a new column of design named EU containing the integers from 1 to 6 as labels for the experimental units. Then the last statement asks for the sorted design to be displayed.

> design = design[order(ranno), ] # Sort rows by RNs, save > design$EU = c(1:6) # Add col EU = (1,2,3,4,5,6) to design > design # Display the results of the randomization

trtmt ranno EU
6 2 0.010771 1  3 1 0.174414 2  1 1 0.447827 3  5 2 0.473540 4  2 1 0.494462 5  4 2 0.894132 6

Experimental units 2, 3, and 5 are to be assigned to treatment 1, and experimental units 1, 4, and 6 are to be assigned to treatment 2.

#### Reading and Plotting Data

A sample R program to input, display, and plot the data is given in Table 10. Line numbers have been included for reference, but they are not part of the R program and if included in the R code would yield error messages. The prompt ">" and the continuation prompt "+" are supplied by R and should not be typed by the user.

We use the data in Table 2, p. 23, from the soap experiment, and assume that the data are stored in the file soap.txt in the data subdirectory of the working directory; that is, in data/soap.txt.

\begin{table}
\begin{tabular}{r r} Line & R Code and Output \\  1 & \textgreater{} \# Read the data into the data.frame "soap.data" \\  2 & \textgreater{} soap.data = read.table(’data/soap.txt’, header = TRUE) \\  3 & \textgreater{} head(soap.data, 5) \# Display first 5 lines of soap.data \\  4 & Soap Cube PreWt PostWt WtLoss \\  5 & 1 & 1 13.14 13.44 -0.30 \\  6 & 2 & 1 2 13.17 13.27 -0.10 \\  7 & 3 & 1 3 13.17 13.31 -0.14 \\  8 & 4 & 1 4 13.17 12.77 0.40 \\  9 & 5 & 2 5 13.03 10.40 2.63 \\
10 & \textgreater{} \# Add factor variable fSoap to soap.data for later ANOVA \\  11 & \textgreater{} soap.data$fSoap = factor(soap.data$Soap) \\
12 & \textgreater{} \# Plot WtLoss vs Soap, specify axis labels, suppress x-axis. \\  13 & \textgreater{} plot(WtLoss \textasciitilde{} Soap, data = soap.data, xlab = "Soap", \\  14 & \textgreater{} ylab = "Weight Loss (grams)", las = l, xext = "n") \\  15 & \textgreater{} \# Insert x-axis (axis 1) with tick marks from 1 to 3 by 1. \\
16 & \textgreater{} axis(1, at = seq(1,3,1)) \\ \end{tabular}
\end{table}
Table 10: R program for the soap experiment: reading and plotting data Line 2 of Table 3.10 reads the data from the file soap.txt and puts it into an R data set (data frame) called soap.data. Alternatively, one could enter the data via the keyboard, which is the standard input device stdin(), by replacing line 2 with the following.

> soap.data = read.table(stdin(), header = TRUE)
0: Soap Cube PreWt PostWt WtLoss
1: 1 1 13.14 13.44 -0.30
2: 1 2 13.17 13.27 -0.10
: : : : : : 12: 3 12 13.00 11.18 1.82
13:

Keyboard data entry is ended by hitting the return key twice.

The head(soap.data, 5) command in line 3 displays the first five lines of the data set shown in lines 4-9. Alternatively, the command head(soap.data) would display the first six lines by default, and the command soap.data would display the full data set. The first column displayed indicates the data is from rows 1-5 of the data set, and the other five columns show the five variables in the data set, including the response variable WtLoss and the corresponding level of the treatment factor Soap. In line 2, the statement header = TRUE (i.e. header = T) tells R that the columns of data in the file soap.txt have headings, and these can be seen in line 4. If a data file has no headings, the header statement may be omitted, the default being header = FALSE (i.e. header = F).

In line 11, the data set soap.data is augmented with a new variable, fSoap, created by converting the numerical variable Soap to a factor variable, needed later for the analysis of variance.

The remaining code generates a plot of the data. The plot command in lines 13-14 generates a scatterplot of WtLoss versus Soap like that shown in Fig.3.6, with labels specified for each axis by xlab and ylab. The option data = soap.data indicates that the variables being plotted are in the data set soap.data. Alternatively, one could use the syntax

plot(soap.data$WtLoss ~ soap.data$Soap, xlab ="Soap",

in line 13. The dollar sign identifies specific columns of the data set, so, for example, soap.data$Soap just means "read the column labeled Soap from the data set soap.data". The + prompt in line 14 indicates that the prior command is not yet complete. The option las = 1 sets _labels style_ 1, making tick mark labels horizontal, impacting \(y\)-axis labeling. The option xaxt = "n" in line 14 suppresses the automatically generated x-axis (which would have five tick marks), then the axis command in line 16 includes instead an x-axis with three tick marks specified to be at 1, 2 and 3--namely, a sequence starting at 1 and ending at 3 in steps of size 1. If the numerical variable Soap was replaced by the factor variable fSoap in line 13, then a box plot would be obtained instead of a scatterplot.

The resulting scatterplot is displayed in a graphics window, by default (on a PC). Alternatively, one can redirect the scatterplot to be saved in the file ch3soap.pdf in pdf format, for example, as illustrated by the following code.

pdf("figs/ch3soapplot.pdf", width = 5, height = 3) # Open a pdf file
# Insert plot command and its subcommands here dev.off() # Close the pdf file

The pdf command opens the pdf file ch3soapplot.pdf in the figs subdirectory of the working directory (as specified by the user upon startup), and specifies the dimension of the graphic image to be saved. Once this has been done, plot function calls will send output to the pdf file.

Then the dev.off() command closes the pdf file, so graphical output reverts to the default graphics window.

#### Analysis of Variance

In this section we illustrate how the R software can be used to conduct a one-way analysis of variance test for equality of the treatment effects, assuming model (3.3.1) is appropriate. Table 3.11 contains a sample program and output, with line numbers again included for reference only. We continue to use the soap experiment data, which in line 1 is read from the file soap.txt into the data set soap.data.

In line 3, we convert the numerical variable Soap to a factor variable, saving it as a new variable fSoap of the soap.data data set. The statement in line 4 generates summary statistics for the variables in columns 1, 5 and 6 of the data set, with the output shown in lines 5-11. If all six variables are to be summarized, the statement summary(soap.data) without column numbers is sufficient. One can see that the summary command treats the numeric variable Soap and the factor variable fSoap differently, providing summary statistics for the Soap values, but levels and frequencies for fSoap. A _factor variable_ is treated as a qualitative variable by R, analogous to a CLASS variable in SAS software.

The aov function in line 12 fits a linear model to the soap data, specifying WtLoss as the response variable and fSoap as the primary source of variation, the symbol "\(\sim\)" separating and distinguishing these, saving the resulting information as the object model. Because fSoap is a factor variable, it is modeled as a classification variable as desired. The parameter \(\mu\) and the error variables are automatically included in the model. The anova(modell) command in line 13 displays the one-way analysis of variance information shown in lines 14-19. In lines 17-18, the F value is the value of the ratio msT/msE for testing the null hypothesis that the three treatment effects are all equal, and Pr(>F) is the _p_-value of the test to be compared with the chosen significance level. The listed _p_-value is \(5.91\times 10^{-7}\), so the null hypothesis is rejected for any chosen significance level larger than this small value.

The library(lmeans) command in line 21 loads the package lmeans from the user's library for subsequent use; (this assumes the reader has already installed the package as discussed in the next paragraph). The lmeans command in line 22 generates the least squares means for the three levels of the factor fSoap, plus further statistical information which will be discussed in Chap. 4. The output is shown in lines 23-28.

Figure 3.6: R data plot for the soap experiment

#### Add-On Packages

Installation of the R software (see Sect. 1.2) installs the base software, including some base packages providing limited functionality. There are thousands of additional user-defined packages that the user may freely download, the lmeans package introduced above being one example. To use any such function not included in the base software installation, the "add-on" package containing the function must first be installed and loaded. For example, the command install.packages("lmeans") in line 20 installs the lmeans package, permanently saving it in a library of packages on the user's computer, so the command library(lmeans) can load the lmeans package from the user's library. A package only needs to be installed once. However, any add-on package must be loaded by the user prior to its first use in any new R session. As such, when our programs require an add-on package, we will routinely include the necessary library command to load the package. Furthermore, when we use an add-on package for the first time, the corresponding program will include the corresponding install.packages command, but commented out. Before running such a program the first time,

\begin{table}
\begin{tabular}{r r r} Line & R Code or Output \\  1 & \textgreater{} soap.data = read.table("data/soap.txt", header = TRUE) \\  2 & \textgreater{} \# Add factor variable fSoap to soap.data for ANOVA \\  3 & \textgreater{} soap.data\textless{}fSoap = factor(soap.data\$Soap) \\  4 & \textgreater{} summary(soap.data[,c(1,5:6)]) \# Summarize data in cols 1, 5, 6 \\  5 & Soap & WtLoss fSoap \\  6 & Min. :1 & Min. :-0.300 & 1:4 \\  7 & 1st Qu.:1 & 1st Qu.: 0.275 & 2:4 \\  8 & Median :2 & Median : 1.945 & 3:4 \\  9 & Mean :2 & Mean : 1.552 \\  10 & 3rd Qu.:3 & 3rd Qu.: 2.460 \\  11 & Max. :3 & Max. : 3.150 \\  12 & \textgreater{} model1 = aov(WtLoss \textasciitilde{} fSoap, data = soap.data) \\  13 & \textgreater{} anova(model1) \\  14 & Analysis of Variance Table \\  15 & 16 & Response: WtLoss \\  17 & Df Sum Sq Mean Sq F value Pr(\textgreater{}F) \\  18 & fSoap 2 16.12 & 8.06 & 104 5.9e-07 \\  19 & Residuals 9 0.69 & 0.08 \\  20 & \textgreater{} \# install.packages("lmeans") \\  21 & \textgreater{} library(lmeans) \\  22 & \textgreater{} lmeans(model1, "fSoap") \\  23 & fSoap lsamean SE df lower.CL upper.CL \\  24 & 1 -0.0350 & 0.1389 & 9 -0.34922 & 0.27922 \\  25 & 2 2.7000 & 0.1389 & 9 2.38578 & 3.01422 \\  26 & 3 & 1.9925 & 0.1389 & 9 1.67828 & 2.30672 \\  27 & 28 & Confidence level used: 0.95 \\ \end{tabular}
\end{table}
Table 3.11: R program for the soap experiment: analysis of variance and least squares meansthe reader can simply delete the comment character, "#", so the package gets installed. On most systems, the process is automatic.

For linux users, when the install.packages command is invoked for the first time, you may get a warning that says in effect that a library is not writable and it will ask you whether you would like to use a personal library. If you answer y, it will ask you if you would like to create one. If you answer y again, it will ask you to select a CRAN "mirror" (i.e. a site from which to download the package for installation). Select (give the number of) any site near your location, and then R will create the personal library and download the package. After this, the install.packages command will proceed automatically.

#### Calculating Sample Size Using Power of a Test

In Table 12, we show a sample R program which calculates the power of the test of the null hypothesis \(H_{0}:\{\tau_{1}=\cdots=\tau_{v}\}\) against \(H_{A}\): {at least two of the \(\tau_{i}\)'s differ}. The code shown is for the soap experiment in Example 3.6.1, but is easily modified for other experiments by changing the values of the number of levels of the treatment factor (v), the difference (del) to be detected (i.e. \(\Delta\)), the assumed largest value of the error variance (sig2), the significance level of the test (alpha), and the desired power of the test pwr.

The R program from Table 12 uses function pwr.anova.test which can be found in the package pwr. The function's inputs k = v, sig.level = alpha, and power = pwr are self-explanatory. The degrees of freedom \(\nu_{1}=v-1\), \(\nu_{2}=n-v=v(r-1)\), and the critical value \(F_{v-1,n-v,\alpha}\) for the \(F\)-distribution corresponding to the required significance level are calculated internally by R. From (3.6.20), the value of \(\phi/\sqrt{r}\), labeled as input f, is calculated as \(\sqrt{\Delta^{2}/(2v\sigma^{2})}\) and is needed by the non-central \(F\) distribution in the calculation of the power for different values of \(r\). The output is also shown in Table 12. and we can see that, just as in Example 3.6.1, to achieve a power of approximately 0.9, the number of observations needed is \(r=4\) per level of the treatment factor. Notice that \(r\) is labelled n in the R output.

\begin{table}
\begin{tabular}{l} \textgreater{} \#install.packages(pwr) \\ \textgreater{} library(pwr) \\ \textgreater{} v = 3; del = 0.25; sig2 = 0.007; alpha = 0.05; pwr = 0.90 \\ \textgreater{} pwr.anova.test(k = v, sig.level = alpha, power = pwr, \\ + f = sqrt(del’2/(2*v*sig2))) \\ \end{tabular} \\ \end{tabular}
\end{table}
Table 12: Calculating sample sizes using power of the test 

## Exercises

1. Suppose that you are planning to run an experiment with one treatment factor having four levels and no blocking factors. Suppose that the calculation of the required number of observations has given \(r_{1}=r_{2}=r_{3}=r_{4}=5\). Assign at random 20 experimental units to the \(v=4\) levels of the treatments, so that each treatment is assigned 5 units.
2. Suppose that you are planning to run an experiment with one treatment factor having three levels and no blocking factors. It has been determined that \(r_{1}=3\), \(r_{2}=r_{3}=5\). Assign at random 13 experimental units to the \(v=3\) treatments, so that the first treatment is assigned 3 units and the other two treatments are each assigned 5 units.
3. Suppose that you are planning to run an experiment with three treatment factors, where the first factor has two levels and the other two factors have three levels each. Write out the coded form of the 18 treatment combinations. Assign 36 experimental units at random to the treatment combinations so that each treatment combination is assigned two units.
4. For the one-way analysis of variance model (3.3.1), p. 33, the solution to the normal equations used by the SAS software is \(\hat{\tau}_{i}=\overline{y}_{i.}-\overline{y}_{v.}\) (\(i=1,\ldots,v\)) and \(\hat{\mu}=\overline{y}_{v.}\).
5. Is \(\tau_{i}\) estimable? Explain.
6. Calculate the expected value of the least squares estimator for \(\tau_{1}-\tau_{2}\) corresponding to the above solution. Is \(\tau_{1}-\tau_{2}\) estimable? Explain.
7. Consider a completely randomized design with observations on three treatments (coded 1, 2, 3). For the one-way analysis of variance model (3.3.1), p. 33, determine which of the following are estimable. For those that are estimable, state the least squares estimator. 1. \(\tau_{1}+\tau_{2}-2\tau_{3}\). 2. \(\mu+\tau_{3}\). 3. \(\tau_{1}-\tau_{2}-\tau_{3}\). 4. \(\mu+(\tau_{1}+\tau_{2}+\tau_{3})/3\).
8. (requires calculus) Show that the normal equations for estimating \(\mu\), \(\tau_{1}\), \(\ldots\), \(\tau_{v}\) are those given in Eq. (3.4.3) on p. 35.
9. (requires calculus) Show that the least squares estimator of\(\mu+\tau\) is \(\overline{Y}_{.}\) for the linear model \(Y_{it}=\mu+\tau+\epsilon_{it}^{0}\) (\(t=1,\ldots,r_{i}\); \(i=1,2,\ldots,v\)), where the \(\epsilon_{it}^{0}\)'s are independent random variables with mean zero and variance \(\sigma^{2}\). (This is the reduced model for the one-way analysis of variance test, Sect. 3.5.1, p. 41.)
10. For the model in the previous exercise, find an unbiased estimator for\(\sigma^{2}\). (Hint: first calculate \(E[ssE_{0}]\) in (3.5.10), p. 42.)
11. (requires calculus) Find the least squares estimates of \(\mu_{1}\), \(\mu_{2}\), \(\ldots\), \(\mu_{v}\) for the linear model \(Y_{it}=\mu_{i}+\epsilon_{it}\) (\(t=1,\ldots,r_{i}\); \(i=1,2,\ldots,v\)), where the \(\epsilon_{it}\)'s are independent random variables with mean zero and variance \(\sigma^{2}\). Compare these estimates with the least squares estimates of \(\mu+\tau_{i}\) (\(i=1,2,\ldots,v\)) in model (3.3.1), p. 33.
12. For the model in the previous exercise, find an unbiased estimator for \(\sigma^{2}\). Compare the estimator with that in (3.4.7), p. 39.
13. Verify, for the one-way analysis of variance model (3.3.1), p. 33, that each treatment sample variance \(S_{i}^{2}\) is an unbiased estimator of the error variance \(\sigma^{2}\), so that \[E(SSE)=\sum_{i}(r_{i}-1)E(S_{i}^{2})=(n-v)\sigma^{2}.\]12. **Balloon experiment** Prior to 1985, the experimenter (Meily Lin) had observed that some colors of birthday balloons seem to be harder to inflate than others. She ran this experiment to determine whether balloons of different colors are similar in terms of the time taken for inflation to a diameter of 7 inches. Four colors were selected from a single manufacturer. An assistant blew up the balloons and the experimenter recorded the times (to the nearest 1/10 second) with a stop watch. The data, in the order collected, are given in Table 3.13, where the codes 1, 2, 3, 4 denote the colors pink, yellow, orange, blue, respectively. 1. Plot inflation time versus color and comment on the results. 2. Estimate the mean inflation time for each balloon color, and add these estimates to the plot from part (a). 3. Construct an analysis of variance table and test the hypothesis that color has no effect on inflation time. 4. Plot the data for each color in the order that it was collected. Are you concerned that the assumptions on the model are not satisfied? If so, why? If not, why not? 5. Is the analysis conducted in part (c) satisfactory?
13. **Heart-lung pump experiment, continued** The heart-lung pump experiment was described in Example 3.4.1, p. 37, and the data were shown in Table 3.2, p. 38. 1. Calculate an analysis of variance table and test the null hypothesis that the different number of revolutions per minute have the same effects on the fluid flow rate. 2. Are you happy with your conclusion? Why or why not? 3. Calculate a 90% upper confidence limit for the error variance \(\sigma^{2}\).
14. **Meat cooking experiment** (L. Alvarez, M. Burke, R. Chow, S. Lopez, and C. Shirk, 1998)

\begin{table}
\begin{tabular}{c c c c c c c c} \hline Time order & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 \\ Coded color & 1 & 3 & 1 & 4 & 3 & 2 & 2 & 2 \\ Inflation time & 22.0 & 24.6 & 20.3 & 19.8 & 24.3 & 22.2 & 28.5 & 25.7 \\ Time order & 9 & 10 & 11 & 12 & 13 & 14 & 15 & 16 \\ Coded color & 3 & 1 & 2 & 4 & 4 & 4 & 3 & 1 \\ Inflation time & 20.2 & 19.6 & 28.8 & 24.0 & 17.1 & 19.3 & 24.2 & 15.8 \\ Time order & 17 & 18 & 19 & 20 & 21 & 22 & 23 & 24 \\ Coded color & 2 & 1 & 4 & 3 & 1 & 4 & 4 & 2 \\ Inflation time & 18.3 & 17.5 & 18.7 & 22.9 & 16.3 & 14.0 & 16.6 & 18.1 \\ Time order & 25 & 26 & 27 & 28 & 29 & 30 & 31 & 32 \\ Coded color & 2 & 4 & 2 & 3 & 3 & 1 & 1 & 3 \\ Inflation time & 18.9 & 16.0 & 20.1 & 22.5 & 16.0 & 19.3 & 15.9 & 20.3 \\ \hline \end{tabular}
\end{table}
Table 3.13: Times (in seconds) for the balloon experiment An experiment was run to investigate the amount of weight lost (in grams) by ground beef hamburgers after grilling or frying, and how much the weight loss is affected by the percentage fat in the beef before cooking. The experiment involved two factors: cooking method (factor \(A\), with two levels frying and grilling, coded 1, 2), and fat content (factor \(B\), with three levels 10, 15, and 20%, coded 1, 2, 3). Thus there were six treatment combinations 11, 12, 13, 21, 22, 23, relabeled as treatment levels 1, 2,..., 6, respectively. Hamburger patties weighing 110 g each were prepared from meat with the required fat content. There were 30 "cooking time slots" which were randomly assigned to the treatments in such a way that each treatment was observed five times (\(r=5\)). The patty weights after cooking are shown in Table 3.14.

1. Plot the data and comment on the results.
2. Write down a suitable model for this experiment.
3. Calculate the least squares estimate of the mean response for each treatment. Show these estimates on the plot obtained in part (a).
4. Test the null hypothesis that the treatments have the same effect on patty post-cooking weight.
5. Estimate the contrast \(\tau_{1}-(\tau_{2}+\tau_{3})/2\) which compares the effect on the post-cooked weight of the average of the two higher fat contents versus the leanest meat for the fried hamburger patties.
6. Calculate the variance associated with the contrast in part (e). How does the value of the variance compare with the variance \(\sigma^{2}\) of the random error variables?
15. **Trout experiment** (Gutsell 1951, Biometrics) The data in Table 3.15 show the measurements of hemoglobin (grams per 100 ml) in the blood of brown trout. The trout were placed at random in four different troughs. The fish food added to the troughs contained, respectively, 0, 5, 10, and 15 g of sulfamerazine per 100 pounds of fish (coded 1, 2, 3, 4). The measurements were made on ten randomly selected fish from each trough after 35 days.

\begin{table}
\begin{tabular}{c c c c c c c c c} \hline Code & \multicolumn{6}{c}{Hemoglobin (grams per 100 ml)} \\ \hline
1 & 6.7 & 7.8 & 5.5 & 8.4 & 7.0 & 7.8 & 8.6 & 7.4 & 5.8 & 7.0 \\
2 & 9.9 & 8.4 & 10.4 & 9.3 & 10.7 & 11.9 & 7.1 & 6.4 & 8.6 & 10.6 \\
3 & 10.4 & 8.1 & 10.6 & 8.7 & 10.7 & 9.1 & 8.8 & 8.1 & 7.8 & 8.0 \\
4 & 9.3 & 9.3 & 7.2 & 7.8 & 9.3 & 10.2 & 8.7 & 8.6 & 9.3 & 7.2 \\ \hline \end{tabular} Source: Güsell (1951). Copyright © 1951 International Biometric Society. Reprinted with permission

\end{table}
Table 3.15: Data for the trout experiment 1. Plot the data and comment on the results.
2. Write down a suitable model for this experiment, assuming trough effects are negligible.
3. Calculate the least squares estimate of the mean response for each treatment. Show these estimates on the plot obtained in (a). Can you draw any conclusions from these estimates?
4. Test the hypothesis that sulfamerazine has no effect on the hemoglobin content of trout blood.
5. Calculate a 95% upper confidence limit for \(\sigma^{2}\).

16. **Trout experiment, continued** Suppose the trout experiment of Exercise 3.15 is to be repeated with the same \(v=4\) treatments, and suppose that the same hypothesis, that the treatments have no effect on hemoglobin content, is to be tested. 1. For calculating the number of observations needed on each treatment, what would you use as a guess for \(\sigma^{2}\)? 2. Calculate the sample sizes needed for an analysis of variance test with \(\alpha=0.05\) to have power 0.95 if: (i) \(\Delta=1.5\); (ii) \(\Delta=1.0\); (iii) \(\Delta=2.0\).

17. **Meat cooking experiment, continued** Suppose the meat cooking experiment of Exercise 3.14 is to be repeated with the same \(v=6\) treatments, and suppose the same hypothesis, that the treatments have the same effect on burger patty weight loss, is to be tested. 1. Calculate an unbiased estimate of \(\sigma^{2}\) and a 90% upper confidence limit for it. 2. Calculate the sample sizes needed for an analysis of variance test with \(\alpha=0.05\) to have power 0.90 if: (i) \(\Delta=5.0\); (ii) \(\Delta=10.0\).

18. The diameter of a ball bearing is to be measured using three different calipers. How many observations should be taken on each caliper type if the null hypothesis \(H_{0}\):{effects of the calipers are the same} is to be tested against the alternative hypothesis that the three calipers give different average measurements. It is required to detect a difference of 0.01 mm in the effects of the caliper types with probability 0.98 and a Type I error probability of \(\alpha=0.05\). It is thought that \(\sigma\) is about 0.03 mm.
19. An experiment is to be run to determine whether or not time differences in performing a simple manual task are caused by different types of lighting. Five levels of lighting are selected ranging from dim colored light to bright white light. The one-way analysis of variance model (3.3.1), p. 33 is thought to be a suitable model, and \(H_{0}:\{\tau_{1}=\tau_{2}=\tau_{3}=\tau_{4}=\tau_{5}\}\)is to be tested against the alternative hypothesis \(H_{A}\):{the \(\tau_{i}\)'sare not all equal} at significance level 0.05. How many observations should be taken at each light level given that the experimenter wishes to reject \(H_{0}\) with probability 0.90 if the difference in the effects of any two light levels produces a 4.5-second time difference in the task? It is thought that \(\sigma\) is at most 3.0 seconds.

### 4.1 Introduction

The objective of an experiment is often much more specific than merely determining whether or not all of the treatments give rise to similar responses. For example, a chemical experiment might be run primarily to determine whether or not the yield of the chemical process increases as the amount of the catalyst is increased. A medical experiment might be concerned with the efficacy of each of several new drugs as compared with a standard drug. A nutrition experiment may be run to compare high fiber diets with low fiber diets. Such treatment comparisons are formalized in Sect. 4.2. The purpose of this chapter is to provide confidence intervals and hypothesis tests about treatment comparisons and treatment means. We start, in Sect. 4.3, by considering a single treatment comparison or mean, and then, in Sect. 4.4, we develop the techniques needed when more than one treatment comparison or mean is of interest. The number of observations required to achieve confidence intervals of given lengths is calculated in Sect. 4.5. SAS and R commands for confidence intervals and hypothesis tests are provided in Sects. 4.6 and 4.7, respectively.

### 4.2 Contrasts

In Chap. 3, we defined a contrast to be a linear combination of the parameters \(\tau_{1},\tau_{2},\ldots,\tau_{v}\) of the form

\[\sum c_{i}\tau_{i}\,\quad\text{with}\quad\sum c_{i}=0\.\]

For example, \(\tau_{u}-\tau_{s}\) is the contrast that compares the effects (as measured by the response variable) of treatments \(u\) and \(s\). If \(\tau_{u}-\tau_{s}=0\), then treatments \(u\) and \(s\) affect the response in exactly the same way, and we say that these treatments do not differ. Otherwise, the treatments do differ in the way they affect the response. We showed in Sect. 3.4 that for a completely randomized design and the one-way analysis of variance model (3.3.1), every contrast \(\sum c_{i}\tau_{i}\) is estimable with least squares estimate

\[\sum c_{i}\hat{\tau}_{i}=\sum c_{i}(\hat{\mu}+\hat{\tau}_{i})=\sum c_{i} \overline{y}_{i}. \tag{4.2.1}\]and corresponding least squares estimator \(\sum c_{i}\overline{Y}_{i.}\). The variance of the least squares estimator is

\[\text{Var}\left(\sum c_{i}\overline{Y}_{i.}\right)=\sum c_{i}^{2}\text{Var}( \overline{Y}_{i.})=\sum c_{i}^{2}(\sigma^{2}/r_{i})=\sigma^{2}\sum(c_{i}^{2}/r_ {i})\,. \tag{4.2.2}\]

The first equality uses the fact that the treatment sample means \(\overline{Y}_{i.}\) involve different response variables, which in model (3.3.1) are independent. The error variance \(\sigma^{2}\) is generally unknown and is estimated by the unbiased estimate _m_sE, giving the estimated variance of the contrast estimator as

\[\widehat{\text{Var}}\left(\sum c_{i}\overline{Y}_{i.}\right)=\text{m}sE\sum(c _{i}^{2}/r_{i}).\]

The _estimated standard error_ of the estimator is the square root of this quantity, namely,

\[\sqrt{\widehat{\text{Var}}\left(\sum c_{i}\overline{Y}_{i.}\right)}=\sqrt{m \text{s}E\ \sum(c_{i}^{2}/r_{i})}\,. \tag{4.2.3}\]

#### Normalized Contrasts

When several contrasts are to be compared, it is sometimes helpful to be able to measure them all on the same scale. A contrast is said to be _normalized_ if it is scaled so that its least squares estimator has variance \(\sigma^{2}\). From (4.2.2), it can be seen that a contrast \(\Sigma c_{i}\tau_{i}\) is normalized by dividing it by \(\sqrt{\Sigma c_{i}^{2}/r_{i}}\). If we write \(h_{i}=c_{i}/\sqrt{\Sigma c_{i}^{2}/r_{i}}\), then the least squares estimator \(\Sigma h_{i}\overline{Y}_{i.}\) of the normalized contrast \(\Sigma h_{i}\tau_{i}\) has the following distribution:

\[\sum h_{i}\overline{Y}_{i.}\sim N\left(\sum h_{i}\tau_{i},\sigma^{2}\right)\,, \ \ \text{where}\ h_{i}=\frac{c_{i}}{\sqrt{\sum c_{i}^{2}/r_{i}}}\,.\]

Normalized contrasts will be used for hypothesis testing (Sect. 4.3.3).

#### Contrast Coefficients

It is convenient to represent a contrast by listing only the coefficients of the parameters \(\tau_{1}\), \(\tau_{2}\),..., \(\tau_{v}\). Thus, \(\sum c_{i}\tau_{i}=c_{1}\tau_{1}+c_{2}\tau_{2}+\cdots+c_{v}\tau_{v}\) would be represented by the list of _contrast coefficients_

\[[c_{1},\ c_{2},\ \ldots,\ c_{v}]\,.\]

Some types of contrasts are used frequently in practice, and these are identified in Sects. 4.2.1-4.2.4.

#### Pairwise Comparisons

As the name suggests, _pairwise comparisons_ are simple differences \(\tau_{u}-\tau_{s}\) of pairs of parameters \(\tau_{u}\) and \(\tau_{s}\) (\(u\neq s\)). These are of interest when the experimenter wishes to compare each treatment with every other treatment. The list of contrast coefficients for the pairwise difference \(\tau_{u}-\tau_{s}\) is

\[[0,0,1,0,\ldots,0,-1,0,\ldots,0]\,,\]

where the \(1\) and \(-1\) are in positions \(u\) and \(s\), respectively. The least squares estimate of \(\tau_{u}-\tau_{s}\) is obtained from (4.2.1) by setting \(c_{u}=1\), \(c_{s}=-1\), and all other \(c_{i}\) equal to zero, giving \[\hat{\tau}_{u}-\hat{\tau}_{s}=\overline{y}_{u.}-\overline{y}_{s.}\,\]

and the corresponding least squares estimator is \(\overline{Y}_{u.}-\overline{Y}_{s.}\). Its estimated standard error is obtained from (4.2.3) and is equal to

\[\sqrt{\widehat{\mathsf{Var}}(\overline{Y}_{u.}-\overline{Y}_{s.})}=\sqrt{ \mathsf{msE}\left((1/r_{u})+(1/r_{s})\right)}\.\]

#### 4.2.1 Battery experiment, continued

Details for the battery experiment were given in Sect. 2.5.2 (p. 24). The experimenter was interested in comparing the life per unit cost of each battery type with that of each of the other battery types. The average lives per unit cost (in minutes/dollar) for the four batteries, calculated from the data in Table 2.8, p. 27, are

\[\overline{y}_{1.}=570.75\,\quad\overline{y}_{2.}=860.50\,\quad\overline{y}_{3.}=433.00\,\quad\overline{y}_{4.}=496.25\.\]

The least squares estimates of the pairwise differences are, therefore,

\[\hat{\tau}_{1}-\hat{\tau}_{2}=-289.75\,\quad\hat{\tau}_{1}-\hat{\tau}_{3}=137.75\,\quad\hat{\tau}_{1}-\hat{\tau}_{4}=\ \ 74.50\,\] \[\hat{\tau}_{2}-\hat{\tau}_{3}=\ \ 427.50\,\quad\hat{\tau}_{2}-\hat{\tau}_{4}=364.25\,\quad\hat{\tau}_{3}-\hat{\tau}_{4}=-63.25\.\]

The estimated pairwise differences suggest that battery type 2 (alkaline, store brand) is vastly superior to the other three battery types in terms of the mean life per unit cost. Battery type 1 (alkaline, name brand) appears better than types 3 and 4, and battery type 4 (heavy duty, store brand) better than type 3 (heavy duty, name brand). We do, however, need to investigate whether or not these perceived differences might be due only to random fluctuations in the data.

In Example 3.4.2 (p. 40), the error variance was estimated to be _msE_ = 2367.71. The sample sizes were \(r_{1}=r_{2}=r_{3}=r_{4}=4\), and consequently, the estimated standard error for each pairwise comparison is equal to

\[\sqrt{2367.71\ \left(\frac{1}{4}+\frac{1}{4}\right)}=34.41\ \text{min}/\$\,.\]

It can be seen that all of the estimated pairwise differences involving battery type 2 are bigger than four times their estimated standard errors. This suggests that the perceived differences in battery type 2 and the other batteries are of sizable magnitudes and are unlikely to be due to random error. We shall formalize these comparisons in terms of confidence intervals in Example 4.4.3 later in this chapter. \(\square\)

#### 4.2.2 Treatment Versus Control

If the experimenter is interested in comparing the effects of one special treatment with the effects of each of the other treatments, then the special treatment is called the _control_. For example, a pharmaceutical experiment might involve one or more experimental drugs together with a standard drug that has been on the market for some years. Frequently, the objective of such an experiment is to compare the effect of each experimental drug with that of the standard drug but not necessarily with the effects of any of the other experimental drugs. The standard drug is then the control. If we code the control as level 1, and the experimental drugs as levels 2, 3,..., \(v\), respectively, then the contrasts of interest are \(\tau_{2}-\tau_{1}\), \(\tau_{3}-\tau_{1}\),..., \(\tau_{v}-\tau_{1}\). These contrasts are known as _treatment versus control_ contrasts. They form a subset of the pairwise differences, so we can use the same formulae for the least squares estimate and the estimatedstandard error. The contrast coefficients for the contrast \(\tau_{i}-\tau_{1}\) are [\(-1\), \(0\),..., \(0\), \(1\), \(0\),..., \(0\)], where the \(1\) is in position \(i\).

#### Difference of Averages

Sometimes the levels of the treatment factors divide naturally into two or more groups, and the experimenter is interested in the _difference of averages_ contrast that compares the average effect of one group with the average effect of the other group(s). For example, consider an experiment that is concerned with the effect of different colors of exam paper (the treatments) on students' exam performance (the response). Suppose that treatments \(1\) and \(2\) represent the pale colors, white and yellow, whereas treatments \(3\), \(4\), and \(5\) represent the darker colors, blue, green and pink. The experimenter may wish to compare the effects of light and dark colors on exam performance. One way of measuring this is to estimate the contrast \(\frac{1}{2}(\tau_{1}+\tau_{2})-\frac{1}{3}(\tau_{3}+\tau_{4}+\tau_{5})\), which is the difference of the average effects of the light and dark colors. The corresponding contrast coefficients are

\[\left[\begin{array}{ccc}1&\frac{1}{2},&-\frac{1}{3},&-\frac{1}{3},&-\frac{1}{ 3}\end{array}\right].\]

From (4.2.1) and (4.2.3), the least squares estimate would be

\[\frac{1}{2}\overline{y}_{1}.+\frac{1}{2}\overline{y}_{2}.-\frac{1}{3} \overline{y}_{3}.-\frac{1}{3}\overline{y}_{4}.-\frac{1}{3}\overline{y}_{5}.\]

with estimated standard error

\[\sqrt{\text{ms}E\left(\frac{1}{4r_{1}}+\frac{1}{4r_{2}}+\frac{1}{9r_{3}}+\frac {1}{9r_{4}}+\frac{1}{9r_{5}}\right)}.\]

#### Battery experiment, continued

In the battery experiment of Sect. 2.5.2, p. 24, battery types 1 and 2 were alkaline batteries, while types 3 and 4 were heavy duty. In order to compare the running time per unit cost of these two types of batteries, we examine the contrast \(\frac{1}{2}(\tau_{1}+\tau_{2})-\frac{1}{2}(\tau_{3}+\tau_{4})\). The least squares estimate is

\[\frac{1}{2}(570.75+860.50)-\frac{1}{2}(433.00+496.25)=251.00\;\text{min}/ \$\,,\]

suggesting that the alkaline batteries are more economical (on average by over four hours per dollar spent). The associated standard error is \(\sqrt{\text{ms}E(4/16)}=24.32\) min/$, so the estimated difference in running time per unit cost is over ten times larger than the standard error, suggesting that the observed difference is not just due to random fluctuations in the data. 

#### Trends

_Trend contrasts_ may be of interest when the levels of the treatment factor are quantitative and have a natural ordering. For example, suppose that the treatment factor is temperature and its selected levels are \(50\,^{\circ}\)C, \(75\,^{\circ}\)C, \(100\,^{\circ}\)C, coded as \(1\), \(2\), \(3\), respectively. The experimenter may wish to know whether the value of the response variable increases or decreases as the temperature increases and, if so, whether the rate of change remains constant. These questions can be answered by estimating linear and quadratic trends in the response.

The trend contrast coefficients for \(v\)_equally spaced_ levels of a treatment factor and _equal sample sizes_ are listed in Table 2 for values of \(v\) between 3 and 7. For \(v\) treatments, trends up to \((v-1)\)th order can be measured. Experimenters rarely use more than four levels for a quantitative treatment factor, since it is unusual for strong quartic and higher-order trends to occur in practice, especially within the narrow range of levels considered in a typical experiment.

Table 2 does not tabulate contrast coefficients for unequally spaced levels or for unequal sample sizes. The general method of obtaining the coefficients of the trend contrasts involves fitting a regression model to the noncoded levels of the treatment factor. It can be shown that the linear trend contrast coefficients can easily be calculated as

\[c_{i}\ =\ r_{i}(x_{i}-\overline{x}_{\cdot}),\ \text{where}\ \overline{x}_{\cdot}=(\Sigma r_{i}x_{i})/n\,, \tag{4.2.4}\]

where \(r_{i}\) is the number of observations taken on the \(i\)th uncoded level \(x_{i}\) of the treatment factor, and \(n=\Sigma r_{i}\) is the total number of observations. We are usually interested only in whether or not the linear trend is likely to be negligible, and to make this assessment, the contrast estimate is compared with its standard error. Consequently, we may multiply or divide the calculated coefficients by any integer without losing any information. When the \(r_{i}\) are all equal, the coefficients listed in Appendix 0.A.2 are obtained, possibly multiplied or divided by an integer. Expressions for quadratic and higher-order trend coefficients are more complicated (see Draper and Smith 1998, Chap. 22).

#### 0.2.3 Heart-lung pump experiment, continued

The experimenter who ran the heart-lung pump experiment of Example 3.4.1, p. 37, expected to see a linear trend in the data, since he expected the flow rate to increase as the number of revolutions per minute (rpm) of the pump head was increased. The plot of the data in Fig. 3.1 (p. 38) shows the observed flow rates at the five different levels of rpm. From the figure, it might be anticipated that the linear trend is large but higher-order trends are very small.

The five levels of rpm observed were 50, 75, 100, 125, 150, which are equally spaced. Had there been equal numbers of observations at each level, then we could have used the contrast coefficients \([-2,-1,\ 0,\ 1,\ 2]\) for the linear trend contrast and \([\ 2,-1,\ -2,-1,\ 2\ ]\) for the quadratic trend contrast as listed in Table 2 for \(v=5\) levels of the treatment factor. However, here the sample sizes were \(r_{1}=r_{3}=r_{5}=5\), \(r_{2}=3\) and \(r_{4}=2\). The coefficients for the linear trend are calculated via (4.2.4). Now \(n=\Sigma r_{i}=20\), and

\[(\Sigma r_{i}x_{i})/n\ =\ 20^{-1}\times(5(50)+3(75)+5(100)+2(125)+5(150))\ =\ 98.75\,.\]

So, we have If the coefficients are multiplied by 4, they are then integers each divisible by 5 so rather than using the calculated coefficients \([-243.75,\ -71.25,\ 6.25,\ 52.50,\ 256.25]\), we can multiply them by 4/5 and use the linear trend coefficients \([-195,\ -57,\ 5,\ 42,\ 205]\). The average flow rates (l/min) were calculated as

\[\overline{y}_{1.}=1.1352\,,\ \overline{y}_{2.}=1.7220\,,\ \overline{y}_{3.}=2.3268\,,\ \overline{y}_{4.}=2.9250\,,\ \overline{y}_{5.}=3.5292\,.\]

The least squares estimate \(\Sigma c_{i}\overline{y}_{i.}\) of the linear contrast is then

\[-195\overline{y}_{1.}-57\overline{y}_{2.}+5\overline{y}_{3.}+42\overline{y}_{4.}+205\overline{y}_{5.}=538.45\]

l/min. The linear trend certainly appears to be large. However, before drawing conclusions, we need to compare this trend estimate with its corresponding estimated standard error. The data give \(\sum\sum y_{it}^{2}=121.8176\), and we calculate the error sum of squares (3.4.5), p. 39, as \(\text{s}\text{s}\text{s}\text{E}=0.0208\,,\) giving an unbiased estimate of \(\sigma^{2}\) as

\[\text{m}\text{s}\text{E}=\text{s}\text{s}\text{E}/(n-v)=0.0208/(20-5)=0.001387\,.\]

The estimated standard error of the linear trend estimator is then

\[\sqrt{\text{m}\text{s}\text{E}\left(\frac{(-195)^{2}}{5}+\frac{(-57)^{2}}{3}+ \frac{(5)^{2}}{5}+\frac{(42)^{2}}{2}+\frac{(205)^{2}}{5}\right)}=4.988\,.\]

Clearly, the estimate of the linear trend is extremely large compared with its standard error.

Had we normalized the contrast, the linear contrast coefficients would each have been divided by

\[\sqrt{\sum c_{i}^{2}/r_{i}}=\sqrt{\frac{(-195)^{2}}{5}+\frac{(-57)^{2}}{3}+ \frac{(5)^{2}}{5}+\frac{(42)^{2}}{2}+\frac{(205)^{2}}{5}}=134.09,\]

and the normalized linear contrast estimate would have been 4.0156. The estimated standard error of all normalized contrasts is \(\sqrt{\text{m}\text{s}\text{E}}=0.03724\) for this experiment, so the normalized linear contrast estimate remains large compared with the standard error. 

### Individual Contrasts and Treatment Means

#### Confidence Interval for a Single Contrast

In this section, we obtain a formula for a confidence interval for an individual contrast. If confidence intervals for more than one contrast are required, then the multiple comparison methods of Sect. 4.4 should be used instead. We give the formula first, and the derivation afterwards. A \(100(1-\alpha)\%\) confidence interval for the contrast \(\Sigma c_{i}\tau_{i}\) is

\[\sum c_{i}\overline{y}_{i.}-t_{n-v,\alpha/2}\,\sqrt{\text{m}\text{s}\text{E} \sum c_{i}^{2}/r_{i}}\ \leq\ \sum c_{i}\tau_{i} \tag{4.3.5}\]

\[\leq\sum c_{i}\overline{y}_{i.}+t_{n-v,\alpha/2}\,\sqrt{\text{m}\text{s}\text{ E}\sum c_{i}^{2}/r_{i}}\,.\]

We can write this more succinctly as 

[MISSING_PAGE_FAIL:98]

Consider the heart-lung pump experiment of Examples 3.4.1 and 4.2.3, p. 37 and 73. The least squares estimate of the difference in fluid flow at 75 rpm and 50 rpm (levels 2 and 1 of the treatment factor, respectively) is

\[\Sigma c_{i}\overline{y}_{i.}=\overline{y}_{2.}-\overline{y}_{1.}=0.5868\]

l/min. Since there were \(r_{2}=5\) observations at 75 rpm and \(r_{1}=3\) observations at 50 rpm, and msE = 0.001387, the estimated standard error of this contrast is

\[\sqrt{msE\ \Sigma c_{i}^{2}/r_{i}}=\sqrt{0.001387\ \left(\frac{1}{3}+\frac{1}{5} \right)}=0.0272\,1/\text{min}\.\]

Using this information, together with \(t_{15,0.025}=2.131\), we obtain from (4.3.6) a 95% confidence interval (in units of l/min) for \(\tau_{2}-\tau_{1}\) as

\[(0.5868\pm(2.131)(0.0272)) = (0.5288,\,0.6448)\.\]

This tells us that with 95% confidence, the fluid flow at 75 rpm of the pump is between 0.53 and 0.64 liters per minute greater than at 50 rpm. 

_Confidence bounds_, or one-sided confidence intervals, can be derived in the same manner as two-sided confidence intervals. For the completely randomized design and one-way analysis of variance model (3.3.1), a 100(\(1-\alpha\))% _upper confidence bound_ for \(\sum c_{i}\tau_{i}\) is

\[\sum c_{i}\tau_{i}<\sum c_{i}\overline{y}_{i.}+t_{df,\alpha}\,\sqrt{msE\sum c_ {i}^{2}/r_{i}}\, \tag{4.3.10}\]

and a 100(\(1-\alpha\))% _lower confidence bound_ for \(\sum c_{i}\tau_{i}\) is

\[\sum c_{i}\tau_{i}>\sum c_{i}\overline{y}_{i.}-t_{df,\alpha}\,\sqrt{msE\sum c_ {i}^{2}/r_{i}}\, \tag{4.3.11}\]

where \(t_{df,\alpha}\) is the percentile of the \(t\) distribution with \(df\) degrees of freedom and probability \(\alpha\) in the right-hand tail.

#### Confidence Interval for a Single Treatment Mean

For the one-way analysis of variance model (3.3.1), the true mean response \(\mu+\tau_{s}\) of the \(s\)th level of a treatment factor was shown in Sect. 3.4 to be estimable with least squares estimator \(\overline{Y}_{s.}\). Although one is unlikely to be interested in only one of the treatment means, we can obtain a confidence interval as follows.

Since \(\overline{Y}_{s.}\sim N(\mu+\tau_{s},\,\sigma^{2}/r_{s})\) for model (3.3.1), we can follow the same steps as those leading to (4.3.6) and obtain a 100(\(1-\alpha\))% confidence interval for \(\mu+\tau_{s}\) as

\[\mu+\tau_{s}\in(\overline{y}_{s.}\pm t_{df,\alpha/2}\sqrt{msE/r_{s}}). \tag{4.3.12}\]

#### Example 4.3.2 Heart-lung pump experiment, continued

Suppose that the experimenter had required a 99% confidence interval for the true average fluid flow (\(\mu+\tau_{3}\)) for the heart-lung pump experiment of Example 3.4.1, p. 37, when the revolutions per minute of the pump are set to 100 rpm. Using (4.3.12) and \(r_{3}=5\), \(\overline{y}_{3.}=2.3268\), \(\text{msE}=0.001387\), \(n-v=20-5\), and \(t_{15,0.005}=2.947\), the 99% confidence interval for \(\mu+\tau_{3}\) is

\[\mu+\tau_{3}\ \in\ \ (2.3268\pm(2.947)(0.01666))\ \ =\ \ (2.2777,\,2.3759)\.\]

So, with 99% confidence, the true average flow rate at 100 rpm of the pump is believed to be between 2.28 and 2.38 l/min. 

#### Hypothesis Test for a Single Contrast or Treatment Mean

The outcome of a hypothesis test can be deduced from the corresponding confidence interval in the following way. The null hypothesis \(H_{0}:\Sigma c_{i}\tau_{i}=h\) will be rejected at significance level \(\alpha\) in favor of the two-sided alternative hypothesis \(H_{A}:\Sigma c_{i}\tau_{i}\neq h\) if the corresponding confidence interval for \(\Sigma c_{i}\tau_{i}\) fails to contain \(h\). For example, the 95% confidence interval for \(\tau_{2}-\tau_{1}\) in Example 4.3.1 does not contain zero, so the hypothesis \(H_{0}:\tau_{2}-\tau_{1}=0\) (that the flow rates are the same at 50 and 75 rpm) would be rejected at significance level \(\alpha=0.05\) in favor of the alternative hypothesis (that the flow rates are not equal).

We can make this more explicit, as follows. Suppose we wish to test the hypothesis \(H_{0}:\Sigma c_{i}\tau_{i}=0\) against the alternative hypothesis \(H_{A}\colon\Sigma c_{i}\tau_{i}\neq 0\). The interval (4.3.6) fails to contain 0 if the absolute value of \(\Sigma c_{i}\overline{y}_{i.}\) is bigger than \(t_{n-v,\alpha/2}\sqrt{\text{msE}}\;\Sigma c_{i}^{2}/r_{i}\). Therefore, the rule for testing the null hypothesis against the alternative hypothesis is

\[\text{reject }H_{0}\text{ if }\left|\frac{\sum c_{i}\overline{y}_{i.}}{\sqrt{ \text{msE}}\sum c_{i}^{2}/r_{i}}\right|>t_{n-v,\alpha/2}\, \tag{4.3.13}\]

where \(|\ |\) denotes absolute value. We call such rules _decision rules_. If \(H_{0}\) is rejected, then \(H_{A}\) is automatically accepted. The test statistic can be squared, so that the decision rule becomes

\[\text{reject }H_{0}\text{ if }\frac{\left(\sum c_{i}\overline{y}_{i.}\right)^{2}}{ \text{msE}\sum c_{i}^{2}/r_{i}}>t_{n-v,\alpha/2}^{2}=F_{1,n-v,\alpha}\,\]

and the \(F\) distribution can be used instead of the \(t\) distribution. Notice that the test statistic is the square of the normalized contrast estimate divided by msE. We call the quantity

\[\text{ssc}=\frac{\left(\sum c_{i}\overline{y}_{i.}\right)^{2}}{\sum c_{i}^{2} /r_{i}} \tag{4.3.14}\]

the _sum of squares for the contrast_, or _contrast sum of squares_ (even though it is the "sum" of only one squared term). The decision rule can be more simply expressed as

\[\text{reject }H_{0}\text{ if }\frac{\text{ssc}}{\text{msE}}>F_{1,n-v,\alpha}. \tag{4.3.15}\]For future reference, we can see that the general form of ssc/ms\(E\) is

\[\frac{\text{ssc}}{\text{ms}E}=\frac{\left(\sum c_{i}\tilde{\tau}_{i}\right)^{2}}{ \widetilde{\text{Var}}\left(\sum c_{i}\tilde{\tau}_{i}\right)}\,. \tag{4.3.16}\]

The above test is a two-tailed test, since the null hypothesis will be rejected for both large and small values of the contrast. One-tailed tests can be derived also, as follows.

The decision rule for the test of \(H_{0}:\Sigma c_{i}\tau_{i}=0\) against the one-sided alternative hypothesis \(H_{A}:\sum c_{i}\tau_{i}>0\) is

\[\text{reject }H_{0}\text{ if }\frac{\sum c_{i}\overline{y}_{i.}}{\sqrt{\text{ms}E \sum c_{i}^{2}/r_{i}}}>t_{n-v,\alpha}\,. \tag{4.3.17}\]

The outcome of this test can be deduced from the appropriate one-sided confidence bound. In particular, the null hypothesis will be rejected at significance level \(\alpha\) if the corresponding \(100(1-\alpha)\)% lower confidence bound for \(\sum c_{i}\tau_{i}\) in Eq. (4.3.11) is above zero so excludes zero.

Similarly, for the one-sided alternative hypothesis \(H_{A}:\sum c_{i}\tau_{i}<0\), the decision rule is

\[\text{reject }H_{0}\text{ if }\frac{\sum c_{i}\overline{y}_{i.}}{\sqrt{\text{ms }E\sum c_{i}^{2}/r_{i}}}<-t_{n-v,\alpha}\,. \tag{4.3.18}\]

Here the null hypothesis will be rejected at significance level \(\alpha\) if the corresponding \(100(1-\alpha)\)% upper confidence bound for \(\sum c_{i}\tau_{i}\) in Eq. (4.3.10) is below zero so excludes zero.

If the hypothesis test concerns a single treatment mean, for example, \(H_{0}:\mu+\tau_{s}=0\), then the decision rules (4.3.13)-(4.3.18) are modified by setting \(c_{s}\) equal to one and all the other \(c_{i}\) equal to zero.

#### Filter experiment

Lorenz et al. (1982) describe an experiment that was carried out to determine the relative performance of seven membrane filters in supporting the growth of bacterial colonies. The seven filter types are regarded as the seven levels of the treatment factor and are coded 1, 2,..., 7. Filter types 1, 4, and 7 were received preferilized. Several different types of data were collected, but the only data considered here are the colony counts of fecal coliforms from a sample of Olentangy River water (August 1980) that grew on each filter. Three filters of each type were observed and the average colony counts1 were

\[\overline{y}_{1.}=36.0,\ \overline{y}_{2.}=18.0,\ \overline{y}_{3.}=27.7,\ \overline{y}_{4.}=28.0,\ \overline{y}_{5.}=28.3,\ \overline{y}_{6.}=37.7,\ \overline{y}_{7.}=30.3\,.\]

Footnote 1: Reprinted from Journal AWWA, Vol. 74, No. 8 (August 1982), by permission. Copyright © 1982, American Water Works Association.

The mean squared error was \(m\text{s}E=21.6\). Suppose we wish to test the hypothesis that the preferilized filters do not differ from the nonpresterilized filters in terms of the average colony counts, against a two-sided alternative hypothesis that they do differ. The hypothesis of interest involves a difference of averages contrast, that is,

\[H_{0}:\frac{1}{3}(\tau_{1}+\tau_{4}+\tau_{7})-\frac{1}{4}(\tau_{2}+\tau_{3}+ \tau_{5}+\tau_{6})=0\,.\]From (4.3.15), the decision rule is to reject \(H_{0}\) if

\[\frac{ssc}{msE}=\ \frac{\left[\frac{\left[\frac{1}{3}(\overline{y}_{1}.+\overline {y}_{4}.+\overline{y}_{7}.)-\frac{1}{4}(\overline{y}_{2}.+\overline{y}_{3}.+ \overline{y}_{5}.+\overline{y}_{6}.)\right]^{2}}{msE\left[\frac{(\frac{1}{3})^ {2}}{3}+\frac{(\frac{1}{3})^{2}}{3}+\frac{(\frac{1}{3})^{2}}{3}+\frac{(-\frac{1 }{3})^{2}}{3}+\frac{(-\frac{1}{3})^{2}}{3}+\frac{(-\frac{1}{3})^{2}}{3}+\frac{ (-\frac{1}{3})^{2}}{3}\right]}>F_{1,14,\alpha}\.\]

Selecting a probability of a Type I error equal to \(\alpha=0.05\), this becomes

\[\text{reject }H_{0}\ \ \text{if}\ \ \frac{(3.508)^{2}}{(21.6)(0.1944)}=2.931\ >\ F_{1,14,0.05}\.\]

Since \(F_{1,14,0.05}=4.6\), there is not sufficient evidence to reject the null hypothesis, and we conclude that the presterilized filters do not differ significantly from the nonpresterilized filters when \(\alpha\) is set at \(0.05\).

Notice that the null hypothesis would be rejected if the probability of a Type I error is set a little higher than \(\alpha=0.10\), since \(F_{1,14,0.10}=3.10\). Thus, if these experimenters are willing to accept a high risk of incorrectly rejecting the null hypothesis, they would be able to conclude that there is a difference between the presterilized and the nonpresterilized filters.

A \(95\%\) confidence interval for this difference can be obtained from (4.3.6) as follows:

\[\frac{1}{3}(\tau_{1}+\tau_{4}+\tau_{7})-\frac{1}{4}(\tau_{2}+\tau_{3}+\tau_{5} +\tau_{6})\in\left(3.508\pm t_{14,0.025}\sqrt{(21.6)(0.1944)}\right)\,\]

and since \(t_{14,0.025}=2.145\), the interval becomes

\[(3.508\pm(2.145)(2.0492))=(-0.888,7.904)\,\]

where the measurements are average colony counts. The interval contains zero, which agrees with the hypothesis test at \(\alpha=0.05\). 

#### Equivalence of Tests and Confidence Intervals (Optional)

There is a stronger relationship between hypothesis tests and confidence intervals (including both 1- and 2-sided confidence intervals) than was described in Sect. 4.3.3. As already discussed, the outcome of a hypothesis test at significance level \(\alpha\) can be deduced from the corresponding \(100(1-\alpha)\%\) confidence interval. Correspondingly, though less well known, one can conclude from a hypothesis test that the true value of the parameter is in the corresponding confidence interval, by virtue of rejecting all values outside the interval, providing more specific test conclusions than simply whether or not one rejects the null hypothesis and so believes the alternative.

To illustrate this, consider a two-tailed level-\(\alpha\) test of the null hypothesis \(H_{0}:\sum c_{i}\tau_{i}=0\) against the alternative hypothesis \(H_{A}:\sum c_{i}\tau_{i}\neq 0\). Under standard practice, only the null hypothesis \(H_{0}\) is tested at significance level \(\alpha\). If \(H_{0}\) is rejected in favor of \(H_{A}\), one simply eliminates zero as a possible value of the treatment contrast, and the hypothesis testing procedure guarantees that the probability of making a mistake by rejecting \(H_{0}:\sum c_{i}\tau_{i}=0\) when it is true is at most \(\alpha\).

Expanding upon standard practice, suppose one not only tests \(H_{0}\); rather, suppose one conducts a standard two-tailed level-\(\alpha\) test of the null hypothesis \(H_{0b}:\sum c_{i}\tau_{i}=b\) against the alternative hypothesis \(H_{Ab}:\sum c_{i}\tau_{i}\neq b\) for _each_ real number \(b\). Then the probably of rejecting \(H_{0}:\sum c_{i}\tau_{i}=0\) if it is true is still controlled to be \(\alpha\). Moreover, even though this expanded testing procedure involves conducting an infinite number of tests rather than only one, the probability of making _any_ false rejections--namely, of falsely rejecting any true null hypothesis \(H_{0b}\)--is still at most \(\alpha\). This follows from the _partitioning principle_, (see Finner and Strassburger 2002, and references therein). In particular, because the sets \(\{b\}\) partition the set of real numbers, \(H_{0b}\) is only true for exactly one value of \(b\), \(b^{*}\) say. So, one can only make a mistake by rejecting the only true null hypothesis \(H_{0b^{*}}\), and the probability of rejecting \(H_{0b^{*}}\) is \(\alpha\). Thus, in terms of error rates, there is no additional cost in testing infinitely many hypothesis \(H_{0b}\) instead of just one.

Furthermore, as we know, the null hypothesis \(H_{0b}\) will be rejected at level-\(\alpha\) precisely for those values \(b\) outside the 100(\(1-\alpha\))% confidence interval for \(\sum c_{i}\tau_{i}\). In other words, all values of \(\sum c_{i}\tau_{i}\) outside of the 100(\(1-\alpha\))% confidence interval are rejected at simultaneous significance level \(\alpha\). Hence, one can conclude from this extended test that the true value of \(\sum c_{i}\tau_{i}\) is in the corresponding 100(\(1-\alpha\))% confidence interval for \(\sum c_{i}\tau_{i}\). This is true whether or not one rejects \(H_{0}\), providing a more specific conclusion than simply rejecting the null hypothesis or not.

For example, if one does reject \(H_{0}:\sum c_{i}\tau_{i}=0\) at significance level \(\alpha\), then one can conclude with Type I error probability, \(\alpha\) not only that \(\sum c_{i}\tau_{i}\neq 0\) but also more specifically that the true value of \(\sum c_{i}\tau_{i}\) is in the corresponding 100(\(1-\alpha\))% confidence interval for \(\sum c_{i}\tau_{i}\), where this confidence interval will consist only of positive values if \(H_{0}\) is rejected and \(\sum c_{i}\hat{\tau}_{i}>0\), or only of negative values if \(H_{0}\) is rejected and \(\sum c_{i}\hat{\tau}_{i}<0\). On the other hand, if one fails to reject \(H_{0}\), one can still conclude that the true value of \(\sum c_{i}\tau_{i}\) is in the corresponding 100(\(1-\alpha\))% confidence interval for \(\sum c_{i}\tau_{i}\), but this confidence interval will include zero as a possible value of the treatment contrast.

The analogous equivalence exists between one-sided tests and corresponding confidence bounds. Consider for example the standard level-\(\alpha\) test of \(H_{0}:\Sigma c_{i}\tau_{i}=0\) against the one-sided alternative hypothesis \(H_{A}:\sum c_{i}\tau_{i}>0\). More broadly, one can conduct a standard one-tailed \(\alpha\)-level test of the null hypothesis \(H_{0b}:\sum c_{i}\tau_{i}=b\) against the alternative hypothesis \(H_{Ab}:\sum c_{i}\tau_{i}>b\) for each real number \(b\). In so doing, \(H_{0b}:\sum c_{i}\tau_{i}=b\) will be rejected for exactly those values of \(b\) that are below the 100(\(1-\alpha\))% lower confidence bound for \(\sum c_{i}\tau_{i}\) given in Eq. (4.3.11). In other words, the values of \(\sum c_{i}\tau_{i}\) rejected at level \(\alpha\) are exactly the values outside of the 100(\(1-\alpha\))% (one-sided) confidence interval. Consequently, whether or not \(H_{0}\) is rejected, one can conclude that the true value of \(\sum c_{i}\tau_{i}\) is above the 100(\(1-\alpha\))% lower confidence bound for \(\sum c_{i}\tau_{i}\), and one will reject \(H_{0}\) and conclude \(\sum c_{i}\tau_{i}>0\) exactly when the lower confidence bound is positive.

Similarly, for testing \(H_{0}:\Sigma c_{i}\tau_{i}=0\) against \(H_{A}:\sum c_{i}\tau_{i}<0\) at level \(\alpha\), one can expand this by conducting a standard one-tailed level-\(\alpha\) test of \(H_{0b}:\sum c_{i}\tau_{i}=b\) against \(H_{Ab}:\sum c_{i}\tau_{i}<b\) for each real number \(b\). Then the values of \(\sum c_{i}\tau_{i}\) rejected at level \(\alpha\) are exactly the values above the 100(\(1-\alpha\))% upper confidence bound given in Eq. (4.3.10). Consequently, whether or not \(H_{0}\) is rejected, one can conclude that the true value of \(\sum c_{i}\tau_{i}\) is below its 100(\(1-\alpha\))% upper confidence bound. Also, one will reject \(H_{0}\) and conclude \(\sum c_{i}\tau_{i}<0\) exactly when the upper confidence bound is negative.

The equivalence between testing and confidence intervals illustrated above applies quite broadly, including for example to one-step multiple comparison procedures such as those considered in the next section (as discussed by Voss 2008, 2010). The partitioning principle also facilitates the construction of more complicated confidence sets corresponding to stepwise multiple tests (see Stefansson et al. 1988).

### Methods of Multiple Comparisons

#### Multiple Confidence Intervals

Often, the most useful analysis of experimental data involves the calculation of a number of different confidence intervals, one for each of several contrasts or treatment means. The confidence level for a single confidence interval is based on the probability, like (4.3.9), that the random interval will be "correct" (meaning that the random interval will contain the true value of the contrast or function).

It is shown below that when several confidence intervals are calculated, the probability that they are all simultaneously correct can be alarmingly small. Similarly, when several hypotheses are to be tested, the probability that at least one hypothesis is incorrectly rejected can be uncomfortably high. Much research has been done over the years to find ways around these problems. The resulting techniques are known as _methods of multiple comparison_, the intervals are called _simultaneous confidence intervals_, and the tests are called _simultaneous hypothesis tests_.

Suppose an experimenter wishes to calculate \(m\) confidence intervals, each having a \(100(1-\alpha^{*})\%\) confidence level. Then each interval will be individually correct with probability \(1-\alpha^{*}\). Let \(S_{j}\) be the event that the \(j\)th confidence interval will be correct and \(\overline{S}_{j}\) the event that it will be incorrect (\(j=1,\ldots,m\)). Then, using the standard rules for probabilities of unions and intersections of events, it follows that

\[P(S_{1}\cap S_{2}\cap\cdots\cap S_{m})=1-P(\overline{S}_{1}\cup\overline{S}_{2 }\cup\cdots\cup\overline{S}_{m})\;.\]

This says that the probability that all of the intervals will be correct is equal to one minus the probability that at least one will be incorrect. If \(m=2\),

\[P(\overline{S}_{1}\cup\overline{S}_{2}) = P(\overline{S}_{1})+P(\overline{S}_{2})-P(\overline{S}_{1}\cap \overline{S}_{2})\] \[\leq P(\overline{S}_{1})+P(\overline{S}_{2})\;.\]

A similar result, which can be proved by mathematical induction, holds for any number \(m\) of events, that is,

\[P(\overline{S}_{1}\cup\overline{S}_{2}\cup\cdots\cup\overline{S}_{m})\leq\sum_ {j}P(\overline{S}_{j})\;,\]

with equality if the events \(\overline{S}_{1}\), \(\overline{S}_{2}\),..., \(\overline{S}_{m}\) are mutually exclusive. Consequently,

\[P(S_{1}\cap S_{2}\cap\cdots\cap S_{m})\geq 1-\sum_{j}P(\overline{S}_{j})=1-m \alpha^{*}\;; \tag{4.4.19}\]

that is, the probability that the \(m\) intervals will simultaneously be correct is at least \(1-m\alpha^{*}\). The probability \(m\alpha^{*}\)is called the _overall significance level_ or _experimentwise error rate_. A typical value for \(\alpha^{*}\) for a single confidence interval is \(0.05\), so the probability that six confidence intervals each calculated at a \(95\%\) individual confidence level will simultaneously be correct is at least \(0.7\). Although "at least" means "bigger than or equal to," it is not known in practice how much bigger than \(0.7\) the probability might actually be. This is because the degree of overlap between the events \(\overline{S}_{1}\), \(\overline{S}_{2}\),..., \(\overline{S}_{m}\) is generally unknown. The probability "at least \(0.7\)" translates into an _overall confidence level_ of "at least \(70\%\)" when the responses are observed. Similarly, if an experimenter calculates ten confidence intervals each having individual confidence level \(95\%\), then the simultaneous confidence level for theten intervals is at least 50%, which is not very informative. As \(m\) becomes larger the problem becomes worse, and when \(m\geq 20\), the overall confidence level is at least 0%, clearly a useless assertion!

Similar comments apply to the hypothesis testing situation. If hypotheses for \(m\) different contrasts are to be tested, each at significance level \(\alpha^{*}\), then the probability that at least one hypothesis is incorrectly rejected is at most \(m\alpha^{*}\).

Various methods have been developed to ensure that the overall confidence level is not too small and the overall significance level is not too high. Some methods are completely general, that is, they can be used for any set of estimable functions, while others have been developed for very specialized purposes such as comparing each treatment with a control. Which method is best depends on which contrasts are of interest and the number of contrasts to be investigated. In this section, four methods are discussed that control the overall confidence level and overall significance level. The terms _preplanned contrasts_ and _data snooping_ occur in the summary of methods and the subsequent subsections. These have the following meanings. Before the experiment commences, the experimenter will have written out a checklist, highlighted the contrasts and/or treatment means that are of special interest, and designed the experiment in such a way as to ensure that these are estimable with as small variances as possible. These are the preplanned contrasts and means. After the data have been collected, the experimenter usually looks carefully at the data to see whether anything unexpected has occurred. One or more unplanned contrasts may turn out to be the most interesting, and the conclusions of the experiment may not be as anticipated. Allowing the data to suggest additional interesting contrasts is called data snooping.

The following summary is written in terms of confidence intervals, but it also applies to hypothesis tests. A shorter confidence interval corresponds to a more powerful hypothesis test. The block designs mentioned in the summary will be discussed in Chaps. 10 and 11.

**Summary of Multiple Comparison Methods**

1. **Bonferroni method for preplanned comparisons** Applies to any \(m\) preplanned estimable contrasts or functions of the parameters. Gives shorter confidence intervals than the other methods listed if \(m\) is small. Can be used for any design. Cannot be used for data snooping.
2. **Scheffe method for all comparisons** Applies to any \(m\) estimable contrasts or functions of the parameters. Gives shorter intervals than Bonferroni's method if \(m\) is large. Allows data snooping. Can be used for any design.
3. **Tukey method for all pairwise comparisons** Best for all pairwise comparisons. Can be used for completely randomized designs, randomized block designs, and balanced incomplete block designs. Is believed to be applicable (conservative) for other designs as well. Can be extended to include all contrasts, but Scheffe's method is generally better for these.
4. **Dunnett method for treatment-versus-control comparisons** Best for all treatment-versus-control contrasts. Can be used for completely randomized designs, randomized block designs, and balanced incomplete block designs.

Details of confidence intervals obtained by each of the above methods are given in Sects. 4.4.2-4.4.6. The terminology "a set of simultaneous \(100(1-\alpha)\)% confidence intervals" will always refer to the fact that the _overall_ confidence level for a set of contrasts or treatment means is (at least) \(100(1-\alpha)\)%. Each of the four methods discussed gives confidence intervals of the form \[\sum_{i}c_{i}\tau_{i}\in\left(\sum_{i}c_{i}\hat{\tau}_{i}\pm w\sqrt{\widehat{\rm Var }(\Sigma c_{i}\hat{\tau}_{i})}\right), \tag{4.4.20}\]

where \(w\), which we call the _critical coefficient_, depends on the method, on \(v\), on the number of confidence intervals calculated, and on the number of error degrees of freedom. The term

\[\text{msd}=w\sqrt{\widehat{\rm Var}(\Sigma c_{i}\hat{\tau}_{i})}\,,\]

which is added and subtracted from the least squares estimate in (4.4.20), is called the _minimum significant difference_, because if the estimate is larger than \(\text{msd}\), the confidence interval excludes zero, and the contrast is significantly different from zero.

#### Bonferroni Method for Preplanned Comparisons

The inequality (4.4.19) shows that if \(m\) simultaneous confidence intervals are calculated for preplanned contrasts, and if each confidence interval has confidence level \(100(1-\alpha^{*})\%\), then the overall confidence level is greater than or equal to \(100(1-m\alpha^{*})\%\). Thus, an experimenter can ensure that the overall confidence level is at least \(100(1-\alpha)\%\) by setting \(\alpha^{*}=\alpha/m\). This is known as the Bonferroni method for simultaneous confidence intervals. Replacing \(\alpha\) by \(\alpha/m\) in the formula (4.3.6), p. 75, for an individual confidence interval, we obtain a formula for a set of simultaneous \(100(1-\alpha)\%\) confidence intervals for \(m\) preplanned contrasts \(\Sigma c_{i}\tau_{i}\) in a completely randomized design with the one-way analysis of variance model (3.3.1), as

\[\sum_{i}c_{i}\tau_{i}\in\left(\sum_{i}c_{i}\overline{y}_{i}\pm t_{n-v,\alpha/ (2m)}\sqrt{\text{ms}E\,\sum_{i}c_{i}^{2}/r_{i}}\right)\,, \tag{4.4.21}\]

where the critical coefficient, \(w_{B}\), is

\[w_{B}=t_{n-v,\alpha/(2m)}\,.\]

Since \(\alpha/(2m)\) is likely to be an atypical value, the percentiles \(t_{n-v,\alpha/(2m)}\) may need to be obtained by use of a computer package, or by approximate interpolation between values in Table A.4, or by using the following approximate formula due to Peiser (1943):

\[t_{df,\alpha/(2m)}\approx z_{\alpha/(2m)}+(z_{\alpha/(2m)}^{3}+z_{\alpha/(2m) })/(4(a))\,, \tag{4.4.22}\]

where \(df\) is the error degrees of freedom (equal to \(n-v\) in the present context), and where \(z_{\alpha/(2m)}\) is the percentile of the standard normal distribution corresponding to a probability of \(\alpha/(2m)\) in the right hand tail. The standard normal distribution is tabulated in Table A.3 and covers the entire range of values for \(\alpha/(2m)\). When \(m\) is very large, \(\alpha/(2m)\) is very small, possibly resulting in extremely wide simultaneous confidence intervals. In this case, the Scheffe or Tukey methods described in the following subsections would be preferred.

If some of the \(m\) simultaneous intervals are for true mean responses \(\mu+\tau_{s}\), then the required intervals are of the form (4.3.12), p. 76, with \(\alpha\) replaced by \(\alpha/m\), that is,

\[\mu+\tau_{s}\in\left(\overline{y}_{s.}\pm t_{n-v,\alpha/(2m)}\sqrt{\text{ms}E /r_{s}}\right)\,. \tag{4.4.23}\]Similarly, replacing \(\alpha\) by \(\alpha/m\) in (4.3.15), a set of \(m\) null hypotheses, each of the form

\[H_{0}:\sum_{i=1}^{v}c_{i}\tau_{i}=0\,,\]

can be tested against their respective two-sided alternative hypotheses at overall significance level \(\alpha\) using the set of decision rules each of the form

\[\text{reject }H_{0}\text{ if }\frac{\text{ssc}}{\text{msE}}>F_{1,df,\alpha/m}\,. \tag{4.4.24}\]

Each null hypothesis is rejected if the corresponding confidence interval (4.4.21) excludes zero, and each confidence interval consists of exactly those values that would not be rejected by a two-tailed test.

Note that Bonferroni's method can be use only for _preplanned_ contrasts and means. An experimenter who looks at the data and then proceeds to calculate simultaneous confidence intervals for the few contrasts that look interesting has effectively calculated a very large number of intervals. This is because the interesting contrasts are usually those that seem to be significantly different from zero, and a rough mental calculation of the estimates of a large number of contrasts has to be done to identify these interesting contrasts. Scheffe's method should be used for contrasts that were selected after the data were examined.

#### _Example 4.4.1_ Filter experiment, continued

The filter experiment was described in Example 4.3.3, p. 78. Suppose that before the data had been collected, the experimenters had planned to calculate a set of simultaneous 90% confidence intervals for the following \(m=3\) contrasts. These contrasts have been selected based on the details of the original study described by Lorenz et al. (1982).

1. \(\frac{1}{3}(\tau_{1}+\tau_{4}+\tau_{7})-\frac{1}{4}(\tau_{2}+\tau_{3}+\tau_{5 }+\tau_{6})\). This contrast measures the difference in the average effect of the presterilized and the nonpresterilized filter types. This was used in Example 4.3.3 to illustrate a hypothesis test for a single contrast.
2. \(\frac{1}{2}(\tau_{1}+\tau_{7})-\frac{1}{5}(\tau_{2}+\tau_{3}+\tau_{4}+\tau_{5 }+\tau_{6})\). This contrast measures the difference in the average effects of two filter types with gradated pore size and five filter types with uniform pore size.
3. \(\frac{1}{6}(\tau_{1}+\tau_{2}+\tau_{4}+\tau_{5}+\tau_{6}+\tau_{7})-\tau_{3}\). This contrast is the difference in the average effect of the filter types that are recommended by their manufacturers for bacteriophage analysis of water and the single filter type that is recommended for sterility testing of pharmaceutical or cosmetic products.

From Example 4.3.3, we know that

\[\overline{y}_{1.}=36.0,\ \ \ \overline{y}_{2.}=18.0,\ \ \ \overline{y}_{3.}=27.7,\ \ \ \ \overline{y}_{4.}=28.0,\ \ \ \overline{y}_{5.}=28.3,\] \[\overline{y}_{6.}=37.7,\ \ \ \overline{y}_{7.}=30.3,\ \ \ \ r_{i}=3,\ \ \ \ \ \ \text{msE}=21.6.\]

The formula for each of the three preplanned simultaneous 90% confidence intervals is given by (4.4.21) and involves the critical coefficient \(w_{B}=t_{14,(0.1)/6}=t_{14,0.0167}\), which is not available in Table A.4. Either the value can be calculated from a computer program, or an approximate value can be obtained from formula (4.4.22) as

\[t_{14,0.0167}\approx 2.128+(2.128^{3}+2.128)/(4\times 14)=2.338.\]The minimum significant difference for each of the three simultaneous 90% confidence intervals is

\[\text{msd}\;=\;2.338\sqrt{(21.6)\;\sum c_{i}^{2}/3}\;=\;6.2735\sqrt{\sum c_{i}^{2}}\;.\]

Thus, for the first interval, we have

\[\text{msd}\;=\;6.2735\sqrt{3\left(\frac{1}{9}\right)+4\left(\frac{1}{16} \right)}\;=\;4.791\;,\]

giving the interval as

\[\frac{1}{3}(\tau_{1}+\tau_{4}+\tau_{7})-\frac{1}{4}(\tau_{2}+\tau_{3}+\tau_{5}+ \tau_{6})\in(3.508\pm 4.791)\;\;=\;\;(-1.283,\;8.299)\;.\]

Calculating the minimum significant differences separately for the other two confidence intervals leads to

\[\frac{1}{2}(\tau_{1}+\tau_{7})-\frac{1}{5}(\tau_{2}+\tau_{3}+\tau_{4}+\tau_{5}+ \tau_{6})\in(-0.039,\;10.459)\;;\]

\[\frac{1}{6}(\tau_{1}+\tau_{2}+\tau_{4}+\tau_{5}+\tau_{6}+\tau_{7})-\tau_{3}\in( -4.759,\;8.793)\;.\]

Notice that all three intervals include zero, although the second is close to excluding it. Thus, at overall significance level \(\alpha=0.10\), we would fail to reject the hypothesis that there is no difference in average colony counts between the presterilized and nonpresterilized filters, nor between filter 3 and the others, nor between filters with gradated and uniform pore sizes. At a slightly higher significance level, we would reject the hypothesis that the filters with gradated pore size have the same average colony counts as those with uniform pore size. The same conclusion would be obtained if (4.4.24) were used to test simultaneously, at overall level \(\alpha=0.10\), the hypotheses that each of the three contrasts is zero. The confidence interval, whether utilized directly or obtained as the conclusion of the test, has the added benefit that it provides more specific conclusions. For example, we can say with overall 90% confidence that on average, the filters with gradated pore size give rise to colony counts up to 10.4 greater than the filters with uniform pore sizes. 

#### 4.4.3 Scheffe Method of Multiple Comparisons

The main drawbacks of the Bonferroni method of multiple comparisons are that the \(m\) contrasts to be examined must be preplanned and the confidence intervals can become very wide if \(m\) is large. Scheffe's method, on the other hand, provides a set of simultaneous 100(\(1-\alpha\))% confidence intervals whose widths are determined only by the number of treatments and the number of observations in the experiment, no matter how many contrasts are of interest. The two methods are compared directly later in this section.

Scheffe's method is based on the fact that every possible contrast \(\Sigma c_{i}\tau_{i}\) can be written as a linear combination of the set of \((v-1)\) treatment versus control contrasts, \(\tau_{2}-\tau_{1}\), \(\tau_{3}-\tau_{1}\),..., \(\tau_{v}-\tau_{1}\). (We leave it to the reader to check that this is true.) Once the experimental data have been collected, it is possible to find a 100(\(1-\alpha\))% confidence region for these \(v-1\) treatment-versus-control contrasts.

[MISSING_PAGE_FAIL:109]

The formula for a set of Scheffe 90% simultaneous confidence intervals is given by (4.4.25) with \(\alpha=0.10\). Since \(v=7\), \(n=21\), and \(\text{ms}E=21.6\) for the filter experiment, the minimum significant difference for each interval becomes

\[\text{ms}d=\sqrt{6F_{6,14,0.10}}\sqrt{21.6\ \Sigma c_{i}^{2}/3}=9.837\sqrt{ \Sigma c_{i}^{2}}\,.\]

The twelve simultaneous 90% confidence intervals are then

\[\frac{1}{3}(\tau_{1}+\tau_{4}+\tau_{7})-\frac{1}{3}(\tau_{3}+\tau _{5}+\tau_{6})\] \[\in \left((31.43-31.23)\ \pm\ 9.837\sqrt{3\left(\frac{1}{9}\right)+3 \left(\frac{1}{9}\right)}\right)\] \[= \left(-7.83,\,8.23\right),\]

\[\frac{1}{2}(\tau_{1}+\tau_{7})-\frac{1}{4}(\tau_{3}+\tau_{4}+ \tau_{5}+\tau_{6})\in\left(-5.79,\,11.24\right),\] \[\frac{1}{5}(\tau_{1}+\tau_{4}+\tau_{5}+\tau_{6}+\tau_{7})-\tau_{ 3}\in\left(-6.42,\,15.14\right),\]

\[\tau_{1}-\tau_{3}\in \left(-5.61,\,22.21\right),\ \ \tau_{6}-\tau_{3}\in\left(-3.91,\,23.91\right),\] \[\tau_{1}-\tau_{4}\in \left(-5.91,\,21.91\right),\ \ \tau_{6}-\tau_{4}\in\left(-4.21,\,23.61\right),\] \[\tau_{1}-\tau_{5}\in \left(-6.21,\,21.61\right),\ \ \tau_{6}-\tau_{5}\in\left(-4.51,\,23.31\right),\] \[\tau_{1}-\tau_{6}\in \left(-15.61,\,12.21\right),\ \ \tau_{6}-\tau_{7}\in\left(-6.51,\,21.31\right),\] \[\tau_{1}-\tau_{7}\in \left(-8.21,\,19.61\right).\]

These intervals are all fairly wide and all include zero. Consequently, at overall error rate \(\alpha=0.1\), we are unable to infer that any of the contrasts are significantly different from zero. 

#### Relationship Between Analysis of Variance and the Scheffe Method

The analysis of variance test and the Scheffe method of multiple comparisons are equivalent in the following sense. The analysis of variance test will reject the null hypothesis \(H_{0}:\tau_{1}=\tau_{2}=\cdots=\tau_{v}\) at significance level \(\alpha\) if there is at least one confidence interval among the infinite number of Scheffe simultaneous 100(\(1-\alpha\))% confidence intervals for all contrasts \(\Sigma c_{i}\tau_{i}\) that excludes zero. However, the intervals that exclude zero may not be among those for the interesting contrasts being examined.

Other methods of multiple comparisons do not relate to the analysis of variance test in this way. It is possible when using one of the other multiple comparison methods that one or more intervals in a simultaneous 100(\(1-\alpha\))% set may exclude 0, while the analysis of variance test of \(H_{0}\) is _not_ rejected at significance level \(\alpha\). Hence, if specific contrasts of interest have been identified in advance of running the experiment and a method of multiple comparisons other than Scheffe's method is to be used, then it is sensible to analyze the data using only the multiple comparison procedure.

#### Tukey Method for All Pairwise Comparisons

In some experiments, confidence intervals may be required only for pairwise difference contrasts. Tukey, in 1953, proposed a method that is specially tailored to handle this situation and that gives shorter intervals for pairwise differences than do the Bonferroni and Scheffe methods.

For the completely randomized design and the one-way analysis of variance model (3.3.1), Tukey's simultaneous confidence intervals for all pairwise comparisons \(\tau_{i}-\tau_{s}\), \(i\neq s\), with overall confidence level at least \(100(1-\alpha)\)% is given by

\[\tau_{i}-\tau_{s}\in\left((\overline{y}_{i.}-\overline{y}_{s.})\pm w_{T}\sqrt{ \text{m}\text{s}\text{E}\left(\frac{1}{r_{i}}+\frac{1}{r_{s}}\right)}\right), \tag{4.4.27}\]

where the critical coefficient \(w_{T}\) is

\[w_{T}=q_{v,n-v,\alpha}/\sqrt{2}\,,\]

and where \(q_{v,n-v,\alpha}\) is tabulated in Appendix A.8. When the sample sizes are equal (\(r_{i}=r\); \(i=1,\ldots,v\)), the overall confidence level is _exactly_\(100(1-\alpha)\)%. When the sample sizes are unequal, the confidence level is _at least_\(100(1-\alpha)\)%.

The derivation of (4.4.27) is as follows. For equal sample sizes, the formula for Tukey's simultaneous confidence intervals is based on the distribution of the statistic

\[Q=\frac{\text{max}\{T_{i}\}-\text{min}\{T_{i}\}}{\sqrt{\text{MSE}/r}}\,,\]

where \(T_{i}=\overline{Y}_{i.}-(\mu+\tau_{i})\) for the one-way analysis of variance model (3.3.1), and where \(\text{max}\{T_{i}\}\) is the maximum value of the random variables \(T_{1}\), \(T_{2}\),..., \(T_{v}\) and \(\text{min}\{T_{i}\}\) the minimum value. Since the \(\overline{Y}_{i.}\)'s are independent, the numerator of \(Q\) is the range of \(v\) independent \(N(0,\,\sigma^{2}/r)\) random variables, and is standardized by the estimated standard deviation. The distribution of \(Q\) is called the _Studentized range distribution_. The percentile corresponding to a probability of \(\alpha\) in the right-hand tail of this distribution is denoted by \(q_{v,n-v,\alpha}\), where \(v\) is the number of treatments being compared, and \(n-v\) is the number of degrees of freedom for error. Therefore,

\[P\left(\frac{\text{max}\{T_{i}\}-\text{min}\{T_{i}\}}{\sqrt{\text{MSE}/r}}\leq q _{v,n-v,\alpha}\right)=1-\alpha\,.\]

Now, if \(\text{max}\{T_{i}\}-\text{min}\{T_{i}\}\) is less than or equal to \(q_{v,n-v,\alpha}\sqrt{\text{MSE}/r}\), then it must be true that \(|T_{i}-T_{s}|\leq q_{v,n-v,\alpha}\sqrt{\text{MSE}/r}\) for _every_ pair of random variables \(T_{i}\), \(T_{s}\), \(i\neq s\). Using this fact and the above definition of \(T_{i}\), we have

\[\begin{array}{ll}1-\alpha=P\left(-q_{v,n-v,\alpha}\sqrt{\text{MSE}/r}\leq( \overline{Y}_{i.}-\overline{Y}_{s.})-(\tau_{i}-\tau_{s})\right.\\ \leq\left.q_{v,n-v,\alpha}\sqrt{\text{MSE}/r}\,,\,\text{for all}\,\,i\neq s \right)\,.\end{array}\]

Replacing \(\overline{Y}_{i.}\) by its observed value \(\overline{y}_{i.}\), and MSE by the observed value mS_E_, a set of simultaneous \(100(1-\alpha)\)% confidence intervals for all pairwise differences \(\tau_{i}-\tau_{s}\), \(i\neq s\), is given by

\[\tau_{i}-\tau_{s}\in\left((\overline{y}_{i.}-\overline{y}_{s.})\pm q_{v,n-v, \alpha}\sqrt{\text{m}\text{s}\text{E}/r}\right)\,,\]

which can be written in terms of the critical coefficient as

\[\tau_{i}-\tau_{s}\in\left((\overline{y}_{i.}-\overline{y}_{s.})\pm w_{T}\sqrt {\text{m}\text{s}\text{E}\left(\frac{1}{r}+\frac{1}{r}\right)}\right). \tag{4.4.28}\]More recently, Hayter (1984) showed that the same form of interval can be used for unequal sample sizes as in (4.4.27), and that the overall confidence level is then at least \(100(1-\alpha)\%\).

#### 4.4.3 Battery experiment, continued

In the battery experiment of Example 4.2.1 (p. 71), we considered the pairwise differences in the life lengths per unit cost of \(v=4\) different battery types, and we obtained the least squares estimates

\[\begin{array}{rllll}\hat{\tau}_{1}-\hat{\tau}_{2}=-289.75\;,&\hat{\tau}_{1}- \hat{\tau}_{3}=137.75\;,&\hat{\tau}_{1}-\hat{\tau}_{4}=\phantom{-}74.50\;,\\ \hat{\tau}_{2}-\hat{\tau}_{3}=\phantom{-}427.50\;,&\hat{\tau}_{2}-\hat{\tau}_ {4}=364.25\;,&\hat{\tau}_{3}-\hat{\tau}_{4}=-63.25\;.\end{array}\]

The standard error was \(\sqrt{\text{msE}(\frac{1}{4}+\frac{1}{4})}=34.41\), and the number of error degrees of freedom was \(n-v=(16-4)=12\). From Table A.8, \(q_{4,12,0.05}=4.20\), so \(w_{T}=4.20/\sqrt{2}\), and the minimum significant difference is

\[\text{msd}=(4.20/\sqrt{2})\;(34.41)=102.19\;.\]

Therefore, using Tukey's method, the simultaneous 95% confidence intervals for the pairwise comparisons of lifetimes per unit cost of the different battery types are

\[\tau_{1}-\tau_{2}\in(-289.75\pm 102.19)=(-391.94,-187.56),\] \[\tau_{1}-\tau_{3}\in(137.75\pm 102.19)=(35.56,\,239.94),\] \[\tau_{1}-\tau_{4}\in(-27.69,\,176.69),\qquad\tau_{2}-\tau_{3}\in(3 25.31,\,529.69),\] \[\tau_{2}-\tau_{4}\in(262.06,\,466.44),\qquad\tau_{3}-\tau_{4}\in(- 165.44,\,38.94).\]

Four of these intervals exclude zero, and one can conclude (at an overall 95% confidence level) that battery type 2 (alkaline, store brand) has the highest lifetime per unit cost, and battery type 3 (heavy duty, name brand) has lower lifetime per unit cost than does battery type 1 (alkaline, name brand). The intervals show us that with overall 95% confidence, battery type 2 is between 188 and 391 minute per dollar better than battery type 1 (the name brand alkaline battery) and even more economical than the heavy-duty brands. 

#### 4.4.4 Bonferroni, Scheffe and Tukey methods compared

Suppose that \(v=5\), \(n=35\), and \(\alpha=0.05\), and that only the 10 pairwise comparisons \(\tau_{i}-\tau_{s}\), \(i\neq s\), are of interest to the experimenter and these were specifically selected prior to the experiment (i.e., were preplanned). If we compare the critical coefficients for the three methods, we obtain

\[\text{Bonferroni}:\;w_{B} = t_{30,\,025/10} = 3.02,\] \[\text{Scheffe}:\;\;\;\;w_{S} = \sqrt{4\;F_{4,30,\,05}} = 3.28,\] \[\text{Tukey}:\;\;\;\;\;\;w_{T} = \frac{1}{\sqrt{2}}q_{5,\,30,\,05} = 2.91.\]

Since \(w_{T}\) is less than \(w_{B}\), which is less than \(w_{S}\) for this example, the Tukey intervals will be shorter than the Bonferroni intervals, which will be shorter than the Scheffe intervals.

#### Dunnett Method for Treatment-Versus-Control Comparisons

In 1955, Dunnett developed a method of multiple comparisons that is specially designed to provide a set of simultaneous confidence intervals for preplanned treatment-versus-control contrasts \(\tau_{i}-\tau_{1}\) (\(i=2,\ldots,v\)), where level 1 corresponds to the control treatment. The intervals are shorter than those given by the Scheffe, Tukey, and Bonferroni methods, but the method should not be used for any other type of contrasts.

The formulae for the simultaneous confidence intervals are based on the joint distribution of the estimators \(\overline{Y}_{i.}-\overline{Y}_{1.}\) of \(\tau_{i}-\tau_{1}\) (\(i=2,\ldots,v\)). This distribution is a special case of the multivariate \(t\) distribution and depends on the correlation between \(\overline{Y}_{i.}-\overline{Y}_{1.}\) and \(\overline{Y}_{s.}-\overline{Y}_{1.}\). For the completely randomized design, with equal numbers of observations \(r_{2}=\cdots=r_{v}=r\) on the experimental treatments and \(r_{1}=c\) observations on the control treatment, the correlation is

\[\rho=r/(c+r)\,.\]

In many experiments, the same number of observations will be taken on the control and experimental treatments, in which case \(\rho=0.5\). However, the shortest confidence intervals for comparing \(v-1\) experimental treatments with a control treatment are generally obtained when \(c/r\) is chosen to be close to \(\sqrt{v-1}\). Since we have tabulated the multivariate \(t\)-distribution only with correlation \(\rho=0.5\), we will discuss only the case \(c=r\). Other tables can be found in the book of Hochberg and Tamhane (1987), and intervals can also be obtained via some computer packages (see Sects. 4.6.2 and 4.7.2 for the SAS and R software, respectively).

If the purpose of the experiment is to determine which of the experimental treatments give a significantly higher response than the control treatment, then one-sided confidence bounds should be used. For a completely randomized design with equal sample sizes and the one-way analysis of variance model (3.3.1), Dunnett's simultaneous one-sided \(100(1-\alpha)\)% confidence bounds for treatment-versus-control contrasts \(\tau_{i}-\tau_{1}\) (\(i=2,3,\ldots,v\)) are

\[\tau_{i}-\tau_{1}\geq(\overline{y}_{i.}-\overline{y}_{1.})-w_{D1}\,\sqrt{m \text{s}E\left(\frac{2}{r}\right)}\,, \tag{4.4.29}\]

where the critical coefficient is

\[w_{D1}=t_{v-1,n-v,\alpha}^{(0.5)}\]

and where \(t_{v-1,n-v,\alpha}^{(0.5)}\) is the percentile of the maximum of a multivariate \(t\)-distribution with common correlation \(0.5\) and \(n-v\) degrees of freedom, corresponding to a Type I error probability of \(\alpha\) in the right-hand tail. The critical coefficient is tabulated in Table A.9. If the right hand side of (4.4.29) is positive, we infer that the \(i\)th experimental treatment gives a larger response than the control.

If the purpose is to determine which of the experimental treatments give a significantly lower response than the control, then the inequality is reversed, and the confidence bound becomes

\[\tau_{i}-\tau_{1}\leq(\overline{y}_{i.}-\overline{y}_{1.})+w_{D1}\,\sqrt{m \text{s}E\left(\frac{2}{r}\right)}\,. \tag{4.4.30}\]

If the right-hand side is negative, we infer that the \(i\)th experimental treatment gives a smaller response than the control.

To determine which experimental treatments are better than the control _and_ which ones are worse, two-sided intervals of the general form (4.4.20) are used as for the other multiple comparison methods. For the completely randomized design, one-way analysis of variance model (3.3.1), and equal sample sizes, the formula is

\[\tau_{i}-\tau_{1}\in\left(\overline{y}_{i,}-\overline{y}_{1,}\pm w_{D2}\,\sqrt {m{\rm s}E\left(\frac{2}{r}\right)}\right)\,, \tag{4.4.31}\]

where the critical coefficient is

\[w_{D2}=|t|_{v-1,n-v,\alpha}^{(0.5)}\]

and is the upper critical value for the maximum of the absolute values of a multivariate \(t\)-distribution with correlation \(0.5\) and \(n\,-\,v\) error degrees of freedom, corresponding to the chosen value of \(\alpha\) in the right-hand tail. The critical coefficients for equal sample sizes are provided in Table A.10.

For future reference, the general formula for Dunnett's two-sided simultaneous \(100(1-\alpha)\)% confidence intervals for treatment versus control contrasts \(\tau_{i}-\tau_{1}\) (\(i=2,3,\ldots,v\)) is

\[\tau_{i}-\tau_{1}\in\left((\hat{\tau}_{i}-\hat{\tau}_{1})\pm w_{D2}\,\sqrt{ \widetilde{\rm Var}(\hat{\tau}_{i}-\hat{\tau}_{1})}\right)\,, \tag{4.4.32}\]

and, for one-sided confidence bounds, we replace \(w_{D2}\) by \(w_{D1}\) and replace "\(\in\)" by "\(\leq\)" or "\(\geq\)." The critical coefficients are

\[w_{D2}=|t|_{v-1,df,\alpha}^{(0.5)}\,\,\,\mbox{and}\,\,\,w_{D1}=t_{v-1,df, \alpha}^{(0.5)}\]

for two-sided and one-sided intervals, respectively, where \(df\)is the number of error degrees of freedom.

#### 4.4.5 Soap experiment, continued

Suppose that as a preplanned objective of the soap experiment of Sect. 2.5.1, p. 20, the experimenter had wanted simultaneous 99% confidence intervals comparing the weight losses of the deodorant and moisturizing soaps (levels 2 and 3) with that of the regular soap (level 1). Then it is appropriate to use Dunnett's method as given in (4.4.31). From Sect. 3.7.2, \(r_{1}=r_{2}=r_{3}=4,\,\,m{\rm s}E=0.0772\), \(\hat{\tau}_{2}-\hat{\tau}_{1}=2.7350\), and \(\hat{\tau}_{3}-\hat{\tau}_{1}=2.0275\). From Table A.10, \(w_{D2}=|t|_{v-1,n-v,\alpha}^{(0.5)}=|t|_{2,9,0.01}^{(0.5)}=3.63\), so the minimum significant difference is

\[m{\rm s}d=3.63\,\sqrt{m{\rm s}E(2/4)}=0.713\,.\]

Hence, the simultaneous 99% confidence intervals are

\[\tau_{2}-\tau_{1}\in(2.7350\pm 0.713)\approx(2.022,\,3.448)\]

and

\[\tau_{3}-\tau_{1}\in(2.0275\pm 0.713)\approx(1.314,\,2.741)\,.\]

One can conclude from these intervals (with overall 99% confidence) that the deodorant soap (soap 2) loses between 2 and 3.4 g more weight on average than does the regular soap, and the moisturizing soap loses between 1.3 and 2.7 g more weight on average than the regular soap. We leave it to the reader to verify that neither the Tukey nor the Bonferroni method would have been preferred for these contrasts (see Exercise 7).

#### Combination of Methods

The Bonferroni method is based on the fact that if \(m\) individual confidence intervals are obtained, each with confidence level \(100(1-\alpha^{*})\%\), then the overall confidence level is at least \(100(1-m\alpha^{*})\%\). The same fact can be used to combine the overall confidence levels arising from more than one multiple comparison procedure.

In Example 4.4.1 (p. 84), the Bonferroni method was used to calculate simultaneous 90% confidence intervals for \(m=3\) preplanned contrasts. In Example 4.4.2 (p. 86), the analysis was continued by calculating simultaneous 90% Scheffe intervals for twelve other contrasts. The overall error rate for these two sets of intervals combined is therefore at most \(0.1+0.1=0.2\), giving an overall, or "experimentwise," confidence level of at least \(100(1-0.2)\%=80\%\) for all fifteen intervals together.

Different possible strategies for multiple comparisons should be examined when outlining the analysis at step (g) of the checklist (Sect. 2.2, p. 7). Suppose that in the above example the overall level for all intervals (both planned and otherwise) had been required to be at least 90%. We examine two possible strategies that could have been used. First, the confidence levels for the Bonferroni and Scheffe contrasts could have been adjusted, dividing \(\alpha=0.10\) into two pieces, \(\alpha_{1}\) for the preplanned contrasts and \(\alpha_{2}\) for the others, where \(\alpha_{1}+\alpha_{2}=0.10\). This strategy would have resulted in intervals that were somewhat wider than the above for all of the contrasts. Alternatively, Scheffe's method could have been used with \(\alpha=0.10\) for all of the contrasts including the three preplanned contrasts. This strategy would have resulted in wider intervals for the three preplanned contrasts but not for the others. Both strategies would result in an overall, or experimentwise, confidence level of 90% instead of 80%.

#### Methods Not Controlling Experimentwise Error Rate

We have introduced four methods of multiple comparisons, each of which allows the experimenter to control the overall confidence level, and the same methods can be used to control the experimentwise error rate when multiple hypotheses are to be tested. There exist other multiple comparison procedures that are more powerful (i.e., that more easily detect a nonzero contrast) but do not control the overall confidence level nor the experimentwise error rate. While some of these are used quite commonly, we do not advocate their use. Such procedures include Duncan's multiple range test, Fisher's protected LSD procedure, and the Newman-Keuls method. (For more details, see Hsu 1996.)

### Sample Sizes

Before an experiment can be run, it is necessary to determine the number of observations that should be taken on each level of each treatment factor (step (h) of the checklist in Sect. 2.2, p. 7). In Sect. 3.6.2, a method was presented to calculate the sample sizes needed to achieve a specified power of the test of the hypothesis \(H_{0}:\tau_{1}=\cdots=\tau_{v}\). In this section we show how to determine the sample sizes to achieve confidence intervals of specified lengths.

The lengths of confidence intervals decrease as sample sizes increase. Consequently, if the length of an interval is specified, it should be possible to calculate the required sample sizes, especially when these are equal. However, there is a problem. Since the experimental data have not yet been collected, the value of the mean squared error is not known. As in Sect. 3.6.2, if the value of the mean squared error can be reasonably well be guessed at, either from previous experience or from a pilot study, then a trial and error approach to the problem can be followed, as illustrated in the next example.

#### Example 4.5.1 \(\mathrm{Bean}\)-soaking experiment

Suppose we were to plan an experiment to compare the effects of \(v=5\) different soaking times on the growth rate of mung bean seeds. The response variable will be the length of a shoot of a mung bean seed 48 hours after soaking. Suppose that a pilot experiment has indicated that the mean square for error is likely to be not more than 10 \(\mathrm{mm}^{2}\), and suppose that we would like a set of 95% simultaneous confidence intervals for pairwise differences of the soaking times, with each interval no wider than 6 \(\mathrm{mm}\) (that is, the half width or minimum significant difference should be no greater than 3 \(\mathrm{mm}\)).

The formula for each of the simultaneous confidence intervals for pairwise comparisons using Tukey's method of multiple comparisons is given by (4.4.27) p. 88. For equal sample sizes, the interval half width, or minimum significant difference, is required to be at most 3 \(\mathrm{mm}\); that is, we require

\[\mathrm{msd}=w_{T}\sqrt{10\left(\frac{1}{r}+\frac{1}{r}\right)}\leq 3\,,\]

where \(w_{T}=q_{5,5r-5,\,05}/\sqrt{2}\) or, equivalently,

\[q_{5,5r-5,\,05}^{2}\leq 0.9r\.\]

Adopting a trial-and-error approach, we guess a value for \(r\), say \(r=10\). Then, from Table A.8, we find \(q_{5,45,\,05}^{2}\approx 4.03^{2}=16.24\), which does not satisfy the requirement that \(q^{2}\leq 0.9r=9\). A larger value for \(r\) is needed, and we might try \(r=20\) next. The calculations are most conveniently laid out in table form, as follows.

\[\begin{array}{cccc}r&5r-5&q_{5,5r-5,\,0.05}^{2}&0.9r&Action\\ \hline 10&45&4.03^{2}=16.24&9.00&\mathrm{Increase}&r\\ 20&95&3.95^{2}=15.60&18.00&\mathrm{Decrease}&r\\ 15&70&3.97^{2}=15.76&13.50&\mathrm{Increase}&r\\ 18&85&3.96^{2}=15.68&16.20&\mathrm{Decrease}&r\\ 17&80&3.96^{2}=15.68&15.30&\end{array}\]

If \(r=17\) observations are taken on each of the five soaking times, and if the mean square for error is approximately 10 \(\mathrm{mm}^{2}\) in the main experiment, then the 95% Tukey simultaneous confidence intervals for pairwise comparisons will be a little over the required 6 \(\mathrm{mm}\) in length. If \(r=18\) observations are taken, the interval will be a little shorter than the 6 \(\mathrm{mm}\) required. If the cost of the experiment is high, then \(r=17\) would be selected; otherwise, \(r=18\) might be preferred.

Trial and error procedures such as that illustrated in Example 4.5.1 for Tukey's method of multiple comparisons can be used for any of the other multiple comparison methods to obtain the approximate sample sizes required to meet the objectives of the experiment. The same type of calculation can be done for unequal sample sizes, provided that the relative sizes are specified, for example \(r_{1}=2r_{2}=2r_{3}=2r_{4}\).

Unless more information is desired on some treatments than on others, or unless costs or variances are unequal, it is generally advisable to select equal sample sizes whenever possible. Choosing equal sample sizes produces two benefits! Confidence intervals for pairwise comparisons are all the same length, which makes them easier to compare, and the multiple comparison and analysis of variance procedures are less sensitive to an incorrect assumption of normality of the error variables.

Quite often, the sample size calculation will reveal that the required number of observations is too large to meet the budget or the time restrictions of the experiment. There are several possible remedies:1. Refine the experimental procedure to reduce the likely size of msE,
2. Omit one or more treatments,
3. Allow longer confidence intervals,
4. Allow a lower confidence level.

### Using SAS Software

In this section we illustrate how to use the SAS software to generate information for confidence intervals and hypothesis tests for individual contrasts and means and also for the multiple comparison procedures. We use the data from the battery experiment of Sect. 2.5.2 (p. 24).

A sample SAS program to analyze the data is given in Table 4.1. As in Chap. 3, line numbers have been included for reference but are not part of the SAS program. A data set BATTERY, with variables TYPE, LPUC and ORDER, is created from the statements in lines 1-9. The treatment factor is the type of battery TYPE, the response variable is the life per unit cost LPUC, and the one-way analysis of variance model (3.3.1) was used for the analysis. Lines 10-12 generate the analysis of variance table shown in the top of Fig. 4.1.

#### Inferences on Individual Contrasts

The SAS statements ESTIMATE and CONTRAST are part of the GLM procedure and are used for making inferences concerning specific contrasts.

The ESTIMATE statements (lines 13-15 of Table 4.1) generate information for constructing confidence intervals or conducting hypothesis tests for individual contrasts. Each of the three ESTIMATE statements includes a user-selected contrast name in single quotes, together with the name of the factor for which the effects of levels are to be compared, and the coefficients of the contrast to be estimated.

\begin{table}
\begin{tabular}{r c} Line & SAS Program \\  1 & DATA BATTERY; \\  2 & INPUT TYPE LPUC ORDER; \\  3 & LINES; \\  4 & 1 611 1 \\  5 & 2 923 2 \\  6 & 1 537 3 \\  7 & : : \\  8 & 3 413 16 \\  9 & ; \\  10 & PROC GLM; \\  11 & CLASS TYPE; \\  12 & MODEL LPUC = TYPE; \\  13 & ESTIMATE ’DUTY’ & TYPE 1 1 -1 -1 -1 / DIVISOR = 2; \\  14 & ESTIMATE ’BRAND’ & TYPE 1 -1 1 -1 / DIVISOR = 2; \\  15 & ESTIMATE ’INTERACTN’ & TYPE 1 -1 -1 1 / DIVISOR = 2; \\  16 & CONTRAST ’BRAND’ & TYPE 1 -1 1 -1; \\  17 & LSMEANS TYPE / ADJUST = TUKEY CL PDIFF ALPHA = 0.01; \\ \end{tabular}
\end{table}
Table 4.1: SAS program for the battery experiment: contrasts and multiple comparisonsIf the contrast coefficients are to be divided by a constant, this is indicated by means of the DIVISOR option. The information generated by these statements is shown in the bottom section of Fig. 4.1.

The columns show the contrast name, the contrast estimate \(\Sigma c_{i}\overline{y}_{i}\), the standard error \(\sqrt{\text{ms}E(\Sigma c_{i}^{2}/r_{i})}\) for the estimate, the value of the \(t\)-statistic for testing the null hypothesis that the contrast is zero (see (4.3.13), p. 77), and the corresponding \(p\)-value for a two-tailed test. For each of the contrasts shown in Fig. 4.1, the \(p\)-value is at most 0.0006, indicating that all three contrasts are significantly different from zero for any choice of _individual_ significance level \(\alpha\)* greater than 0.0006. The overall and individual significance levels should be selected prior to analysis. The parameter estimates and standard errors can be used to construct confidence intervals by hand, using the critical coefficient for the selected multiple comparison methods (see also Sect. 4.6.2).

The CONTRAST statement in line 16 of Table 4.1 generates the information shown in the middle portion of Fig. 4.1 that is needed in (4.3.15), p. 77, for testing the single null hypothesis that the brand contrast is zero versus the alternative hypothesis that it is not zero. The "P Value" of 52.63 is the square of the "t Value" of \(-7.25\) (up to rounding error) for the brand contrast generated by the ESTIMATE statement, the two tests (4.3.13) and (4.3.15) being equivalent.

#### Multiple Comparisons

The LSMEANS statement (line 17) in the GLM procedure in Table 4.1 can be used to generate the observed least squares means \(\overline{y}_{i}\) for each level of a factor, and to implement the multiple comparisons procedures introduced in Sect. 4.4. Inclusion of the options ADJUST=TUKEY, PDIFF and CL causes the SAS software to use the Tukey method to compare the effects of each pair of levels, providing both \(p\)-values for simultaneous testing and confidence limits for simultaneous estimation of all pairwise comparisons. Individual confidence intervals for each treatment mean are also provided as a consequence of the CL option. The option ALPHA=0.01 sets the confidence level at 99%, both for Tukey's

Figure 4.1: Analysis of variance and output from the CONTRASTS and ESTIMATE statements

method for the simultaneous pairwise comparisons and for the individual confidence intervals for each treatment mean. Part of the corresponding SAS output is given in Fig. 4.2.

Other methods of multiple comparisons can also be requested as options in the LSMEANS statement of the GLM procedure. For example, the options ADJUST=BON and ADJUST=SCHEFFE request all pairwise comparisons using the methods of Bonferroni and Scheffe, respectively. The option ADJUST=DUNNETT requests Dunnett's 2-sided method of comparing all treatments with a control, the lowest treatment level serving as the control by default. To explicitly specify level 1, say, as the control, replace PDIFF with PDIFF=CONTROL('l'). Similarly, replacing PDIFF with PDIFF=CONTROLU('l') requests simultaneous lower bounds for the treatment-versus-control contrasts \(\tau_{i}-\tau_{1}\) by Dunnett's method and is useful for "upper-tailed"alternative hypotheses--namely, for showing which treatments have a larger effect than the control treatment (coded 1). Likewise, the option PDIFF=CONTROLL('l') provides upper bounds useful for "lower-tailed" alternatives--namely, for showing which treatments have a smaller effect than the control treatment (coded 1).

### Using R Software

In this section we illustrate how to use the R software to generate information for confidence intervals and hypothesis tests for individual contrasts and means and also for the multiple comparison procedures. We use the data from the battery experiment of Sect. 2.5.2 (p. 24). The treatment factor is type of battery Type, the response variable is the life per unit cost LPUC, and the one-way analysis of variance model (3.3.1) was used for the analysis.

A sample R program to analyze the data is given in Table 4.2. Line numbers have been included for the sake of reference but they are not part of the R program. The data are read from file by the statement in line 1 of the R code. In line 2, the data set is augmented with a new variable, fType, created by converting the numerical variable Type to a factor variable. The head command in line 3 displays the first 3 lines of the data set. The function aov in line 4 fits the one-way analysis of variance model (3.3.1) to the data, saving the results as the object modell for use by subsequent R functions.

Figure 4.2: Tukey’s method for the battery experiment

The anova(model1) function in line 5 generates the analysis of variance data shown in the top of Table 4.3.

#### 4.7.1 Inferences on Individual Contrasts

The lsmeans package, loaded in line 7, provides the functionality for computing least squares means and using these for inferences on treatment contrasts. The lsmeans statement (line 8) uses the results of the previously fitted model (line 4) to compute least squares means for each battery type (i.e. for each level of fType), saving the results as lsmType. The levels command in line 9 displays the levels of the factor fType in order: "1" "2" "3" "4". Using the least squares means saved in line 8, the summary and contrast functions of the lsmeans package (lines 10-13 of Table 4.2) are coupled to generate least squares estimates, tests, and confidence intervals for specified treatment contrasts. For each of these contrasts, the coefficients correspond to the respective levels of fType displayed by line 9. In particular, the contrast function inputs the least squares means lsmType for each battery type plus a list of contrasts, including a name and the coefficients for each, and would generate the information in the middle of Table 4.3 except the confidence limits. The confidence limits are obtained by wrapping the contrast function in the summary function, for which the option infer=c(T,T) requests confidence intervals and tests. The confidence level is optionally specified to be 95% (the default). Two-sided confidence intervals and tests (the default) are also optionally specified, whereas side="<" would request upper confidence limits and specify one-sided alternative hypotheses corresponding to the contrasts being less than zero, for example.

\begin{table}
\begin{tabular}{r l} Line & R Code \\
1 & battery.data = read.table("data/battery.txt", header=T) \\
2 & battery.data$fType = factor(battery.data$Type) \\
3 & head(battery.data, 3) \\
4 & model1 = aov(LPUC ~ fType, data=battery.data) \# Fit aov model \\
5 & anova(model1) \# Display l-way ANOVA \\
6 & \# Individual contrasts: estimates, CIs, tests \\
7 & library(lsmeans) \\
8 & lsmType = lsmeans(model1, ~ fType) \# Compute and save lsmeans \\
9 & levels(battery.data$fType) \\
10 & summary(contrast(lsmType, list(Duty=c(1,1,-1,-1)/2, \\ 11 & Brand=c(1,-1,1,-1)/2, \\ 12 & DB=c(1,-1,-1,1)/2)), \\
13 & infer=c(T,T), level=0.95, side="two-sided") \\
14 & \# Multiple comparisons \\
15 & confint(lsmType, level=0.90) \# Display lsmeans and 90 \\
16 & \# Tukey’s method \\
17 & summary(contrast(lsmType, method="pairwise", adjust="tukey"), \\
18 & infer=c(T,T), level=0.99, side="two-sided") \\
19 & \# Dunnett’s method \\
20 & summary(contrast(lsmType, method="trt.vs.ctrl", adjust="mvt", ref=l), \\
21 & infer=c(T,T), level=0.99, side="two-sided") \\ \end{tabular}
\end{table}
Table 4.2: R program for the battery experiment 

[MISSING_PAGE_EMPTY:8056]

comparisons including non-pairwise comparisons, the contrast estimates and standard errors could be used to construct confidence intervals by hand, using the critical coefficient for the selected multiple comparison methods (see Sect. 4.6.2). Pairwise comparisons will be illustrated in the next section.

#### Multiple Comparisons

Multiple comparisons procedures introduced in Sect. 4.4 are implemented by the R code in lines 14-21 of Table 4.2. The least squares means package lsmeans, loaded in line 7, provides functions to generate the observed least squares means \(\overline{y}_{i.}\) for each level of a factor, and also to implement the multiple comparisons procedures introduced in Sect. 4.4. In line 8, lsmeans uses the information stored in modell to compute the least squares mean for each battery type, saving the least squares means as lsmType for subsequent use. The confint function in line 15 would display the least squares means and corresponding individual 90% confidence intervals for the treatment means (not shown).

Multiple comparison methods can be implemented by coupling the summary and contrast functions, as illustrated for Tukey's method in lines 16-18. These code lines and the corresponding output are shown in the bottom of Table 4.3. The option method="pairwise" requests all pairwise comparisons. The contrast statement embedded in line 17 would apply Tukey's method to test whether each pairwise comparison is zero. One also gets the corresponding Tukey confidence intervals by including the summary function and its options, where infer=c(T,T) requests confidence intervals as well as tests, level=0.99 sets the confidence level, and side="two-sided" requests two-sided confidence intervals and tests. Tukey's method and two-sided inferences are the defaults for all pairwise comparisons, so adjust="tukey" and side="two-sided" are redundant here, but one can replace "tukey" with "scheffe" or "bonferroni" to apply the corresponding method, or with "none" for no multiple comparisons adjustment. The default confidence level is 95%. Using method="revpairwise" reverses the order of the pairwise comparisons, considering \(\tau_{j}-\tau_{i}\) rather than \(\tau_{i}-\tau_{j}\).

Implementation of Dunnett's method for all treatment-versus-control comparisons is similar and illustrated by lines 19-21 of Table 4.2. The option method="trt.vs.ctrl" yields all treatment-versus-control comparisons (not shown). Dunnett's method uses critical values from the multivariate \(t\)-distribution, corresponding to adjust="mvt". These critical values are computed by simulation, so the results vary slightly from run to run unless a simulation seed is specified. Also, if the number of treatments is large, implementation of R functions for the multivariate \(t\)-distribution may be slow or simply not work, so the default option adjust="dunnettx" provides an approximation of Dunnett's method for two-sided confidence intervals that runs faster and dependably, though it is only applicable when the contrast estimates have pairwise correlations of 0.5 such as in the equireplicate case. The first level of the factor, "l", which happens to be level 1 in this case, is the control by default; the syntax ref=1 illustrates how to specify the first (or any) level as the control. Also, "two-sided" is the default for confidence intervals and tests, but one can specify side="<" for the one-sided alternative \(H_{A}:\tau_{i}<\tau_{1}\) and the corresponding upper confidence bound for \(\tau_{i}-\tau_{1}\), or side=">" for the alternative \(H_{A}:\tau_{i}>\tau_{1}\) and the corresponding lower confidence bound for \(\tau_{i}-\tau_{1}\).

For additional functionality for multiple comparisons procedures, see the multiple comparisons package multcomp.

## Exercises

1. **Buoyancy experiment** Consider conducting an experiment to investigate the question, "Is the buoyancy of an object in water affected by different concentrations of salt in the water?" 1. Complete steps (a)-(d) of the checklist (p. 7) in detail. Specify any preplanned contrasts or functions that should be estimated. State, with reasons, which, if any, methods of multiple comparisons will be used. 2. Run a small pilot experiment to obtain a preliminary estimate of \(\sigma^{2}\). 3. Finish the checklist.
2. **Cotton-spinning experiment, continued** For the cotton-spinning experiment of Sect. 2.3, p. 13, identify any contrasts or functions that you think might be interesting to estimate. For any contrasts that you have selected, list the corresponding contrast coefficients.
3. **Meat cooking experiment, continued** The meat cooking experiment was described in Exercise 14 of Chap. 3, and the data were given in Table 3.14, p. 68. 1. Compare the effects of the six treatments, pairwise, using Scheffe's method of multiple comparisons and a 95% overall confidence level. 2. Consider \(\mu+(\tau_{1}+\tau_{4})/2\), \(\mu+(\tau_{2}+\tau_{5})/2\), and \(\mu+(\tau_{3}+\tau_{6})/2\). What do these represent? Make pairwise comparisons of these three expressions, using Scheffe's method of multiple comparisons and a 95% overall confidence level for all treatment contrasts. Interpret the results.
4. **Reaction time experiment** (L. Cai, T. Li, Nishant, and A. van der Kouwe, 1996) The experiment was run to compare the effects of auditory and visual cues on speed of response of a human subject. A personal computer was used to present a "stimulus" to a subject, and the reaction time required for the subject to press a key was monitored. The subject was warned that the stimulus was forthcoming by means of an auditory or a visual cue. The experimenters were interested in the effects on the subjects' reaction time of the auditory and visual cues and also in different elapsed times between cue and stimulus. Thus, there were two different treatment factors: "cue stimulus" at two levels "auditory" or "visual," and "elapsed time between cue and stimulus" at three levels "five," "ten," or "fifteen" seconds. This gave a total of six treatment combinations, which can be coded as 1 = auditory, 5 sec 4 = visual, 5 sec 2 = auditory, 10 sec 5 = visual, 10 sec 3 = auditory, 15 sec 6 = visual, 15 secThe results of a pilot experiment, involving only one subject, are shown in Table 4.4. The reaction times were measured by the computer and are shown in seconds. The order of observation is shown in parentheses. 1. Identify a set of contrasts that you would find particularly interesting in this experiment. (Hint: A comparison between the auditory treatments and the visual treatments might be of interest). These are your preplanned contrasts. 2. Plot the data. What does the plot suggest about the treatments? 3. Test the hypothesis that the treatments do not have different effects on the reaction time against the alternative hypothesis that they do have different effects. 4. Calculate a set of simultaneous 90% confidence intervals for your preplanned contrasts, using a method or methods of your choice. State your conclusions.
5. **Trout experiment, continued** Exercise 15 of Chap. 3 (p. 67) concerns a study of the effects of four levels of sulfamerazine (0, 5, 10, 15 g per 100 lb of fish) on the hemoglobin content of trout blood. An analysis of variance test rejected the hypothesis that the four treatment effects are the same at significance level \(\alpha=0.01\). 1. Compare the four treatments using Tukey's method of pairwise comparisons and a 99% overall confidence level. 2. Compare the effect of no sulfamerazine on the hemoglobin content of trout blood with the average effect of the other three levels. The overall confidence level of all intervals in parts (a) and (b) should be at least 98%.
6. **Battery experiment, continued** In Example 4.4.3 (page 89), Tukey's method is used to obtain a set of 95% simultaneous confidence intervals for the pairwise differences \(\tau_{i}-\tau_{s}\). Verify that this method gives shorter confidence intervals than would either of the Bonferroni or Scheffe methods (for \(v=4\) and \(r=4\)).
7. **Soap experiment, continued** The soap experiment was described in Sect. 2.5.1, p. 20, and an analysis was given in Sect. 3.7.2, p. 50. 1. Suppose that the experimenter had been interested only in the contrast \(\tau_{1}-\frac{1}{2}(\tau_{2}+\tau_{3})\), which compares the weight loss for the regular soap with the average weight loss for the other two soaps. Calculate a confidence interval for this single contrast.

\begin{table}
\begin{tabular}{c c c c c c} \hline  & \multicolumn{4}{c}{Treatments} \\
1 & 2 & 3 & 4 & 5 & 6 \\ \hline
0.204 (9) & 0.167 (3) & 0.202 (13) & 0.257 (7) & 0.283 (6) & 0.256 (1) \\
0.170 (10) & 0.182 (5) & 0.198 (16) & 0.279 (14) & 0.235 (8) & 0.281 (2) \\
0.181 (18) & 0.187 (12) & 0.236 (17) & 0.269 (15) & 0.260 (11) & 0.258 (4) \\ \hline \end{tabular}
\end{table}
Table 4.4: Reaction times, in seconds, for the reaction time experiment—(order of collection in parentheses)2. Test the hypothesis that the regular soap has the same average weight loss as the average of the other two soaps. Do this via your confidence interval in part (a) and also via (4.3.13) and (4.3.15). 3. In Example 4.4.5 (p. 91), Dunnett's method was used for simultaneous 99% confidence intervals for two preplanned treatment-versus-control contrasts. Would either or both of the Bonferroni and Tukey methods have given shorter intervals? 4. Which method would be the best if all pairwise differences are required? Calculate a set of simultaneous 99% confidence intervals for all of the pairwise differences. Why are the intervals longer than those in part (c)?
8. **Trout experiment, continued** 1. For the trout experiment in Exercise 15 of Chap. 3 (see p. 67), test the hypotheses that the linear and quadratic trends in hemoglobin content of trout blood due to the amount of sulfamerazine added to the diet is negligible. State the overall significance level of your tests. 2. Regarding the absence of sulfamerazine in the diet as the control treatment, calculate simultaneous 99% confidence intervals for the three treatment-versus-control comparisons. Which method did you use and why? 3. What is the overall confidence level of the intervals in part (b) together with those in Exercise 5? Is there a better strategy than using three different procedures for the three sets of intervals? Explain.
9. **Battery experiment, continued** Suppose the battery experiment of Sect. 2.5.2 (p. 24) is to be repeated. The experiment involved four treatments, and the error standard deviation is estimated from that experiment to be about 48.66 minutes per dollar (minute/dollar). 1. Calculate a 90% upper confidence limit for the error variance \(\sigma^{2}\). 2. How large should the sample sizes be in the new experiment if Tukey's method of pairwise comparisons is to be used and it is desired to obtain a set of 95% simultaneous confidence intervals of length at most 100 minutes per dollar? 3. How large should the sample sizes be in the new experiment if Scheffe's method is to be used to obtain a set of 95% simultaneous confidence intervals for various contrasts and if the confidence interval for the duty contrast is to be of length at most 100 minute per dollar?
10. **Trout experiment, continued** Consider again the trout experiment in Exercise 15 of Chap. 3. 1. Suppose the experiment were to be repeated. Suggest the largest likely value for the error mean square msE. 2. How many observations should be taken on each treatment so that the length of each interval in a set of simultaneous 95% confidence intervals for pairwise comparisons should be at most 2 g per 100 ml?

### 5.1 Introduction

Throughout the two previous chapters, we discussed experiments whose data could be described by the one-way analysis of variance model (3.3.1), that is,

\[\begin{array}{c}Y_{it}=\mu+\tau_{i}+\epsilon_{it}\,,\\ \epsilon_{it}\sim N(0,\sigma^{2})\,,\\ \epsilon_{it}{}^{\prime}\mbox{s are mutually independent}\,,\\ t=1,\,\ldots,r_{i},\;\;\;i=1,\,\ldots,v\,.\end{array}\]

This model implies that the response variables \(Y_{it}\) are mutually independent and have a normal distribution with mean \(\mu+\tau_{i}\) and variance \(\sigma^{2}\), that is, \(Y_{it}\sim N(\mu+\tau_{i},\sigma^{2})\). For a given experiment, the model is selected in step (f) of the checklist using any available knowledge about the experimental situation, including the anticipated major sources of variation, the measurements to be made, the type of experimental design selected, and the results of any pilot experiment. However, it is not until the data have been collected that the adequacy of the model can be checked. Even if a pilot experiment has been used to help select the model, it is still important to check that the chosen model is a reasonable description of the data arising from the main experiment.

Methods of checking the model assumptions form the subject of this chapter, together with some indications of how to proceed if the assumptions are not valid. We begin by presenting a general strategy, including the order in which model assumptions should be checked. For checking model assumptions, we rely heavily on residual plots. We do so because while examination of residual plots is more subjective than would be testing for model lack-of-fit, the plots are often more informative about the nature of the problem, the consequences, and the corrective action.

### 5.2 Strategy for Checking Model Assumptions

In this section we discuss strategy and introduce the notions of residuals and residual plots. A good strategy for checking the assumptions about the model is to use the following sequence of checks.

* _Check the form of the model_--are the mean responses for the treatments adequately described by \(E(Y_{it})=\mu+\tau_{i},\,i=1,\,\ldots,v\)?* _Check for outliers_--are there any unusual observations (outliers)?
* _Check for independence_--do the error variables \(\epsilon_{it}\) appear to be independent?
* _Check for constant variance_--do the error variables \(\epsilon_{it}\) have similar variances for each treatment?
* _Check for normality_--do the error variables \(\epsilon_{it}\) appear to be a random sample from a normal distribution?

For all of the fixed-effects models considered in this book, these same assumptions should be checked, except that \(E(Y_{it})\) differs from model to model. The assumptions of independence, equal variance, and normality are the error assumptions mentioned in Chap. 3.

#### Residuals

The assumptions on the model involve the error variables, \(\epsilon_{it}=Y_{it}-E(Y_{it})\), and can be checked by examination of the _residuals_. The \(it\) th residual \(\hat{e}_{it}\) is defined as the observed value of \(Y_{it}-\hat{Y}_{it}\), where \(\hat{Y}_{it}\) is the least squares estimator of \(E[Y_{it}]\), that is,

\[\hat{e}_{it}=y_{it}-\hat{y}_{it}\;.\]

For the one-way analysis of variance model (3.3.1), \(E[Y_{it}]=\mu+\tau_{i}\), so the \(it\) th residual is

\[\hat{e}_{it}=y_{it}-(\hat{\mu}+\hat{\tau}_{i})=y_{it}-\overline{y}_{i.}\;.\]

While one can simply use the residuals, we prefer to work with the _standardized residuals_, since standardization facilitates the identification of outliers. The standardization we use is achieved by dividing the residuals by their standard deviation, that is, by \(\sqrt{ssE/(n-1)}\). The standardized residuals,

\[z_{it}=\frac{\hat{e}_{it}}{\sqrt{ssE/(n-1)}}\;,\]

then have sample variance equal to 1.0. Residuals standardized in this simplistic way are _scaled residuals_. Readers may prefer to use _Studentized residuals_, obtained by dividing each residual by its estimated standard error, either including or excluding the corresponding observation from the model fit. However, there is little distinction between these various approaches for analysis of variance models for data that is balanced or nearly so.

If the assumptions on the model are correct, the standardized error variables \(\epsilon_{it}/\sigma\) are independently distributed with a \(N(0,1)\) distribution, so the observed values \(e_{it}/\sigma=(y_{it}-(\mu+\tau_{i}))/\sigma\) would constitute independent observations from a standard normal distribution. Although the standardized residuals are dependent and involve estimates of both \(e_{it}\) and \(\sigma\), their behavior should be similar. Consequently, methods for evaluating the model assumptions using the standardized residuals look for deviations from patterns that would be expected of independent observations from a standard normal distribution.

#### Residual Plots

A _residual plot_ is a plot of the standardized residuals \(z_{it}\) against the levels of another variable, the choice of which depends on the assumption being checked. In Fig. 5.1, we show a plot of the standardized residuals against the levels of the treatment factor for the trout experiment. Plots like this are useful for evaluating the assumption of constant error variance as well as the adequacy of the model.

#### 5.2.1 Constructing a residual plot: trout experiment

The trout experiment was described in Exercise 15 of Chap. 3. There was one treatment factor (grams of sulfamerazine per 100 lb of fish) with four levels coded 1, 2, 3, 4, each observed \(r=10\) times. The response variable was grams of hemoglobin per 100 ml of trout blood. The \(n=40\) data values are reproduced in Table 5.1 together with the treatment means.

Using the one-way analysis of variance model (3.3.1), it can be verified that ssE = 56.471. The residuals \(\hat{e}_{it}=y_{it}-\overline{y}_{i}\) and the standardized residuals \(z_{it}=\hat{e}_{it}/\sqrt{\text{ssE}/(n-1)}\) are shown in Table 5.2. For example, the observation \(y_{11}=6.7\) yields the residual

\[\hat{e}_{11}=6.7-7.2=-0.5\]

and the standardized residual

\[z_{11}=-0.5/\sqrt{56.471/39}=-0.42\]

to two decimal places.

A plot of the standardized residuals against treatments is shown in Fig. 5.1. The residuals sum to zero for each treatment since \(\Sigma_{t}(y_{it}-\overline{y}_{i}.)=0\) for each \(i=1,\ldots,v\). The standardized residuals seem fairly well scattered around zero, although the spread of the residuals for treatment 2 seems a little larger than the spread for the other three treatments. This could be interpreted as a sign of unequal variances of the error variables or that the data values having standardized residuals 2.14 and \(-2.43\)

\begin{table}
\begin{tabular}{c c c c c c c c c c c} \hline Code & & & Hemoglobin (grams per 100 ml) & & & \(\overline{y}_{i}\). \\ \hline
1 & 6.7 & 7.8 & 5.5 & 8.4 & 7.0 & 7.8 & 8.6 & 7.4 & 5.8 & 7.0 & 7.20 \\
2 & 9.9 & 8.4 & 10.4 & 9.3 & 10.7 & 11.9 & 7.1 & 6.4 & 8.6 & 10.6 & 9.33 \\
3 & 10.4 & 8.1 & 10.6 & 8.7 & 10.7 & 9.1 & 8.8 & 8.1 & 7.8 & 8.0 & 9.03 \\
4 & 9.3 & 9.3 & 7.2 & 7.8 & 9.3 & 10.2 & 8.7 & 8.6 & 9.3 & 7.2 & 8.69 \\ \hline \end{tabular} Source: Gutsell (1951). Copyright © 1951 International Biometric Society. Reprinted with permission

\end{table}
Table 5.1: Data for the trout experiment are outliers, or it could be attributed to chance variation. Methods for checking for outliers and equality of variances will be discussed in Sects. 5.4 and 5.6, respectively. 

### Checking the Fit of the Model

The first assumption to be checked is the assumption that the model \(E(Y_{it})\) for the mean response is correct. One purpose of running a pilot experiment is to choose a model that is a reasonable description of the data. If this is done, the model assumption checks for the main experiment should show no problems. If the model for mean response does not adequately fit the data, then there is said to be model _lack of fit_. If this occurs and if the model is changed accordingly, then any stated confidence levels and significance levels will only be approximate. This should be taken into account when decisions are to be made based on the results of the experiment.

In general, the fit of the model is checked by plotting the standardized residuals versus the levels of each independent variable (treatment factor, block factor, or covariate) included in the model. Lack of fit is indicated if the residuals exhibit a nonrandom pattern about zero in any such plot, being too often positive for some levels of the independent variable and too often negative for others.

For model (3.3.1), the only independent variable included in the model is the treatment factor. Since the residuals sum to zero for each level of the treatment factor, lack of fit would only be detected if there were a number of unusually large or small observations. However, lack of fit can also be detected by plotting the standardized residuals against the levels of factors that were omitted from the model. For example, for the trout experiment, if the standardized residuals were plotted against the age of the corresponding fish and if the plot were to show a pattern, then it would indicate that age should have been included in the model as a covariate. A similar idea is discussed in Sect. 5.5 with respect to checking for independence.

\begin{table}
\begin{tabular}{c r r r r r} \hline Treatment & \multicolumn{5}{c}{Residuals} \\ \hline
1 & \(-0.50\) & \(0.60\) & \(-1.70\) & \(1.20\) & \(-0.20\) \\  & \(0.60\) & \(1.40\) & \(0.20\) & \(-1.40\) & \(-0.20\) \\
2 & \(0.57\) & \(-0.93\) & \(1.07\) & \(-0.03\) & \(1.37\) \\  & \(2.57\) & \(-2.23\) & \(-2.93\) & \(-0.73\) & \(1.27\) \\
3 & \(1.37\) & \(-0.93\) & \(1.57\) & \(-0.33\) & \(1.67\) \\  & \(0.07\) & \(-0.23\) & \(-0.93\) & \(-1.23\) & \(-1.03\) \\
4 & \(0.61\) & \(0.61\) & \(-1.49\) & \(-0.89\) & \(0.61\) \\  & \(1.51\) & \(0.01\) & \(-0.09\) & \(0.61\) & \(-1.49\) \\ \hline Treatment & \multicolumn{5}{c}{Standardized residuals} \\ \hline
1 & \(-0.42\) & \(0.50\) & \(-1.41\) & \(1.00\) & \(-0.17\) \\  & \(0.50\) & \(1.16\) & \(0.17\) & \(-1.16\) & \(-0.17\) \\
2 & \(0.47\) & \(-0.77\) & \(0.89\) & \(-0.02\) & \(1.14\) \\  & \(2.14\) & \(-1.85\)

### Checking for Outliers

An _outlier_ is an observation that is much larger or much smaller than expected. This is indicated by a residual that has an unusually large positive or negative value. Outliers are fairly easy to detect from a plot of the standardized residuals versus the levels of the treatment factors. Any outlier should be investigated. Sometimes such investigation will reveal an error in recording the data, and this can be corrected. Otherwise, outliers may be due to the error variables not being normally distributed, or having different variances, or an incorrect specification of the model.

If all of the model assumptions hold, including normality, then approximately 68% of the standardized residuals should be between \(-1\) and \(+1\), approximately 95% between \(-2\) and \(+2\), and approximately 99.7% between \(-3\) and \(+3\). If there are more outliers than expected under normality, then the true confidence levels are lower than stated and the true significance levels are higher.

#### 5.4.1 Checking for outliers: battery experiment

In the battery experiment of Sect. 2.5.2 (p. 24), four observations on battery life per unit cost were collected for each of four battery types. Figure 5.2 shows the standardized residuals plotted versus battery type for the data as originally entered into the computer for analysis using model (3.3.1). This plot shows two related anomalies. There is one apparent outlier for battery type 2, the residual value being \(-2.98\). Also, _all_ of the standardized residuals for the other three battery types are less than one in magnitude. This is many more than the 68% expected.

An investigation of the outlier revealed a data entry error for the corresponding observation--a life length of 473 minutes was typed, but the recording sheet for the experiment showed the correct value to be 773 minutes. The unit cost for battery type 2 was $0.935 per battery, yielding the erroneous value of 506 minutes per dollar for the life per unit cost, rather than the correct value of 827. After correcting the error, the model was fitted again and the standardized residuals were replotted, as shown in Fig. 5.3.

Observe how correcting the single data entry error corrects both problems observed in Fig. 5.2. Not only is there no outlier, but the distribution of the 16 standardized residuals about zero is as one might anticipate for independent observations from a standard normal distribution--about a third of the standardized residuals exceed one in magnitude, and all are less than two in magnitude. The two anomalies are related, since correcting the data entry error makes ssE smaller and the standardized residuals correspondingly larger. 

For an outlier like that shown in Fig. 5.2, the most probable cause of the problem is a measurement error, a recording error, or a transcribing error. When an outlier is detected, the experimenter should

Figure 5.2: Original residual plot for the battery experimentlook at the original recording sheet to see whether the original data value has been copied incorrectly at some stage. If the error can be found, then it can be corrected. When no obvious cause can be found for an outlier, the data value should not automatically be discarded, since it may be an indication of an occasional erratic behavior of a treatment. For example, had it not been due to a typographical error, the outlier for battery type 2 in the previous example might have been due to a larger variability in the responses for battery type 2.

The experimenter has to decide whether to include the unusual value in the analysis or whether to omit it. First, the data should be reanalyzed without the outlying value. If the conclusions of the experiment remain the same, then the outlier can safely be left in the analysis. If the conclusions change dramatically, then the outlier is said to be _influential_, and the experimenter must make a judgment as to whether the outlying observation is likely to be an experimental error or whether unusual observations do occur from time to time. If the experimenter decides on the former, then the analysis should be reported without the outlying observation. If the experimenter decides on the latter, then the model is not adequate to describe the experimental situation, and a more complicated model would be needed.

### Checking Independence of the Error Terms

Since the checks for the constant variance and normality assumptions assume that the error terms are independent, a check for independence should be made next. The most likely cause of nonindependence in the error variables is the similarity of experimental units close together in time or space. The independence assumption is checked by plotting the standardized residuals against the order in which the corresponding observations were collected and against any spatial arrangement of the corresponding experimental units. If the independence assumption is satisfied, the residuals should be randomly scattered around zero with no discernible pattern. Such is the case for Fig. 5.4 for the battery experiment. If the plot were to exhibit a strong pattern, then this would indicate a serious violation of the independence assumption, as illustrated in the following example.

#### Checking independence: balloon experiment

The experimenter who ran the balloon experiment in Exercise 12 of Chap. 3 was concerned about lack of independence of the observations. She had used a single subject to blow up all the balloons in the experiment, and the subject had become an expert balloon blower before the experiment was finished! Having fitted the one-way analysis of variance model (3.3.1) to the data (Table 3.13), she plotted the standardized residuals against the time order in which the balloons were inflated. The plot

Figure 5.3: Residual plot after data correction for the battery experiment

is shown in Fig. 5.5. There appears to be a strong downward drift in the residuals as time progresses. The observations are clearly _dependent_. 

If an analysis is conducted under the assumptions of model (3.3.1) when, in fact, the error variables are dependent, the statistical conclusions may be distorted. For example, if errors corresponding to observations on the same treatment are positively correlated, but errors associated with different treatments are independently distributed, this artificially increases the power of tests, causing the true significance levels of tests under model (3.3.1) to be higher than stated, and causing the true confidence levels of confidence intervals to be lower than stated. Conversely, if groups of observations on different treatments (analogous to observations in the same block) have positively correlated errors, but errors associated with other pairs of observations (analogous to observations in different blocks) are independent, this tends to inflate the mean squared error and deflate test power, causing the true significance levels of tests under model (3.3.1) to be lower than stated, and causing the true confidence levels of confidence intervals to be higher than stated. The problem of dependent errors can be difficult to correct and a different model would need to be used (e.g. Chap. 17). If there is a clear trend in the residual plot, such as the linear trend in Fig. 5.5, it may be possible to add terms into the model to represent a time or space effect. For example, a more complex model that might be adequate for the balloon experiment is

Figure 5.4: Residual plot for the battery experiment

Figure 5.5: Residual plot for the balloon experiment

\[\begin{array}{c}Y_{it}=\mu+\tau_{i}+\gamma x_{it}+\epsilon_{it}\\ \epsilon_{it}\sim N(0,\sigma^{2})\\ \epsilon_{it}{}^{\prime}\text{s}\text{are mutually independent}\\ t=1,2,\ldots,r_{i};\quad i=1,\ldots,v\,,\end{array}\]

where the variable \(x_{it}\) denotes the time at which the observation was taken and \(\gamma\) is a linear time trend parameter that must be estimated. Such a model is called an _analysis of covariance_ model and will be studied in Chap. 9. The assumptions for analysis of covariance models are checked using the same types of plots as discussed in this chapter. In addition, the standardized residuals should also be plotted against the values of \(x_{it}\).

Had the experimenter in the balloon experiment anticipated a run order effect, she could have selected an analysis of covariance model prior to the experiment. Alternatively, she could have grouped the observations into blocks of, say, eight observations. Notice that each group of eight residuals in Fig. 5.5 looks somewhat randomly scattered. As mentioned earlier in this chapter, when the model is changed after the data have been examined, then stated confidence levels and significance levels using that same data are inaccurate.

If a formal test of independence is desired, the most commonly used test is that of Durbin and Watson (1951) for time-series data (see Neter et al. 1996, pp. 504-510).

### Checking the Equal Variance Assumption

If the independence assumption appears to be satisfied, then the equal-variance assumption should be checked. Studies have shown that if the sample sizes \(r_{1}\),..., \(r_{v}\) are chosen to be equal, then unless one variance is considerably larger than the others, the significance level of hypothesis tests and confidence levels of the associated confidence intervals remain close to the stated values. However, if the sample sizes are unequal, and if the treatment factor levels which are more highly variable in response happen to have been observed fewer times (i.e. if smaller \(r_{i}\) coincide with larger \(\text{Var}(\epsilon_{it})=\sigma_{i}^{2}\)), then the statistical procedures are generally quite liberal, and the experimenter has a greater chance of making a Type I error in testing than anticipated, and also, the true confidence level of a confidence interval is lower than intended. On the other hand, if the large \(r_{i}\) coincide with large \(\sigma_{i}^{2}\), then the procedures are conservative (significance levels are lower than stated and confidence levels are higher). Thus, unless there is good knowledge of which treatment factor levels are the more variable, an argument can be made that _the sample sizes should be chosen to be equal_.

#### Detection of Unequal Variances

The most common pattern of nonconstant variance is that in which the error variance increases as the mean response increases. This situation is suggested when the plot of the standardized residuals versus the fitted values resembles a megaphone in shape, as in Fig. 5.6. In such a case, one can generally find a transformation of the data, known as a variance-stabilizing transformation, which will correct the problem (see Sect. 5.6.2).

If the residual plot indicates unequal variances but not the pattern of Fig. 5.6 (or its mirror image), then a variance-stabilizing transformation is generally not available. Approximate and somewhat less powerful methods of data analysis such as those discussed in Sect. 5.6.3 must then be applied.

An unbiased estimate of the error variance \(\sigma_{i}^{2}\) for the \(i\)th treatment is the sample variance of the residuals for the \(i\)th treatment, namely \[s_{i}^{2} =\frac{1}{r_{i}-1}\sum_{t=1}^{r_{i}}\hat{e}_{it}^{2}\ \ =\ \ \frac{1}{r_{i}-1}\sum_{t=1}^{r_{i}}(y_{it}-\hat{\mu}-\hat{\tau}_{i})^{2} \tag{5.6.1}\] \[=\frac{1}{r_{i}-1}\sum_{t=1}^{r_{i}}(y_{it}-\overline{y}_{i.})^{2}\,.\]

There do exist tests for the equality of variances, but they tend to have low power unless there are large numbers of observations on each treatment factor level. Also, the tests tend to be very sensitive to nonnormality. (The interested reader is referred to Neter et al. 1996, p. 763).

A rule of thumb that we shall apply is that the usual analysis of variance \(F\)-test and the methods of multiple comparisons discussed in Chap. 4 are appropriate, provided that the ratio of the largest of the \(v\) treatment variance estimates to the smallest, \(s_{\max}^{2}/s_{\min}^{2}\), does not exceed three. The rule of thumb is based on simulation studies suggesting that the methods of analysis are appropriate, provided that the largest ratio of actual variances, \(\sigma_{\max}^{2}/\sigma_{\min}^{2}\), does not exceed three. Since the actual variances are unknown in practice, we are basing our rule of thumb on the estimates \(s_{i}^{2}\) of the variances. Be aware, however, that _it is possible, and perhaps even likely, for the ratio of extreme variance estimates \(s_{\max}^{2}/s_{\min}^{2}\) to exceed three, even when the model assumptions are correct, making the rule of thumb conservative_.

Example 5.6.1: Comparing variances: trout experiment

Figure 5.1 (p. 105) shows a plot of the standardized residuals against the levels of the treatment factor for the trout experiment. The plot suggests that the variance of the error variables for treatment 2 might be larger than the variances for the other treatments. Using the data in Table 3.15, we obtain

\[\begin{array}{c|ccc}i&1&2&3&4\\ \hline\overline{y}_{i.}&7.20&9.33&9.03&8.69\\ s_{i}^{2}&1.04&2.95&1.29&1.00\end{array}\]

so \(s_{\max}^{2}/s_{\min}^{2}=2.95\), which satisfies our rule of thumb, but only just. Both the standard analysis using model (3.3.1) and an approximate analysis that does not require equal variances will be discussed in Example 5.6.3.

#### Data Transformations to Equalize Variances

Finding a transformation of the data to equalize the variances of the error variables involves finding some function \(h(y_{it})\) of the data so that the model

\[h(Y_{it})=\mu^{*}+\tau_{i}^{*}+\epsilon_{it}^{*}\]

holds and \(\epsilon_{it}^{*}\sim N(0,\,\sigma^{2})\) and the \(\epsilon_{it}^{*}\)'s are mutually independent for all \(t=1,\,\ldots,\,r_{i}\) and \(i=1,\,\ldots,\,v\). An appropriate transformation can generally be found if there is a clear relationship between the error variance \(\sigma_{i}^{2}=\text{Var}(\epsilon_{it})\) and the mean response \(E[Y_{it}]=\mu+\tau_{i}\), for \(i=1,\,\ldots,\,v\). If the variance and the mean increase together, as suggested by the megaphone-shaped residual plot in Fig. 5.6, or if one increases as the other decreases, then the relationship between \(\sigma_{i}^{2}\) and \(\mu+\tau_{i}\) is often of the form

\[\sigma_{i}^{2}=k(\mu+\tau_{i})^{q}\;, \tag{5.6.2}\]

where \(k\) and \(q\) are constants. In this case, the function \(h(y_{it})\) should be chosen to be

\[h(y_{it})=\left\{\begin{array}{ll}(y_{it})^{1-(q/2)}&\text{if $q\neq 2$,}\\ \ln(y_{it})&\text{if $q=2$ and all $y_{it}$'s are nonzero,}\\ \ln(y_{it}+1)&\text{if $q=2$ and some $y_{it}$'s are zero.}\end{array}\right. \tag{5.6.3}\]

Here "\(\ln\)" denotes the natural logarithm, which is the logarithm to the base \(e\). Usually, the value of \(q\) is not known, but a reasonable approximation can be obtained empirically as follows. Substituting the least squares estimates for the parameters into Eq. (5.6.2) and taking logs of both sides gives

\[\ln(s_{i}^{2})=\ln(k)+q\left(\ln(\overline{y}_{i.})\right)\;.\]

Therefore, the slope of the line obtained by plotting \(\ln(s_{i}^{2})\) against \(\ln(\overline{y}_{i.})\) gives an estimate for \(q\). This will be illustrated in Example 5.6.2.

The value of \(q\) is sometimes suggested by theoretical considerations. For example, if the normal distribution assumed in the model is actually an approximation to the Poisson distribution, then the variance would be equal to the mean, and \(q=1\). The square-root transformation \(h(y_{it})=(y_{it})^{1/2}\) would then be appropriate. The binomial distribution provides another commonly occurring case for which an appropriate transformation can be obtained theoretically. If each \(Y_{it}\) has a binomial distribution with mean \(mp\) and variance \(mp(1-p)\), then a variance-stabilizing transformation is

\[h(y_{it})=\sin^{-1}\sqrt{y_{it}/m}=\arcsin\left(\sqrt{y_{it}/m}\right)\;.\]

When a transformation is found that equalizes the variances, then it is necessary to check or recheck the other model assumptions, since a transformation that cures one problem could cause others. If there are no problems with the other model assumptions, then analysis can proceed using the techniques of the previous two chapters, but using the transformed data \(h(y_{it})\).

#### Choosing a transformation: battery experiment

In Sect. 2.5.2, the response variable considered for the battery experiment was "battery life per unit cost," and a plot of the residuals versus the fitted values looks similar to Fig. 5.3 and shows fairly constant error variances.

Suppose, however, that the response variable of interest had been "battery life" regardless of cost. The corresponding data are given in Table 5.3. The battery types are

1 = alkaline, name brand

2 = alkaline, store brand

3 = heavy duty, name brand

4 = heavy duty, store brand

Figure 5.7 shows a plot of the standardized residuals versus the fitted values. Variability seems to be increasing modestly with mean response, suggesting that a transformation can be found to stabilize the error variance. The ratio of extreme variance estimates is \(s_{\max}^{2}/s_{\min}^{2}=s_{2}^{2}/s_{3}^{2}=3151.70/557.43\approx 5.65\). Hence, based on the rule of thumb, a variance stabilizing transformation should be used. Using the treatment sample means and variances from Table 5.3, we have

\[\begin{array}{ccccc}i&\overline{y}_{i}&\ln(\overline{y}_{i})&s_{i}^{2}&\ln(s _{i}^{2})\\ \hline 1&562.50&6.3324&1333.71&7.1957\\ 2&804.75&6.6905&3151.70&8.0557\\ 3&225.50&5.4183&557.43&6.3233\\ 4&245.75&5.5043&601.72&6.3998\\ \end{array}\]

Figure 5.8 shows a plot of \(\ln(s_{i}^{2})\) against \(\ln(\overline{y}_{i})\). This plot is nearly linear, so the slope will provide an estimate of \(q\) in (5.6.2). A line can be drawn by eye or by the regression methods of Chap. 8. Both methods give a slope approximately equal to \(q=1.25\). From Eq. (5.6.3) a variance-stabilizing transformation is

\[h(y_{it})=(y_{it})^{0.375}\,.\]

\begin{table}
\begin{tabular}{c c c c c c} \hline Battery & Lifetime (minutes) & & \(\overline{y}_{i}\). & \(s_{i}^{2}\) \\ \hline
1 & 602 & 529 & 534 & 585 & 562.50 & 1333.71 \\
2 & 863 & 743 & 773 & 840 & 804.75 & 3151.70 \\
3 & 232 & 255 & 200 & 215 & 225.50 & 557.43 \\
4 & 235 & 282 & 238 & 228 & 245.75 & 601.72 \\ \hline \end{tabular}
\end{table}
Table 5.3: Life data for the battery experiment

Figure 5.7: Residual plot for the battery life data

Since \((y_{it})^{0.375}\) is close to \((y_{it})^{0.5}\), and since the square root of the data values is perhaps more meaningful than \((y_{it})^{0.375}\), we will try taking the square root transformation. The square roots of the data are shown in Table 4.

The transformation has stabilized the variances considerably, as evidenced by \(s_{\max}^{2}/s_{\min}^{2}=0.982/0.587\approx 1.67\). Checks of the other model assumptions for the transformed data also reveal no severe problems. The analysis can now proceed using the transformed data. The stated significance level and confidence levels will now be approximate, since the model has been changed based on the data. For the transformed data, \(\text{msE}=0.6936\). Using Tukey's method of multiple comparisons to compare the lives of the four battery types (regardless of cost) at an overall confidence level of 99%, the minimum significant difference obtained from Eq. (4.4.28) is

\[\text{msd}=q_{4,12,0.01}\sqrt{\text{msE}/4}=5.50\sqrt{0.6936/4}=2.29\,.\]

Comparing \(\text{msd}\) with the differences in the sample means \(\overline{x}_{i.}\) of the transformed data in Table 4, we can conclude that at an overall 99% level of confidence, all pairwise differences are significantly different from zero except for the comparison of battery types 3 and 4. Furthermore, it is reasonable to conclude that type 2 (alkaline, store brand) is best, followed by type 1 (alkaline, name brand). However, any more detailed interpretation of the results is muddled by use of the transformation, since the comparisons use mean values of \(\sqrt{\text{life}}\). A more natural transformation, which also provided approximately equal error variances, was used in Sect. 2.5.2. There, the response variable was taken to be "life per unit cost," and confidence intervals were able to be calculated in meaningful units.

#### Analysis with Unequal Error Variances

An alternative to transforming the data to equalize the error variances is to use a method of data analysis that is designed for nonconstant variances. Such a method will be presented for constructing confidence intervals. The method is approximate and tends to be less powerful than the methods of Chap. 4 with transformed data. However, the original data units are maintained, and the analysis can be used whether or not a variance-stabilizing transformation is available.

Without the assumption of equal variances for all treatments, the one-way analysis of variance model (3.3.1) is

\[\begin{array}{c}Y_{it}=\mu+\tau_{i}+\epsilon_{it}\,,\\ \epsilon_{it}\sim N(0,\sigma_{i}^{2})\,,\\ \epsilon_{it}{}^{\prime}\text{s are mutually independent }\,,\\ t=1,\ldots,r_{i},\quad i=1,\ldots,v.\end{array}\]

For this model, each contrast \(\Sigma c_{i}\tau_{i}\) in the treatment parameters remains estimable, but the least squares estimator \(\Sigma c_{i}\hat{\tau}_{i}=\Sigma c_{i}\overline{Y}_{i}\). now has variance \(\text{Var}(\Sigma c_{i}\overline{Y}_{i})=\Sigma c_{i}^{2}\sigma_{i}^{2}/r_{i}\). If we estimate \(\sigma_{i}^{2}\) by \(s_{i}^{2}\) as given in (5.6.1), then

\[\frac{\Sigma c_{i}\hat{\tau}_{i}-\Sigma c_{i}\tau_{i}}{\sqrt{\text{Var}(\Sigma c _{i}\hat{\tau}_{i})}}\]

has approximately a \(t\)-distribution with df degrees of freedom, where

\[\widehat{\text{Var}}(\Sigma c_{i}\hat{\tau}_{i})=\sum\frac{c_{i}^{2}}{r_{i}}s_ {i}^{2}\quad\text{and}\quad\text{df}=\frac{(\Sigma c_{i}^{2}s_{i}^{2}/r_{i})^ {2}}{\sum\frac{(c_{i}^{2}s_{i}^{2}/r_{i})^{2}}{(r_{i}-1)}}\,. \tag{5.6.4}\]

Then an approximate \(100(1-\alpha)\%\) confidence interval for a single treatment contrast \(\Sigma c_{i}\tau_{i}\) is

\[\sum c_{i}\tau_{i}\in\left(\sum c_{i}\hat{\tau}_{i}\pm w\sqrt{\widehat{\text{ Var}}(\Sigma c_{i}\hat{\tau}_{i})}\right)\,, \tag{5.6.5}\]

where \(w=t_{df,\alpha/2}\) and \(\Sigma c_{i}\hat{\tau}_{i}=\Sigma c_{i}\overline{y}_{i}\)., all sums being from \(i=1\) to \(i=v\). The formulae for \(\widehat{\text{Var}}(\Sigma c_{i}\hat{\tau}_{i})\) and df in (5.6.4), often called _Satterthwaite's approximation_, are due to Smith (1936), Welch (1938), and Satterthwaite (1946). The approximation is best known for use in inferences on a pairwise comparison \(\tau_{h}-\tau_{i}\) of the effects of two treatments, in which case, for samples each of size \(r\), (5.6.4) reduces to

\[\widehat{\text{Var}}(\hat{\tau}_{h}-\hat{\tau}_{i})=\frac{s_{h}^{2}}{r}+\frac{ s_{i}^{2}}{r}\quad\text{and}\quad\text{df}=\frac{(r-1)(s_{h}^{2}+s_{i}^{2})^ {2}}{s_{h}^{4}+s_{i}^{4}}\,. \tag{5.6.6}\]

Satterthwaite's approach can be extended to multiple comparison procedures by changing the critical coefficient \(w\) appropriately and computing \(\Sigma c_{i}\hat{\tau}_{i}\) and df separately for each contrast. For Tukey's method, for example, the critical coefficient in (5.6.5) is \(w_{T}=q_{v,df,\alpha}/\sqrt{2}\); this variation on Tukey's method is the _Games-Howell method_ due to Games and Howell (1976). Simulation studies by Dunnett (1980) have shown this Games-Howell method to maintain approximately the specified error rate, though in a few circumstances it can be modestly liberal (true \(\alpha\) slightly larger than the stated value).

#### 5.6.3 Satterthwaite's approximation: trout experiment

In Example 5.6.1, it was shown that the ratio of the maximum to the minimum error variance for the trout experiment satisfies the rule of thumb, but only just. The standardized residuals are plotted against the fitted values in Fig. 5.9. The data for treatment 2 are the most variable and have the highest mean response, but there is no clear pattern of variability increasing as the mean response increases. In fact, it can be verified that a plot of \(\ln(s_{i}^{2})\) against \(\ln(\overline{y}_{i}.)\) is not very close to linear, suggesting that a transformation will not be successful in stabilizing the variances.

To obtain simultaneous approximate 95% confidence intervals for pairwise comparisons in the treatment effects by Tukey's method using Satterthwaite's approximation, we use Eqs. (5.6.5) and (5.6.6) with \(r=10\). The minimum significant difference for pairwise comparison \(\tau_{h}-\tau_{l}\) is

\[\text{msd}=\frac{1}{\sqrt{2}}q_{4,df,0.05}\sqrt{\frac{s_{h}^{2}}{r}+\frac{s_{l }^{2}}{r}}\,,\]

the size of which depends upon which pair of treatments is being compared. From Example 5.6.1, we have

\[s_{1}^{2}=1.04,\ \ s_{2}^{2}=2.95,\ \ s_{3}^{2}=1.29,\ \ s_{4}^{2}=1.00\,.\]

The values of \(\sqrt{\widehat{\text{Var}}(\widehat{\tau}_{h}-\widehat{\tau}_{l})}=\sqrt{s_{h }^{2}/r+s_{i}^{2}/r}\) are listed in Table 5.5. Comparing the values of msd with the values of \(\overline{y}_{h}.-\overline{y}_{i}.\) in Table 5.5, we can conclude with simultaneous approximate 95% confidence

\begin{table}
\begin{tabular}{c c c c c c} \hline \((h,i)\) & \(\sqrt{s_{h}^{2}/r+s_{i}^{2}/r}\) & \(\text{d}f\) & \(q_{4,df,0.05}\) & msd & \(\overline{y}_{h}.-\overline{y}_{i}.\) \\ \hline \((2,3)\) & 0.651 & 15.6 \(\approx\) 16 & 4.05 & 1.86 & 0.30 \\ \((2,4)\) & 0.629 & 14.5 \(\approx\) 15 & 4.08 & 1.82 & 0.64 \\ \((2,1)\) & 0.631 & 14.6 \(\approx\) 15 & 4.08 & 1.82 & 2.13 \\ \((3,4)\) & 0.478 & 17.7 \(\approx\) 18 & 4.00 & 1.35 & 0.34 \\ \((3,1)\) & 0.483 & 17.8 \(\approx\) 18 & 4.00 & 1.37 & 1.83 \\ \((4,1)\) & 0.452 & 18.0 \(\approx\) 18 & 4.00 & 1.28 & 1.49 \\ \hline \end{tabular}
\end{table}
Table 5.5: Approximate values for Tukey’s multiple comparisons for the trout experiment

Figure 5.9: Residual plot for the trout experimentthat each of treatments 2, 3, and 4 yields statistically significantly higher mean response than does treatment 1.

Since \(s_{max}^{2}/s_{min}^{2}=2.95\), we could accept the rule of thumb and apply Tukey's method (4.4.28) for equal variances. The minimum significant difference for each pairwise comparison would then be

\[\text{msd}=q_{4,36,0.05}\sqrt{\text{msE}/10}=3.82\sqrt{1.5685/10}\approx 1.51\.\]

Comparing this with the values of \(\overline{y}_{h}-\overline{y}_{i}\). in Table 5.5, the same conclusion is obtained as in the analysis using Satterthwaite's approximation, namely, treatment 1 has significantly lower mean response than do treatments 2, 3, and 4. The three confidence intervals involving treatment 2, having length 2(msd), would be slightly wider using Satterthwaite's approximation, and the other three confidence intervals would be slightly narrower. Where there is so little difference in the two methods of analysis, the standard analysis would usually be preferred. 

### Checking the Normality Assumption

The assumption that the error variables have a normal distribution is checked using a _normal probability plot_, which is a plot of the standardized residuals against their normal scores. _Normal scores_ are percentiles of the standard normal distribution, and we will show how to obtain them after providing motivation for the normal probability plot.

If a given linear model is a reasonable description of a set of data without any outliers, and if the error assumptions are satisfied, then the standardized residuals would look similar to \(n\) independent observations from the standard normal distribution. In particular, the \(q\)th smallest standardized residual would be approximately equal to the \(100[q/(n+1)]\)th percentile of the standard normal distribution. Consequently, when the model assumptions hold, a plot of the \(q\)th smallest standardized residual against the \(100[q/(n+1)]\)th percentile of the standard normal distribution for each \(q=1\), 2,..., \(n\) would show points roughly on a straight line through the origin with slope equal to 1.0. However, if any of the model assumptions fail, and in particular if the normality assumption fails, then the normal probability plot shows a nonlinear pattern.

Blom, in 1958, recommended that the standardized residuals be plotted against the \(100[(q-0.375)/(n+0.25)]\)th percentiles of the standard normal distribution rather than the \(100[q/(n+1)]\)th percentiles, since this gives a slightly straighter line. These percentiles are called _Blom's normal scores_.

Blom's \(q\)th normal score is the value \(\xi_{q}\) for which

\[P(Z\leq\xi_{q})=(q-0.375)/(n+0.25),\]

where \(Z\) is a standard normal random variable. Hence, Blom's \(q\)th normal score is

\[\xi_{q}=\Phi^{-1}[(q-0.375)/(n+0.25)]\,, \tag{5.7.7}\]

where \(\Phi\) is the cumulative distribution function (cdf) of the standard normal distribution. The normal scores possess a symmetry about zero, that is, the \(j\)th smallest and the \(j\)th largest scores are always equal in magnitude but opposite in sign.

The normal scores are easily obtained and normal probability plots are easily generated using most statistical packages, as illustrated in Sects. 5.8 and 5.9 for SAS and R software, respectively. Alternatively, the normal scores can be calculated as shown in Example 5.7.1 using Table A.3 for the standard normal distribution.

#### Example 5.7.1 Computing normal scores: battery experiment

To illustrate the normal probability plot and the computation of normal scores, consider the battery life data (regardless of cost) that were transformed in Example 5.6.2 to equalize the variances. The transformed observations, standardized residuals, and normal scores are listed in Table 5.6, in order of increasing size of the residuals. In the battery experiment there were \(n=16\) observations in total. The first normal score that corresponds to the smallest residual (\(q=1\)) is

\[\xi_{1}=\Phi^{-1}[(1-0.375)/(16+0.25)]=\Phi^{-1}(0.0385)\,.\]

Thus, the area under the standard normal curve to the left of \(\xi_{1}\) is \(0.0385\). Using a table for the standard normal distribution or a computer program, this value is

\[\Phi^{-1}(0.0385)=-1.77\,.\]

By symmetry, the largest normal score is \(1.77\). The other normal scores are calculated in a similar fashion, and the corresponding normal probability plot is shown in Fig. 5.10. We discuss the interpretation of this plot below. 

For inferences concerning treatment means and contrasts, the assumption of normality needs only to be approximately satisfied. Interpretation of a normal probability plot, such as that in Fig. 5.10, requires some basis of comparison. The plot is not completely linear. Such plots always exhibit some sampling variation even if the normality assumption is satisfied. Since it is difficult to judge a straight line for small samples, normal probability plots are useful only if there are at least 15 standardized residuals being plotted. A plot for 50 standardized residuals that are known to have a normal distribution is shown in plot (a) of Fig. 5.11 and can be used as a benchmark of what might be expected when the assumption of normality is satisfied.

Small deviations from normality do not badly affect the stated significance levels, confidence levels, or power. If the sample sizes are equal, the main case for concern is that in which the distribution has

\begin{table}
\begin{tabular}{c c c c} \hline \(z_{it}\) & \(\xi_{q}\) & \(\sqrt{y_{it}}\) & Battery \\ \hline \(-1.47\) & \(-1.77\) & \(27.258\) & \(2\) \\ \(-1.15\) & \(-1.28\) & \(14.142\) & \(3\) \\ \(-0.95\) & \(-0.99\) & \(23.000\) & \(1\) \\ \(-0.80\) & \(-0.76\) & \(23.108\) & \(1\) \\ \(-0.76\) & \(-0.57\) & \(15.100\) & \(4\) \\ \(-0.74\) & \(-0.40\) & \(27.803\) & \(2\) \\ \(-0.45\) & \(-0.23\) & \(14.663\) & \(3\) \\ \(-0.45\) & \(-0.08\) & \(15.330\) & \(4\) \\ \(-0.32\) & \(0.08\) & \(15.427\) & \(4\) \\ \(0.31\) & \(0.23\) & \(15.232\) & \(3\) \\ \(0.64\) & \(0.40\) & \(24.187\) & \(1\) \\ \(0.84\) & \(0.57\) & \(28.983\) & \(2\) \\ \(1.11\) & \(0.76\) & \(24.536\) & \(1\) \\ \(1.30\) & \(0.99\) & \(15.969\) & \(3\) \\ \(1.37\) & \(1.28\) & \(29.377\) & \(2\) \\ \(1.52\) & \(1.77\) & \(16.793\) & \(4\) \\ \hline \end{tabular}
\end{table}
Table 5.6: Normal scores: battery experimentheavier tails than the normal distribution, as in plot (b) of Fig. 5.11. The apparent outliers are caused by the long tails of the nonnormal distribution, and a model based on normality would not be adequate to represent such a set of data. If this is the case, then use of nonparametric methods of analysis should be considered (as described, for example, by Hollander and Wolfe 2013). Sometimes, a problem of nonnormality can be cured by taking a transformation of the data, such as \(\ln(y_{it})\). However, it should be remembered that any transformation could cause a problem of unequal variances where none existed before. If the equal variance assumption does not hold for a given set of data, then a separate normal probability plot should be generated for each treatment instead of one plot using all \(n\) residuals (provided that there are sufficient data values).

The plot for the transformed battery life data shown in Fig. 5.10 is less linear than the benchmark plot, but it does not exhibit the extreme behavior of plot (b) of Fig. 5.11 for the heavy-tailed nonnormal distribution. Consequently, the normality assumption can be taken to be approximately satisfied, and the stated confidence and significance levels will be approximately correct.

### Using SAS Software

#### Residual Plots

We now illustrate use of the SAS software to generate the various plots used in this chapter. In the following sections, we will check the assumptions on the one-way analysis of variance model (3.3.1) for the data of the mung bean experiment described in Example 5.8.1 below.

Figure 5.10: Normal probability plot for the square root battery data

#### Example 5.8.1Mung bean experiment

An experiment was run in 1993 by K.H. Chen, Y.F. Kuo, R. Sengupta, J. Xu, and L.L. Yu to compare watering schedules and growing mediums for mung bean seeds. There were two treatment factors: "amount of water" with three levels (1, 2, and 3 teaspoons of water per day) and "growing medium" having two levels (tissue and paper towel, coded 1 and 2). We will recode the six treatment combinations as 1 = 11, 2 = 12, 3 = 21, 4 = 22, 5 = 31, 6 = 32.

Forty-eight beans of approximately equal weights were randomly selected for the experiment. These were all soaked in water in a single container for two hours. After this time, the beans were placed in separate containers and randomly assigned to a treatment (water/medium) combination in such a way that eight containers were assigned to each treatment combination. The 48 containers were placed on a table in a random order. The shoot lengths of the beans were measured (in mm) after one week. The data are shown in Table 5.7 together with the order in which they were collected. 

A SAS program that generates the residual plots for the mung bean experiment is shown in Table 5.8. The program uses the SAS procedures GLM, PRINT, and SGPLOT, all of which were introduced in Sect. 3.8.

The values of the factors ORDER (order of observation), WATER, MEDIUM, and the response variable LENGTH are entered into the data set MUNGBEAN using the INPUT statement. The treatment combinations are then recoded, with the levels of TRTMT representing the recoded levels 1-6.

The OUTPUT statement in the GLM procedure calculates and saves the predicted values \(\widehat{\gamma}_{it}\) as the variable YPRED and two copies of the residuals \(\hat{e}_{it}\) as the variables E and Z in a new data set named MUNGBN2. The data set MUNGBN2 also contains all of the variables in the original data set MUNGBEAN. The residuals stored as the variable Z are then standardized using the procedure STANDARD by dividing each residual by \(\sqrt{ssE/(n-1)}\). This is done by requesting the procedure STANDARD to achieve a standard deviation of 1.0. The variables E and Z then represent the residuals and standardized residuals, respectively.

The procedure RANK is used to compute Blom's normal scores. The procedure orders the standardized residuals from smallest to largest and calculates their ranks. (The \(q\)th smallest residual has rank \(q\).) The values of the variable NSCORE calculated by this procedure are the normal scores for the values of Z. The PRINT procedure prints all the values of the variables created so far. Some representative output is shown in Fig. 5.12. The PRINT statement can be omitted if this information is not wanted.

\begin{table}
\begin{tabular}{c c c c c} \hline Treatment & Shoot length in mm (Order of observation in parentheses) \\ \hline
1 & 1.5 (14) & 1.1 (15) & 1.3 (18) & 0.9 (30) \\  & 8.5 (35) & 10.6 (39) & 3.5 (42) & 7.4 (43) \\
2 & 0.0 (3) & 0.6 (4) & 9.5 (7) & 11.3 (12) \\  & 12.6 (17) & 8.1 (27) & 7.8 (29) & 7.3 (37) \\
3 & 5.2 (16) & 0.4 (23) & 3.6 (31) & 2.8 (36) \\  & 12.3 (45) & 14.1 (46) & 0.3 (47) & 1.8 (48) \\
4 & 13.2 (1) & 14.8 (11) & 10.7 (13) & 13.8 (20) \\  & 9.6 (24) & 0.0 (34) & 0.6 (40) & 8.2 (44) \\
5 & 5.1 (5) & 3.3 (21) & 0.2 (26) & 3.9 (28) \\  & 7.0 (32) & 9.5 (33) & 11.1 (38) & 6.2 (41) \\
6 & 11.6 (2) & 2.3 (6) & 6.7 (8) & 2.5 (9) \\  & 10.6 (10) & 10.8 (19) & 15.9 (22) & 9.0 (25) \\ \hline \end{tabular}
\end{table}
Table 5.7Data for the mung bean experiment

[MISSING_PAGE_EMPTY:8079]

Plots of the standardized residuals \(z_{it}\) against treatments, predicted values, run order, and normal scores may be of interest. For illustration, the last two of these are requested using the SGPLOT procedure. Vertical and horizontal reference lines at zero may be included as appropriate via the REFLINE statements.

For the mung bean experiment, a plot of the standardized residuals against the order in which the observations are collected is shown in Fig. 13, and a plot of standardized residuals against normal scores is shown in Fig. 14. Neither of these plots indicates any serious problems with the assumptions on the model.

A plot of the standardized residuals against the predicted values (not shown) suggests that treatment variances are not too unequal, but that there could be outliers associated with one or two of the treatments. The first nine lines of the SAS program in Table 9, through the first PRINT procedure, produced the first four columns of output of Fig. 15. From this, the rule of thumb can be checked that the sample variances should not differ by more than a factor of 3. It can be verified that the ratio of the maximum and minimum variances is under 2.7 for this experiment.

When the equal-variance assumption does not appear to be valid, the experimenter may choose to use an analysis based on Satterthwaite's approximation (see Sect. 8.3), using formulas involving the treatment sample variances such as those in Fig. 15. A normal probability plot such as that of Fig. 14 would not be relevant; rather, the normality assumption needs to be checked for each treatment separately. This can be done by generating a separate normal probability plot for each treatment (provided that the sample sizes are sufficiently large). To obtain the plots, first obtain the normal scores separately for each treatment by including a BY TRTMT statement in the SORT and

Figure 14: Plot of \(z_{it}\) versus normal score: mung bean experiment

Figure 13: Plot of \(z_{it}\) versus run order: mung bean experiment

RANK procedures. Then, instead of SGPLOT, use the SGPANEL procedure and PANELBY TRTMT to produce a panel of plots--one for each treatment. Sample program lines are as follows.

PROC SORT; BY TRTMT; PROC RANK NORMAL=BLOM; BY TRTMT; VAR Z; RANKS NCORE; PROC SGPANEL; PANELBY TRTMT; SCATTER X=NSCORE Y=Z;

#### Transforming the Data

If a variance-stabilizing transformation is needed, a plot of \(\ln(s_{i}^{2})\) against \(\ln(\tilde{y}_{i.})\) can be achieved via the program in Table 9 (shown for the mung bean experiment). These statements can be added to those in Table 9 either before the GLM procedure or at the end of the program.

The SORT procedure and the BY statement sort the observations in the original data set MUNGBEAN using the values of the variable TRTMT. This is required by the subsequent MEANS procedure with the NOPRINT option, which computes the mean and variance of the variable LENGTH separately for each treatment, without printing the results. The OUTPUT statement creates a data set named MUNGBN3, with one observation for each treatment, and with the two variables MEANLNTH and VARLNTH containing the sample mean lengths and sample variances for each treatment. Two new variables LN_MEAN and LN_VAR are created.

These are the natural logarithm, or log base \(e\), of the sample mean and variance of length for each treatment. The PRINT procedure prints the values of the variables TRTMT, MEANLNTH, VARLNTH, LN_MEAN, LN_VAR. The output is in Fig. 15.

Finally, the SGPLOT procedure generates the plot of \(\ln(s_{i}^{2})\) against \(\ln(\widetilde{y}_{i.})\), shown in Fig. 16. The values do not fall along a straight line, so a variance-stabilizing transformation of the type given in Eq. (5.6.3) does not exist for this data set. However, since the ratio of the maximum to the minimum variance is less than 3.0, a transformation is not vital, according to our rule of thumb.

If an appropriate transformation is identified, then the transformed variable can be created from the untransformed variable in a DATA step of a SAS program, just as the variables LN_MEAN and LN_VAR were created in the data set MUNGBN3 by transforming the variables MEANLNTH and VARLNTH, respectively. Alternatively, the transformation can be achieved after the INPUT statement in the same way as the factor TRTMT was created. SAS statements useful for the variance-stabilizing transformations of Eq. (5.6.3) include:

\[\begin{array}{ll}\text{Transformation}&\text{SAS Statement}\\ \hline h=\ln(y)&\text{H}=\text{LOG(Y);}\\ h=\sin^{-1}(y)&\text{H}=\text{ARSIN(Y);}\\ h=y^{p}&\text{H}=\text{Y}*\ast\text{P;}\end{array}\]

#### Implementing Satterthwaite's Method

In Example 5.6.3, given indications of unequal variances in the trout experiment, simultaneous approximate 95% confidence intervals for pairwise comparisons were computed using the Games-Howell method--namely, using Satterthwaite's approximation in conjunction with Tukey's method. This method can be implemented in SAS software using PROC MIXED--a procedure that will be introduced in greater detail in later chapters. Appropriate statements are given in Table 10. The REPEATED statement relaxes the model assumption of equal variances, allowing for separate variance estimates \(s_{i}^{2}\) at each level of sulfa. Correspondingly, the model is fit by restricted maximum likelihood estimation rather than ordinary least squares (see Chap. 19 for more on restricted maximum likelihood estimation). The collective options in the MODEL and LSMEANS statements implement Tukey's method,

[MISSING_PAGE_EMPTY:8083]

were 48 containers placed in random order on a table. The data were provided in Table 5.7, with the six treatment combinations recoded as 1 = 11, 2 = 12, 3 = 21, 4 = 22, 5 = 31, 6 = 32.

An R program that generates the residual plots for the mung bean experiment is shown in Table 5.11, with the first three lines of data displayed. After reading the data, the program uses the R function aov, introduced in Sect. 3.9.3, to fit model (3.3.1), saving related information as the object model. Consequently, the fitted values and residuals are available as the columns \(\tt{ypred}\ =\ \tt{fitted}\ (\tt{model})\) and \(\tt{e}\ =\ \tt{resid}\ (\tt{model})\), respectively. The function sd(e) computes the sample standard deviation of the residuals, so the column \(\tt{z}\ =\ \tt{e}/\tt{sd}(e)\) contains the standardized residuals. Semi-colons separate commands on the same line. Blom's normal scores are computed by Eq. (5.7.7), p. 117, using the column \(\tt{q}\ =\ \tt{rank}\ (\tt{e})\) of ranks of the residuals and the standard normal quantile (inverse cumulative distribution) function qnorm, and are saved as the column nscore. The \(q\)th smallest residual has rank \(q\) and yields the \(q\)th smallest normal score. Creating these four new variables within the brackets of the statement

\(\tt{mung.data}\ =\ \tt{within}(\tt{mung.data},\ \{\ldots\})\)

\(\tt{\#}\ \tt{R}\ \tt{code}\ \tt{and}\ \tt{output}\)\(\tt{mung.data}\ =\ \tt{read.table}(\tt{"data}/\tt{mungbean.txt"},\ \tt{header=T})\)\(\tt{model1}\ =\ \tt{aov}(\tt{Length}\ \char 6\ \tt{factor}(\tt{Trtmt}),\ \tt{data=mung.data})\)

\(\tt{\#}\ \tt{Compute}\ \tt{predicted}\ \tt{values},\ \tt{residuals},\ \tt{standardized}\ \tt{residuals},\ \tt{normal}\ \tt{scores}\)\(\tt{mung.data}\ =\ \tt{within}(\tt{mung.data},\ \{\ \tt{\#}\ \tt{Compute}\ \tt{predicted},\ \tt{residual},\ \tt{and}\ \tt{standardized}\ \tt{residual}\ \tt{values}\)\(\tt{ypred}\ =\ \tt{fitted}(\tt{model1});\ \tt{e}\ =\ \tt{resid}(\tt{model1});\ \tt{z}\ =\ \tt{e}/\tt{sd}(\tt{e});\)

\(\tt{\#}\ \tt{Compute}\ \tt{Blom's}\ \tt{normal}\ \tt{scores}\)\(\tt{n}\ =\ \tt{length}(\tt{e});\ \tt{q}\ =\ \tt{rank}(\tt{e});\ \tt{nscore}\ =\ \tt{qnorm}((\tt{q-0.375})/(\tt{n+0.25}))\ )\(\tt{\})\)

\(\tt{\#}\ \tt{Display}\ \tt{first}\ 3\ \tt{lines}\ \tt{of}\ \tt{mung.data},\ 4\ \tt{digits}\ \tt{per}\ \tt{variable}\)\(\tt{print}(\tt{head}(\tt{mung.data},\ 3),\ \tt{digits}\tt{=4})\)

Order Water Medium Length Trtmt nscore q n z eypred
1 1 2 2 13.2 4 0.920140480.98204.3378.863
2 2 3 2 11.6 6 0.57583548.06622.9258.675
3 3 3 1 2 0.0 2 -1.6036348-1.6188-7.1507.150

\(\tt{\#}\ \tt{Generate}\ \ \tt{residual}\ \tt{plots}\)\(\tt{plot}(\tt{z}\ \char 67\ \tt{Trtmt},\ \tt{data=mung.data},\ \tt{ylab="Standardized}\ \tt{Residuals"},\ \tt{las=1})\)\(\tt{abline}(\tt{h=0})\ \tt{\#}\ \tt{Horizontal}\ \tt{line}\ \tt{at}\ \tt{zero}\)\(\tt{plot}(\tt{z}\ \char 67\ \tt{Order},\ \tt{data=mung.data},\ \tt{ylab="Standardized}\ \tt{Residuals"},\ \tt{las=1})\)\(\tt{abline}(\tt{h=0})\)\(\tt{plot}(\tt{z}\ \char 67\ \tt{ypred},\ \tt{data=mung.data},\ \tt{ylab="Standardized}\ \tt{Residuals"},\ \tt{las=1})\)\(\tt{abline}(\tt{h=0})\)\(\tt{plot}(\tt{z}\ \char 67\ \tt{nscore},\ \tt{data=mung.data},\ \tt{ylab="Standardized}\ \tt{Residuals"},\ \tt{las=1})\)\(\tt{abline}(\tt{h=0})\)\(\tt{plot}(\tt{z}\ \char 67\ \tt{nscore},\ \tt{data=mung.data},\ \tt{ylab="Standardized}\ \tt{Residuals"},\ \tt{las=1})\)\(\tt{q}\ \tt{qline}(\tt{mung.data}\tt{z})\)\(\tt{\#}\ \tt{Line}\ \tt{through}\ \tt{1st}\ \tt{and}\ \tt{3rd}\ \tt{quantile}\)\(\tt{points}\)\(\tt{\#}\ \tt{A}\ \tt{simpler}\ \tt{way}\ \tt{to}\ \tt{generate}\ \tt{the}\ \tt{normal}\ \tt{probability}\)\(\tt{plot}\)\(\tt{q}\ \tt{q}\tt{norm}(\tt{mung.data}\tt{z});\ \tt{q}\tt{q}\tt{linenables their creation from variables in the data set mung.data and their addition to the data set. Alternatively, the normal scores could be obtained by replacing the three statements for n, q and nscore with the single statement

 nscore = qqnorm(z)5x

 though the resulting normal scores are only Blom's normal scores for 10 or fewer residuals, with nscore = qnorm((q-0.5)/n) otherwise. Here, qqnorm is a plotting function to be discussed shortly that generates a normal probability plot with normal scores on the \(x\) axis.

Plots of the standardized residuals \(z_{it}\) against treatments, run order, predicted values, and normal scores are generated by the four plot function calls. For each of the first three plots, the statement abline(h=0) causes inclusion of a horizontal reference line at zero. For the normal probability plot, the statement qqline(mung.data$z) causes inclusion of a line through the first and third quantile-quantile points of z and nscore--namely, through the point corresponding to the first quantile of each variable, and through the point corresponding to their third quantiles.

The last three lines of code illustrate an alternative, simpler method of generating the normal probability plot, using the function qqnorm(z). This function generates a normal probability plot, plotting the standardized residuals z against the normal scores--namely, the quantiles of the standard normal distribution. This function uses Blom's normal scores for 10 or fewer \(z\)-values, and uses normal scores equal to the \(100[(q-0.5)/n]\)th percentiles of the standard normal distribution otherwise. These normal scores, corresponding to the \(x\)-axis of the plot, can be saved by the command nscore = qqnorm(z) $x as noted above. As will be seen, using the qqnorm function is convenient if separate normal probability plots are needed for each treatment.

For the mung bean experiment, a plot of the standardized residuals against the order in which the observations are collected is shown in Fig. 5.18, and a plot of standardized residuals against normal

Figure 5.19: Plot of \(z_{it}\) versus normal score: mung bean experiment

Figure 5.18: Plot of \(z_{it}\) versus order: mung bean experiment

scores is shown in Fig. 19. Neither of these plots indicates any serious problems with the assumptions on the model.

A plot of the standardized residuals against the predicted values (not shown) suggests that treatment variances are not too unequal, but that there could be outliers associated with one or two of the treatments. In the R program in Table 12, the second block of code computes the sample statistics displayed subsequently by treatment. The by function is used to compute the (sample) mean and variance of Length by Trtmt, saving the results in the columns MeanLnth and VarLnth, respectively. Then the natural log of each value is computed, saving the log sample means and log sample variances in the columns LnMean and LnVar, respectively. The cbind function column-binds these four columns with another containing the treatment labels, saving them as stats, which is then displayed. Given the displayed information, the rule of thumb can be checked that the sample variances should not differ by more than a factor of 3. It can be verified that the ratio of the maximum and minimum variances is under 2.7 for this experiment.

When the equal-variance assumption does not appear to be valid, the experimenter may choose to use an analysis based on Satterthwaite's approximation (see Sect. 5.9.3), using formulas involving the treatment sample variances such as those in Table 12. A normal probability plot such as that of Fig. 19 would not be relevant, but the normality assumption needs to be checked for each treatment separately. This can be done by generating a separate normal probability plot for each treatment (provided that the sample sizes are sufficiently large). These separate plots are generated by the following single line of R code.

\begin{table}
\begin{tabular}{c c} \# R Code and Output \\ mung.data = read.table(*data/mungbean.txt*, header=T) \\ \# Compute sample means and variances and their natural logs by trtmt \\ MeanLnth = by(mung.data$Length, mung.data$Trtmt, mean) \# Sample means \\ VarLnth = by(mung.data$Length, mung.data$Trtmt, var) \# Sample variances \\ LnMean = log(MeanLnth) \# Column of ln sample means \\ LnVar = log(VarLnth) \# Column of ln sample variances \\ Trtmt = c(1:6) \# Column of trtmt levels \\ stats = cbind(Trtmt, MeanLnth, VarLnth, LnMean, LnVar) \# Column bind \\ stats \# Display the stats data \\ Trtmt MeanLnth VarLnth LnMean LnVar \\
1 1 4.3500 15.171 1.4702 2.7194 \\
2 2 7.1500 21.117 1.9671 3.0501 \\
3 3 5.0625 28.057 1.6219 3.3342 \\
4 4 8.8625 32.803 2.1818 3.4905 \\
5 5 5.7875 12.156 1.7557 2.4978 \\
6 6 8.6750 21.679 2.1604 3.0764 \\ plot(LnVar \(\widetilde{\ }\) LnMean, las=1) \\ \end{tabular}
\end{table}
Table 12: R program to plot ln(\(s_{i}^{2}\)) against ln(\(\overline{y}_{i}\)): mung bean experiment The by function applies the function qqnorm to the variable z at each Trtmt level. Alternatively, these plots can be generated one-by-one using the following example for treatment 1, where the main option adds a main title to the plot.

```
qqnorm(mung.data$z[mung.data$Trtmt == 1], main = "Normal Probability Plot: Trtmt 1") qqline(mung.data$z)
```

#### Transforming the Data

If a variance-stabilizing transformation is needed, a plot of \(\ln(s_{i}^{2})\) against \(\ln(\bar{y}_{i}.)\) can be achieved as illustrated in the R program in Table 5.12 (shown for the mung bean experiment). First, we need to compute the statistics to be plotted. The R functions mean and var compute sample mean and variance, respectively, of a specified variable and, when coupled with the by function, can compute such statistics for a specified variable at each level of a factor. In our program, the by function in the code line

```
MeanLnth = by(mung.data$Length, mung.data$Trtmt, mean)
```

applies the function mean to the variable Length for (by) each level of Trtmt, saving the resulting sample means as elements of the column MeanLnth. The column VarLnth of sample variances is computed similarly, coupling the by and var functions. The function, log, is then used to compute the natural logarithm, or log base \(e\), of the average length and the sample variance for each treatment, saving the results in the columns LnMean and LnVar, respectively. The levels 1-6 of Trtmt are assigned to the new column Trtmt for display purposes. The results are then displayed as columns using the cbind function. Note that these columns of data were created outside of the mung.data data set, since they have fewer entries.

Finally, the plot function generates the plot of \(\ln(s_{i}^{2})\) against \(\ln(\bar{y}_{i}.)\), shown in Fig. 5.20. The values do not fall along a straight line, so a variance-stabilizing transformation of the type given in Eq. (5.6.3) does not exist for this data set. However, since the ratio of the maximum to the minimum variance is less than 3.0, a transformation is not vital, according to our rule of thumb.

If an appropriate transformation is identified, then the transformed variable can be created from the untransformed variable by applying the appropriate R function. R functions useful for the variance-stabilizing transformations of Eq. (5.6.3) include:

#### Implementing Satterthwaite's Method

In Example 5.6.3, given indications of unequal variances in the trout experiment, simultaneous approximate 95% confidence intervals for pairwise comparisons were computed using the Games-Howell method--namely, using Satterthwaite's approximation in conjunction with Tukey's method. This method is implemented in Table 5.13 by reading the author-defined R function GamesHowell from the file GamesHowell.r in the funcs subdirectory of the working directory, then calling this function via the following code line:

 GamesHowell(y = trout.data$Hemo, T = trout.data$Sulfa, alpha = 0.05) The function inputs are the column of observations y, the column of corresponding treatment levels T, and the joint significance level \(\alpha\) with a default value of 0.05. The results, shown at the bottom of Table 5.13, match the corresponding information in Table 5.5 and Fig. 5.17.

This touches upon an important characteristic of the R software--namely, that one can create user-defined functions to implement methods and procedures that may not otherwise be available as R functions. For example, the code

 GamesHowell = function(y, T, alpha = 0.05){function code}

\begin{table}
\begin{tabular}{l l} \hline \hline  & \\ \multicolumn{1}{c}{} & \\ \uses function to create and define a new function named GamesHowell in terms of three parameters y, T, and alpha, with 0.05 as the default value of alpha. Here "function code" would be replaced by R code defining what the function does given the input parameters and what information it returns when done. Such code defining a function can be saved in a separate file then read into a program using the source function, as illustrated in Table 13. This facilitates reuse of the function in other R programs. Alternatively, the code defining a function can simply be included directly in an R program, replacing the code line source("GamesHowell.r") in Table 13, for example. For the interested reader, the GamesHowell function code is provided and discussed in the following optional subsection.

##### The User-Defined R Function GamesHowell (Optional)

The author-defined function GamesHowell was used in Table 13 to implement the Games-Howell method of multiple comparisons. The R code defining the function is provided in Table 14 for the interested reader. R functions are defined via the R function function. In particular, the code GamesHowell = function(y, T, alpha=0.05) indicates that a new function named GamesHowell is being defined in terms of three parameters y, T, and alpha, and that the default value of alpha is 0.05. All of the subsequent code inside the brackets "{}" is the R code defining what the function does.

\begin{table}
\begin{tabular}{c} \# Contents of file GamesHowell.r: \\ GamesHowell = function(y, T, alpha=0.05){ \\ \# y is a data column, T the corresp column of trtmt levels. \\ \# For the y-values corresponding to each level in T, compute: \\ r = tapply(y, T, length) \# Column of reps r_i \\ ybar = tapply(y, T, mean) \# Column of trtmt sample means ybar_i \\ s2 = tapply(y, T, var) \# Column of trtmt sample variances s^2\_i \\ v = length(r) \# v = number of treatments (length of column r) \\ combos = combn(v,2) \# 2 by v-choose-2, cols being combos (i,s) \\ i = combos[1,] \# Save row 1, i.e. the i’s, as the column i \\ s = combos[2,] \# Save row 2, i.e. the s’s, as the column s \\ \# For each combo (i,s), compute est of tau\_i - tau\_s, stde, etc. \\ estimate = combn(v, 2, function(is) -diff(ybar[is]) ) \# est’s \\ stde = combn(v, 2, function(is) sqrt(sum(s2[is]/r[is])) ) \# stde’s \\ t = estimate/stde \# t-statistics \\ df = combn(v, 2, function(is) \\ (sum(s2[is]/r[is]))^2/(sum((s2[is]/r[is])^2/(r[is]-1)))) \# df’s \\ p = pttukey(abs(t)*sqrt(2), v, df, lower.tail=F) \# p-values \\ p = round(p, digits=5) \# Keep at most 5 decimal places \\ w = qtukey(0.05,v,df, lower.tail=F)/sqrt(2) \# Critical coefficients \\ msd = w*stde \# msd’s \\ lc1 = estimate - msd \# Lower confidence limits \\ ucl = estimate + msd \# Upper confidence limits \\ results = cbind(i, s, estimate, stde, df, t, p, msd, lc1, ucl) \\ results = signif(results, digits=5) \# Keep 5 significant digits \\ results = results[rev(order(estimate)),] \# Sort by estimates \\ rownames(results) = seq(1:nrow(results)) \# Name rows 1,2,...,nrows \\ header=paste("Games-Howell method of MCP for tau\_i-tau\_s", \\ "with alpha =",alpha) \\ return(list(header,results)) \\ \# end function \\ \end{tabular}
\end{table}
Table 14: R function GamesHowell for multiple comparisons with unequal variancesWhen calling the function GamesHowell, one can specify alpha or not; if not, the default value of 0.05 will be used. The other parameters y and T represent the column of response values and the corresponding column of treatment levels, respectively. In Table 5.13, the function call GamesHowell(y=trout.data$Hemo, T=trout.data$Sulfa, alpha=0.05) explicitly indicates that the column trout.data$Hemo contains the response values (y in the function) and the column trout.data$Sulfa contains the treatment levels (T in the function code). If one is explicit, using y=, T=, and alpha=, then the parameters may be entered in any order. Otherwise, they must be entered in the same order (y,T,alpha) as they are listed in the definition of the function. For example, the function call GamesHowell(trout.data$Hemo, trout.data$Sulfa, 0.05) also works, but not if the parameters were entered in any other order.

This code makes use of the R functions tapply and combin. Given data for a completely randomized design, the function tapply(y,T,fn) applies any specified R function fn separately to the subset of the observations y corresponding to each trtmt level. For example, given observations y and corresponding treatment levels T for a completely randomized design, the statement \(\mathtt{ybar}=\mathtt{tapply(y,T,mean)}\) applies the function mean to compute the mean \(\overline{y}_{i.}\) of y for each level of T, saving these as \(\mathtt{ybar}=(\overline{y}_{1,}\ldots,\overline{y}_{v.})\) but as a column. Similarly, tapply is used to compute the column r of replication numbers \(r_{i}\) and the column s2 of treatment sample variances \(s_{i}^{2}\).

Having \(v\) treatments, the function combn(v,2) returns the \(\binom{v}{2}=v(v-1)/2\) combinations \((i,s)\) of the integers \(1,\ldots,v\) taken two at a time as the columns of a matrix, providing the treatment pairs for pairwise comparisons. For each combination or treatment pair \((i,s)\), the function combn(v,2,function(is),-diff(ybar[is])) computes the negative difference of the \(i\)th and \(s\)th elements of the column ybar, yielding the column estimate of estimates \(\overline{y}_{i.}-\overline{y}_{s.}\). The column stde of standard errors of the estimates is obtained similarly from the columns r and s2.

Other functions used include ptukey and qtukey, pertaining to the Studentized range distribution, (Table A.8). In particular, ptukey(x,v,df,lower.tail=F), which provides the upper-tail probability \(P(X>x)\) of the range \(X\) of \(v\) Studentized variates each involving d_f_ degrees of freedom, is used to compute \(p\)-values. Likewise, qtukey(\(\alpha\),v,df,lower.tail=F), which provides the upper-\(\alpha\) quantile of the same distribution, is used to obtain the critical coefficients for the simultaneous confidence intervals.

An R function can return one object, via the return function. In this case, the function returns one list consisting of two objects: (i) header, containing a description of the statistical procedure conducted; and (ii) results, an R data.frame containing the numerical results. This returned information, automatically displayed when the function finishes executing, is shown at the bottom of Table 5.13.

## Exercises

1. **Meat cooking experiment, continued** Check the assumptions on the one-way analysis of variance model (3.3.1) for the meat cooking experiment, which was introduced in Exercise 14 of Chap. 3. The data were given in Table 3.14. (the order of collection of observations is not available).
2. **Soap experiment, continued** Check the assumptions on the one-way analysis of variance model (3.3.1) for the soap experiment, which was introduced in Sect. 2.5.1. The data are reproduced in Table 5.15 (the order of collection of observations is not available).

[MISSING_PAGE_FAIL:156]

2. Suggest a way to design the experiment using more than one subject. (Hint: consider using subjects as blocks in the experiment).
5. **Catalyst experiment** H. Smith, in the 1969 volume of _Journal of Quality Technology_, described an experiment that investigated the effect of four reagents and three catalysts on the production rate in a catalyst plant. He coded the reagents as \(A\), \(B\), \(C\), and \(D\), and the catalysts as \(X\), \(Y\), and \(Z\), giving twelve treatment combinations, coded as \(AX\), \(AY\), \(\ldots\), \(DZ\). Two observations were taken on each treatment combination, and these are shown in Table 5.18, together with the order in which the observations were collected. Are the assumptions on the one-way analysis of variance model (3.3.1) approximately satisfied for these data? If not, can you suggest what needs to be done in order to be able to analyze the experiment?
6. **Bicycle experiment** (Debra Schomer 1987) The bicycle experiment was run to compare the crank rates required to keep a bicycle at certain speeds, when the bicycle was in twelfth gear on flat ground. The speeds chosen were 5, 10, 15, 20, and 25 mph, (coded 1-5). The data are given in Table 5.19. The experimenter fitted the one-way

\begin{table}
\begin{tabular}{c c c c c c c c} Time order & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 \\ Coded treatment & \(CY\) & \(AZ\) & \(DX\) & \(AY\) & \(CX\) & \(DZ\) & \(AX\) & \(CZ\) \\ Yield & 9 & 5 & 12 & 7 & 13 & 7 & 4 & 13 \\ Time order & 9 & 10 & 11 & 12 & 13 & 14 & 15 & 16 \\ Treatment & \(BY\) & \(CZ\) & \(BZ\) & \(DX\) & \(BX\) & \(CX\) & \(DY\) & \(BZ\) \\ Yield & 13 & 13 & 7 & 12 & 4 & 15 & 12 & 9 \\ Time order & 17 & 18 & 19 & 20 & 21 & 22 & 23 & 24 \\ Treatment & \(BX\) & \(DY\) & \(AY\) & \(DZ\) & \(BY\) & \(AX\) & \(CY\) & \(AZ\) \\ Yield & 6 & 14 & 11 & 9 & 15 & 6 & 15 & 9 \\ \end{tabular}
\end{table}
Table 5.18: Production rates for the catalyst experiment analysis of variance model (3.3.1) and plotted the standardized residuals. She commented in her report: Note the larger spread of the data at lower speeds. This is due to the fact that in such a high gear, to maintain such a low speed consistently for a long period of time is not only bad for the bike, it is rather difficult to do. Thus the experimenter was not surprised to find a difference in the variances of the error variables at different levels of the treatment factor. 1. Plot the standardized residuals against \(\widehat{y}_{it}\), compare the sample variances, and evaluate equality of the error variances for the treatments. 2. Choose the best transformation of the data of the form (5.6.3), and test the hypotheses that the linear and quadratic trends in crank rates due to the different speeds are negligible, using an overall significance level of 0.01. 3. Repeat part (b), using the untransformed data and Satterthwaite's approximation for unequal variances, 4. Discuss the relative merits of the methods applied in parts (b) and (c).
7. **Dessert experiment** (P. Clingan, Y. Deng, M. Geil, J. Mesaros, and J. Whitmore, 1996) The experimenters were interested in whether the melting rate of a frozen orange dessert would be affected (and, in particular, slowed down) by the addition of salt and/or sugar. At this point, they were not interested in taste testing. Six treatments were selected, as follows: 1 = 1/8 tsp salt, 1/4 cup sugar 4 = 1/4 tsp salt, 1/4 cup sugar 2 = 1/8 tsp salt, 1/2 cup sugar 5 = 1/4 tsp salt, 1/2 cup sugar 3 = 1/8 tsp salt, 3/4 cup sugar 6 = 1/4 tsp salt, 3/4 cup sugar For each observation of each treatment, the required amount of sugar and salt was added to the contents of a 12-ounce can of frozen orange juice together with 3 cups of water. The orange juice mixes were frozen in ice cube trays and allocated to random positions in a freezer. After 48 hours, the cubes were removed from the freezer, placed on half-inch mesh wire grid and allowed to melt into a container in the laboratory (which was held at 24.4 \({}^{\circ}\)C) for 30 minutes. The percentage melting (by weight) of the cubes are recorded in Table 5.20. The coded position on the table during melting is also recorded. 1. Plot the data. Does it appear that the treatments have different effects on the melting of the frozen orange dessert?

\begin{table}
\begin{tabular}{c c c c c} \hline Code & Treatment (mph) & Crank rates & & \\ \hline
1 & 5 & 15 & 19 & 22 \\
2 & 10 & 32 & 34 & 27 \\
3 & 15 & 44 & 47 & 44 \\
4 & 20 & 59 & 61 & 61 \\
5 & 25 & 75 & 73 & 75 \\ \hline \end{tabular}
\end{table}
Table 5.19: Data for the bicycle experiment 2. Check whether the assumptions on the one-way analysis of variance model (3.3.1) are satisfied for these data. Pay particular attention to the equal-variance assumption. 3. Use Satterthwaite's method to compare the pairs of treatments, using individual 99% confidence intervals. If doing the computations by hand, compute only the confidence intervals corresponding to the three most disparate pairs of treatment sample means. 4. What conclusions can you draw about the effects of the treatments on the melting of the frozen orange dessert? If your concern was to produce frozen dessert with a long melting time, which treatment would you recommend? What other factors should be taken into account before production of such a dessert?
8. **Wildflower experiment** (Barbra Foderaro 1986) An experiment was run to determine whether or not the germination rate of the endangered species of Ohio plant _Froelichia floridana_ is affected by storage temperature or storage method. The two levels of the factor "temperature" were "spring temperature, 14-24 degC" and "summer temperature, 18-27 degC." The two levels of the factor "storage" were "stratified" and "unstratified." Thus, there were four treatment combinations in total. Seeds were divided randomly into sets of 20 and the sets assigned at random to the treatments. Each stratified set of seeds was placed in a mesh bag, spread out to avoid overlapping, buried in two inches of moist sand, and placed in a refrigeration unit for two weeks at 50 degF. The unstratified sets of seeds were kept in a paper envelope at room temperature. After the stratification period, each set of seeds was placed on a dish with 5 ml of distilled deionized water, and the dishes were put into one of two growth chambers for two weeks according to their assigned level of temperature. At the end of this period, each dish was scored for the number of germinated seeds. The resulting data are given in Table 5.21. 1. For the original data, evaluate the constant-variance assumption on the one-way analysis of variance model (3.3.1) both graphically and by comparing sample variances. 2. It was noted by the experimenter that since the data were the numbers of germinated seeds out of a total of 20 seeds, the observations \(Y_{it}\) should have a binomial distribution. Does the corresponding transformation help to stabilize the variances? 3. Plot \(\ln(s_{i}^{2})\) against \(\ln(\overline{y}_{i.})\) and discuss whether or not a power transformation of the form given in Eq. (5.6.3) might equalize the variances. 4. Use Scheffe's method of multiple comparisons, in conjunction with Satterthwaite's approximation, to construct 95% confidence intervals for all pairwise comparisons and for the two contrasts

\begin{table}
\begin{tabular}{c c c c c c c} \hline Position & 1 & 2 & 3 & 4 & 5 & 6 \\ Treatment & 2 & 5 & 5 & 1 & 4 & 3 \\ \% melt & 12.06 & 9.66 & 7.96 & 9.04 & 10.17 & 7.86 \\ Position & 7 & 8 & 9 & 10 & 11 & 12 \\ Treatment & 4 & 1 & 3 & 1 & 2 & 4 \\ \% melt & 8.14 & 9.52 & 4.28 & 8.32 & 10.74 & 5.98 \\ Position & 13 & 14 & 15 & 16 & 17 & 18 \\ Treatment & 2 & 6 & 6 & 3 & 6 & 5 \\ \% melt & 9.84 & 7.58 & 6.65 & 9.26 & 8.46 & 12.83 \\ \hline \end{tabular}
\end{table}
Table 5.20: Percentage melting of frozen orange cubes for the dessert experiment \[\frac{1}{2}[1,\,1,\,-1,\,-1]\quad\text{and}\quad\frac{1}{2}[1,\,-1,\,1,\,-1]\,,\] which compare the effects of temperature and storage methods, respectively.
9. **Spaghetti sauce experiment** (K. Brewster, E. Cesmeli, J, Kosa, M. Smith, and M. Soliman 1996) The spaghetti sauce experiment was run to compare the thicknesses of three particular brands of spaghetti sauce, both when stirred and unstirred. The six treatments were: 1 = store brand, unstirred 2 = store brand, stirred 3 = national brand, unstirred 4 = national brand, stirred 5 = gourmet brand, unstirred 6 = gourmet brand, stirred Part of the data collected is shown in Table 5.22. There are three observations per treatment, and the response variable is the weight (in grams) of sauce that flowed through a colander in a given period of time. A thicker sauce would give rise to smaller weights. 1. Check the assumptions on the one-way analysis of variance model (3.3.1). 2. Use Satterthwaite's method to obtain simultaneous confidence intervals for the six preplanned contrasts \[\tau_{1}-\tau_{2}\,,\quad\tau_{3}-\tau_{4}\,,\quad\tau_{5}-\tau_{6}\,,\quad \tau_{1}-\tau_{5}\,,\quad\tau_{1}-\tau_{3}\,,\quad\tau_{3}-\tau_{5}\,,\] Select an overall confidence level of at least 94%. 
\begin{table}
\begin{tabular}{l c c c c c c c} \hline Treatment combination & \multicolumn{4}{c}{Number germinating} & \(\overline{y}_{i}\). & \(s_{i}\) \\ \hline
1: Spring/stratified & 12 & 13 & 2 & 7 & 19 & 8.4 & 6.995 \\  & 0 & 0 & 3 & 17 & 11 & & \\
2: Spring/unstratified & 6 & 2 & 0 & 2 & 4 & 2.5 & 3.308 \\  & 1 & 0 & 10 & 0 & 0 & & \\
3: Summer/stratified & 6 & 4 & 5 & 7 & 6 & 5.0 & 1.633 \\  & 5 & 7 & 5 & 2 & 3 & & \\
4: Summer/unstratified & 0 & 6 & 2 & 5 & 1 & 3.6 & 2.271 \\  & 5 & 2 & 3 & 6 & 6 & & \\ \hline \end{tabular}
\end{table}
Table 5.21: Data for the wildflower experiment

\begin{table}
\begin{tabular}{l c c c c c c c c} \hline Time order & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 \\ Treatment & 3 & 2 & 4 & 3 & 4 & 5 & 1 & 6 & 6 \\ Weight & 14 & 69 & 26 & 15 & 20 & 12 & 55 & 14 & 16 \\ Time order & 10 & 11 & 12 & 13 & 14 & 15 & 16 & 17 & 18 \\ Treatment & 5 & 1 & 2 & 4 & 6 & 3 & 5 & 2 & 1 \\ Weight & 16 & 66 & 64 & 23 & 17 & 22 & 18 & 64 & 53 \\ \hline \end{tabular}
\end{table}
Table 5.22: Weights (in grams) for the spaghetti sauce experiment 

### _Introduction_

In this chapter, we discuss the use of completely randomized designs for experiments that involve two crossed treatment factors. We label the treatment factors as \(A\) and \(B\), where factor \(A\) has \(a\) levels coded 1, 2,..., \(a\), and factor \(B\) has \(b\) levels coded 1, 2,..., \(b\). Factors are _crossed_ if every combination of levels may be observed. For experiments considered in this chapter, every level of \(A\) is observed with every level of \(B\), so the factors are crossed. In total, there are \(v=ab\) treatments (treatment combinations), and these are coded as 11, 12,..., \(1b\), 21, 22,..., \(2b\),..., \(ab\).

In the previous three chapters, we recoded the treatment combinations as 1, 2,..., \(v\) and used the one-way analysis of variance for comparing their effects. In this chapter, we investigate the contributions that each of the factors make individually to the response, and it is more convenient to retain the 2-digit code _ij_ for a treatment combination in which factor \(A\) is at level \(i\) and factor \(B\) is at level \(j\). In Sect. 6.2.1, we define the "interaction" of two treatment factors. Allowing for the possibility of interaction leads one to select a "two-way complete model" to model the data (Sect. 6.4). However, if it is known in advance that the factors do not interact, a "two-way main-effects model" would be selected (Sect. 6.5). Estimation of contrasts, confidence intervals, and analysis of variance techniques are described for these basic models. The calculation of sample sizes is also discussed (Sect. 6.6). The corresponding commands for SAS and R software are described in Sects. 6.8 and 6.9, respectively.

If each of the two factors has a large number of levels, the total number of treatment combinations could be quite large. When observations are costly, it may be necessary to limit the number of observations to one per treatment combination. Analysis for this situation is discussed in Sect. 6.7.

### _Models and Factorial Effects_

#### The Meaning of Interaction

In order to understand the meaning of the interaction between two treatment factors, it is helpful to look at possible data sets from a hypothetical experiment. Universities have become increasingly interested in online courses and other nontraditional modes of instruction. While an online course may be offered for a group of students and involve interaction between the students in a common section, consider development of a course that students take independently of one another. Suppose that a hypothetical statistics department wishes to know to what extent student performance in an introductoryonline course is affected by the primary presentation format (textbook reading assignments, videotaped lectures, or interactive software) and course structure (structured, with regular deadlines throughout the term; or unstructured, with only a deadline to finish by the end of the term).

There are two treatment factors of interest, namely "presentation format," which has three levels, coded 1, 2, and 3, and "course structure," which has two levels, coded 1 and 2. Both of the treatment factors have fixed effects, since their levels have been specifically chosen (see Sect. 2.2, p. 11, step (f)). The students who enroll in the introductory course are the experimental units and are allocated at random to one of the six treatment combinations in such a way that approximately equal numbers of students are assigned to each combination of presentation format and course structure. Student performance is to be measured by means of a computer-graded multiple-choice examination, and an average exam score \(\overline{y}_{ij}\). for each treatment combination will be obtained, averaging over students for each treatment combination.

There are eight different types of situations that could occur, and these are depicted in Figs. 6.1 and 6.2, where the plotted character indicates the course structure used. The plots are called _interaction plots_ and give an indication of how the different format-structure combinations affect the average exam score.

In plots (a)-(d) of Fig. 6.1, the lines joining the average exam scores for the two course structures are parallel (and sometimes coincide). In plot (b), all the presentation formats have obtained higher exam scores with course structure 1 than with structure 2, but the presentation formats themselves look very similar in terms of the average exam scores obtained. Thus there is an effect on the average exam

Figure 6.1: Possible configurations of effects present for two factors, presentation format (F) and course structure (S) when the significant interaction effect is absent

score of course structure (S) but no effect of presentation format (F). Below the plot this is highlighted by the notation "F = no, S = yes." The notation "FS = no" refers to the fact that the lines are parallel, indicating that there is no interaction (see below). In plot (c), no difference can be seen in the average scores obtained from the two course structures for any presentation format, although the presentation formats themselves appear to have achieved different average scores. Thus, the presentation formats have an effect on the average exam score, but the course structures do not (F = yes, S = no). Plot (d) shows the type of plot that might be obtained if there is both a presentation-format effect and a course-structure effect. The plot shows that all three presentation formats have obtained higher average exam scores using structure 1 than using structure 2. But also, presentation format 1 has obtained higher average scores than the other two presentation formats. The individual course-structure effects and presentation-format effects are known as _main effects_.

In plots (a)-(d) of Fig. 6.2, the lines are not parallel. This means that more is needed to explain the differences in exam scores than just course structure and presentation format effects. For example, in plot (a), all presentation formats have obtained higher exam scores using course structure 1 than using structure 2, but the difference is very small for presentation format 3 and very large for presentation format 1. In plot (d), presentation format 1 has obtained higher exam scores with structure 2, while the other two presentation formats have done better with structure 1. In all of plots (a)-(d) the presentation formats have performed differently with the different structures. This is called an effect of _interaction_ between presentation format and course structure.

Figure 6.2: Possible configurations of effects present for two factors, presentation format (F) and course structure (S) when the significant interaction effect is present

In plot (c), the presentation formats clearly differ. Two do better with structure 1 and one with structure 2. However, if we ignore course structures, the presentation formats appear to have achieved very similar average exam scores overall. So, averaged over the structures, there is little difference between them. In such a case, a standard computer analysis will declare that there is no difference between presentation formats, which is somewhat misleading. We use the notation "FS = yes" to denote an interaction between presentation format and Structure, and "F = no?" to highlight the fact that a conclusion of no difference between presentation formats should be interpreted with caution in the presence of interaction. In general, _if there is an interaction between two treatment factors, then it may not be sensible to examine either of the main effects separately_. Instead, it will often be preferable to compare the effects of the treatment combinations themselves.

While interaction plots are extremely helpful in interpreting the analysis of an experiment, they give no indication of the size of the experimental error. Sometimes a perceived interaction in the plot will not be distinguishable from error variability in the analysis of variance. On the other hand, if the error variability is very small, then an interaction effect may be statistically significant in the analysis, even if it appears negligible in the plot.

#### Models for Two Treatment Factors

If we use the two-digit codes _ij_ for the treatment combinations in the one-way analysis of variance model (3.3.1), we obtain the model

\[\begin{array}{c}Y_{ijt}=\mu+\tau_{ij}+\epsilon_{ijt}\;,\\ \epsilon_{ijt}\sim N(0,\sigma^{2})\;,\\ \epsilon_{ijt}\mbox{'s independent}\;,\\ t=1,\ldots,r_{ij};\quad i=1,\ldots,a;\quad j=1,\ldots,b,\end{array} \tag{6.2.1}\]

where \(i\) and \(j\) are the levels of \(A\) and \(B\), respectively. This model is known as the _cell-means model_. The "cell" refers to the cell of a table whose rows represent the levels of \(A\) and whose columns represent the levels of \(B\).

Since the interaction plot arising from a two-factor experiment could be similar to any of the plots of Figs. 6.1 and 6.2, it is often useful to model the effect on the response of treatment combination _ij_ to be the sum of the individual effects of the two factors, together with their interaction; that is,

\[\tau_{ij}=\alpha_{i}+\beta_{j}+(\alpha\beta)_{ij}.\]

Here, \(a_{i}\) is the effect (positive or negative) on the response due to the fact that the _i_th level of factor \(A\) is observed, and \(b_{j}\) is the effect (positive or negative) on the response due to the fact that the _j_th level of factor \(B\) is observed, and (_a__b__j_) is the extra effect (positive or negative) on the response of observing levels \(i\) and \(j\) of factors \(A\) and \(B\) together. The corresponding model, which we call the _two-way complete model,_ or the _two-way analysis of variance model,_ is as follows:

\[\begin{array}{c}Y_{ijt}=\mu+\alpha_{i}+\beta_{j}+(\alpha\beta)_{ij}+\epsilon _{ijt}\;,\\ \epsilon_{ijt}\sim N(0,\sigma^{2})\;,\\ \epsilon_{ijt}\mbox{'s are mutually independent}\;,\\ t=1,\ldots,r_{ij};\quad i=1,\ldots,a;\quad j=1,\ldots,b.\end{array} \tag{6.2.2}\]The phrase "two-way" refers to the fact that there are two primary sources of variation, namely, the two treatment factors. Model (6.2.2) is equivalent to model (6.2.1), since all we have done is to express the effect of the treatment combination in terms of its constituent parts.

Occasionally, an experimenter has sufficient knowledge about the two treatment factors being studied to state with reasonable certainty that the factors do not interact and that an interaction plot similar to one of the plots of Fig. 6.1 will occur. This knowledge may be gleaned from previous similar experiments or from scientific facts about the treatment factors. If this is so, then the interaction term can be dropped from model (6.2.2), which then becomes

\[\begin{array}{c}Y_{ijt}=\mu+\alpha_{i}+\beta_{j}+\epsilon_{ijt}\,,\\ \epsilon_{ijt}\sim N(0,\sigma^{2})\,,\\ \epsilon_{ijt}{}^{\prime}\text{s are mutually independent}\,,\\ t=1,\ldots,r_{ij};\quad i=1,\ldots,a;\quad j=1,\ldots,b\,.\end{array} \tag{6.2.3}\]

Model (6.2.3) is a "submodel" of the two-way complete model and is called a _two-way main-effects model_, or _two-way additive model_, since the effect on the response of treatment combination _ij_ is modeled as the sum of the individual effects of the two factors. If an additive model is used when the factors really do interact, then inferences on main effects can be very misleading. Consequently, if the experimenter does not have reasonable knowledge about the interaction, then the two-way complete model (6.2.2) or the equivalent cell-means model (6.2.1) should be used.

#### Checking the Assumptions on the Model

The assumptions implicit in both the two-way complete model (6.2.2) and the two-way main-effects model (6.2.3) are that the error random variables have equal variances, are mutually independent, and are normally distributed. The strategy and methods for checking the error assumptions are the same as those in Chap. 5. The standardized residuals are calculated as

\[z_{ijt}=(y_{ijt}-\hat{y}_{ijt})/\sqrt{\text{ssE}/(n-1)}\]

with

\[\hat{y}_{ijt}=\hat{\tau}_{ij}=\hat{\alpha}_{i}+\hat{\beta}_{j}+(\widehat{ \alpha}\beta)_{ij}\]

or

\[\hat{y}_{ijt}=\hat{\tau}_{ij}=\hat{\alpha}_{i}+\hat{\beta}_{j}\,,\]

depending upon which model is selected, where the "hat" denotes a least squares estimate. The residuals are plotted against

1. the order of observation to check independence,
2. the levels of each factor and \(\hat{y}_{ijt}\) to check for outliers and for equality of variances,
3. the normal scores to check the normality assumption.

When the main-effects model is selected, interaction plots of the data, such as those in Figs. 6.2 and 6.1, can be used to check the assumption of no interaction. An alternative way to check for interaction is to plot the standardized residuals against the levels of one of the factors with the plotted labels being the levels of the second factor. An example of such a plot is shown in Fig. 6.3. (For details of the original experiment, see Exercise 17.9.1, p. 650.) If the main-effects model had represented the data well, then the residuals would have been randomly scattered around zero. However, a pattern can be seen that is reminiscent of the interaction plot (b) of Fig. 6.2 suggesting that a two-way complete model would have been a much better description of the data. If the model is changed based on the data, subsequent stated confidence levels and significance levels will be inaccurate, and analyses must be interpreted with caution.

If there is some doubt about the equality of the variances, the rule of thumb \(s_{\text{max}}^{2}/s_{\text{min}}^{2}<3\) can be employed, where \(s_{\text{max}}^{2}\) is the maximum of the variances of the data values within the cells, and \(s_{\text{min}}^{2}\) is the minimum (see Sect. 5.6.1). In a two-way layout, however, there may not be sufficient observations per cell to allow this calculation to be made. Nevertheless, we can at least check that the error variances are the same for each level of any given factor by employing the rule of thumb for the variances of the nonstandardized residuals calculated at each level of the factor.

### 6.3 Contracts

#### 6.3.1 Contrasts for Main Effects and Interactions

Since the cell-means model (6.2.1) is equivalent to the one-way analysis of variance model, we know that all contrasts in the treatment effects \(\tau_{ij}\) are estimable (cf. Sect. 3.4.1, p. 34). Contrasts of interest for a cell-means model are typically of three main types: treatment contrasts, interaction contrasts, and main-effect contrasts.

Treatment contrasts \(\Sigma_{i}\Sigma_{j}d_{ij}\tau_{ij}\) are no different from the types of contrasts described in Chap. 4. For example, \(\tau_{ij}-\tau_{sh}\) is a pairwise difference between treatment combinations \(ij\) and \(sh\). All the confidence interval methods of Chap. 4 are directly applicable.

Interaction contrasts are the contrasts that we use in order to measure whether or not the lines on the interaction plots (cf. Figs. 6.1 and 6.2) are parallel. An example of an interaction contrast is

\[(\tau_{sh}-\tau_{(s+1)h})-(\tau_{sq}-\tau_{(s+1)q})\,. \tag{6.3.4}\]

We can verify that this is, indeed, an interaction contrast by using the equivalent two-way complete model notation with \(\tau_{ij}=\alpha_{i}+\beta_{j}+(\alpha\beta)_{ij}\). Substituting this into (6.3.4) gives the contrast

\[\big{(}(\alpha\beta)_{sh}-(\alpha\beta)_{(s+1)h}\big{)}-\big{(}(\alpha\beta)_ {sq}-(\alpha\beta)_{(s+1)q}\big{)}\,, \tag{6.3.5}\]

Figure 6.3: Residual plot for the temperature experiment

which is a function of interaction parameters only. Interaction contrasts are always of the form

\[\sum_{i}\sum_{j}d_{ij}\tau_{ij}=\sum_{i}\sum_{j}d_{ij}(\alpha\beta)_{ij}\,, \tag{6.3.6}\]

where

\[\sum_{i}d_{ij}=0\ \text{for each}\ j\quad\text{and}\quad\sum_{j}d_{ij}=0\ \text{for each}\ i\,.\]

Some, but not all, interaction contrasts have coefficients \(d_{ij}=c_{i}k_{j}\). For example, if we take \(c_{s}=k_{h}=1\) and \(c_{s+1}=k_{q}=-1\) and all other \(c_{i}\) and \(k_{j}\) zero, then, setting \(d_{ij}=c_{i}k_{j}\) in (6.3.6), we obtain the coefficients in contrast (6.3.5).

If the interaction effect is very small, then the lines on an interaction plot are almost parallel (as in plots (a)-(d) of Fig. 6.1). We can then compare the average effects of the different levels of \(A\) (averaging over the levels of \(B\)). Thus, contrasts of the form \(\Sigma c_{i}\overline{\tau}_{i,.}\), with \(\Sigma c_{i}=0\), would be of interest. However, if there is an interaction (as in plot (c) of Fig. 6.2), such an average may make little sense. This becomes obvious when we use the two-way complete model formulation, since a main effect contrast in \(A\) is

\[\sum_{i}c_{i}\overline{\tau}_{i.}=\sum_{i}c_{i}(\alpha_{i}+(\overline{\alpha \beta})_{i.}) \tag{6.3.7}\]

where \((\overline{\alpha\beta})_{i.}=\frac{1}{b}\ \sum_{j}(\alpha\beta)_{ij}\), and we can see clearly that we have averaged over any interaction effect that might be present. We will often write

\[\alpha_{i}^{*}=\alpha_{i}+(\overline{\alpha\beta})_{i.}\ \ \text{and}\ \ \beta_{j}^{*}=\beta_{j}+(\overline{\alpha\beta})_{j}\]

for convenience. A contrast in the main effect of \(A\) for the two-way complete model is then written as \(\Sigma c_{i}\alpha_{i}^{*}\ \ (\Sigma c_{i}=0)\), and a contrast in the main effect of \(B\) is

\[\sum_{j}k_{j}\overline{\tau}_{j}=\sum_{j}k_{j}(\beta_{j}+(\overline{\alpha \beta})_{j})=\sum_{j}k_{j}\beta_{j}^{*}\,, \tag{6.3.8}\]

where \(\Sigma k_{j}=0\) and \((\overline{\alpha\beta})_{j}=\frac{1}{a}\sum_{i}(\alpha\beta)_{ij}\).

Sometimes, it is of interest to compare the effects of the levels of one factor separately at each level of the other factor. Consider a variation on the hypothetical experiment in Sect. 6.2.1. Suppose the hypothetical statistics department also wishes to study the effects on student learning of two pedagogies (traditional lecture, and discovery-based learning) for three instructors teaching an introductory statistics course. Unless the department wants all instructors (factor \(A\), say) to use the same pedagogy (factor \(B\), say) in teaching the course, a natural objective might be to choose a best pedagogy for each instructor separately. If comparison of the effects of levels of factor \(B\) for each level of factor \(A\) is required, then contrasts of the form

\[\sum_{j}c_{j}\tau_{ij}\,,\quad\text{with}\quad\sum_{j}c_{j}=0\ \ \text{for each}\ i=1,2,\ldots,a\,,\]

are of interest. We call such contrasts _simple contrasts_ in the levels of \(B\). As a special case, we have the _simple pairwise differences_ of factor \(B\):\[\tau_{ih}-\tau_{\bar{y}},\;\;\;\;\mbox{for each}\;\;i=1,\ldots,a\,.\]

These are a subset of the pairwise comparison contrasts. Simple contrasts and simple pairwise differences of factor \(A\) are defined in an analogous way.

When it is known in advance of the experiment that factors \(A\) and \(B\) do not interact, the two-way main-effects model (6.2.3) would normally be used. In this model, there is no interaction term, so \(\tau_{\bar{y}}=\alpha_{i}+\beta_{j}\). The main-effects contrasts for \(A\) and \(B\) are respectively of the form

\[\sum c_{i}\overline{\tau}_{i.}=\sum c_{i}\alpha_{i}\;\mbox{and}\;\sum k_{j} \overline{\tau}_{j}=\sum k_{\bar{y}}\beta_{j},\]

with \(\sum c_{i}=0\) and \(\sum k_{\bar{y}}=0\).

#### Writing Contrasts as Coefficient Lists

Instead of writing out a contrast explicitly, it is sometimes sufficient, and more convenient, to list the contrast coefficients only. For the two-way complete model, we have a choice. We can refer to contrasts as either a list of coefficients of the parameters \(\alpha_{i}^{*},\beta_{j}^{*}\), and \((\alpha\beta)_{\bar{y}}\) or as a list of coefficients of the \(\tau_{\bar{y}}\)'s. This is illustrated in the following example.

##### Battery experiment, continued

The four treatment combinations in the battery experiment of Sect. 2.5.2, p. 24, involved two treatment factors, "duty" and "brand," each having two levels (1 for alkaline and 2 for heavy duty; 1 for name brand and 2 for store brand), giving treatment combinations 11, 12, 21, and 22. (These were coded in previous examples as 1, 2, 3, and 4, respectively.) There were \(r=4\) observations on each treatment combination.

The interaction plot in Fig. 6.4 shows a possible interaction between the two factors, since the dotted lines on the plot are not close to parallel. However, we should remember that we cannot be certain whether the nonparallel lines are due to an interaction or to inherent variability in the data, and we will need to investigate the cause in more detail later.

The interaction is measured by the contrast

\[\tau_{11}-\tau_{12}-\tau_{21}+\tau_{22}=(\alpha\beta)_{11}-(\alpha\beta)_{12}- (\alpha\beta)_{21}+(\alpha\beta)_{22}\,,\]

Figure 6.4: Plot of average life per unit cost against “Duty” level \(i\) by “Brand” level \(j\) for the battery experiment

[MISSING_PAGE_FAIL:169]

Now,

\[\alpha_{i}^{*}=\overline{\tau}_{i.},\ \ \text{giving}\ \ \Sigma_{i}c_{i}\alpha_{i}^{*} =\Sigma_{i}c_{i}\left(\frac{1}{6}\Sigma_{j}\tau_{ij}\right)=\frac{1}{6}\Sigma_ {i}\Sigma_{j}c_{i}\tau_{ij}\,,\]

and

\[\beta_{j}^{*}=\overline{\tau}_{j},\ \ \text{giving}\ \ \Sigma_{j}k_{j}\beta_{j}^{*} =\Sigma_{j}k_{j}\left(\frac{1}{3}\Sigma_{i}\tau_{ij}\right)=\frac{1}{3} \Sigma_{i}\Sigma_{j}k_{j}\tau_{ij}\,,\]

and we can write all of the above trends in terms of contrasts in \(\tau_{ij}\), as shown in the columns of Table 6.1. Contrast coefficients are also listed for cubic, quartic, and quintic trends for \(B\). If we wish to compare the \(A\) and \(B\) trends on the same scale, we can normalize the contrasts (see Sect. 4.2).

In order to model a three-dimensional surface, we need to know not only how the response is affected by the levels of each factor averaged over the levels of the other factor, but also how the response changes as the levels of \(A\) and \(B\) change together. The linear\(A\times\)linear\(B\) trend (\(A_{\text{L}}B_{\text{L}}\)) measures whether or not the linear trend in \(A\) changes in a linear fashion as the levels of \(B\) are increased, and vice versa. This is an interaction contrast whose coefficients are of the form \(d_{ij}=c_{i}k_{j}\), where \(c_{i}\) are the contrast coefficients for \(A\), and \(k_{j}\) are the contrast coefficients for \(B\). The \(A_{\text{L}}B_{\text{L}}\) contrast coefficients are shown in Table 6.1, and it can be verified that they are obtained by multiplying together corresponding main-effect linear trend coefficients in the same row. Coefficients for the linear\(A\times\)quintic\(B\) (\(A_{\text{L}}B_{\text{qn}}\)) contrast is also shown for use later in this chapter. 

\begin{table}
\begin{tabular}{c c c c c c c c c c} \hline _ij_ & \(A_{\text{L}}\) & \(A_{\text{Q}}\) & \(B_{\text{L}}\) & \(B_{\text{Q}}\) & \(B_{\text{C}}\) & \(B_{\text{qr}}\) & \(B_{\text{qn}}\) & \(A_{\text{L}}B_{\text{L}}\) & \(A_{\text{L}}B_{\text{qn}}\) \\ \hline
11 & \(-1\) & \(1\) & \(-5\) & \(5\) & \(-5\) & \(1\) & \(-1\) & \(5\) & \(1\) \\
12 & \(-1\) & \(1\) & \(-3\) & \(-1\) & \(7\) & \(-3\) & \(5\) & \(3\) & \(-5\) \\
13 & \(-1\) & \(1\) & \(-1\) & \(-4\) & \(4\) & \(2\) & \(-10\) & \(1\) & \(10\) \\
14 & \(-1\) & \(1\) & \(1\) & \(-4\) & \(-4\) & \(2\) & \(10\) & \(-1\) & \(-10\) \\
15 & \(-1\) & \(1\) & \(3\) & \(-1\) & \(-7\) & \(-3\) & \(-5\) & \(-3\) & \(5\) \\
16 & \(-1\) & \(1\) & \(5\) & \(5\) & \(5\) & \(1\) & \(1\) & \(-5\) & \(-1\) \\
21 & \(0\) & \(-2\) & \(-5\) & \(5\) & \(-5\) & \(1\) & \(-1\) & \(0\) & \(0\) \\
22 & \(0\) & \(-2\) & \(-3\) & \(-1\) & \(7\) & \(-3\) & \(5\) & \(0\) & \(0\) \\
23 & \(0\) & \(-2\) & \(-1\) & \(-4\) & \(4\) & \(2\) & \(-10\) & \(0\) & \(0\) \\
24 & \(0\) & \(-2\) & \(1\) & \(-4\) & \(-4\) & \(2\) & \(10\) & \(0\) & \(0\) \\
25 & \(0\) & \(-2\) & \(3\) & \(-1\) & \(-7\)

### Analysis of the Two-Way Complete Model

In the analysis of an experiment with two treatment factors that possibly interact, we may proceed with the analysis in two equivalent ways. We may use the cell-means model (6.2.1) together with all the analysis techniques of Chaps. 3 and 4, or we may use the two-way complete model (6.2.2) and isolate the contributions to the response made by each of the two factors and their interaction separately.

A sensible strategy is to start with the two-way complete model and test a hypothesis of no interaction. If the hypothesis is not rejected, we may then continue with the analysis by examining the main effects under the same two-way complete model. We would not change to the two-way main-effects model, since this is not an equivalent model. However, if the hypothesis of no interaction is rejected, then we would normally prefer to change to the equivalent cell-means model and examine differences in the effects of the treatment combinations. We would also use the cell-means model when the objective of the experiment is to find the best treatment combination.

#### Least Squares Estimators for the Two-Way Complete Model

As in Sect. 3.4.3, p. 35, the least squares estimator of \(\mu+\tau_{ij}\) is \(\overline{Y}_{ij.}\), so the least squares estimators of the parameters in the cell-means model (6.2.1) and the equivalent two-way complete model (6.2.2) are

\[\hat{\mu}+\hat{\tau}_{ij}=\hat{\mu}+\hat{\alpha}_{i}+\hat{\beta}_{j}+(\widehat{ \alpha\beta})_{ij}=\overline{Y}_{ij.}\,\]

and the corresponding variance is \(\sigma^{2}/r_{ij}\). Any interaction contrast of the form \(\Sigma\,\Sigma d_{ij}\tau_{ij}\) (with \(\Sigma_{i}d_{ij}=0\) and \(\Sigma_{j}d_{ij}=0\)) has least squares estimator and associated variance equal to

\[\sum_{i}\sum_{j}d_{ij}\overline{Y}_{ij.}\ \ \text{and}\ \ \sigma^{2}\sum_{i} \sum_{j}\left(\frac{d_{ij}^{2}}{r_{ij}}\right).\]

In particular, the least squares estimator of the interaction contrast

\[(\tau_{sh}-\tau_{uh})-(\tau_{sq}-\tau_{uq})\]

is

\[\overline{Y}_{sh.}-\overline{Y}_{uh.}-\overline{Y}_{sq.}+\overline{Y}_{uq.} \tag{6.4.9}\]

with variance

\[\sigma^{2}\left(\frac{1}{r_{sh}}+\frac{1}{r_{uh}}+\frac{1}{r_{sq}}+\frac{1}{r _{uq}}\right). \tag{6.4.10}\]

The least squares estimators of main-effect contrasts \(\Sigma c_{i}\alpha_{i}^{*}\) and \(\Sigma k_{j}\beta_{j}^{*}\) are

\[\sum_{i}c_{i}\hat{\alpha}_{i}^{*} = \sum_{i}c_{i}\left(\frac{1}{b}\sum_{j}\overline{Y}_{ij.}\right) \ \ \text{and}\ \ \sum_{j}k_{j}\hat{\beta}_{j}^{*}\ \ =\ \ \sum_{j}k_{j}\left(\frac{1}{a}\sum_{i}\overline{Y}_{ij.}\right) \tag{6.4.11}\]

with variances\[\text{Var}(\Sigma c_{i}\hat{\alpha}_{i}^{*}) = \sigma^{2}\left(\sum_{i}\sum_{j}\frac{c_{i}^{2}}{b^{2}r_{ij}}\right) \text{ and }\text{ Var}(\Sigma k_{j}\hat{\beta}_{j}^{*})\ \ =\ \ \sigma^{2}\left(\sum_{i}\sum_{j}\frac{k_{j}^{2}}{a^{2}r_{ij}}\right)\,, \tag{6.4.12}\]

respectively. If the sample sizes are equal, the least squares estimators of \(\sum c_{i}\alpha_{i}^{*}\) and \(\sum k_{j}\beta_{j}^{*}\) reduce to

\[\sum_{i}c_{i}\hat{\alpha}_{i}^{*}\ \ =\ \ \sum_{i}c_{i}\overline{Y}_{i..}\text{ and }\ \sum_{j}k_{j}\hat{\beta}_{j}^{*}\ \ =\ \ \sum_{j}k_{j}\overline{Y}_{j.}\,, \tag{6.4.13}\]

where \(\overline{Y}_{i..}=\sum_{j}\sum_{t}Y_{ijt}/br\) and \(\overline{Y}_{j.}=\sum_{i}\sum_{t}Y_{ijt}/ar\). Thus, for equal sample sizes,

\[\hat{\alpha}_{i}^{*}-\hat{\alpha}_{s}^{*}=\overline{Y}_{i..}-\overline{Y}_{s..}\text{ and }\hat{\beta}_{j}^{*}-\hat{\beta}_{q}^{*}=\overline{Y}_{j.}-\overline{Y}_{q.} \tag{6.4.14}\]

with associated variances \(2\sigma^{2}/(br)\) and \(2\sigma^{2}/(ar)\), respectively.

#### Example 6.4.1 Battery experiment, continued

The four treatment combinations in the battery experiment of Sect. 2.5.2, p. 24, involved two treatment factors, "duty" and "brand," each having two levels (1 for alkaline and 2 for heavy duty; 1 for name brand and 2 for store brand), giving treatment combinations 11, 12, 21, and 22. There were \(r=4\) observations on each treatment combination. The observed average lifetimes per unit cost for the treatment combinations were

\[\overline{y}_{11.}=570.75,\ \ \ \overline{y}_{12.}=860.50,\ \ \ \overline{y}_{21.}=433.00,\ \ \ \overline{y}_{22.}=496.25.\]

The interaction contrast

\[\frac{1}{2}(\tau_{11}-\tau_{12}-\tau_{21}+\tau_{22})=\frac{1}{2}\left((\alpha \beta)_{11}-(\alpha\beta)_{12}-(\alpha\beta)_{21}+(\alpha\beta)_{22}\right)\]

has least squares estimate

\[\frac{1}{2}(\overline{y}_{11.}-\overline{y}_{12.}-\overline{y}_{21.}+\overline {y}_{22.})=-113.25\,,\]

with associated variance

\[\sigma^{2}\left(\sum\sum d_{ij}^{2}/r\right)=\sigma^{2}\left((\frac{1}{2})^{2 }+(-\frac{1}{2})^{2}+(-\frac{1}{2})^{2}+(\frac{1}{2})^{2}\right)/4=\sigma^{2} /4\,.\]

The duty contrast,

\[\alpha_{1}^{*}-\alpha_{2}^{*}=(\alpha_{1}+(\overline{\alpha\beta})_{1.})-( \alpha_{2}+(\overline{\alpha\beta})_{2.})=\frac{1}{2}\left(\tau_{11}+\tau_{12 }-\tau_{21}-\tau_{22}\right)\,,\]

has least squares estimate \(\overline{y}_{1..}-\overline{y}_{2..}=251.00\) and associated variance \(\sigma^{2}/4\). The brand contrast,

\[\beta_{1}^{*}-\beta_{2}^{*}=(\beta_{1}+(\overline{\alpha\beta})_{1.1})-(\beta _{2}+(\overline{\alpha\beta})_{2.2})=\frac{1}{2}\left(\tau_{11}-\tau_{12}+\tau _{21}-\tau_{22}\right)\,,\]

has least squares estimate \(\overline{y}_{1..}-\overline{y}_{2..}=-176.50\) and associated variance \(\sigma^{2}/4\).

#### Estimation of \(\sigma^{2}\) for the Two-Way Complete Model

Since the two-way complete model (6.2.2) is equivalent to the cell-means model (6.2.1), an unbiased estimate of \(\sigma^{2}\) is the same as that for the one-way analysis of variance model, apart from an extra subscript \(j\). Thus, the error sum of squares ssE can be obtained from (3.4.4) or (3.4.5), p. 39, that is,

\[\text{ss}E = \sum_{i}\sum_{j}\sum_{t}(y_{ijt}-\overline{y}_{ij})^{2} \tag{6.4.15}\] \[= \sum_{i}\sum_{j}\sum_{t}y_{ijt}^{2}-\sum_{i}\sum_{j}r_{ij} \overline{y}_{ij}^{2}. \tag{6.4.16}\]

An unbiased estimate for \(\sigma^{2}\) is obtained as \(\text{ms}E=\text{ss}E/(n-v)\), with \(v=ab\). An upper \(100(1-\alpha)\%\) confidence bound for \(\sigma^{2}\) is given by (3.4.9), p. 40, that is,

\[\sigma^{2}\leq\frac{\text{ss}E}{\chi_{n-ab,1-\alpha}^{2}}\,. \tag{6.4.17}\]

##### _Example 6.4.2_ Reaction time experiment, continued

The reaction time pilot experiment, run in 1996 by Liming Cai, Tong Li, Nishant, and Andre van der Kouwe, was described in Exercise 4 of Chap. 4. The experiment was run to compare the speed of response of a human subject to audio and visual stimuli. A personal computer was used to present a "stimulus" to a subject, and the time that the subject took to press a key in response was monitored. The subject was warned that the stimulus was forthcoming by means of an auditory or a visual cue. The two treatment factors were "Cue Stimulus" at two levels, "auditory" and "visual" (Factor \(A\), coded 1, 2), and "Cue Time" at three levels, 5, 10, and 15 seconds between cue and stimulus (Factor \(B\), coded 1, 2, 3), giving a total of \(v=6\) treatment combinations (coded 11, 12, 13, 21, 22, 23). Three observations were taken on each treatment combination for a single subject. The reaction times are shown in Table 6.2. It can be verified that \(\sum\sum\sum y_{ijt}^{2}=0.96519\). Using (6.4.16) and the sums in Table 6.2, the sum of squares for error is

\[\text{ss}E = \sum_{i}\sum_{j}\sum_{t}y_{ijt}^{2}-3\sum_{i}\sum_{j}\overline{y}_ {ij}^{2}\] \[= 0.96519-3(0.32057)=0.00347\,,\]

\begin{table}
\begin{tabular}{c c c c c c c} \hline \(A\): & Cue stimulus & \(B\): & Cue time & Treatment combination & Reaction time \(y_{ijt}\) & Sums \(y_{ij}\) \\ \hline
1 & 1 & 11 & 0.204 & 0.170 & 0.181 & 0.555 \\
1 & 2 & 12 & 0.167 & 0.182 & 0.187 & 0.536 \\
1 & 3 & 13 & 0.202 & 0.198 & 0.236 & 0.636 \\
2 & 1 & 21 & 0.257 & 0.279 & 0.269 & 0.805 \\
2 & 2 & 22 & 0.283 & 0.235 & 0.260 & 0.778 \\
2 & 3 & 23 & 0.256 & 0.281 & 0.258 & 0.795 \\ \hline \end{tabular}
\end{table}
Table 6.2: Data (in seconds) for the reaction time experimentand an unbiased estimate of \(\sigma^{2}\) is \(\text{ms}E=\text{ss}E/(18-6)=0.000289\) seconds\({}^{2}\). An upper 95% confidence bound for \(\sigma^{2}\) is

\[\frac{\text{ss}E}{\chi^{2}_{12,.95}}\ =\ \frac{0.00347}{5.226}\ =\ 0.000664\ \text{seconds}^{2}\,\]

and taking square roots, an upper 95% confidence bound for \(\sigma\) is 0.0257 seconds. 

#### Multiple Comparisons for the Complete Model

In outlining the analysis at step (g) of the checklist of Chap. 2, the experimenter should specify which treatment contrasts are of interest, together with overall error rates for hypothesis tests and overall confidence levels for confidence intervals. If the two-way complete model has been selected, comparison of treatment combinations, comparison of main effects of \(A\), and comparison of main effects of \(B\) may all be of interest. A possibility in outlining the analysis is to select error rates of \(\alpha_{1}\), \(\alpha_{2}\), and \(\alpha_{3}\) for the three sets of inferences. Then, by the Bonferroni method, the _experimentwise_ simultaneous error rate is at most \(\alpha_{1}+\alpha_{2}+\alpha_{3}\), and the experimentwise confidence level is at least 100(\(1-\alpha_{1}-\alpha_{2}-\alpha_{3}\))%. If interaction contrasts are also of interest, then the overall \(\alpha\)-level can be divided into four parts instead of three.

##### Comparing Treatment Combinations

When comparison of treatment combinations is of most interest, the cell-means model (6.2.1) is used. The formulae for the Bonferroni, Scheffe, Tukey, and Dunnett methods can all be used in the same way as was done in Chap. 4, but with ssE given by (6.4.16) and with \(v=ab\).

The best treatment combination can be found using Tukey's method of multiple comparisons. The best treatment combination may not coincide with the apparent best levels of \(A\) and \(B\) separately. For example, in Fig. 6.2(d), p. 141, the apparent best treatment combination occurs with presentation format 2 and structure 1, whereas the best presentation format, on average, appears to be number 3.

##### Comparing Main Effects

Main-effect contrasts compare the effects of the levels of one factor _averaging_ over the levels of the other factor and may not be of interest if the two factors interact. If main-effect contrasts are to be examined, then the Bonferroni, Scheffe, Tukey, and Dunnett methods can be used for each factor separately. The general formula is equivalent to (4.4.20), p. 83. For factor \(A\) and _equal sample sizes_ the formula is

\[\sum_{i}c_{i}\overline{\tau}_{i.}=\sum_{i}c_{i}\alpha_{i}^{*}\in\left(\sum_{i} c_{i}\overline{y}_{i.}\pm w\ \sqrt{\text{ms}E\ \sum_{i}c_{i}^{2}/br}\right)\, \tag{6.4.18}\]

where the critical coefficient \(w\) for each of the four methods is, respectively,

\[w_{B}=t_{n-ab,\alpha/2m}\ \ ;\ \ w_{S}=\sqrt{(a-1)F_{a-1,n-ab,\alpha}}\ \ ;\] \[w_{T}=q_{a,n-ab,\alpha}/\sqrt{2}\ \ ;\ \ w_{D2}=|t|^{(0.5)}_{a-1,n- ab,\alpha}\ \.\]

The general formula for a confidence interval for a contrast in factor \(B\) is

\[\sum_{j}k_{j}\overline{\tau}_{j}=\sum_{j}k_{j}\beta_{j}^{*}\in\left(\sum_{j}k_ {j}\overline{y}_{j.}\pm w\sqrt{\text{ms}E\ \sum_{j}k_{j}^{2}/(ar)}\right) \tag{6.4.19}\]with critical coefficients as above but interchanging \(a\) and \(b\). The error variance estimate is \(\text{msE}=\text{ssE}/(n-ab)\), where ssE is obtained from (6.4.16).

For _unequal sample sizes_, the Bonferroni and Scheffe methods can be used, but the least squares estimates and variances must be replaced by (6.4.11) and (6.4.12), respectively. It has not yet been proved that the other two methods retain an overall confidence level of at least \(100(1-\alpha)\)% for unequal sample sizes, although this is widely believed to be the case for Tukey's method.

#### _Example 6.4.3_ Reaction time experiment, continued

Suppose the preplanned analysis for the reaction time experiment of Example 6.4.2 (p. 151) had been to use the two-way complete model and to test the null hypothesis of no interaction. If the hypothesis were to be rejected, then the plan was to use Tukey's method at level 99% for the pairwise comparisons of the treatment combinations. Otherwise, Tukey's method would be used at level 99% for the pairwise comparison of the levels of \(B\) (cue time), and a single 99% confidence interval would be obtained for comparing the two levels of \(A\) (cue stimulus). Then the experimentwise confidence level for the three sets of intervals would have been at least 97%.

After looking at the data plotted in Fig. 6.5, the experimenters might decide that comparison of the levels of cue stimulus (averaged over cue time) is actually the only comparison of interest. However, the experimentwise confidence level remains at least 97%, because two other sets of intervals were planned ahead of time and only became uninteresting after the data were examined.

The sample mean weights for the two cue stimuli (averaged over cue times) are

\[\overline{y}_{1..}=0.1919,\;\;\;\overline{y}_{2..}=0.2642.\]

The mean square for error was calculated in Example 6.4.2 to be \(\text{msE}=0.000289\). The formula for a 99% confidence interval for the comparison of \(a=2\) treatments and \(br=9\) observations on each treatment is obtained from (6.4.18) with \(w=w_{B}=t_{18-6,0.005}=3.055\), giving

\[\alpha_{2}^{*}-\alpha_{1}^{*} \in \left(\overline{y}_{2..}-\overline{y}_{1..}\pm w_{B}\sqrt{\text{ msE}\left(1/br+1/br\right)}\right)\] \[= 0.0723\pm(3.055)\sqrt{0.000289(2/9)}\;=\;(0.0478,0.0968)\,.\]

Thus, at an experimentwise confidence level of at least 97%, we can conclude that the average reaction time with an auditory cue is between 0.0478 and 0.0968 seconds faster than with a visual cue.

Fig. 6.5: Average times for the reaction time experiment 

#### Multiple Comparisons When Variances are Unequal

When the variances of the error variables are unequal, and no transformation can be found to remedy the problem, Satterthwaite's approximation, introduced in Sect. 5.6.3 (p. 115), can be used. This is illustrated in Example 6.4.4.

##### Example 6.4.4

##### Example 6.4.4

The bleach experiment was run by Annie Autret in 1986 to study the effect of different bleach concentrations (factor A) and the effect of the type of stain (factor B) on the speed of stain removal from a piece of cloth. The bleach concentration was to be observed at levels 3, 5, and 7 teaspoonfuls of bleach per cup of water (coded 1, 2, 3), and three types of stain (blue ink, jam, tomato sauce; coded 1, 2, 3) were of interest, giving \(v=9\) treatment combinations in total. The experimenter calculated that she needed \(r=5\) observations per treatment combination in order to be able to detect, with probability 0.9, at significance level 0.05, a difference of 5 min in the time of stain removal between the levels of either treatment factor.

The data are shown in Table 6.3 together with the sample mean and standard deviation for each treatment combination. The maximum sample standard deviation is about 8.9 times the size of the minimum sample standard deviation, so the ratio of the maximum to the minimum variance is about 80, and a transformation of the data should be contemplated. The reader can verify, using the technique described in Sect. 5.6.2, that a plot of \(\ln(s_{ij}^{2})\) against \(\ln(\overline{y}_{ij})\) is not linear, so no transformation of the form \(h(y_{ijt})=y_{ijt}^{1-(q/2)}\) will adequately equalize the error variances.

An alternative is to apply Satterthwaite's approximation (Sect. 5.6.3, p. 115). The plan of the analysis was to use Tukey's method with an error rate of 0.01 for each of the main-effect comparisons and for the pairwise differences of the treatment combinations, giving an experimentwise confidence level of at least 97%. For the main effect of \(B\), for example, a pairwise comparison of levels \(u\) and \(h\) of factor \(B\) is of the form

\[\beta_{u}^{*}-\beta_{h}^{*}=\overline{\tau}_{.u}-\overline{\tau}_{.h}=\frac{1} {3}\left(\tau_{1u}+\tau_{2u}+\tau_{3u}-\tau_{1h}-\tau_{2h}-\tau_{3h}\right)\,,\]

which has least squares estimate

\[\widehat{\beta}_{u}^{*}-\widehat{\beta}_{h}^{*}\;=\;\overline{y}_{.u.}- \overline{y}_{.h.}\;=\;\frac{1}{3}\left(\overline{y}_{1u.}+\overline{y}_{2u.} +\overline{y}_{3u.}-\overline{y}_{1h.}-\overline{y}_{2h.}-\overline{y}_{3h.} \right)\,.\]

\begin{table}
\begin{tabular}{r r r r r r r r} \hline \(ij\) & Time for stain removal (in seconds) & & & \(\overline{y}_{ij.}\) & \(s_{ij}\) \\ \hline
11 & 3600 & 3920 & 3340 & 3173 & 2452 & 3297.0 & 550.27 \\
12 & 495 & 236 & 515 & 573 & 555 & 474.8 & 137.04 \\
13 & 733 & 525 & 793 & 1026 & 510 & 717.4 & 212.85 \\
21 & 2029 & 2271 & 2156 & 2493 & 2805 & 2350.8 & 305.94 \\
22 & 428 & 432 & 335 & 288 & 376 & 371.8 & 61.60 \\
23 & 880 & 759 & 1138 & 780 & 1625 & 1036.4 & 361.91 \\
31 & 3660 & 4105 & 4545 & 3569 & 3342 & 3844.2 & 479.85 \\
32 & 410 & 225 & 437 & 350 & 140 & 312.4 & 126.32 \\
33 & 539 & 1354 & 347 & 584 & 781 & 721.0 & 386.02 \\ \hline \end{tabular}
\end{table}
Table 6.3: Data for the bleach experiment, with treatment factors “concentration” (A) and “stain type” (\(B\))If \(s_{ij}^{2}\) denotes the sample variance of the data for treatment combination \(ij\), the estimated variance of this estimator, as in (5.6.4), p. 115, is

\[\widehat{\text{Var}}\left(\widehat{\beta}_{u}^{*}-\widehat{\beta}_{h}^{*}\right) =\sum_{i}\sum_{j}d_{ij}^{2}\frac{s_{ij}^{2}}{r_{ij}}=\frac{1}{9\times 5}(s_{1u}^ {2}+s_{2u}^{2}+s_{3u}^{2}+s_{1h}^{2}+s_{2h}^{2}+s_{3h}^{2}),\]

and since \(r=5\), the approximate number of degrees of freedom for error is

\[df=\frac{(s_{1u}^{2}+s_{2u}^{2}+s_{3u}^{2}+s_{1h}^{2}+s_{2h}^{2}+s_{3h}^{2})^{2 }}{(s_{1u}^{4}/4)+(s_{2u}^{4}/4)+(s_{3u}^{4}/4)+(s_{1h}^{4}/4)+(s_{2h}^{4}/4)+( s_{3h}^{4}/4)}\]

after canceling the factor \(r^{2}=25\) in the numerator and denominator.

For Tukey's method of pairwise comparisons for factor \(B\) with \(b=3\) levels, the minimum significant difference is

\[\text{msd}=w_{T}\sqrt{\widehat{\text{Var}}\left(\widehat{\beta}_{u}^{*}- \widehat{\beta}_{h}^{*}\right)},\]

with \(w_{T}=q_{3,df,01}/\sqrt{2}\). For measurements in seconds, we have the following values:

\[\begin{array}{ccccc}(u,h)&df&q_{3,df,0.01}&\widehat{\text{Var}}\left(\widehat {\beta}_{u}^{*}-\widehat{\beta}_{h}^{*}\right)&\text{msd}&\overline{y}_{u.}- \overline{y}_{h.}\\ \hline(1,2)&11.5&5.09&14,780.6&437.57&2,777.67\\ (1,3)&18.6&4.68&21,153.5&481.31&2,339.07\\ (3,2)&12.6&4.99&8,084.7&317.26&438.60\end{array}\]

The set of 99% simultaneous Tukey confidence intervals for pairwise differences is then

\[\beta_{1}^{*}-\beta_{2}^{*}\in(2777.67\pm 437.57)=(2340.10,3215.24)\;,\]

\[\beta_{1}^{*}-\beta_{3}^{*}\in(1857.76,2820.38)\;,\;\;\;\;\;\;\beta_{3}^{*}- \beta_{2}^{*}\in(121.34,755.86)\;.\]

Since none of the intervals contains zero, we can state that all pairs of levels of \(B\) (stain types) have different effects on the speed of stain removal, averaged over the three concentrations of bleach. With experimentwise confidence level at least 97%, the mean time to remove blue ink (level 1) is between 1857 and 2820 seconds longer than that for tomato sauce (level 3), and the mean time to remove tomato sauce is between 121 and 755 seconds longer than that for jam (level 2). 

#### Analysis of Variance for the Complete Model

There are three standard hypotheses that are usually examined when the two-way complete model is used. The first hypothesis is that the interaction between treatment factors \(A\) and \(B\) is negligible; that is,

\[H_{0}^{AB}:\left\{(\alpha\beta)_{ij}-(\alpha\beta)_{iq}-(\alpha\beta)_{sj}+( \alpha\beta)_{sq}=0\;\;\text{for all}\;i\neq s,j\neq q\right\},\]

which occurs when the interaction plots show parallel lines. Notice that if all of the contrasts \((\alpha\beta)_{ij}-(\alpha\beta)_{iq}-(\alpha\beta)_{sj}+(\alpha\beta)_{sq}\) are zero, then their averages over \(s\) and \(q\) are also zero. This leads to an equivalent way to write \(H_{0}^{AB}\)\[H_{0}^{AB}:\{(\alpha\beta)_{ij}-(\overline{\alpha\beta})_{i.}-(\overline{\alpha \beta})_{j}+(\overline{\alpha\beta})_{..}=0\;\;\mbox{for all }ij\}\;.\]

In this form, it appears that \(H_{0}^{AB}\) is based on \(ab\) estimable contrasts, but in fact, some of them are redundant, since the \(ab\) contrasts add to zero over the subscript \(i=1,2,\ldots,a\) and also over the subscript \(j=1,2,\ldots,b\). Consequently, \(H_{0}^{AB}\) is actually based on \((a-1)(b-1)\) estimable contrasts, and the test is based on \((a-1)(b-1)\) degrees of freedom.

The other two standard hypotheses are the main-effect hypotheses

\[H_{0}^{A}:\{\alpha_{1}^{*}=\alpha_{2}^{*}=\ldots=\alpha_{a}^{*}\}\;\;\;\mbox{ and}\;\;\;H_{0}^{B}:\{\beta_{1}^{*}=\beta_{2}^{*}=\ldots=\beta_{b}^{*}\}\;,\]

where \(\alpha_{i}^{*}=\alpha_{i}+(\overline{\alpha\beta})_{i.}\) and \(\beta_{j}^{*}=\beta_{j}+(\overline{\alpha\beta})_{j.}\) However, these main-effect hypotheses may not be of interest if there is a sizable interaction. Each of the main-effect hypotheses can be rephrased in terms of estimable contrasts in the parameters, and so can be tested. As in Chap. 3, the tests will be based on \((a-1)\) and \((b-1)\) degrees of freedom, respectively.

When the sample sizes are unequal, there are no neat algebraic formulae for the decision rules of the hypothesis tests. Therefore, we will obtain the tests for equal sample sizes and postpone discussion of the unequal sample size case to Sects. 6.8 and 6.9, where analysis will be done by computer.

### Testing Interactions--Equal Sample Sizes

Since tests for main effects may not be relevant if the two factors interact, the hypothesis of negligible interaction should be tested first. As in Sect. 3.5.1, p. 41, in order to test

\[H_{0}^{AB}:\{(\alpha\beta)_{ij}-(\overline{\alpha\beta})_{i.}-(\overline{\alpha \beta})_{.j}+(\overline{\alpha\beta})_{..}=0\;\;\mbox{for all }ij\}\]

against the alternative hypothesis \(H_{A}^{AB}\):{the interaction is not negligible}, we compare the sum of squares for error ssE under the two-way complete model (6.2.2) with the sum of squares for error ssE\({}_{0}^{AB}\) under the reduced model obtained when \(H_{0}^{AB}\) is true. The difference

\[\mbox{ss}AB=\mbox{ss}E_{0}^{AB}-\mbox{ss}E\]

is called the _sum of squares for the interaction_ AB, and the test rejects \(H_{0}^{AB}\) in favor of \(H_{A}^{AB}\) if ssAB is large relative to ssE.

We can rewrite the two-way complete model as

\[y_{ijt} = \mu+\alpha_{i}+\beta_{j}+(\alpha\beta)_{ij}+\epsilon_{ijt}\] \[= \mu^{*}+\alpha_{i}^{*}+\beta_{j}^{*}+[(\alpha\beta)_{ij}-( \overline{\alpha\beta})_{i.}-(\overline{\alpha\beta})_{.j}+(\overline{\alpha \beta})_{..}]+\epsilon_{ijt}\;,\]

where \(\mu^{*}\) is the constant \(\mu-(\overline{\alpha\beta})_{..}\) So, when \(H_{0}^{AB}\) is true, the reduced model is

\[y_{ijt}=\mu^{*}+\alpha_{i}^{*}+\beta_{j}^{*}+\epsilon_{ijt}\;,\]

which has the same form as the two-way main-effects model.

We will show in Sect. 6.5.1 that the least squares estimate of \(\mu+\alpha_{i}+\beta_{j}\) for the two-way main-effects model is \(\overline{y}_{i..}+\overline{y}_{.j..}-\overline{y}_{..}\), for equal sample sizes. Similarly, the least squares estimate of \(\mu^{*}+\alpha_{i}^{*}+\beta_{j}^{*}\) in the above reduced model is also \(\overline{y}_{i..}+\overline{y}_{.j..}-\overline{y}_{..}\). Hence, the sum of squares for error for the reduced model is \[\text{ssE}_{0}^{AB} =\sum_{i}\sum_{j}\sum_{t}\left(y_{ijt}-\bar{\mu}^{*}-\hat{\alpha}_{i} ^{*}-\hat{\beta}_{j}^{*}\right)^{2}\] \[=\sum_{i}\sum_{j}\sum_{t}(y_{ijt}-\overline{y}_{i..}-\overline{y}_ {j..}+\overline{y}_{...})^{2}\,.\]

Adding and subtracting a term \(\overline{y}_{ij.}\) to this expression, we have

\[\text{sE}_{0}^{AB} =\sum_{i}\sum_{j}\sum_{t}\left((y_{ijt}-\overline{y}_{ij.})+( \overline{y}_{j.}-\overline{y}_{i..}-\overline{y}_{j.}+\overline{y}_{...}) \right)^{2}\] \[=\sum_{i}\sum_{j}\sum_{t}(y_{ijt}-\overline{y}_{ij.})^{2}+\sum_{i }\sum_{j}\sum_{t}(\overline{y}_{ij.}-\overline{y}_{i.}-\overline{y}_{j.}+ \overline{y}_{...})^{2}\,.\]

But the first term is just ssE given in (6.4.15). So, for equal sample sizes,

\[\text{ssAB} =\text{sE}_{0}^{AB}-\text{sE}\] \[=r\sum_{i}\sum_{j}(\overline{y}_{ij.}-\overline{y}_{i.}- \overline{y}_{j.}+\overline{y}_{...})^{2} \tag{6.4.20}\] \[=r\sum_{i}\sum_{j}\overline{y}_{ij.}^{2}-br\sum_{i}\overline{y}_ {i.}^{2}-ar\sum_{j}\overline{y}_{j.}^{2}+abr\overline{y}_{...}^{2}\,.\]

It can be shown that when \(H_{0}^{AB}\) is true, the corresponding random variable \(\text{SS}(AB)/\sigma^{2}\) has a chi-squared distribution with \((a-1)(b-1)\) degrees of freedom. Also, \(\text{SSE}/\sigma^{2}\sim\chi_{n-ab}^{2}\) and SSE can be shown to be independent of \(\text{SS}(AB)\). So, when \(H_{0}^{AB}\) is true,

\[\frac{\text{SS}(AB)/(a-1)(b-1)\sigma^{2}}{\text{SSE}/(n-ab)\sigma^{2}}=\frac{ \text{MS}(AB)}{\text{MSE}}\sim F_{(a-1)(b-1),n-ab}\,.\]

We reject \(H_{0}^{AB}\) for large values of the ratio \(\text{msAB}/\text{msE}\). Thus, the rule for testing the hypothesis \(H_{0}^{AB}\) against the alternative hypothesis that the interaction is not negligible is

\[\text{reject}\,H_{0}^{AB}\text{ if }\frac{\text{msAB}}{\text{msE}}>F_{(a-1)(b-1),n- ab,\alpha}\,, \tag{6.4.21}\]

where \(\text{msAB}=\text{ssAB}/(a-1)(b-1)\), \(\text{msE}=\text{ssE}/(n-ab)\), \(\text{ssAB}\) is given in (6.4.20), and ssE is

\[\text{sE}=\sum_{i}\sum_{j}\sum_{t}y_{ijt}^{2}-\sum_{i}\sum_{j}r\overline{y}_{ ij.}^{2}\,.\]

If \(H_{0}^{AB}\) is rejected, it is often preferable to use the equivalent cell-means model and look at contrasts in the treatment combinations. If \(H_{0}^{AB}\) is not rejected, then tests and contrasts for main effects are usually of interest, and the two-way complete model is retained. (We do not change to the inequivalent main-effects model.)

#### Testing Main Effects of \(A\)--Equal Sample Sizes

In testing the hypothesis that factor \(A\) has no effect on the response, one can either test the hypothesis that the levels of \(A\) (averaged over the levels of \(B\)) have the same average effect on the response, that is,\[H^{A}_{0}:\left\{\alpha^{*}_{1}=\alpha^{*}_{2}=\cdots=\alpha^{*}_{a}\right\},\]

or one can test the hypothesis that the response depends only on the level of \(B\), that is

\[H^{A+AB}_{0}:\left\{H^{A}_{0}\text{ and }H^{AB}_{0}\text{are both true}\right\}.\]

The traditional test, which is produced automatically by many computer packages, is a test of the former, and the sum of squares for error ssE under the two-way complete model is compared with the sum of squares for error ssE\({}^{A}_{0}\) under the reduced model

\[Y_{jit}=\mu^{**}+\beta^{*}_{j}+\left((\alpha\beta)_{ij}-(\overline{\alpha\beta })_{i.}-(\overline{\alpha\beta})_{j}+(\overline{\alpha\beta})_{..}\right)+ \epsilon_{jit}\,.\]

It is, perhaps, more intuitively appealing to test \(H^{A+AB}_{0}\) rather than \(H^{A}_{0}\), since the corresponding reduced model is

\[Y_{jit}=\mu^{*}+\beta^{*}_{j}+\epsilon_{jit}\,,\]

suggesting that \(A\) has no effect on the response whatsoever.

In this book, we take the view that the main effect of \(A\) would not be tested unless the hypothesis of no interaction were first accepted. If it is true that there is no interaction, then the two hypotheses and corresponding reduced models are the same, and the results of the two tests should be similar. Consequently, we will derive the test of the standard hypothesis \(H^{A}_{0}\).

It can be shown that if the sample sizes are equal, the least squares estimate of \(E[Y_{jit}]\) for the reduced model under \(H^{A}_{0}\) is

\[\overline{y}_{ij.}-\overline{y}_{i..}+\overline{y}_{...}\,,\]

and so the sum of squares for error for the reduced model is

\[\text{ssE}^{A}_{0}=\sum_{i}\sum_{j}\sum_{t}(y_{jit}-\overline{y}_{ij.}+ \overline{y}_{i..}-\overline{y}_{...})^{2}\,.\]

Taking the terms in pairs and expanding the terms in parentheses, we obtain

\[\text{ssE}^{A}_{0}=\sum_{i=1}^{a}\sum_{j=1}^{b}\sum_{t=1}^{r}(y_{jit}-\overline {y}_{ij.})^{2}-br\sum_{i=1}^{a}(\overline{y}_{i..}-\overline{y}_{...})^{2}\,.\]

Since the first term is the formula (6.4.15) for ssE, the _sum of squares for treatment factor A_ is

\[\text{ssA}\ =\ \text{ssE}^{A}_{0}-\text{ssE}\ =\ br\sum_{i=1}^{a}(\overline{y}_{i.. }-\overline{y}_{...})^{2}\ =\ br\sum_{i=1}^{a}\overline{y}_{i..}^{2}-abr\overline{y}_{...}^{2}\,. \tag{6.4.22}\]

Notice that this formula for ssA is similar to the formula (3.5.12), p. 43, for ssT used to test the hypothesis \(H_{0}\):\(\left\{\tau_{1}=\tau_{2}=\cdots=\tau_{a}\right\}\) in the one-way analysis of variance.

We write SSA for the random variable corresponding to ssA. It can be shown that if \(H^{A}_{0}\) is true, SSA/\(\sigma^{2}\) has a chi-squared distribution with \(a-1\) degrees of freedom, and that SSA and SSE are independent. So, writing MSA = SSA/(\(a-1\)), we have that MSA/MSE has an \(F\)-distribution when 

[MISSING_PAGE_FAIL:181]

#### Example 6.4.5 Reaction time experiment, continued

The reaction time experiment was described in Example 6.4.2, p. 151. There were \(a=2\) levels of cue stimulus and \(b=3\) levels of cue time, and \(r=3\) observations per treatment combination. Using the data in Table 6.2, we have

\[\text{sstot} = \sum_{i}\sum_{j}\sum_{i}y_{\bar{y}i}^{2}-abr\overline{y}_{\ldots}^{2} \ =\ 0.96519-0.93617=0.02902\,,\] \[\text{ssA} = br\sum_{i}\overline{y}_{i\ldots}^{2}-abr\overline{y}_{\ldots}^{2} \ =\ 9(0.1918^{2}+0.2642^{2})-0.93617=0.02354\,,\] \[\text{ssB} = ar\sum_{j}\overline{y}_{j\ldots}^{2}-abr\overline{y}_{\ldots}^{2} \ =\ 6(0.2267^{2}+0.2190^{2}+0.2385^{2})-0.93617=0.00116\] \[\text{ssAB} = r\sum_{i}\sum_{j}\overline{y}_{ij\ldots}^{2}-br\sum_{i}\overline {y}_{i\ldots}^{2}-ar\sum_{j}\overline{y}_{j\ldots}^{2}\] \[= 0.96172-0.95971-0.93733+0.93617=0.00085\,,\]

and in Example 6.4.2, ssE was calculated to be 0.00347. It can be seen that \(\text{sstot}=\text{ssA}+\text{ssB}+\text{ssAB}+\text{ssE}\). The analysis of variance table is shown in Table 6.5. The mean squares are the sums of squares divided by their degrees of freedom.

There are three hypotheses to be tested. If the Type I error probability \(\alpha\) is selected to be 0.01 for each test, then the probability of incorrectly rejecting at least one hypothesis when it is true is at most 0.03. The interaction plots in Fig. 6.5, p. 153, suggest that there is no interaction between cue stimulus (\(A\)) and cue time (\(B\)). To test this hypothesis, we obtain from the analysis of variance table

\[\text{msAB}/\text{msE}=0.00043/0.00029=1.46\,.\]

which is less than \(F_{2,12.,01}=6.93\). Therefore, at individual significance level \(\alpha=0.01\), there is not sufficient evidence to reject the null hypothesis \(H_{0}^{AB}\) that the interaction is negligible. This agrees with the interaction plot.

Now consider the main effects. Looking at Fig. 6.5, if we average over cue stimulus, there does not appear to be much difference in the effect of cue time. If we average over cue time, then auditory cue stimulus (level 1) appears to produce a shorter reaction time than a visual cue stimulus (level 2). From the analysis of variance table, \(\text{msA}/\text{msE}=0.02354/0.00029=81.38\). This is larger than \(F_{1,12.,01}=9.33\), so we reject \(H_{0}^{A}\):\(\{\alpha_{1}^{*}=\alpha_{2}^{*}\}\), and we would conclude that there is a difference in cue stimulus averaged over the cue times. On the other hand, \(\text{msB}/\text{msE}=0.00058/0.00029=2.0\), which

\begin{table}
\begin{tabular}{l c c c c c} \hline Source of Variation & Degrees of Freedom & Sum of Squares & Mean Square & Ratio & \(p\)-value \\ \hline Cue stimulus & 1 & 0.02354 & 0.02354 & 81.38 & 0.0001 \\ Cue time & 2 & 0.00116 & 0.00058 & 2.00 & 0.1778 \\ Interaction & 2 & 0.00085 & 0.00043 & 1.46 & 0.2701 \\ Error & 12 & 0.00347 & 0.00029 & & \\ \hline Total & 17 & 0.02902 & & & \\ \hline \end{tabular}
\end{table}
Table 6.5: Two-way ANOVA for the reaction time experimentis less than \(F_{2,12,\,01}=6.93\). Consequently, we do not reject \(H_{0}^{B}:\{\beta_{1}^{*}=\beta_{2}^{*}=\beta_{3}^{*}\}\) and conclude that there is no evidence for a difference in the effects of the cue times averaged over the two cue stimuli.

If the analysis were done by a computer program, the \(p\)-values in Table 6.5 would be printed. We would reject any hypothesis whose corresponding \(p\)-value is less than the selected individual \(\alpha^{*}\) level. In this example, we selected \(\alpha^{*}=0.01\), and we would fail to reject \(H_{0}^{AB}\) and \(H_{0}^{B}\), but we would reject \(H_{0}^{A}\), as in the hand calculations.

This was a pilot experiment, and since the experimenters already believed that cue stimulus and cue time really do not interact, they selected the two-way main-effects model in planning the main experiment. 

### Analysis of the Two-Way Main-Effects Model

#### Least Squares Estimators for the Main-Effects Model

The two-way main-effects model (6.2.3) is

\[Y_{ijt}=\mu+\alpha_{i}+\beta_{j}+\epsilon_{ijt}\,,\] \[\epsilon_{ijt}\sim N(0,\sigma^{2})\,,\] \[\epsilon_{ijt}{}^{\prime}\text{s are mutually independent}\,,\] \[t=1,\ldots,r_{ij};\;\;\;i=1,\ldots,a;\;\;\;j=1,\ldots,b.\]

This model is a submodel of the two-way complete model (6.2.2) in the sense that it can only describe situations similar to those depicted in plots (a)-(d) of Fig. 6.1 and cannot describe plots (a)-(d) of Fig. 6.2. When the sample sizes are unequal, the least squares estimators of the parameters in the main-effects model are not easy to obtain, and calculations are best left to a computer (see Sects. 6.8 and 6.9). In the optional subsection below, we show that when the sample sizes are all equal to \(r\), the least squares estimator of \(E[Y_{ijt}]=\mu+\alpha_{i}+\beta_{j}\) is

\[\hat{\mu}+\hat{\alpha}_{i}+\hat{\beta}_{j}=\overline{Y}_{i\ldots}+\overline{Y} _{j,\,\,\,\,-}\,\overline{Y}_{\ldots}\,. \tag{6.5.26}\]

The least squares estimator for the estimable main-effect contrast \(\sum_{i}c_{i}\alpha_{i}\) with \(\sum_{i}c_{i}=0\) is then

\[\sum_{i}c_{i}\hat{\alpha}_{i} =\sum_{i}c_{i}(\hat{\mu}+\hat{\alpha}_{i}+\hat{\beta}_{j})\;\;= \;\;\;\sum_{i}c_{i}\left(\overline{Y}_{i\ldots}+\overline{Y}_{j,\,\,\,-}\, \overline{Y}_{\ldots}\right)\] \[=\sum_{i}c_{i}\overline{Y}_{i\ldots}\,,\]

which has variance

\[\text{Var}\left(\sum_{i}c_{i}\hat{\alpha}_{i}\right)=\text{Var}\left(\sum_{i} c_{i}\overline{Y}_{i\ldots}\right)=\frac{\sigma^{2}}{br}\sum_{i}c_{i}^{2}\,. \tag{6.5.27}\]

For example, \(\alpha_{p}-\alpha_{s}\), the pairwise comparison of levels \(p\) and \(s\) of \(A\), has least squares estimator and associated variance

\[\hat{\alpha}_{p}-\hat{\alpha}_{s}=\overline{Y}_{p\ldots}-\overline{Y}_{s\ldots }\;\;\;\;\;\;\text{with}\;\;\;\;\;\;\text{Var}(\overline{Y}_{p\ldots}-\overline {Y}_{s\ldots})=\frac{2\sigma^{2}}{br}\,.\]These are exactly the same formulas as for the two-way complete model and similar to those for the one-way model. Likewise for \(B\), a main-effect contrast \(\sum k_{j}\beta_{j}\) with \(\sum_{j}k_{j}=0\) has least squares estimator and associated variance

\[\sum_{j}k_{j}\hat{\beta}_{j}=\sum_{j}k_{j}\overline{Y}_{.j.}\quad\text{ and }\quad\text{Var}\left(\sum_{j}k_{j}\overline{Y}_{.j.}\right)=\frac{\sigma^{2}}{ar}\sum_{j}k_{j}^{2}\;, \tag{6.5.28}\]

and the least squares estimator and associated variance for the pairwise difference \(\beta_{h}-\beta_{q}\) is

\[\hat{\beta}_{h}-\hat{\beta}_{q}=\overline{Y}_{.h.}-\overline{Y}_{.q.}\quad\text{ with }\quad\text{Var}(\overline{Y}_{.h.}-\overline{Y}_{.q.})=\frac{2\sigma^{2}}{ar}\;.\]

#### _Example 6.5.1_ Nail varnish experiment

An experiment on the efficacy of nail varnish solvent in removing nail varnish from cloth was run by Pascale Quester in 1986. Two different brands of solvent (factor \(A\)) and three different brands of nail varnish (factor \(B\)) were investigated. One drop of nail varnish was applied to a piece of cloth (dropped from the applicator 20 cm above the cloth). The cloth was immersed in a bowl of solvent and the time measured (in minutes) until the varnish completely dissolved. There were six treatment combinations 11, 12, 13, 21, 22, 23, where the first digit represents the brand of solvent and the second digit represents the brand of nail varnish used in the experiment. The design was a completely randomized design with \(r=5\) observations on each of the six treatment combinations. The data are listed in Table 6.6 in the order in which they were collected.

The experimenter had run a pilot experiment to estimate the error variance \(\sigma^{2}\) and to check that the experimental procedure was satisfactory. The pilot experiment indicated that the interaction between nail varnish and solvent was negligible. The similarity of the chemical composition of the varnishes and solvents, and the verification from the pilot experiment, suggest that the main-effects model (6.2.3) will be a satisfactory model for the main experiment. The data from the main experiment give the interaction plots in Fig. 6.6. Although the lines are not quite parallel, the selected main-effects model would not be a severely incorrect representation of the data.

Using the data in Table 6.6, the average dissolving time (in minutes) for the two brands of solvent are

\begin{table}
\begin{tabular}{l l l l l l l l l} \hline Solvent & 2 & 1 & 1 & 2 & 2 & 2 & 1 & 2 \\ Varnish & 3 & 3 & 3 & 3 & 2 & 2 & 2 & 2 \\ Time & 32.50 & 30.20 & 27.25 & 24.25 & 34.42 & 26.00 & 22.50 & 31.08 \\ \hline Solvent & 1 & 2 & 1 & 1 & 2 & 1 & 2 & 2 \\ Varnish & 2 & 1 & 1 & 1 & 1 & 3 & 3 & 2 \\ Time & 25.17 & 29.17 & 27.58 & 28.75 & 31.75 & 29.75 & 30.75 & 29.17 \\ \hline Solvent & 1 & 1 & 2 & 1 & 2 & 2 & 1 & 2 \\ Varnish & 2 & 1 & 2 & 2 & 1 & 3 & 3 & 1 \\ Time & 27.75 & 25.83 & 24.75 & 21.50 & 32.08 & 29.50 & 24.50 & 28.50 \\ \hline Solvent & 2 & 1 & 1 & 2 & 1 & 1 & & \\ Varnish & 3 & 3 & 1 & 1 & 1 & 2 & & \\ Time & 28.75 & 22.75 & 29.25 & 31.25 & 22.08 & 25.00 & & \\ \hline \end{tabular}
\end{table}
Table 6.6: Data (minutes) for the nail varnish experiment \[\overline{y}_{1..}=25.9907\quad\text{and}\quad\overline{y}_{2..}=29.5947\,.\]

So the least squares estimate of the difference in the dissolving times for the two solvents is

\[\hat{\alpha}_{1}-\hat{\alpha}_{2}=\overline{y}_{1..}-\overline{y}_{2..}=-3.6040\,,\]

and the variance of the estimator is \(2\sigma^{2}/(rb)=2\sigma^{2}/15\). A difference of 3.6 minutes seems quite substantial, but this needs to be compared with the experimental error via a confidence interval to see whether such a difference could have occurred by chance (see Examples 6.5.2 and 6.5.3).

The average dissolving times for the three brands of nail varnish are

\[\overline{y}_{.1..}=28.624,\quad\overline{y}_{.2..}=26.734,\text{ and }\overline{y}_{.3.}=28.020\,,\]

and the least squares estimates of the pairwise comparisons are

\[\hat{\beta}_{1}-\hat{\beta}_{2}=1.890\,,\quad\hat{\beta}_{1}-\hat{\beta}_{3}=0.604\,,\text{ and }\hat{\beta}_{2}-\hat{\beta}_{3}=-1.286\,,\]

each with associated variance \(2\sigma^{2}/10\). Since levels 1 and 2 of the nail varnish represented French brands, while level 3 represented an American brand, the difference of averages contrast

\[\frac{1}{2}(\beta_{1}+\beta_{2})-\beta_{3}\]

would also be of interest. The least squares estimate of this contrast is

\[\frac{1}{2}(\hat{\beta}_{1}+\hat{\beta}_{2})-\hat{\beta}_{3} = \frac{1}{2}(\overline{y}_{.1.}+\overline{y}_{.2.})-\overline{y}_{.3.} = -0.341\,,\]

with associated variance \(6\sigma^{2}/40\). 

#### Deriving Least Squares Estimators for Equal Sample Sizes (Optional)

We now sketch the derivation (using calculus) of the least squares estimators for the parameters of the two-way main-effects model (6.2.3), when the sample sizes are all equal to \(r\). A reader without knowledge of calculus may jump to Sect. 6.5.2, p. 165.

Figure 6.6: Average dissolving times for the nail varnish experiment

As in Sect. 3.4.3, the least squares estimates of the parameters in a model are those estimates that give the minimum value of the sum of squares of the estimated errors. For the two-way main-effects model (6.2.3), the sum of squared errors is

\[\sum_{i=1}^{a}\sum_{j=1}^{b}\sum_{i=1}^{r}e_{ijt}^{2}=\sum_{i=1}^{a}\sum_{j=1}^{b }\sum_{t=1}^{r}\left(y_{ijt}-(\mu+\alpha_{i}+\beta_{j})\right)^{2}\,.\]

The least squares estimates are obtained by differentiating the sum of squared errors with respect to each of the parameters \(\mu\), \(\alpha_{i}\) (\(i=1,\ldots,a\)), and \(\beta_{j}\) (\(j=1,\ldots,b\)) in turn and setting the derivatives equal to zero. The resulting set of normal equations is as follows.

\[y_{\ldots}-abr\hat{\mu}-br\sum_{i}\hat{\alpha}_{i}-ar\sum_{j} \hat{\beta}_{j}=0, \tag{6.5.29}\] \[y_{i\ldots}-br\hat{\mu}-br\hat{\alpha}_{i}-r\sum_{j}\hat{\beta}_ {j}=0\,,\quad i=1,\ldots,a,\] (6.5.30) \[y_{j.}-ar\hat{\mu}-r\sum_{i}\hat{\alpha}_{i}-ar\hat{\beta}_{j}=0,\quad j=1,\ldots,b. \tag{6.5.31}\]

There are \(1+a+b\) normal equations in \(1+a+b\) unknowns. However, the equations are not all distinct (linearly independent), since the sum of the \(a\) equations listed in (6.5.30) is equal to the sum of the \(b\) equations listed in (6.5.31), which is equal to (6.5.29). Consequently, there are at most, and, in fact, exactly, \(1+a+b-2\) distinct equations, and two extra equations are needed in order to obtain a solution. Many computer packages, including the SAS software, use the extra equations \(\hat{\alpha}_{a}=0\) and \(\hat{\beta}_{b}=0\), while the R package uses the extra equations \(\hat{\alpha}_{1}=0\) and \(\hat{\beta}_{1}=0\). However, when working by hand, it is easier to use the equations \(\sum_{i}\hat{\alpha}_{i}=0\) and \(\sum_{j}\hat{\beta}_{j}=0\), in which case (6.5.29)-(6.5.31) give the following least squares solutions:

\[\hat{\mu}=\overline{y}_{\ldots}\,, \tag{6.5.32}\] \[\hat{\alpha}_{i}=\overline{y}_{i\ldots}-\overline{y}_{\ldots}\,, \quad i=1,\ldots,a\,,\] \[\hat{\beta}_{j}=\overline{y}_{j\ldots}-\overline{y}_{\ldots}\,, \quad j=1,\ldots,b\,.\]

Then the least squares estimate of \(\mu+\alpha_{i}+\beta_{j}\) is

\[\hat{\mu}+\hat{\alpha}_{i}+\hat{\beta}_{j}=\overline{y}_{i\ldots}+\overline{y }_{j\ldots}\,,\quad i=1,\ldots,a,\quad j=1,\ldots,b.\]

##### Deriving Least Squares Estimators for Unequal Sample Sizes (Optional)

If the sample sizes are not equal, then the normal equations for the two-way main-effects model become

\[y_{\ldots}-n\hat{\mu}-\sum_{p=1}^{a}r_{p.}\hat{\alpha}_{p}-\sum_ {q=1}^{b}r_{q}\hat{\beta}_{q}=0, \tag{6.5.33}\] \[y_{i\ldots}-r_{i.}\hat{\mu}-r_{i.}\hat{\alpha}_{i}-\sum_{q=1}^{b }r_{iq}\hat{\beta}_{q}=0\,,\quad i=1,\ldots,a, \tag{6.5.34}\]\[y_{j,\cdot}-r_{j}\hat{\mu}-\sum_{p=1}^{a}r_{pj}\hat{\alpha}_{p}-r_{j}\hat{\beta}_{ j}=0,\;\;\;j=1,\ldots,b, \tag{6.5.35}\]

where \(n=\sum_{i}\sum_{j}r_{ij}\), \(r_{p,\cdot}=\sum_{j}r_{pj}\), and \(r_{\cdot q}=\sum_{i}r_{iq}\). As in the equal sample size case, the normal equations represent \(a+b-1\) distinct equations in \(1+a+b\) unknowns, and two extra equations are needed to obtain a particular solution. Looking at (6.5.33), a sensible choice might be \(\sum_{p}r_{p,\cdot}\hat{\alpha}_{p}=0\) and \(\sum_{q}r_{\cdot q}\hat{\beta}_{q}=0\). Then \(\hat{\mu}=\overline{y}_{\ldots}\) as in the equal sample size case. However, obtaining solutions for the \(\hat{\alpha}_{i}\)'s and \(\hat{\beta}_{j}\)'s is not so easy. One can solve for \(\hat{\beta}_{j}\) in (6.5.35) and substitute this into (6.5.34), which gives the following equations in the \(\hat{\alpha}_{i}\)'s:

\[\hat{\alpha}_{i}-\sum_{q=1}^{b}\frac{r_{iq}}{r_{\cdot q}r_{\cdot i}}\sum_{p=1} ^{a}r_{pq}\hat{\alpha}_{p}=\overline{y}_{i,\cdot}-\sum_{q=1}^{b}\frac{r_{iq}}{ r_{\cdot q}r_{\cdot i}}y_{\cdot q}\,,\;\;\;\mbox{for $i=1,\ldots,a$}. \tag{6.5.36}\]

Equations in the \(\hat{\beta}_{j}\)'s can be obtained similarly. Algebraic expressions for the individual parameter estimates are generally complicated, and we will leave the unequal sample size case to a computer analysis (Sects. 6.8 and 6.9).

#### Estimation of \(\sigma^{2}\) in the Main-Effects Model

The minimum value of the sum of squares of the estimated errors for the two-way main-effects model is

\[\mbox{\it ssE} =\sum_{i=1}^{a}\sum_{j=1}^{b}\sum_{t=1}^{r}(y_{jit}-\hat{\mu}- \hat{\alpha}_{i}-\hat{\beta}_{j})^{2} \tag{6.5.37}\] \[=\sum_{i=1}^{a}\sum_{j=1}^{b}\sum_{t=1}^{r}(y_{jit}-\overline{y} _{i,\cdot}-\overline{y}_{j,\cdot}+\overline{y}_{\ldots})^{2}\,.\]

Expanding the terms in parentheses in (6.5.37) yields the following formula useful for direct hand calculation of ssE:

\[\mbox{\it ssE}=\sum_{i}\sum_{j}\sum_{t}y_{jit}^{2}-br\sum_{i}\overline{y}_{i, \cdot}^{2}-ar\sum_{j}\overline{y}_{\cdot j,\cdot}^{2}+abr\overline{y}_{\ldots} ^{2} \tag{6.5.38}\]

Now, ssE is the observed value of

\[\mbox{\it SSE}=\sum_{i}\sum_{j}\sum_{t}(Y_{jit}-\overline{Y}_{i,\cdot}- \overline{Y}_{j,\cdot}+\overline{Y}_{\ldots})^{2}\,.\]

In Exercise 19, the reader will be asked to prove, for the equal sample size case, that

\[E[\mbox{\it SSE}]=(n-a-b+1)\sigma^{2}\,,\]

where \(n=abr\), so an unbiased estimator of \(\sigma^{2}\) is \[MSE=SSE/(n-a-b+1)\,.\]

It can be shown that \(SSE/\sigma^{2}\) has a chi-squared distribution with \((n-a-b+1)\) degrees of freedom. An upper \(100(1-\alpha)\%\) confidence bound for \(\sigma^{2}\) is therefore given by

\[\sigma^{2}\leq\frac{ssE}{\chi_{n-a-b+1,1-\alpha}^{2}}\,.\]

_Example 6.5.2_: Nail varnish experiment, continued

The data for the nail varnish experiment are given in Table 6.6 of Example 6.5.1, p. 162, and \(a=2\), \(b=3\), \(r=5\), \(n=30\). It can be verified that

\[\sum_{i}\sum_{j}\sum_{t}y_{jit}^{2}=23,505.7976,\quad\overline{y}_{\ldots}=27.7 927\,,\]

and

\[\overline{y}_{1..}=25.9907,\quad\quad\overline{y}_{2..}=29.5947,\]

\[\overline{y}_{.1..}=28.624,\quad\quad\overline{y}_{.2..}=26.734,\quad\quad \overline{y}_{.3..}=28.020.\]

Thus, from (6.5.38),

\[\begin{array}{l}ssE=23,505.7976-23,270.3857-23,191.6053+23,172.9696\\ =216.7762\,,\end{array}\]

and an unbiased estimate of \(\sigma^{2}\) is

\[\text{ms}E=216.7762/(30-2-3+1)=8.3375\text{ minutes}^{2}\,.\]

A \(95\%\) upper confidence bound for \(\sigma^{2}\) is

\[\frac{ssE}{\chi_{26,\,95}^{2}}=\frac{216.7762}{15.3791}=14.096\text{ minutes}^{2}\,,\]

and taking square roots, a \(95\%\) upper confidence limit for \(\sigma\) is \(3.7544\) minutes. 

#### Multiple Comparisons for the Main-Effects Model

When the sample sizes are equal, the Bonferroni, Scheffe, Tukey, and Dunnett methods described in Sect. 4.4 can all be used for obtaining simultaneous confidence intervals for sets of contrasts comparing the levels of \(A\) or of \(B\). A set of \(100(1-\alpha)\%\) simultaneous confidence intervals for contrasts comparing the levels of factor \(A\) is of the form (4.4.20), which for the two-way model becomes

\[\sum c_{i}\alpha_{i} \in \left(\sum c_{i}\overline{y}_{i..}\pm w\sqrt{msE\sum c_{i}^{2}/ br}\,\right), \tag{6.5.39}\]where the critical coefficients for the various methods are, respectively,

\[w_{B} =t_{n-a-b+1,\alpha/2m}\ \ ;\ \ w_{S}=\sqrt{(a-1)F_{a-1,n-a-b+1,\alpha}}\ \ ;\] \[w_{T} =q_{a,n-a-b+1,\alpha}/\sqrt{2}\ \ ;\ \ w_{D2}=|t|_{a-1,n-a-b+1, \alpha}^{(0.5)}\ \.\]

Similarly, a set of 100(\(1-\alpha\))% confidence intervals for contrasts comparing the levels of factor \(B\) is of the form

\[\sum k_{j}\beta_{j}\in\left(\sum k_{j}\overline{y}_{j.}\pm w\,\sqrt{\text{msE }\sum k_{j}^{2}/ar}\right)\, \tag{6.5.40}\]

and the critical coefficients are as above after interchanging \(a\) and \(b\).

We can also obtain confidence intervals for the treatment means \(\mu+\alpha_{i}+\beta_{j}\) using the least squares estimators \(\overline{Y}_{l.}+\overline{Y}_{j.}-\overline{Y}_{...}\), each of which has a normal distribution and variance \(\sigma^{2}(a+b-1)/(abr)\). We obtain a set of 100(\(1-\alpha\))% simultaneous confidence intervals for the \(ab\) treatment means as

\[\mu+\alpha_{i}+\beta_{j}\in\left\{(\overline{y}_{l.}+\overline{y}_{j.}- \overline{y}_{...})\pm w\sqrt{\text{msE}\left(\frac{a+b-1}{abr}\right)}\right\}\, \tag{6.5.41}\]

with critical coefficient

\[w_{BM}=t_{\alpha/(2ab),(n-a-b+1)}\ \ \ \text{or}\ \ \ w_{SM}=\sqrt{(a+b-1)F_{a+b-1,n-a-b+1,\alpha}}\]

for the Bonferroni and Scheffe methods, respectively.

When confidence intervals are calculated for treatment means and for contrasts in the main effects of factors \(A\) and \(B\), an experimentwise confidence level should be calculated. For example, if intervals for contrasts for factor \(A\) have overall confidence level 100(\(1-\alpha_{1}\))%, and intervals for \(B\) have overall confidence level 100(\(1-\alpha_{2}\))%, and intervals for means have overall confidence level 100(\(1-\alpha_{3}\))%, the experimentwise confidence level for all the intervals combined is at least 100(\(1-(\alpha_{1}+\alpha_{2}+\alpha_{3})\))%. Alternatively, \(w_{SM}\) could be used in (6.5.39) and (6.5.41), and the overall level for all three sets of intervals together would be 100(\(1-\alpha\))%.

#### _Example 6.5.3_Nail varnish experiment, continued

The least squares estimates for the differences in the effects of the two nail varnish solvents and for the pairwise differences in the effects of the three nail varnishes were calculated in Example 6.5.1, p. 162. From Table 6.8, \(\text{msE}=8.3375\) with error degrees of freedom \(n-a-b+1=26\). There is only \(m=1\) contrast for factor \(A\), and a simple 99% confidence interval of the form (6.5.39) can be used to give

\[\alpha_{2}-\alpha_{1} \in\left(\overline{y}_{2..}-\overline{y}_{1..}\pm t_{n-a-b+1, \alpha/2}\sqrt{\text{msE}(2/br)}\right)\] \[=\left(3.6040\pm t_{26,0.005}\sqrt{(8.3375/15)}\right)\.\]

From Table A.4, \(t_{26,0.005}=2.779\), so a 99% confidence interval for \(\alpha_{2}-\alpha_{1}\) is

\[1.5321\leq\alpha_{2}-\alpha_{1}\leq 5.6759\.\]The confidence interval indicates that solvent 2 takes between 1.5 and 5.7 minutes longer, on average, in dissolving the three nail varnishes than does solvent 1.

To compare the nail varnishes in terms of their speed of dissolving, confidence intervals are required for the three pairwise comparisons \(\beta_{1}-\beta_{2}\), \(\beta_{1}-\beta_{3}\), and \(\beta_{2}-\beta_{3}\). If an overall confidence level of 99% is required, Tukey's method gives confidence intervals of the form

\[\beta_{j}-\beta_{p}\in\left(\overline{y}_{j\cdot}-\overline{y}_{p\cdot}\pm(q_{ b,dt,0.01}/\sqrt{2})\;\sqrt{msE(2/(ar))}\right).\]

From Table A.8, \(q_{3,26,0.01}=4.54\). Using the least squares estimates computed in Example 6.5.1, p. 162, and \(msE=8.3375\) with \(n-a-b+1=26\) as above, the minimum significant difference is \(msd=(4.54/\sqrt{2})\;\sqrt{8.3375(2/10)}=4.145\). A set of 99% confidence intervals for the pairwise comparisons for factor \(B\) is

\[\beta_{1}-\beta_{2}\in(1.890\pm 4.145)=(-2.255,6.035)\;,\]

\[\beta_{1}-\beta_{3}\in(-3.541,4.749)\;,\;\;\;\;\;\;\beta_{2}-\beta_{3}\in(-5.4 31,2.859)\;.\]

Each of these intervals includes zero, indicating insufficient evidence to conclude a difference in the speed at which the nail varnishes dissolve. The overall confidence level for the four intervals for factors \(A\) and \(B\) together is at least 98%. Bonferroni's method could have been used instead for all four intervals. To have obtained an overall level of at least 98%, we could have set \(\alpha^{*}=\alpha/m=0.02/4=0.005\) for each of the four intervals. The critical coefficient in (6.5.39) would then have been \(w_{B}=t_{0.0025,26}=3.067\). So the Bonferroni method would have given a longer interval for \(\alpha_{1}-\alpha_{2}\) but shorter intervals for \(\beta_{j}-\beta_{p}\). 

#### Unequal Variances

When the variances of the error variables are unequal and no equalizing transformation can be found, Satterthwaite's approximation can be used. Since the approximation uses the sample variances of the observations for each treatment combination individually, and since the least squares estimates of the main-effect contrasts are the same whether or not interaction terms are included in the model, the procedure is exactly the same as that illustrated for the bleach experiment in Example 6.4.4, p. 154.

#### Analysis of Variance for Equal Sample Sizes

##### Testing Main Effects of \(B\)--Equal Sample Sizes

The hypothesis that the levels of \(B\) all have the same effect on the response is \(H_{0}^{B}:\{\beta_{1}=\beta_{2}=\cdots=\beta_{b}\}\), which can be written in terms of estimable contrasts as \(H_{0}^{B}:\{\beta_{j}-\overline{\beta}\cdot=0,\;\text{for all}\;j=1,\ldots,b\}\). To obtain a test of \(H_{0}^{B}\) against the alternative hypothesis \(H_{A}^{B}:\{\) at least two of the \(\beta_{j}\)'s differ\(\}\), the sum of squares for error for the two-way main-effects model is compared with the sum of squares for error for the reduced model

\[Y_{jit}=\mu+\alpha_{i}+\epsilon_{jit}\;. \tag{6.5.42}\]

This is identical to the one-way analysis of variance model (3.3.1) with \(\mu\) replaced by \(\mu*=\mu+\overline{\beta}\). and with \(br\) observations on the \(i\)th level of treatment factor \(A\). Thus \(ssE_{0}^{B}\) is the same as the sum of squaresfor error in a one-way analysis of variance, and can be obtained from (3.4.4), p. 39, by replacing the subscript \(t\) by the pair of subscripts \(jt\), yielding

\[s{\rm s}{\rm E}_{0}^{B}=\sum_{i}\sum_{j}\sum_{t}(y_{jit}-\overline{y}_{i..})^{2}\,. \tag{6.5.43}\]

The sum of squares for testing \(H_{0}^{B}\) is \(s{\rm s}{\rm E}_{0}^{B}-s{\rm s}{\rm E}\), where \(s{\rm s}{\rm E}\) was derived in (6.5.37), p. 165. So,

\[s{\rm s}B =\sum_{i=1}^{a}\sum_{j=1}^{b}\sum_{t=1}^{r}(y_{jit}-\overline{y}_{i.. })^{2}-\sum_{i=1}^{a}\sum_{j=1}^{b}\sum_{t=1}^{r}\big{(}(y_{jit}-\overline{y}_ {i..})-(\overline{y}_{j..}-\overline{y}_{...})\big{)}^{2}\] \[=ar\sum_{j}(\overline{y}_{j..}-\overline{y}_{...})^{2}\] \[=ar\sum_{j}\overline{y}_{j..}^{2}-ab\overline{y}_{...}^{2}\,. \tag{6.5.44}\]

Notice that the formula for \(s{\rm s}B\) is identical to the formula (6.4.25) for testing the equivalent main-effect hypothesis in the two-way complete model. It can be shown that when \(H_{0}^{B}\) is true, the corresponding random variable \(S{\rm s}B/\sigma^{2}\) has a chi-squared distribution with \((b-1)\) degrees of freedom, and SSB and SSE are independent. Therefore, when \(H_{0}^{B}\) is true,

\[\frac{S{\rm s}B/(b-1)\sigma^{2}}{S{\rm s}{\rm E}/(n-a-b+1)\sigma^{2}}=\frac{M{ \rm s}B}{M{\rm s}{\rm E}}\sim F_{b-1,n-a-b+1}\,,\]

and the decision rule for testing \(H_{0}^{B}\) against \(H_{A}^{B}\) is

\[{\rm reject}\ H_{0}^{B}\ {\rm if}\ \frac{{\rm m}{\rm s}B}{{\rm m}{\rm s}{\rm E }}\sim F_{b-1,n-a-b+1,\alpha}\,. \tag{6.5.45}\]

#### Testing Main Effects of \(A\)--Equal Sample Sizes

A similar rule is obtained for testing \(H_{0}^{A}:\{\alpha_{1}=\alpha_{2}=\cdots=\alpha_{a}\}\) against the alternative hypothesis \(H_{A}^{A}:\{\mbox{at least two of the $\alpha_{i}$'s differ}\}\). The decision rule is

\[{\rm reject}\ H_{0}^{A}\ {\rm if}\ \frac{{\rm m}{\rm s}A}{{\rm m}{\rm s}{\rm E }}\sim F_{a-1,n-a-b+1,\alpha}\,, \tag{6.5.46}\]

where \({\rm m}{\rm s}A=s{\rm s}A/(a-1)\), and

\[s{\rm s}A\ =\ br\sum_{i}(\overline{y}_{i..}-\overline{y}_{...})^{2}\ =\ br\sum_{i}\overline{y}_{i..}^{2}-ab\overline{y}_{...}^{2}\,. \tag{6.5.47}\]

similar to the formula (6.4.22) for testing the equivalent hypothesis in the two-way complete model.

#### Analysis of Variance Table

The information for testing \(H_{0}^{A}\) and \(H_{0}^{B}\) is summarized in the analysis of variance table shown in Table 6.7. When sample sizes are equal, \(s{\rm s}{\rm E}=s{\rm stot}-s{\rm s}A-s{\rm s}B\). When the sample sizes are not equal, the formulae for the sums of squares are complicated, and the analysis should be done by computer (Sects. 6.8 and 6.9).

#### Example 6.5.4

Nail varnish experiment, continued

The analysis of variance table for the nail varnish experiment of Example 6.5.1, p. 162, is given in Table 6.8. The experimenter selected the Type I error probability as 0.05 for testing each of \(H_{0}^{A}\) and \(H_{0}^{B}\), giving an overall error rate of at most 0.1. The ratio msA/msE = 11.68 is larger than \(F_{1,26,0.05}\approx 4.0\), and therefore, the null hypothesis can be rejected. It can be concluded at individual significance level 0.05 that there is a difference in dissolving times for the two solvents.

The ratio \(\text{{msB}}/\text{{msE}}=1.12\) is smaller than \(F_{2,26,0.05}\approx 3.15\). Therefore, the null hypothesis \(H_{0}^{B}\) cannot be rejected at individual significance level 0.05, and it is not possible to conclude that there is a difference in dissolving time among the three varnishes. 

#### Model Building

In some experiments, the primary objective is to find a model that gives an adequate representation of the experimental data. Such experiments are called experiments for _model building_. If there are two crossed, fixed treatment factors, it is legitimate to use the two-way complete model (6.2.2) as a preliminary model. Then, if \(H_{0}^{AB}\) fails to be rejected, the two-way main effects model (6.2.3) can be accepted as a reasonable model to represent the same type of experimental data in _future_ experiments.

Note that it is _not legitimate_ to adopt the two-way main effects model and to use the corresponding analysis of variance table, Table 6.7, to test further hypotheses or calculate confidence intervals using the _same_ set of data. If this is done, the model is changed based on the data, and the quoted significance levels and confidence levels associated with further inferences will not be correct. Model building should be regarded as a completely different exercise from confidence interval calculation. _They should be done using different experimental data_.

\begin{table}
\begin{tabular}{c c c c c c} \hline Source of Variation & Degrees of Freedom & Sum of Squares & Mean Square & Ratio & \(p\)-value \\ \hline Solvent & 1 & 97.4161 & 97.4161 & 11.68 & 0.0021 \\ Varnish & 2 & 18.6357 & 9.3178 & 1.12 & 0.3423 \\ Error & 26 & 216.7761 & 8.3375 & & \\ \hline Total & 29 & 332.8279 & & & \\ \hline \end{tabular}
\end{table}
Table 6.8: Analysis of variance for the nail varnish experiment

\begin{table}
\begin{tabular}{c c c c c} \hline Source of Variation & Degrees of Freedom & Sum of Squares & Mean Square & Ratio \\ \hline Factor \(A\) & \(a-1\) & ssA & \(\frac{\text{{ssA}}}{a-1}\) & \(\frac{\text{{msA}}}{\text{{msE}}}\) \\ Factor \(B\) & \(b-1\) & ssB & \(\frac{\text{{ssB}}}{b-1}\) & \(\frac{\text{{msB}}}{\text{{msE}}}\) \\ Error & \(n-a-b+1\) & ssE & \(\frac{\text{{ssE}}}{n-a-b+1}\) & \\ Total & \(n-1\) & sstot & & \\ \hline \multicolumn{5}{c}{Computational Formulae for Equal Sample Sizes} \\ \hline \(\text{{ssA}}=br\sum_{i}\overline{y}_{i,-}^{2}-n\overline{y}_{-}^{2}\) & & ssB \(=ar\sum_{j}\overline{y}_{j,-}^{2}-n\overline{y}_{-}^{2}\) \\ \(\text{{sstot}}=\sum_{i}\sum_{j}\sum_{i}y_{ij}^{2}-n\overline{y}_{-}^{2}\) & & ssE \(=\text{{sstot}}-\text{{ssA}}-\text{{ssB}}\) \\ \(n=abr\) & & & \\ \hline \end{tabular}
\end{table}
Table 6.7: Two-Way ANOVA, negligible interaction, equal sample sizes

### Calculating Sample Sizes

In Chaps. 3 and 4, we showed two methods of calculating sample sizes. The method of Sect. 3.6 aims to achieve a specified power of a hypothesis test, and the method of Sect. 4.5 aims to achieve a specified length of a confidence interval. Both of these techniques rely on knowledge of the largest likely value of \(\sigma^{2}\) or msE and can also be used for the two-way complete model.

Alternatively, sample sizes can be calculated to ensure that confidence intervals for main-effect contrasts are no longer than a stated size, using the formulae (6.4.18) and (6.4.19) or, for the two-way main-effects model, the formulae (6.5.39) and (6.5.40).

Similarly, the method of Sect. 3.6 for choosing the sample size to achieve the required power of a hypothesis test can be used for each factor separately, with the modification that the sample size calculation is based on

\[r=2a\sigma^{2}\phi^{2}/(b\Delta_{A}^{2}) \tag{6.6.48}\]

for factor \(A\) and

\[r=2b\sigma^{2}\phi^{2}/(a\Delta_{B}^{2})\]

for factor \(B\), where \(\Delta_{A}\) is the smallest difference in the \(\alpha_{i}\)'s (or \(\alpha_{i}^{*}\)'s) and \(\Delta_{B}\) is the smallest difference in the \(\beta_{j}\)'s (or \(\beta_{j}^{*}\)'s) that are of interest. The calculation procedure is identical to that in Sect. 3.6, except that the error degrees of freedom are \(\nu_{2}=n-v\) for the complete model and \(\nu_{2}=n-a-b+1\) for the main-effects model (with \(n=abr\)), and the numerator degrees of freedom are \(\nu_{1}=a-1\) for factor \(A\) and \(\nu_{1}=b-1\) for factor \(B\).

If several different calculations are done and the calculated values of \(r\) differ, then the largest value should be selected.

### Small Experiments

#### One Observation Per Cell

When observations are extremely time-consuming or expensive to collect, an experiment may be designed to have \(r=1\) observation on each treatment combination. Such experiments are called _experiments with one observation per cell_ or _single replicate experiments_. Since the ability to choose the sample sizes is lost, it should be recognized that confidence intervals may be wide and hypothesis tests not very powerful.

If it is known in advance that the interaction between the two treatment factors is negligible, then the experiment can be analyzed using the two-way main-effects model (6.2.3). If this information is not available, then the two-way complete model (6.2.2) needs to be used. However, there is a problem. Under the two-way complete model, the number of degrees of freedom for error is \(ab(r-1)\). If \(r=1\), then this number is zero, and \(\sigma^{2}\) cannot be estimated.

Thus, a single replicate experiment with a possible interaction between the two factors can be analyzed only if one of the following is true:

1. \(\sigma^{2}\) is known in advance.
2. The interaction is expected to be of a certain form that can be modeled with fewer than \((a-1)(b-1)\) degrees of freedom.

3. The number of treatment combinations is large, and only a few contrasts are likely to be nonnegligible (_effect sparsity_).

If \(\sigma^{2}\) is known in advance, formulae for confidence intervals would be based on the normal distribution, and hypothesis tests would be based on the chi-squared distribution. However, this situation is unlikely to occur, and we will not pursue it. The third case tends to occur when the experiment involves a large number of treatment factors and will be discussed in detail in Chap. 7. Here, we look at the second situation and consider two methods of analysis, the first based on orthogonal contrasts, and the second known as Tukey's test for additivity.

#### Analysis Based on Orthogonal Contrasts

Two estimable contrasts are called _orthogonal contrasts_ if and only if their least squares estimators are uncorrelated or, equivalently, have zero covariance. For the moment, we recode the treatment combinations to obtain a single-digit code, as we did in Chap. 3. Two contrasts \(\Sigma c_{i}\tau_{i}\) and \(\Sigma k_{s}\tau_{s}\) are orthogonal if and only if

\[0 = \text{Cov}\left(\sum_{i=1}^{v}c_{i}\overline{Y}_{i.},\sum_{s=1}^ {v}k_{s}\overline{Y}_{s.}\right)\ \ =\ \ \sum_{i=1}^{v}\sum_{s=1}^{v}c_{i}k_{s} \text{Cov}(\overline{Y}_{i.},\overline{Y}_{s.})\] \[= \sum_{i}c_{i}k_{i}\text{Cov}(\overline{Y}_{i.},\overline{Y}_{i.} )+\sum_{i}\sum_{s\neq i}c_{i}k_{s}\text{Cov}(\overline{Y}_{i.},\overline{Y}_{s.})\] \[= \sum_{i}c_{i}k_{i}\text{Var}(\overline{Y}_{i.})\ \ +\ \ 0\] \[= \sigma^{2}\sum_{i}c_{i}k_{i}/r_{i}\,.\]

In the above calculation \(\text{Cov}(\overline{Y}_{i.},\overline{Y}_{s.})\) is zero when \(s\neq i\), because all the \(Y_{i\prime}\)'s are independent of each other in the cell-means model. Thus, two contrasts \(\Sigma c_{i}\tau_{i}\) and \(\Sigma k_{i}\tau_{i}\) are orthogonal if and only if

\[\sum_{i}c_{i}k_{i}/r_{i}=0\,. \tag{6.7.49}\]

If the sample sizes are equal, then this reduces to

\[\sum_{i}c_{i}k_{i}=0\,.\]

Changing back to two subscripts, we have that two contrasts \(\Sigma\Sigma d_{ij}\tau_{ij}\) and \(\Sigma\Sigma h_{ij}\tau_{ij}\) are orthogonal if and only if

\[\sum_{i=1}^{a}\sum_{j=1}^{b}d_{ij}h_{ij}/r_{ij}=0\,, \tag{6.7.50}\]

or, for equal sample sizes, the contrasts are orthogonal if and only if \[\sum_{i=1}^{a}\sum_{j=1}^{b}d_{ij}h_{ij}=0\,. \tag{6.7.51}\]

For equal sample sizes, the trend contrasts provide an illustration of orthogonal contrasts. For example, it can be verified that any pair of trend contrasts in Table 6.1, p. 148, satisfy (6.7.51). For the models considered in this book, the contrast estimators are normally distributed, so orthogonality of contrasts implies that their least squares estimators are independent.

For \(v\) treatments, or treatment combinations, a set of \(v-1\) orthogonal contrasts is called a _complete set of orthogonal contrasts_. It is not possible to find more than \(v-1\) contrasts that are mutually orthogonal. We write the sum of squares for the \(q\)th orthogonal contrast in a complete set as \(ssc_{q}\), where

\[ssc_{q}=(\Sigma\,\Sigma\,c_{ij}\overline{y}_{ij})^{2}/(\Sigma\,\Sigma\,c_{ij}^ {2}/r_{ij})\]

is the square of the normalized contrast estimator (see Sect. 4.3.3, p. 77). The sum of squares for treatments, \(s\)s\(T\), can be partitioned into the sums of squares for the \(v-1\) orthogonal contrasts in a complete set; that is,

\[s\,\!s\!T=ssc_{1}+ssc_{2}+\cdots+ssc_{v-1}\,. \tag{6.7.52}\]

#### 6.7.1 Battery experiment, continued

Main effect and interaction contrasts for the battery experiment were examined in Example 6.3.1, p. 146 and, following that example, were written as columns in a table. Since the sample sizes are all equal, we need only check that (6.7.51) holds by multiplying corresponding coefficients for any two contrasts and adding their products. The duty, brand, and interaction contrasts form a complete set of \(v-1=3\) orthogonal contrasts.

The sums of squares for the three contrasts are shown in Table 6.9. It can be verified that they add to the treatment sum of squares \(s\,\!s\!T=427,915.25\) that was calculated in Example 3.5.1, p. 44. 

We can use the same idea to split the interaction sum of squares \(s\)s\(A\)B into independent pieces. For the two-way complete model (6.2.2) with \(r=1\) observation per cell, the sum of squares for testing the null hypothesis that a particular interaction contrast, say \(\sum_{i}\sum_{j}d_{ij}(\alpha\beta)_{ij}\) (with \(\sum_{i}d_{ij}=0\) and \(\sum_{j}d_{ij}=0\)), is negligible, against the alternative hypothesis that the contrast is not negligible, is

\[ssc=\frac{(\sum_{i}\sum_{j}d_{ij}y_{ij})^{2}}{\sum_{i}\sum_{j}d_{ij}^{2}}\,. \tag{6.7.53}\]

The interaction has \((a-1)(b-1)\) degrees of freedom. Consequently, there are \((a-1)(b-1)\) orthogonal interaction contrasts in a complete set, and their corresponding sums of squares add to \(s\)s\(A\)B, that is,

\begin{table}
\begin{tabular}{c c c c c} \hline Contrast & Coefficients & \(\sum c_{i}\overline{y}_{i}\) & \(\sum c_{i}^{2}/r_{i}\) & ssc \\ \hline Duty & \(\frac{1}{2}[1,\ \ 1,\ -1,\ -1]\) & 251.00 & \(\frac{1}{4}\) & 252,004.00 \\ Brand & \(\frac{1}{2}[1,\ -1,\ \ 1,\ -1]\) & \(-176.50\) & \(\frac{1}{4}\) & 124,609.00 \\ Interaction & \(\frac{1}{2}[1,\ -1,\ -1,\ 1]\) & \(-113.25\) & \(\frac{1}{4}\) & 51,302.25 \\ \hline \end{tabular}
\end{table}
Table 6.9: Three orthogonal contrasts for the battery experiment \[\text{ss}AB=\sum_{h=1}^{(a-1)(b-1)}\text{ss}c_{h}\,,\]

where \(\text{ss}c_{h}\) is the sum of squares for the \(h\)th such contrast.

Suppose it is known _in advance_ that \(e\) specific orthogonal interaction contrasts are likely to be negligible. Then the sums of squares for these \(e\) negligible contrasts can be pooled together to obtain an estimate of error variance, based on \(e\) degrees of freedom,

\[\text{ss}E=\sum_{h=1}^{e}\text{ss}c_{h}\ \ \ \text{and}\ \ \ \text{ms}E=\text{ss}E/e\,.\]

The sums of squares for the remaining interaction contrasts can be used to test the contrasts individually or added together to obtain an interaction sum of squares

\[\text{ss}AB_{m}=\sum_{h=e+1}^{(a-1)(b-1)}\text{ss}c_{h}\,.\]

Then the decision rule for testing the hypothesis \(H_{0}^{AB}\):{the interaction \(AB\) is negligible} against the alternative hypothesis that the interaction is not negligible is

\[\text{reject}\,H_{0}^{AB}\text{ if }\frac{\text{ss}AB_{m}/m}{\text{ss}E/e}>F_{m,e,\alpha}\,,\]

where \(m=(a-1)(b-1)-e\). Likewise, the main effect test statistics have denominator ssE/\(e\) and error degrees of freedom df = \(e\). The tests are summarized in Table 6.10, which shows a modified form of the analysis of variance table for the two-way complete model. A worked example is given in Sect. 6.7.4.

To save calculating the sums of squares for all of the contrasts, the error sum of squares is usually obtained by subtraction, that is,

\[\text{ss}E=\text{s}\text{s}\text{t}\text{ot}-\text{ss}A-\text{ss}B-\text{ss} AB_{m}\,.\]

The above technique is most often used when the factors are quantitative, since higher-order interaction trends are often likely to be negligible. The information about the interaction effects must be known prior to running the experiment. If this information is not available, then one of the techniques discussed in Sect. 7.5 must be used instead.

\begin{table}
\begin{tabular}{c c c c} \hline Source of variation & Degrees of freedom & Sum of squares & Mean square \\ \hline Factor \(A\) & \(a-1\) & ssA & msA \\ Factor \(B\) & \(b-1\) & ssB & msB \\ Interaction & \(m\) & ssAB\({}_{m}\) & msAB \\ Error & \(e\) & ssE & msE \\ Total & \(ab-1\) & sstot & \\ \hline \end{tabular}
\end{table}
Table 6.10: Two-way ANOVA, one observation per cell, \(e\) negligible interaction contrasts, and \(m=(a-1)(b-1)-e\) interaction degrees of freedom 

#### Tukey's Test for Additivity

Tukey's test for additivity uses only one degree of freedom to measure the interaction. It tests the null hypothesis \(H_{0}^{\gamma}\) :\(\{(\alpha\beta)_{ij}=\gamma\alpha_{i}\beta_{j}\) for all \(i,j\}\) against the alternative hypothesis that the interaction is not of this form. The test is appropriate only if the size of the interaction effect is expected to increase proportionally to each of the main effects, and it is not designed to measure any other form of interaction. The test requires that the normality assumption be well satisfied. The decision rule is

\[\text{reject}\,H_{0}^{\gamma}\text{ if }\frac{\text{ss}\text{A}\text{B}^{*}}{ \text{ss}\text{E}/e}>F_{1,e,\alpha}\,, \tag{6.7.54}\]

where

\[\text{ss}\text{A}\text{B}^{*}=\frac{ab\left[\sum_{i}\sum_{j}y_{ij}\overline{y} _{i}.\overline{y}_{j}-(\text{ss}\text{A}+\text{ss}\text{B}+ab\overline{y}_{ \ldots}^{2})\overline{y}_{\ldots}\right]^{2}}{(\text{ss}\text{A})(\text{ss} \text{B})}\]

and

\[\text{ss}\text{E}=\text{ss}\text{tot}-\text{ss}\text{A}-\text{ss}\text{B}- \text{ss}\text{A}\text{B}^{*}\,.\]

The analysis of variance table is as in Table 6.10 with \(m=1\) and with \(e=(a-1)(b-1)-1\).

\begin{table}
\begin{tabular}{c c c c c c c c c} \hline  & & & & & & & & & \\  & \(i\) & 1 & 2 & 3 & 4 & 5 & 6 & \(\overline{y}_{i}\) \\ \hline Rib & 1 & \(-24\) & \(-23\) & 1 & 8 & 29 & 23 & 2.333 \\ Height & 2 & 33 & 28 & 45 & 57 & 74 & 80 & 52.833 \\  & 3 & 37 & 79 & 79 & 95 & 101 & 111 & 83.667 \\ \hline  & \(\overline{y}_{j}\) & 15.333 & 28.00 & 41.667 & 53.333 & 68.000 & 71.333 & 46.278 = \(\overline{y}_{\ldots}\) \\ \hline _Source_ & Willke (1962). Copyright ©1962 Blackwell Publishers. Reprinted with permission \\ \end{tabular}
\end{table}
Table 6.11: Data for the air velocity experiment, with factors Rib Height (\(A\)) and Reynolds Number (\(B\))

Figure 6.7: Data for the air velocity experiment

[MISSING_PAGE_FAIL:198]

\[\Sigma\,\Sigma\,d_{ij}y_{ij}=5(-24)+3(-23)+\cdots+3(101)+5(111)=54\,.\]

Now,

\[\Sigma\,\Sigma d_{ij}^{2}=(5^{2}+3^{2}+\cdots+3^{2}+5^{2})=140\,,\]

so the corresponding sum of squares is

\[ss(A_{\rm L}B_{\rm L})=\frac{54^{2}}{140}=20.829\,.\]

The sums of squares for the other contrasts are computed similarly, and the error sum of squares is calculated as the sum of the sums of squares of the three negligible contrasts. The analysis of variance table is given in Table 6.12.

The hypotheses that the individual contrasts are zero can be tested using Scheffe's procedure or Bonferroni's procedure. If Bonferroni's procedure is used, each of the 14 hypotheses should be tested at a very small \(\alpha\)-level. Taking \(\alpha=0.005\), so that the overall level is at most 0.07, we have \(F_{1,3,0.005}=55.6\), and only the linear \(A\) and linear \(B\) contrasts appear to be significantly different from zero. The plot of the data shown in Fig. 6.7 supports this conclusion.

### Using SAS Software

Table 6.13 contains a sample SAS program for analysis of the two-way complete model (6.2.2). For illustration, we use the data of the reaction time experiment shown in Table 4.4, p. 101, but with the last four observati ons missing, so that \(r_{11}=r_{21}=2,r_{12}=r_{22}=r_{23}=3,r_{13}=1\). In the data input lines, the levels of each of the two treatment factors \(A\) and \(B\) are shown together with the response, the order in which the observations were collected, and the treatment factor level TRTMT. A two-digit code for each treatment combination TC is easily generated by the statement TC = 10*A + B following the INPUT statement. This way of coding the treatment combinations works well for all applications except for drawing plots with TC on one axis. Such a plot would not show numeric codes 11, 12,..., 23 as equally spaced. In the statement TC = PUT(10* A + B, 2.), the function PUT converts the created variable from numeric to character.

#### Analysis of Variance

The GLM procedure in Table 6.13 is used to generate the analysis of variance table, to estimate and to test contrasts, and for multiple comparisons. As in the one-way analysis of variance, the treatment factors must be declared as class variables using a CLASS statement. The two-way complete model is represented as

MODEL Y = A B A*B;

with the main effects listed in either order, but before the interaction. The two-way main-effects model (6.2.3) would be represented as

MODEL Y = A B;

The program also shows the cell-means model (6.2.1) in a second GLM procedure, using

MODEL Y = TC;The output from the first GLM procedure is shown in Fig. 6.8. The analysis of variance table is organized differently from that in Table 6.4, p. 159. The five "model" degrees of freedom are the treatment degrees of freedom corresponding to the six treatment combinations. Information concerning main effects and interactions is provided underneath the table under the heading "Type I" and "Type III" sums of squares.

The _Type III sums of squares_ are the values ssA, ssB, and ssAB and are used for hypothesis testing whether or not the sample sizes are equal. They are calculated by comparing the sum of squares for error in the full and reduced models as in Sect. 6.4.4. The sums of squares listed in the output are always in the same order as the effects in the MODEL statement, but the hypothesis of no interaction should be tested first.

The _Type I sum of squares_ for an effect is the additional variation in the data that is explained by adding that effect to a model containing the previously listed sources of variation. For example, in the program output, the Type I sum of squares for \(A\) is the reduction in the error sum of squares that is achieved by adding the effect of factor \(A\) to a model containing only an intercept term. The reduction in the error sum of squares is equivalent to the extra variation in the data that is explained by adding \(A\) to the model. Here, the "full model" contains \(A\) and the intercept, while the "reduced model" contains only

\begin{table}
\begin{tabular}{l} DATA RTIME; \\  INPUT ORDER TRTMT A B Y; \\  TC = PUT(10*A + B, 2.); * create TC as a character variable for plots; \\  LINES; \\  1 6 2 3 0.256 \\  2 6 2 3 0.281 \\  : : : : \\  14 4 2 1 0.279 \\  ;  PROC GLM; \\  CLASS A B; \\  MODEL Y = A B A*B; \\  LSMEANS A / PDIFF CL ALPHA=0.01; \\  LSMEANS B / PDIFF = ALL CL ADJUST = TUKEY ALPHA = 0.01; \\  CONTRAST ’11-13-21+23’ A*B 1 0 -1 -1 0 1; \\  CONTRAST ’B1-B2’ B 1 -1 0; \\  ESTIMATE ’B1-B2’ B 1 -1 0; \\  ESTIMATE ’B1-B3’ B 1 0 -1; \\  PERC GLM; \\  CLASS TC; \\  MODEL Y = TC; \\  LSMEANS TC / PDIFF = ALL CL ADJUST = TUKEY ALPHA = 0.01; \\  LSMEANS TC / PDIFF = CONTROL CL ADJUST = DUNNETT ALPHA = 0.01; \\  LSMEANS TC / PDIFF = CONTROL CL ADJUST = DUNNETT ALPHA = 0.01; \\  LSMEANS TC / PDIFF = CONTROL CL ADJUST = DUNNETT ALPHA = 0.01; \\  CONTRAST ’11-13-21+23’ TC 1 0 -1 -1 0 1; \\  CONTRAST ’B1-B2’ TC 1 -1 0 1 -1 0; \\ \end{tabular}
\end{table}
Table 6.13: SAS program to illustrate aspects of analysis of a two-way complete model (reaction time experiment)the intercept. The Type I sum of squares for \(B\) is the additional variation in the data that is explained by adding the effect of factor \(B\) to a model that already contains the intercept and the effect of \(A\) (so that the "full model" contains \(A,B\) and the intercept, while the "reduced model" contains only the \(A\) and the intercept). The Type I sums of squares (also known as _sequential sums of squares_) depend upon the order in which the effects are listed in the MODEL statement. Type I sums of squares are used for model building, not for hypothesis testing under an assumed model. Consequently, we will use only the Type III sums of squares.

The Type I and Type III sums of squares are identical when the sample sizes are equal, since the factorial effects are then estimated independently of one another. But when the sample sizes are

Figure 6.8: Some output for the SAS program for a two-way complete model with unequal sample sizes, using data from the reaction time experiment Table 4.4, p. 101, omitting the last 4 observations

unequal, as in the illustrated data set, the Type I and Type III sums of squares differ. In the absence of a sophisticated computer package, each Type I and Type III sum of squares can be calculated as the difference of the error sums of squares obtained from two analysis of variance tables, one for the full model and one for the reduced model.

#### Contrasts and Multiple Comparisons

In the first GLM procedure in Table 6.13, the two-way complete model is used, and the coefficient lists are entered for each factor separately, rather than for the treatment combinations. The first CONTRAST statement is used to test the hypothesis that the interaction contrast \((\alpha\beta)_{11}-(\alpha\beta)_{13}-(\alpha\beta)_{21}+(\alpha\beta)_{23}\) is negligible, and the second CONTRAST statement is used to test the hypothesis that \(\beta_{1}^{*}-\beta_{2}^{*}\) is negligible. These same contrasts are entered as coefficient lists for the treatment combinations in the second GLM procedure. In either case, the contrast sum of squares is as shown under Contrast SS in Fig. 6.8, and the \(p\)-value for the test is as shown under Pr > F.

The statement

LSMEANS A / PDIFF CL ALPHA = 0.01;

of the first GLM procedure causes generation of a 99% confidence interval for the main effect of \(A\) pairwise comparison, \(\alpha_{1}^{*}-\alpha_{2}^{*}\), comparing the effects of \(A\) averaged over the levels of \(B\), as well as an individual 99% confidence interval for each of the \(A\) means \(\mu+\alpha_{i}+\overline{\beta}.+(\overline{\alpha}\overline{\beta})_{i}\).

The statement

LSMEANS B / PDIFF = ALL CL ADJUST = TUKEY ALPHA = 0.01;

of the first GLM procedure causes generation of Tukey's simultaneous 99% confidence intervals, comparing pairwise the main effects of the three levels of \(B\), each averaged over the levels of \(A\). The option PDIFF = ALL requests \(p\)-values for all pairwise comparisons, the option CL asks for the comparisons to be displayed as confidence intervals, and the option ADJUST = TUKEY when coupled with PDIFF = ALL requests Tukey's method for the pairwise comparisons. The output for the reaction time experiment, shown in Fig. 6.9, includes not only the confidence intervals for pairwise comparisons, but also \(p\)-values for simultaneous hypothesis tests using the Tukey method. Also given are individual 99% confidence intervals for the \(B\) means \(\mu+\overline{\alpha}.+\beta_{j}+(\overline{\alpha}\overline{\beta})_{j}\). Because sample sizes are unequal, these least squares means are not simply the corresponding treatment sample means. If CL is omitted, then only the simultaneous tests and intervals for means are printed. The request TUKEY can be replaced by BON or SCHEFFE as appropriate.

In the second GLM procedure in Table 6.13, the cell-means model is used, with a treatment effect \(\tau_{ij}\) associated with each treatment combination \(ij\). The corresponding LSMEANS statements illustrate multiple comparisons of the effects \(\tau_{ij}\) of the six treatment combinations, the first LSMEANS statement generating Tukey's method for all pairwise comparisons, and the remaining LSMEANS statement generating Dunnett's method for comparing all treatments with a control. To generate Dunnett's method, the option PDIFF = ALL is replaced by the option PDIFF = CONTROL for two-sided confidence intervals, and by the option PDIFF = CONTROL or PDIFF = CONTROLU for upper or lower confidence bounds on the treatment-versus-control differences, as follows:

LSMEANS TC / PDIFF = CONTROL CL ADJUST = DUNNETT ALPHA = 0.01; LSMEANS TC / PDIFF = CONTROLCL ADJUST = DUNNETT ALPHA = 0.01; LSMEANS TC / PDIFF = CONTROLU CL ADJUST = DUNNETT ALPHA = 0.01;Figure 6.10 contains the output for the third set of simultaneous confidence intervals--namely, corresponding to the CONTROLU option. This set gives lower bounds for the treatment-minus-control comparisons, corresponding to upper-tailed inferences. The treatments are renumbered by SAS in numerical order. In our program, in Table 6.13, we have requested the treatment-versus-control contrasts be done for the treatment combinations 11, 12, 13, 21, 22, 23. SAS recodes these as 1-6, and treatment 1 (our treatment combination 11), as the lowest treatment combination, is taken as the control by default. One could specify treatment combination 23 as the control, for example, via the option \(\text{PDIFF}=\text{CONTROL}(\,\prime\,23\,\prime\,)\). We have shown only the simultaneous confidence intervals, but simultaneous tests are also given by SAS software.

We remind the reader that for unequal sample sizes, it has not yet been proved that the overall confidence levels achieved by the Tukey and Dunnett methods are at least as great as those stated, except in some special cases such as the one-way layout.

An alternative method of obtaining simultaneous confidence intervals for pairwise comparisons can be obtained from the output of the ESTIMATE statement for each contrast. The corresponding

Figure 6.9: LSMEANS output for a two-way complete model with unequal sample sizes (reaction time experiment)

confidence intervals are of the form

\[\texttt{Estimate}\pm w\left(\texttt{Std Error of Estimate}\right),\]

where \(w\) is the critical coefficient given in (6.4.18) for the complete model and in (6.5.39) for the main-effects model.

#### Plots

Residual plots for checking the error assumptions on the model are generated in the same way as shown in Chap. 5. If the two-way main-effects model (6.2.3) is used, the assumption of additivity should also be checked. For this purpose it is useful to plot the standardized residuals against the level of one factor, using the levels of the other factor for plotting labels (see, for example, Fig. 6.3, p. 144, for the temperature experiment). A plot of the standardized residuals \(z\) against the levels of factor \(A\) using the labels of factor \(B\) can be generated using the following SAS program lines:

 PROC SGPLOT;  SCATTER X = A Y = Z / GROUP = B;

An interaction plot can be obtained by adding the following statements to the end of the program in Table 6.13:

 PROC SORT DATA = RTIME; BY A B;  PROC MEANS DATA = RTIME NOPRINT MEAN VAR; BY A B;  VAR Y;  OUTPUT OUT = RTIME2 MEAN = AV_Y VAR = VAR_Y;  PROC PRINT;  VAR A B AV_Y VAR_Y;  PROC SGPLOT;  SERIES X = A Y = AV_Y / GROUP = B;

The PROC PRINT statement following PROC MEANS also gives the information about the variances that would be needed to check the rule of thumb that \(s_{\text{max}}^{2}/s_{\text{min}}^{2}\leq 3\).

Figure 6.10: Dunnett’s lower bound output for a two-way complete model with unequal sample sizes (reaction time experiment)

In order to check for equal error variances, the residuals or the observations may be plotted against the treatment combinations using the following SAS code:

PROC SGPLOT;  SCATTER X = TC Y = Z; *or Y = Y for observations; If the treatment combination codes were created as TC = 10*A + B, they will not be equally spaced along the axis, since the codes 11, 12, 13, 21, 22, 23 when regarded as 2-digit numbers are not equally spaced. A simple solution to this problem, as shown in Table 6.13, is to convert the variable TC from numeric to character via the statement

TC = PUT(10*A + B, 2.); A plot of the residuals or the observations against the character variable TC will show the character variable codes evenly spaced along the axis.

When there are not sufficient observations to be able to check equality of error variances for all the cells, the standardized residuals should be plotted against the levels of each factor. The rule of thumb may be checked for the levels of each factor by comparing the maximum and minimum variances of the (nonstandardized) residuals. This is done for factor \(A\) by the following lines after creation of RTIME data set as in Table 6.13.

 PROC GLM;  CLASS TC;  MODEL Y = TC;  OUTPUT OUT = RESIDS RESIDUAL = E;  PROC SORT DATA = RESIDS; BY A;  PROC MEANS DATA = RESIDS NOPRINT VAR; BY A;  VAR E;  OUTPUT OUT = RTIME2 VAR = VAR_E;  PROC PRINT;  VAR A VAR_E;

#### One Observation Per Cell

In order to split the interaction sum of squares into parts corresponding to negligible and nonnegligible orthogonal contrasts, we can enter the data in the usual manner and obtain the sums of squares for all of the contrasts via CONTRAST statements in the procedure PROC GLM. The analysis of variance table can then be constructed with the error sum of squares being the sum of the contrast sums of squares for the negligible contrasts. It is possible, however, to achieve this in a more direct way, as follows.

First, enter the contrast coefficients as part of the input data as shown in Table 6.14 for the air velocity experiment. In the air velocity experiment, factor \(A\) had \(a=3\) levels and factor \(B\) had \(b=6\) levels. The main-effect trend contrast coefficients are entered via the INPUT statement line by line directly from Table 6.1, p. 148, and the interaction trend contrast coefficients are obtained by multiplication following the INPUT statement. In the PROC GLM statement, the CLASS designation is omitted. If it were included, then Aln, for example, would be interpreted as one factor with three coded levels \(-1\), \(0\), \(1\), and Agd as a second factor with two coded levels \(1\), \(-2\), and so on. The model is fitted using those contrasts that have not been declared to be negligible. The error sum of squares will be based on the three omitted contrasts AlnBqn, AgdBqr, and AgdBqn, and the resulting analysis of variance table will be equivalent to that in Table 6.12, p. 176.

It is not necessary to input the levels of \(A\) and \(B\) separately as we have done in columns 2 and 3 of the data, but these would be needed if plots of the data were required.

### Using R Software

Table 6.15 contains a sample R program for analysis of the two-way complete model (6.2.2). For illustration, we use the data of the reaction time experiment shown in Table 4.4, p. 101, but with the last four observations missing, so that \(r_{11}=r_{21}=2\), \(r_{12}=r_{22}=r_{23}=3\), \(r_{13}=1\). The data file includes the levels of each of the two treatment factors \(A\) and \(B\), as well as the response, the order in which the observations were collected, and treatment factor levels 1-6. A more descriptive two-digit code for each treatment combination \(\tt{TC}\ =\ 10^{*}A\ +\ B\) is easily generated and added to the data set react.data, along with factor variables \(\tt{fTC}\), \(\tt{fA}\), and \(\tt{fB}\), by the statement

 react.data = within(react.data,  {TC = 10*A + B; fTC = factor(TC); fA = factor(A); fB = factor(B)})

\begin{table}
\begin{tabular}{c c c c c c c c c} DATA AIR; & & & & & & & & & \\ & & & & & & & & & \\ & & & & & & & & & \\ & & & & & & & & & \\ & & & & & & & & & \\ & & & & & & & & & \\ & & & & & & & & & \\ & & & & & & & & & \\ & & & & & & & & & \\ & & & & & & & & & \\ & & & & & & & & & \\ & & & & & & & & & \\ & & & & & & & & & \\ & & & & & & & & & \\ & & & & & & & & & \\ & & & & & & & & & \\ & & & & & & & & & \\ & & & & & & & & & \\ & & & & & & & & & \\ & & & & & & & & & \\ & & & & & & & & & \\ \end{tabular}
\end{table}
Table 6.14: Fitting a model in terms of contrasts (air velocity experiment)9.1.1 The \(\tt{R}\) program to illustrate aspects of analysis of a two-way complete model (reaction time experiment)

This way of coding the treatment combinations works well for all applications except for drawing plots with TC on one axis. Such a plot would not show codes 11, 12, and 21 as equally spaced. An alternative way of creating the treatment combinations axis for plots will be given in Sect. 6.9.3.

\begin{table}
\begin{tabular}{r r} \hline \hline react.data & = read.table(‘‘data/reaction.time.txt’’, header=T) \\ \multicolumn{2}{r}{react.data = head(react.data, 14) \# Keep first l4 observations} \\ \multicolumn{2}{r}{head(react.data, 3)} \\ \multicolumn{2}{r}{Order Trtmt A B Y} \\ \multicolumn{2}{r}{1 1 6 2 3 0.256} \\ \multicolumn{2}{r}{2 2 6 2 3 0.281} \\ \multicolumn{2}{r}{3 3 2 1 2 0.167} \\ \multicolumn{2}{r}{\# Create trtmt combo vbl TC and factors fTC, fA, and fB within data set} \\ \multicolumn{2}{r}{react.data = within(react.data,} \\ \multicolumn{2}{r}{\{TC = 10*A + B; fTC = factor(TC); fA = factor(A); fB = factor(B)\})} \\ \multicolumn{2}{r}{summary(react.data[,c(‘fA’’,‘fB’’,‘fTC’’,‘y’’)])} \\ \multicolumn{2}{r}{\# ANOVA options(contrasts = c(‘contr.sum’’, ‘contr.poly’’))} \\ \multicolumn{2}{r}{modelAB = aov(y~~fA + fB + fA:fB, data = react.data)} \\ \multicolumn{2}{r}{anova(modelAB) \# Type I ANOVA} \\ \multicolumn{2}{r}{drop1(modelAB,~~.test = ''F’’) \# Type III ANOVA} \\ \multicolumn{2}{r}{modelTC = aov(y~~fTC, data = react.data)} \\ \multicolumn{2}{r}{anova(modelTC) \# Model F-test} \\ \multicolumn{2}{r}{\# Contrasts: estimates, CIs, tests} \\ \multicolumn{2}{r}{library(lsmeans)} \\ \multicolumn{2}{r}{\# Main-effect-of-B contrast: B1-B2} \\ \multicolumn{2}{r}{lsmB = lsmeans(modelAB,~~fB)} \\ \multicolumn{2}{r}{summary(contrast(lsmB, list(B12=c( 1,-1, 0))), infer=c(T,T))} \\ \multicolumn{2}{r}{\# AB-interaction contrast: AB11-AB13-AB21+AB23} \\ \multicolumn{2}{r}{lsmAB = lsmeans(modelAB,~~fB:fA) \# Using *fB:fA’’ yields AB lex order} \\ \multicolumn{2}{r}{lsmAB \# Display to see order of AB combos for contrast coefficients} \\ \multicolumn{2}{r}{summary(contrast(lsmAB, list(AB=c( 1,0,-1,-1, 0, 1))), infer=c(T,T))} \\ \multicolumn{2}{r}{\# Multiple comparisons: B} \\ \multicolumn{2}{r}{confint(lsmB, level=0.99) \# lsmeans for B and 99\% CIs} \\ \multicolumn{2}{r}{\# Tukey’s method} \\ \multicolumn{2}{r}{summary(contrast(lsmB, method=‘pairwise’’, adjust=‘‘tukey’’),} \\ \multicolumn{2}{r}{infer=c(T,T), level=0.99)} \\ \multicolumn{2}{r}{\# Dunnett’s method} \\ \multicolumn{2}{r}{summary(contrast(lsmB, method=‘trt.vs.ctrl’’, adj=‘mvt’’, ref=l),} \\ \multicolumn{2}{r}{infer=c(T,T), level=0.99)} \\ \hline \hline \end{tabular}
\end{table}
Table 6.15: R program to illustrate aspects of analysis of a two-way complete model (reaction time experiment)* > # ANOVA > options(contrasts = c("contr.sum", "contr.poly")) > modelAB = aov(y ~ fA + fB + fA:fB, data = react.data) > anova(modelAB) # Type I ANOVA

 Analysis of Variance Table

 Response: y  Df Sum Sq Mean Sq F value Pr(>F)  fA 1 0.02102 0.02102 65.28 0.000041  fB 2 0.00033 0.00017 0.52 0.61  fA:fB 2 0.00018 0.00009 0.28 0.76  Residuals 8 0.00258 0.00032

 > drop1(modelAB, ~., test = "F") # Type III ANOVA

 Single term deletions

 Model:  y ~ fA + fB + fA:fB  Df Sum of Sq RSS AIC F value Pr(>F)  <none> 0.00258 -108.4  fA 1 0.01683 0.01940 -82.1 52.27 0.00009  fB 2 0.00046 0.00303 -110.1 0.71 0.52  fA:fB 2 0.00018 0.00276 -111.5 0.28 0.76

 > modelTC = aov(y ~ fTC, data = react.data)  > anova(modelTC) # Model F-test

 Analysis of Variance Table

 Response: y  Df Sum Sq Mean Sq F value Pr(>F)  fTC 5 0.02153 0.00431 13.4 0.001  Residuals 8 0.00258 0.00032

#### Analysis of Variance

Referring to the R program in Table 6.15, the block of code under the comment "ANOVA" generates the analysis of variance output as shown in Table 6.16. As in the one-way analysis of variance, the treatment factors must be factor variables to be modeled as qualitative variables. The statements

 modelAB = aov(y ~ fA + fB + fA:fB, data = react.data)  modelTC = aov(y ~ fTC, data = react.data)

fit the two-way complete model (6.2.2) and the cell-means model (6.2.1), respectively, saving the results as modelAB and modelTC. In the first model, the main effects may be listed in either order,

\begin{table}
\begin{tabular}{c c} \hline \hline \multicolumn{2}{c}{> \# ANOVA} \\ \multicolumn{2}{c}{> options(contrasts = c("contr.sum", "contr.poly"))} \\ \multicolumn{2}{c}{> modelAB = aov(y ~ fA + fB + fA:fB, data = react.data)} \\ \multicolumn{2}{c}{> anova(modelAB) \# Type I ANOVA} \\ \multicolumn{2}{c}{ Analysis of Variance Table} \\ \multicolumn{2}{c}{ Response: y} \\ \multicolumn{2}{c}{ Df Sum Sq Mean Sq F value Pr(>F)} \\ \multicolumn{2}{c}{ fA} & 1 0.02102 0.02102 65.28 0.000041 \\ \multicolumn{2}{c}{ fB} & 2 0.00033 0.00017 0.52 0.61 \\ \multicolumn{2}{c}{ fA:fB} & 2 0.00018 0.00009 0.28 0.76 \\ \multicolumn{2}{c}{ Residuals 8 0.00258 0.00032} \\ \hline \hline \end{tabular}
\end{table}
Table 6.16: Analysis of variance output for the R program for a two-way complete model with unequal sample sizes (reaction time experiment)

[MISSING_PAGE_EMPTY:8144]

in Table 6.15 generate information for the main effect of \(B\) contrast \(\beta_{1}^{*}-\beta_{2}^{*}\), comparing the effects of \(B\) averaged over the levels of \(A\), using the two-way complete model previously fit and saved as modelAB. The following statements generate analogous information for the interaction contrast \((\alpha\beta)_{11}-(\alpha\beta)_{13}-(\alpha\beta)_{21}+(\alpha\beta)_{23}\).

 lsmAB = lsmeans(modelAB, ~ fB:fA)  summary(contrast(lsmAB, list(AB=c(1,0,-1,-1,0,1))), infer=c(T,T)) Using fB:fA rather than fA:fB yields least squares means in the standard lexicographical order, as can be seen by displaying lsmAB, and the contrast coefficients must be in the corresponding order. These statements and their output are shown in Table 6.17.

Multiple comparisons procedures are also implemented using functions of the lsmeans package, as illustrated for levels of \(B\) by sample code at the bottom of Table 6.15. The statements

 lsmB = lsmeans(modelAB, ~ fB)  confint(lsmB, level = 0.99)

\begin{table}
\begin{tabular}{r r} \multicolumn{2}{l}{ \(>\) \# Main-effect-of-B contrast: B1-B2 \(>\) lsmB = lsmeans(modelAB, ~ fB)} \\ \multicolumn{2}{l}{ \(>\) summary(contrast(lsmB, list(B12=c(1,-1,0))), infer=c(T,T))} \\ \multicolumn{2}{l}{ \({\rm contrast}\) estimate SE df lower.CL upper.CL t.ratio p.value} \\ \multicolumn{2}{l}{ \({\rm B12}\) \(0.0085\) \(0.011582\) \(8\) \(-0.018207\) \(0.035207\) \(0.734\) \(0.4839\)} \\ \multicolumn{2}{l}{ \({\rm Results}\) are averaged over the levels of: fA} \\ \multicolumn{2}{l}{ Confidence level used: 0.95} \\ \multicolumn{2}{l}{ \(>\) \# AB-interaction contrast: AB11-AB13-AB21+AB23 \(>\) lsmAB = lsmeans(modelAB, ~ fB:fA) \# Using *fB:fA” yields AB lex order \(>\) lsmAB \# Display to see order of AB combos for contrast coefficients} \\ \multicolumn{2}{l}{ \({\rm fB}\) fA lsmean SE df lower.CL upper.CL} \\ \multicolumn{2}{l}{ \({\rm 1}\) \(1\) \(0.18700\) \(0.012687\) \(8\) \(0.15774\) \(0.21626\)} \\ \multicolumn{2}{l}{ \({\rm 2}\) \(1\) \(0.17867\) \(0.010359\) \(8\) \(0.15478\) \(0.20255\)} \\ \multicolumn{2}{l}{ \({\rm 3}\) \(1\) \(0.20200\) \(0.017942\) \(8\) \(0.16063\) \(0.24337\)} \\ \multicolumn{2}{l}{ \({\rm 1}\) \(2\) \(0.26800\) \(0.012687\) \(8\) \(0.23874\) \(0.29726\)} \\ \multicolumn{2}{l}{ \({\rm 2}\) \(2\) \(0.25933\) \(0.010359\) \(8\) \(0.23545\) \(0.28322\)} \\ \multicolumn{2}{l}{ \({\rm 3}\) \(2\) \(0.26500\) \(0.010359\) \(8\) \(0.24111\) \(0.28889\)} \\ \multicolumn{2}{l}{ Confidence level used: 0.95} \\ \multicolumn{2}{l}{ \(>\) summary(contrast(lsmAB, list(AB=c(1,0,-1,-1,0,1))), infer=c(T,T))} \\ \multicolumn{2}{l}{ \({\rm contrast}\) estimate SE df lower.CL upper.CL t.ratio p.value} \\ \multicolumn{2}{l}{ \({\rm AB}\) \(-0.018\) \(0.027407\) \(8\) \(-0.0812\) \(0.0452\) \(-0.657\) \(0.5298\)} \\ \multicolumn{2}{l}{ Confidence level used: 0.95} \\ \multicolumn{2}{l}{ \({\rm Confidence}\) \({\rm level}\) used: 0.95} \\ \end{tabular}
\end{table}
Table 6.17: Contrasts output for the R program for a two-way complete model with unequal sample sizes (reaction time experiment)in turn (i) compute least squares estimates of the means \(\mu+\beta_{j}+\overline{\alpha}.+(\overline{\alpha\beta})_{j}\) and related information, saving this information as lsmB; and (ii) display the least squares estimates, standard errors, degrees of freedom, and individual 99% confidence intervals shown at the top of Table 6.18. Because sample sizes are unequal, these least squares means are not simply the corresponding treatment sample means.

The statement

summary(contrast(lsmB, method = "pairwise", adjust = "tukey"),  infer = c(T, T), level = 0.99)

applies Tukey's method, comparing pairwise the main effects of the three levels of \(B\), each averaged over the levels of \(A\). The contrast function coupled with the options method="pairwise" and adjust="tukey" requests tests including \(p\)-values for all pairwise comparisons via Tukey's method. Other adjustment options for pairwise comparisons include "Scheffe" for Scheffe's method, "Bonf" for the Bonferroni method, and "none" for individual inferences. The summary function with its infer=c(T,T) and level=0.99 options requests Tukey's 99% confidence intervals. Specifically, the option infer=c(T,T) indicates "true" for confidence intervals and tests, respectively. The above statement and the corresponding output are shown in the bottom of Table 6.18.

Implementation of Dunnett's method for all treatment-versus-control comparisons is similar and illustrated by the following statement

summary(contrast(lsmB, method="trt.vs.ctrl", adj="mvt", ref=l),  infer=c(T,T), level=0.99)

\begin{table}
\begin{tabular}{r r} \multicolumn{2}{l}{ \(>\) \# Multiple comparisons: B} \\ \multicolumn{2}{l}{ \(>\) confint(lsmB, level=0.99) \# lmeans for B and 99\% CIs} \\ \multicolumn{2}{l}{ fB lsmean SE df lower.CL upper.CL} \\ \multicolumn{2}{l}{ \(1\) 0.2275 0.0089710 8 0.19740 0.25760} \\ \multicolumn{2}{l}{ \(2\) 0.2190 0.0073248 8 0.19442 0.24358} \\ \multicolumn{2}{l}{ \(3\) 0.2335 0.0103588 8 0.19874 0.26826} \\ \end{tabular}
\end{table}
Table 6.18: Multiple comparisons output for a two-way complete model with unequal sample sizes (reaction time experiment)from the bottom of Table 6.15. The option method="trt.vs.ctrl" yields all treatment-versus-control comparisons. Here, other levels of \(B\) are compared to the first level, which happens to be "1", averaging over levels of \(A\). Available options include the following, as discussed in Sect. 4.7.2. Dunnett's method uses (simulation based) critical values from the multivariate \(t\)-distribution, corresponding to adjust="mvt", but the default option adjust="dunnettx" provides an approximation of Dunnett's method for two-sided confidence intervals that runs faster and dependably (but is appropriate only applicable when the contrast estimates have pairwise correlations of 0.5). The first level of a factor is the control by default, corresponding to reference level 1 (ref=1), but one could, for example, specify the second level as the control by the syntax ref=2. Also, "two-sided" is the default for confidence intervals and tests, but one can specify side="<" for the one-sided alternative \(H_{A}:\tau_{i}<\tau_{1}\) and the corresponding upper confidence bound for \(\tau_{i}-\tau_{1}\), or side=">" for the alternative \(H_{A}:\tau_{i}>\tau_{1}\) and the corresponding lower confidence bound for \(\tau_{i}-\tau_{1}\).

Multiple comparisons of all treatments may be obtained using the cell-means model, as illustrated for Dunnett's method by the following code, reproduced with corresponding output in Table 6.19.

 lsmTC = lsameans(modelTC, - fTC)  summary(contrast(lsmTC, method="trt.vs.ctrl", adj="mvt"),  infer=c(T,T), level=0.99, side=">") The same could be accomplished using lsmAB instead of lsmTC. Note that the default control here is "11", which is the first level of fTC.

We remind the reader that for unequal sample sizes, it has not yet been proved that the overall confidence levels achieved by the Tukey and Dunnett methods are at least as great as those stated, except in some special cases such as the one-way layout.

#### Plots

Residual plots for checking the error assumptions on the model are generated in the same way as shown in Chap. 5. If the two-way main-effects model (6.2.3) is used, the assumption of additivity should also be checked. For this purpose it is useful to plot the standardized residuals against the level of one factor, using the levels of the other factor for plotting labels (see, for example, Fig. 6.3, p. 144, for the temperature experiment). A plot of the standardized residuals \(z\) against the levels of factor \(A\) using the labels of factor \(B\) can be generated using the following R program lines:

 plot(z ~ A, data=react.data, xaxt="n", type="n") # Suppress x-axis, pts  axis(1, at=seq(1,2,1)) # Add x-axis with tick marks from 1 to 2 by 1  text(z ~ A, B, cex=0.75, data=react.data) # Plot z vs A using B label  mtext("B=1,2,3", side=3, adj=1, line=1) # Margin text, top-rt, line 1  abline(h=0) # Horizontal line at zero

An interaction plot of treatment means \(\tilde{y}_{ij}\). versus levels of factor \(A\) using the labels of factor \(B\) can be generated by adding the following statement to the end of the program in Table 6.15.

 interaction.plot(x.factor = react.data$fA, trace.factor = react.data$fB,  response = react.data$y, type ="b",  xlab ="A", trace.label ="B", ylab ="Mean of y")

The option type="b" plots both points and lines.

In order to check for equal error variances, the residuals or observations could be plotted against the treatment combinations using the following R code:

 plot(modelAB$res ~ react.data$TC, xlab ="AB", ylab ="Residual")  plot(react.data$y ~ react.data$TC, xlab ="AB", ylab ="y")

However, since the treatment combination codes TC = 10*A + B are numeric as originally created in Table 6.13, they will not be equally spaced along the axis, since the codes 11, 12, 13, 21, 22, 23 when regarded as 2-digit numbers are not equally spaced. One solution to this problem is to plot the residuals or the observations against the treatment variable Trtmt, since its levels 1-6 are equally spaced, but replace each of the labels 1-6 with the corresponding treatment combination label. This is accomplished by the following code.

 plot(modelAB$res ~ react.data$Trtm, xaxt="n", xlab="AB", ylab="Residual")  axis(1, at = react.data$Trtm, labels = react.data$fTC)  plot(react.data$y ~ react.data$Trtm, xaxt="n", xlab="AB", ylab="y")  axis(1, at = react.data$Trtm, labels = react.data$fTC)

In the first plot statement, for example, the residuals are plotted against Trtmt, which has equally spaced levels 1-6, but the \(x\)-axis is suppressed by the option xaxt="n". The axis statement is then used to create an \(x\)-axis, still with tick marks at the equally-spaced Trtmt levels 1-6, but using the treatment combination labels 11, 12,..., 23 of fTC.

When there are not sufficient observations to be able to check equality of error variances for all the cells, the standardized residuals should be plotted against the levels of each factor. The rule of thumb may be checked for the levels of each factor by comparing the maximum and minimum variances of the (nonstandardized) residuals. The sample variance of the residuals may be computed by level of \(A\), for example, by augmenting the statements in Table 6.15 with the following by command.

 by(modelAB$res, react.data$A, var)

[MISSING_PAGE_FAIL:214]

three omitted contrasts \(\mathtt{Aln}\!:\!\mathtt{Bqn}\), \(\mathtt{Agd}\!:\!\mathtt{Bqr}\), and \(\mathtt{Agd}\!:\!\mathtt{Bqn}\), and the resulting analysis of variance table generated by the anova(modell) statement will be equivalent to that in Table 6.12, p. 176.

It is not necessary to input the levels of \(A\,\text{and}\,B\) separately as we have done in columns 2 and 3 of the data, but these would be needed if plots of the data were required.

## Exercises

1. Under what circumstances should the two-way main effects model (6.2.3) be used rather than the two-way complete model (6.2.2)? Discuss the interpretation of main effects in each model.
2. Verify that (\(\tau_{ij}-\overline{\tau}_{i.}-\overline{\tau}_{j}+\overline{\tau}_{..}\)) is an interaction contrast for the two-way complete model. Write down the list of contrast coefficients in terms of the \(\tau_{ij}\)'s when factor \(A\) has \(a=3\) levels and factor \(B\) has \(b=4\) levels.
3. Consider the functions \(\{\alpha_{1}^{*}-\alpha_{2}^{*}\}\) and \(\{(\alpha\beta)_{11}-(\alpha\beta)_{21}-(\alpha\beta)_{12}+(\alpha\beta)_{22}\}\) under the two-way complete model (6.2.2). 1. Verify that the functions are estimable contrasts. 2. Discuss the meaning of each of these contrasts for plot (d) of Fig. 6.1, p. 140, and for plot (g) of Fig. 6.2, p. 141. 3. If \(a=b=3\), give the list of contrast coefficients for each contrast, first for the parameters involved in the contrast, and then in terms of the parameters \(\tau_{ij}\) of the equivalent cell-means model.

\begin{table}
\begin{tabular}{l c c c c c c c c c c} \hline \(A\) & 2 & 1 & 1 & 1 & 2 & 2 & 1 & 2 & 1 & 2 & 1 \\ \(B\) & 2 & 1 & 3 & 1 & 2 & 3 & 3 & 2 & 2 & 2 & 1 \\ Rate & 31 & 27 & 37 & 28 & 32 & 32 & 35 & 30 & 32 & 31 & 27 \\ \hline \(A\) & 2 & 1 & 1 & 1 & 2 & 1 & 1 & 2 & 2 & 2 & 2 \\ \(B\) & 2 & 3 & 3 & 2 & 1 & 1 & 3 & 1 & 3 & 3 & 3 \\ Rate & 34 & 33 & 34 & 31 & 26 & 25 & 35 & 24 & 33 & 31 & 36 \\ \hline \(A\) & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 2 & 1 & 2 \\ \(B\) & 3 & 1 & 1 & 2 & 1 & 2 & 2 & 3 & 3 & 2 & 1 \\ Rate & 36 & 27 & 30 & 33 & 29 & 32 & 34 & 37 & 32 & 34 & 27 \\ \hline \(A\) & 2 & 1 & 1 & 2 & 2 & 1 & 1 & 2 & 2 & 1 & 2 \\ \(B\) & 2 & 1 & 3 & 1 & 2 & 1 & 2 & 1 & 2 & 1 & 3 \\ Rate & 31 & 27 & 38 & 27 & 30 & 29 & 34 & 25 & 34 & 28 & 34 \\ \hline \(A\) & 2 & 1 & 2 & 1 & 1 & 2 & 1 & 1 & 2 & 2 & 2 \\ \(B\) & 2 & 1 & 3 & 2 & 2 & 1 & 3 & 2 & 1 & 1 & 1 \\ Rate & 31 & 30 & 34 & 35 & 34 & 24 & 35 & 31 & 27 & 26 & 25 \\ \hline \(A\) & 2 & 2 & 2 & 1 & 2 & 2 & 2 & 2 & 2 & 1 & 1 \\ \(B\) & 2 & 3 & 1 & 2 & 1 & 2 & 3 & 3 & 3 & 3 & 3 \\ Rate & 32 & 35 & 24 & 33 & 23 & 30 & 34 & 32 & 33 & 37 & 38 \\ \hline \end{tabular}
\end{table}
Table 6.21: Data (beats per 15 seconds) for the weight lifting experiment 4. Show that when the parentheses is expanded in formula (6.4.15) for ssE on p. 151, the computational formula (6.4.16) is obtained.
5. **Weight Lifting Experiment** (Gary Mirka 1986) The experimenter was interested in the effect on pulse rate (heart rate) of lifting different weights with legs either straight or bent (factor \(A\), coded 1, 2). The selected weights were 50 lb, 75 lb, 100 lb (factor \(B\), coded 1, 2, 3). He expected to see a higher pulse rate when heavier weights were lifted. He also expected that lifting with legs bent would result in a higher pulse rate than lifting with legs straight. 1. Write out a detailed checklist for running an experiment similar to this. In the calculation of the number of observations needed, either run your own pilot experiment or use the information that for a single subject in the above study, the error sum of squares was ssE = 130.909 bpfs2 based on df = 60 error degrees of freedom (where bpfs is beats per 15 seconds). 3. The data collected for a single subject by the above experimenter are shown in Table 6.21 in the order collected. The experimenter wanted to use a two-way complete model. Check the assumptions on this model, paying particular attention to the facts that (i) these are count data and may not be approximately normally distributed, and (ii) the measurements were made in groups of ten at a time in order to reduce the fatigue of the subject. 4. Taking account of your answer to part (a), analyze the experiment, especially noting any trends in the response.
6. **Battery experiment, continued** Consider the battery experiment introduced in Sect. 2.5.2, p. 24, for which \(a=b=2\) and \(r=4\). Suppose it is of interest to calculate confidence intervals for the four simple effects \(\tau_{11}-\tau_{12}\), \(\tau_{21}-\tau_{22}\), \(\tau_{11}-\tau_{21}\), \(\tau_{12}-\tau_{22}\), with an overall confidence level of 95%. 1. Determine whether the Tukey or Bonferroni method of multiple comparisons would provide shorter confidence intervals. 2. Apply the better method from part (a) and comment on the results. (The data give \(\overline{y}_{11.}=570.75\), \(\overline{y}_{12.}=860.50\), \(\overline{y}_{21.}=433.00\), and \(\overline{y}_{22.}=496.25\) minutes per unit cost and msE = 2, 367.71.) 3. Discuss the practical meaning of the contrasts estimated in (b) and explain what you have learned from the confidence intervals.
7. **Weld strength experiment** The data shown in Table 6.22 are a subset of the data given by Anderson and McLean (1974) and show the strength of a weld in a steel bar. Two factors of interest were gage bar setting (the distance the weld die travels during the automatic weld cycle) and time of welding (total time of the automatic weld cycle). Assume that the levels of both factors were selected to be equally spaced. 1. Using the cell-means model (6.2.1) for these data, test the hypothesis that there is no difference in the effects of the treatment combinations on weld strength against the alternative hypothesis that at least two treatment combinations have different effects. 2. Suppose the experimenters had planned to calculate confidence intervals for all pairwise comparisons between the treatment combinations, and also to look at the confidence interval for the difference between gage bar setting 3 and the average of the other two. Write down the contrastsin terms of the parameters \(\tau_{\mathit{ij}}\) of the cell-means model, and suggest a strategy for calculating all intervals at overall level "at least 98%."
3. Consider the intervals in part (b). Give the formulae and calculate the actual interval for \(\tau_{13}-\tau_{15}\) (the difference in the true mean strengths at the 3rd and 5th times of welding for the first gage bar setting), and explain what this interval tells you. Also calculate the actual interval for the difference between gage bar setting 3 and the average of the other two, and explain what this interval tells you.
4. Calculate an upper 90% confidence limit for \(\sigma^{2}\).
5. If the experimenters were to repeat this experiment and needed the pairwise comparison intervals in (b) to be of width at most 8, how many observations should they take on each treatment combination? How many observations is this in total?
8. **Weld strength experiment, continued** For the experiment described in Exercise 7, use the two-way complete model instead of the equivalent cell means model. 1. Test the hypothesis of no interaction between gage bar setting and time of weld and state your conclusion. 2. Draw an interaction plot for the two factors Gage bar setting and Time of welding. Does your interaction plot support the conclusion of your hypothesis test? Explain. 3. In view of your answer to part (b), is it sensible to investigate the differences between the effects of gage bar setting? Why or why not? Indicate on your plot what would be compared. 4. Regardless of your answer to (c), suppose the experimenters had decided to look at the linear trend in the effect of gage bar settings. Test the hypothesis that the linear trend in gage setting is negligible (against the alternative hypothesis that it is not negligible).
9. **Sample size calculation** An experiment is to be run to examine three levels of factor \(A\) and four levels of factor \(B\), using the two-way complete model (6.2.2). Determine the required sample size if the error variance \(\sigma^{2}\) is expected to be less than 15 and simultaneous 99% confidence intervals for pairwise comparisons between treatment combinations should have length at most 10 to be useful.
10. **Bleach experiment, continued** Use the data of the bleach experiment of Example 6.4.4, on p. 154. 1. Evaluate the effectiveness of a variance-equalizing transformation. 2. Apply Satterthwaite's approximation to obtain 99% confidence intervals for the pairwise comparisons of the main effects of factor \(A\) using Tukey's method of multiple comparisons.

\begin{table}
\begin{tabular}{c c c c c c c}  & & \multicolumn{6}{c}{Time of welding (\(j\))} \\  & \(i\) & 1 & 2 & 3 & 4 & 5 \\ Gage & 1 & 10, 12 & 13, 17 & 21, 30 & 18, 16 & 17, 21 \\ bar & 2 & 15, 19 & 14, 12 & 30, 38 & 15, 11 & 14, 12 \\ setting & 3 & 10, 8 & 12, 9 & 10, 5 & 14, 15 & 19, 11 \\ \end{tabular}
\end{table}
Table 6.22: Strength of weld 11. **Bleach experiment, continued** The experimenter calculated that she needed \(r=5\) observations per treatment combination in order to be able to detect a difference in the effect of the levels of either treatment factor of 5 minutes (300 seconds) with probability 0.9 at significance level 0.05. Verify that her calculations were correct. She obtained a mean squared error of 43220.8 in her pilot experiment.
12. **Memory experiment** (James Bost 1987) The memory experiment was planned in order to examine the effects of external distractions on short-term memory and also to examine whether some types of words were easier to memorize than others. Consequently, the experiment involved two treatment factors, "word type" and "type of distraction." The experimenter selected three levels for each factor. The levels of "word type" were Level 1 (fruit): words representing fruits and vegetables commonly consumed; Level 2 (nouns): words selected at random from Webster's pocket dictionary, representing tangible (i.e., visualizable) items; Level 3 (mixed): words of any description selected at random from Webster's pocket dictionary. A list of 30 words was prepared for each level of the treatment factor, and the list was not altered throughout the experiment. The levels of "type of distraction" were Level 1 : No distraction other than usual background noise; Level 2 : Constant distraction, supplied by a regular hanging of a metal spoon on a metal pan; Level 3 : Changing distraction, which included vocal, music, banging and motor noise, and varying lighting. The response variable was the number of words remembered (by a randomly selected subject) for a given treatment combination. The response variable is likely to have approximately a binomial distribution, with variance \(30_{p}(1-p)\) where \(p\) is the probability that a subject remembers a given word and 30 is the number of words on the list. It is unlikely that \(p\) is constant for all treatment combinations or for all subjects. However, since \(np(1-p)\) is less than \(30(0.5)(0.5)=7.5\), a reasonable guess for the variance \(\sigma^{2}\) is that it is less than 7.5. The experimenter wanted to reject each of the main-effect hypotheses \(H_{0}^{A}\):{the memorization rate for the three word lists is the same} and \(H_{0}^{B}\):{the three types of distraction have the same effect on memorization} with probability 0.9 if there was a difference of four words in memorization rates between any two word lists or any two distractions (that is \(\Delta_{A}=\Delta_{B}=4\)), using a significance level of \(\alpha=0.05\). Calculate the number of subjects that are needed if each subject is to be assigned to just one treatment combination and measured just once.
13. **Memory experiment, continued** 1. Write out a checklist for the memory experiment of Exercise 12. Discuss how you would obtain the subjects and how applicable the experiment would be to the general population. 2. Consider the possibility of using each subject more than once (i.e., consider the use of a blocking factor). Discuss whether or not an assumption of independent observations is likely to be valid.
14. **Memory experiment, continued** The data for the memory experiment of Exercise 12 are shown in Table 6.23 with three observations per treatment combination.

* The experimenter intended to use the two-way complete model. Check the assumptions on the model for the given data, especially the equal-variance assumption.
* Analyze the experiment. A transformation of the data or use of the Satterthwaite approximation may be necessary.

15. **Ink experiment** Teaching associates who give classes in computer labs at the Ohio State University are required to write on white boards with "dry markers" rather than on chalk boards with chalk. The ink from these dry markers can stain rather badly, and an experiment was planned by M. Chambers, Y.-W. Chen, E. Kurali and R. Vengurlekar in 1996 to determine which type of cloth (factor \(A\), 1 = cotton/polyester, 2 = rayon, 3 = polyester) was most difficult to clean, and whether a detergent plus stain remover was better than a detergent without stain remover (factor \(B\), levels 1, 2) for washing out such a stain. Pieces of cloth were to be stained with 0.1 ml of dry marker ink and allowed to air dry for 24 hours. The cloth pieces were then to be washed in a random order in the detergent to which they were allocated. The stain remaining on a piece of cloth after washing and drying was to be compared with a 19 point scale and scored accordingly, where 1 = black and 19 = white. 1. Make a list of the difficulties that might be encountered in running and analyzing an experiment of this type. Give suggestions on how these difficulties might be overcome or their effects reduced. 2. Why should each piece of cloth be washed separately? (Hint: think about the error variability.) 3. The results of a small pilot study run by the four experimenters are shown in Table 6.24. Plot the data against the levels of the two treatment factors. Can you learn anything from this plot? Which model would you select for the main experiment? Why? 4. Calculate the number of observations that you would need to take on each treatment combination in order to try to ensure that the lengths of confidence intervals for pairwise differences in the effects of the levels of each of the factors were no more than 2 points (on the 19-point scale).

\begin{table}
\begin{tabular}{c c c c c c c c c c c c} \hline \multirow{2}{*}{Cloth type} & 3 & 1 & 3 & 1 & 2 & 1 & 2 & 2 & 2 & 3 & 3 & 1 \\  & 2 & 2 & 2 & 2 & 1 & 1 & 1 & 2 & 2 & 1 & 1 & 1 \\ Stain score & 1 & 6 & 1 & 5 & 11 & 9 & 9 & 8 & 6 & 3 & 4 & 8 \\ \hline \end{tabular}
\end{table}
Table 6.24: Data for the ink experiment in the order of collection

\begin{table}
\begin{tabular}{c r r r r r r r r r r} \hline \multirow{2}{*}{Word list} & \multicolumn{6}{c}{Distraction} \\ \cline{2-11}  & \multicolumn{3}{c}{None} & \multicolumn{3}{c}{Constant} & \multicolumn{3}{c}{Changing} \\ \hline Fruit & 20 & 14 & 24 & 15 & 22 & 17 & 17 & 13 & 12 \\  & 0.27 & \(-\)2.16 & 1.89 & \(-\)1.21 & 1.62 & \(-\)0.40 & 1.21 & \(-\)0.40 & \(-\)0.81 \\ Nouns & 19 & 14 & 19 & 12 & 11 & 14 & 12 & 15 & 8 \\  & 0.67 & \(-\)1.35 & 0.67 & \(-\)0.13 & \(-\)0.54 & 0.67 & 0.13 & 1.35 & \(-\)1.48 \\ Mixed & 11 & 12 & 15 & 8 & 8 & 9 & 12 & 7 & 10 \\  & \(-\)0.67 & \(-\)0.27 & 0.94 & \(-\)0.13 & \(-\)0.13 & 0.27 & 0.94 & \(-\)1.08 & 0.13 \\ \hline \end{tabular}
\end{table}
Table 6.23: Data and standardized residuals for the memory experiment 16. **Survival experiment** (G.E.P. Box and D.R. Cox, 1964) The data in Table 6.25 show survival times of animals to whom a poison and a treatment have been administered. The data were presented by G. E. P. Box and D. R. Cox in an article in the _Journal of the Royal Statistical Society_ in 1964. There were three poisons (factor \(A\) at \(a=3\) levels), four treatments (factor \(B\) at \(b=4\) levels), and \(r=4\) animals (experimental units) assigned at random to each treatment combination. 1. Check the assumptions on a two-way complete model for these data. If the assumptions are satisfied, then analyze the data and discuss your conclusions. 2. Take a reciprocal transformation (\(y^{-1}\)) of the data. The transformed data values then represent "rates of dying." Check the assumptions on the model again. If the assumptions are satisfied, then analyze the data and discuss your conclusions. 3. Draw an interaction plot for both the original and the transformed data. Discuss the interaction between the two factors in each of the measurement scales.
17. Use the two-way main-effects model (6.2.3) with \(a=b=3\). 1. Which of the following are estimable? 1. \(\mu+\alpha_{1}+\beta_{2}\). 2. \(\mu+\alpha_{1}+\frac{1}{2}(\beta_{1}+\beta_{2})\). 3. \(\beta_{1}-\frac{1}{3}(\beta_{2}+\beta_{3})\). 2. Show that \(\overline{Y}_{i\ldots}+\overline{Y}_{j\ldots}-\overline{Y}_{\ldots}\) is an unbiased estimator of \(\mu+\alpha_{i}+\beta_{j}\) with variance, \(\sigma^{2}(a+b-1)/(abr)\). 3. Show that \(\sum_{i}c_{i}\overline{Y}_{i\ldots}\) is an unbiased estimator of the contrast \(\sum_{i}c_{i}\alpha_{i}\).
18. **Meat cooking experiment, continued** The meat cooking experiment was introduced in Exercise 14 of Chap. 3, with the data given in Table 3.14, p. 68.

\begin{table}
\begin{tabular}{c c c c c} \hline  & & Treatment & & \\ \cline{2-5}  & Poison & 1 & 2 & 3 & 4 \\ \hline I & 0.31 & 0.82 & 0.43 & 0.45 \\  & 0.45 & 1.10 & 0.45 & 0.71 \\  & 0.46 & 0.88 & 0.63 & 0.66 \\  & 0.43 & 0.72 & 0.76 & 0.62 \\ II & 0.36 & 0.92 & 0.44 & 0.56 \\  & 0.29 & 0.61 & 0.35 & 1.02 \\  & 0.40 & 0.49 & 0.31 & 0.71 \\  & 0.23 & 1.24 & 0.40 & 0.38 \\ III & 0.22 & 0.30 & 0.23 & 0.30 \\  & 0.21 & 0.37 & 0.25 & 0.36 \\  & 0.18 & 0.38 & 0.24 & 0.31 \\  & 0.23 & 0.29 & 0.22 & 0.33 \\ \hline \end{tabular} _Source_ Box and Cox (1964). Copyright 1964 Blackwell Publishers. Reprinted with permission

\end{table}
Table 6.25: Data for the survival experiment (units of 10 hours)1. Using the two-way complete model, conduct an analysis of variance, testing each hypothesis using a 1% significance level. State your conclusions.
2. Draw an interaction plot for the two treatment factors. Does your interaction plot support the conclusion of your hypothesis test concerning interactions? Explain.
3. Compare the effects of the three levels of fat content pairwise, averaging over cooking methods, using Scheffe's method for all treatment contrasts with a 95% confidence level. Interpret the results.
4. Give a confidence interval for the average difference in weight after cooking between frying and grilling 110 g hamburgers, using Scheffe's method for all treatment contrasts with a 95% confidence level. Interpret the results.
5. Obtain a 95% confidence interval for comparing the effect on post-cooked weight of the low fat content versus the average of the two higher fat contents (averaged over cooking method), using Scheffe's method.
6. What is the overall confidence level of the intervals in parts (c), (d) and (e) taken together?
7. If the contrast in part (e) had been the _only_ contrast of interest, would your answer to part (e) have been different? If so, show the new calculation. If not, explain why not.
19. For the two-way main-effects model (6.2.3) with equal sample sizes, 1. verify the computational formulae for ssE given in (6.5.38), 2. and, if _SSE_ is the corresponding random variable, show that \(E[\text{SSE}]\)is (\(n-a-b+1\))\(\sigma^{2}\). [Hint: \(\text{E}[X^{2}]=\text{Var}(X)+\text{E}[X]^{2}\).]
20. An experiment is to be run to compare the two levels of factor \(A\) and to examine the pairwise differences between the four levels of factor \(B\), with a simultaneous confidence level of 90%. The experimenter is confident that the two factors will not interact. Find the required sample size if the error variance will be at most 25 and the confidence intervals should have length at most 10 to be useful.

\begin{table}
\begin{tabular}{c c c c c} \hline  & \multicolumn{4}{c}{Salt (teaspoons)} \\ \cline{2-5} Burner & 0 & 2 & 4 & 6 \\ \hline Right back & 7(7) & 4(13) & 7(24) & 5(15) \\  & 8(21) & 7(25) & 7(34) & 7(33) \\  & 7(30) & 7(26) & 7(41) & 7(37) \\ Right front & 4(6) & 4(36) & 4(1) & 4(28) \\  & 4(20) & 5(44) & 4(14) & 4(31) \\  & 4(27) & 4(45) & 5(18) & 4(38) \\ Left back & 6(9) & 6(46) & 7(8) & 5(35) \\  & 7(16) & 6(47) & 6(12) & 6(39) \\  & 6(22) & 5(48) & 7(43) & 6(40) \\ Left front & 9(29) & 8(5) & 8(3) & 8(2) \\  & 9(32) & 8(10) & 9(19) & 8(4) \\  & 9(42) & 8(11) & 10(23) & 7(17) \\ \hline \end{tabular}
\end{table}
Table 6.26: Data for the water boiling experiment, in minutes. (Order of observation is in parentheses.)21. **Water boiling experiment** (Kate Ellis 1986) The experiment was run in order to examine the amount of time taken to boil a given amount of water on the four different burners of her stove, and with 0, 2, 4, or 6 teaspoons of salt added to the water. Thus the experiment had two treatment factors with four levels each. The experimenter ran the experiment as a completely randomized design by taking \(r=3\) observations on each of the 16 treatment combinations in a random order. The data are shown in Table 6.26. The experimenter believed that there would be no interaction between the two factors. 1. Check the assumptions on the two-way main-effects model. 2. Calculate a 99% set of Tukey confidence intervals for pairwise differences between the levels of salt, and calculate separately a 99% set of intervals for pairwise differences between the levels of burner. 3. Test a hypothesis that there is no linear trend in the time to boil water due to the level of salt. Do a similar test for a quadratic trend. 4. The experimenter believed that observation number 13 was an outlier, since it has a large standardized residual and it was an observation taken late on a Friday evening. Using statistical software, repeat the analysis in (b) removing this observation. (Tukey's method is approximate for nearly balanced data.) Also repeat the test in part (c) but for the linear contrast only. (The formula for the linear contrast coefficients is given in (4.2.4) on p. 73.) Do you prefer the analysis that uses all the data, or that which removes observation 13? Explain your choice.
22. For \(v=5\) and \(r=4\), show that the first three "orthogonal polynomial contrasts" listed in Table 2 are mutually orthogonal. (In fact all four are.) Find a pair of orthogonal contrasts that are not orthogonal polynomial contrasts. Can you find a third contrast that is orthogonal to each of these? How about a fourth? (This gets progressively harder!)
23. **Air velocity experiment, continued** 1. For the air velocity experiment introduced in Sect. 6.7.4 (p. 176), calculate the sum of squares for each of the three interaction contrasts assumed to be negligible, and verify that these add to the value \(s\)s\(E=175.739\), as in Table 6.12. 2. Check the assumptions on the model by plotting the standardized residuals against the predicted responses, the treatment factor levels, and the normal scores. State your conclusions.

### 7.1 Introduction

Experiments that involve more than two treatment factors are designed and analyzed using many of the same principles that were discussed in Chap. 6 for two-factor experiments. We continue to label the factors with uppercase Latin letters and their numbers of levels with the corresponding lowercase letters. An experiment that involves four factors, \(A\), \(B\), \(C\), and \(D\), having \(a\), \(b\), \(c\), and \(d\) levels, respectively, for example, is known as an "\(a\times b\times c\times d\)_factorial experiment_" (read "\(a\) by \(b\) by \(c\) by \(d\)") and has a total of \(v=abcd\) treatment combinations.

There are several different models that may be appropriate for analyzing a factorial experiment with several treatment factors, depending on which interactions are believed to be negligible. These models, together with definitions of interaction between three or more factors, and estimation of contrasts, form the topic of Sect. 7.2. General rules are given in Sect. 7.3 for writing down confidence intervals and hypothesis tests when there are equal numbers of observations on all treatment combinations. In Sect. 7.5, methods are investigated for analyzing small experiments where there is only one observation per treatment combination. Finally, SAS and R commands for analyzing experiments with several treatment factors are given in Sects. 7.6 and 7.7, respectively, and can be used for unequal sample sizes. Problems caused by empty cells are also investigated.

### 7.2 Models and Factorial Effects

#### Models

One of a number of different models may be appropriate for describing the data from an experiment with several treatment factors. The selection of a suitable model prior to the experiment depends upon available knowledge about which factors do and do not interact. We take as an example an experiment with three factors. Our first option is to use the _cell-means model_, which is similar to the one-way analysis of variance model (3.3.1), p. 33. For example, the cell-means model for three treatment factors is

\[\begin{array}{l}Y_{ijkt}=\mu+\tau_{ijk}+\epsilon_{ijkt}\,,\\ \epsilon_{ijkt}\sim N(0,\sigma^{2})\,,\\ \epsilon_{ijkt}\text{'s mutually independent}\,,\\ t=1,\ldots,r_{ijk};\;\;i=1,\ldots,a;\;\;j=1,\ldots,b;\;\;k=1,\ldots,c\,.\end{array} \tag{7.2.1}\]If there are more than three factors, the cell-means model has correspondingly more subscripts. As in Chap. 6, use of this model allows all of the formulae presented in Chaps. 3 and 4 for one treatment factor to be used to compare the effects of the treatment combinations.

Alternatively, we can model the effect on the response of treatment combination \(ijk\) to be

\[\tau_{ijk}=\alpha_{i}+\beta_{j}+\gamma_{k}+(\alpha\beta)_{ij}+(\alpha\gamma)_{ ik}+(\beta\gamma)_{jk}+(\alpha\beta\gamma)_{ijk}\,,\]

where \(\alpha_{i}\), \(\beta_{j}\), \(\gamma_{k}\) are the effects (positive or negative) on the response of factors \(A\), \(B\), \(C\) at levels \(i\), \(j\), \(k\), respectively, (\(\alpha\beta\))\({}_{ij}\), (\(\alpha\gamma\))\({}_{ik}\), and (\(\beta\gamma\))\({}_{jk}\) are the additional effects of the pairs of factors together at the specified levels, and (\(\alpha\beta\gamma\))\({}_{ijk}\) is the additional effect of all three factors together at levels \(i\), \(j\), \(k\). The three sets of factorial effects are called the main-effect parameters, the two-factor interaction parameters, and the three-factor interaction parameter, respectively. The interpretation of a three-factor interaction is discussed in the next section. If we replace \(\tau_{ijk}\) in model (7.2.1) by the main-effect and interaction parameters, we obtain the equivalent _three-way complete model_; that is,

\[\begin{array}{c}Y_{ijkt}=\mu+\alpha_{i}+\beta_{j}+\gamma_{k}+(\alpha\beta)_ {ij}+(\alpha\gamma)_{ik}+(\beta\gamma)_{jk}+(\alpha\beta\gamma)_{ijk}+\epsilon _{ijkt}\,,\\ \epsilon_{ijkt}\sim N(0,\sigma^{2})\,,\\ \epsilon_{ijkt}\text{'s mutually independent}\,,\\ t=1,\ldots,r_{ijk};\ \ i=1,\ldots,a;\ \ j=1,\ldots,b;\ \ k=1,\ldots,c.\end{array} \tag{7.2.2}\]

This form of the model extends in an obvious way to more than three factors by including a main-effect parameter for every factor and an interaction effect parameter for every combination of two factors, three factors, etc.

If prior to the experiment certain interaction effects are known to be negligible, the corresponding parameters can be removed from the complete model to give a submodel. For example, if the factors \(A\) and \(B\) are known not to interact in a three-factor experiment, then the \(AB\) and \(ABC\) interaction effects are negligible, so the terms (\(\alpha\beta\))\({}_{ij}\) and (\(\alpha\beta\gamma\))\({}_{ijk}\) are excluded from model (7.2.2). In the extreme case, if no factors are expected to interact, then a _main-effects model_ (which includes no interaction terms) can be used.

When a model includes an interaction between a specific set of \(m\) factors, then all interaction terms involving subsets of those \(m\) factors should be included in the model. For example, a model that includes the effect of the three-factor interaction \(ABC\) would also include the effects of the \(AB\), \(AC\), and \(BC\) interactions as well as the main effects \(A\), \(B\), and \(C\).

Use of a submodel, when appropriate, is advantageous, because simpler models generally yield tighter confidence intervals and more powerful tests of hypotheses. However, if interaction terms are removed from the model when the factors do, in fact, interact, then the resulting analysis and conclusions may be totally incorrect.

#### The Meaning of Interaction

The same type of interaction plot as that used in Sect. 6.2.1, p. 139, can be used to evaluate interactions between pairs of factors in an experiment involving three or more factors. The graphical evaluation of three-factor interactions can be done by comparing separate interaction plots at the different levels of a third factor. Such plots will be illustrated for experiments that involve only three factors, but the methods are similar for experiments with four or more factors, except that the sample means being plotted would be averages over the levels of all the other factors.

The following sample means are for a hypothetical \(3\times 2\times 2\) experiment involving the factors \(A\), \(B\), and \(C\) at 3, 2, and 2 levels, respectively.

\[\frac{ijk}{\overline{y}_{ijk.}} : 111 112 121 122 211 212 221 222 311 312 321 322\]

An \(AB\)-interaction plot for these hypothetical data is shown in Fig. 7.1. As in the previous chapter, we must remember that interaction plots give no indication of the size of the experimental error and must be interpreted with a little caution. The lines of the plot in Fig. 7.1 are not parallel, indicating that the factors possibly interact. For factor \(A\), level 2 appears to be the best (highest response) on average, but not consistently the best at each level of \(B\). Likewise, level 1 of factor \(B\) appears to be better on average, but not consistently better at each level of \(A\). The perceived \(AB\) interaction is averaged over the levels of \(C\) and may have no practical meaning if there is an \(ABC\) interaction. Consequently, the three-factor interaction should be investigated first.

A three-factor interaction would be indicated if the interaction effect between any pair of factors were to change as the level of the third factor changes. In Fig. 7.2, a separate \(AB\)-interaction plot is shown for each level of factor \(C\). Each of the two plots suggests the presence of an \(AB\)-interaction effect, but the patterns in the two plots are the same. In other words, the factors \(A\) and \(B\) apparently interact in the same way at each level of factor \(C\). This indicates a negligible \(ABC\)-interaction effect. The shift in the interaction plot as the level of \(C\) changes from one plot to the other indicates a possible main effect of factor \(C\). The \(AB\) interaction plot in Fig. 7.1 is the average of the two plots in Fig. 7.2, showing the \(AB\) interaction averaged over the two levels of \(C\).

Other three-factor interaction plots can be obtained by interchanging the roles of the factors. For example, Fig. 7.3 contains plots of \(\overline{y}_{ijk.}\) against the levels \(i\) of \(A\) for each level \(j\) of factor \(B\), using the levels \(k\) of \(C\) as labels and the same hypothetical data. Lines are parallel in each plot, indicating no \(AC\)-interaction at either level of \(B\). Although the patterns differ from plot to plot, if there is no \(AC\)-interaction at either of the levels of \(B\), there is no change in the \(AC\)-interaction from one level of \(B\) to the other. So, again the \(ABC\)-interaction effect appears to be negligible. An \(AC\) interaction plot would show the average of the two plots in Fig. 7.3, and although the plot would again look different, the lines would still be parallel.

To see what the plots might look like when there is an \(ABC\)-interaction present, we look at the following second set of hypothetical data.

\[\frac{ijk}{\overline{y}_{ijk.}} : 3.0 2.0 1.5 4.0 2.5 3.5 3.0 4.0 3.0 5.0 3.5 6.0

Fig. 7.1: \(AB\)-interaction plot (averaged over levels of \(C\))Figure 7.4 shows plots of \(\overline{y}_{ijk.}\) against the level \(i\) of factor \(A\) for each level \(k\) of factor \(C\), using the level \(j\) of factor \(B\) as the plotting label. In each plot, corresponding lines are not all parallel, _and_ the pattern changes from one plot to the next. In other words, the interaction effect between factors \(A\) and \(B\) apparently changes with the level of \(C\), so there appears to be an \(ABC\)-interaction effect.

Four-factor interactions can be evaluated graphically by comparing the pairs of plots representing a three-factor interaction for the different levels of a fourth factor. Clearly, higher-order interactions are harder to envisage than those of lower order, and we would usually rely solely on the analysis of variance table for evaluating the higher-order interactions. In general, one should examine the higher-order interactions first, and work downwards. In many experiments, high-order interactions do tend to be small, and lower-order interactions can then be interpreted more easily.

Figure 7.2: \(ABC\)-interaction plots with \(C\) as the third factor

Figure 7.3: \(ABC\)-interaction plots with \(B\) as the third factor

#### Separability of Factorial Effects

In an experiment involving three factors, \(A\), \(B\), and \(C\), for which it is known in advance that factor \(C\) will not interact with factor \(A\) or \(B\), the \(AC\), \(BC\), and \(ABC\) interaction effects can be excluded from the model. Interpretation of the results of the experiment is simplified, because a specific change in the level of factor \(C\) has the same effect on the mean response for every combination \(ij\) of levels of \(A\) and \(B\). Likewise, a specific change in the combination of levels of \(A\) and \(B\) has the same effect on the mean response regardless of the level of \(C\). If the objective is to find the best treatment combination \(ijk\), then the task is reduced to two smaller problems involving fewer comparisons, namely choice of the best combination \(ij\) of levels of \(A\) and \(B\) and, separately, choice of the best level \(k\) of \(C\).

When there is such separability of effects, the experimenter should generally avoid the temptation to run separate experiments, one to determine the best combination \(ij\) of levels of factors \(A\) and \(B\) and another to determine the best level \(k\) of \(C\). A single factorial experiment involving \(n\) observations provides the same amount of information on the \(A\), \(B\), \(C\), and \(AB\) effects as would two separate experiments--a factorial experiment for factors \(A\) and \(B\) and another experiment for factor \(C\)--_each_ involving \(n\) observations!

One way to determine an appropriate model for an experiment is as follows. Suppose that the experiment involves \(p\) factors. Draw \(p\) points, labeling one point for each factor (see, for example, Fig. 7.5 for four factors \(A\)-\(D\)). Connect each pair of factors that might conceivably interact with a line to give a _line graph_. For every pair of factors that are joined by a line in the line graph, a two-factor interaction should be included in the model. If three factors are joined by a triangle, then it may be appropriate to include the corresponding three-factor interaction in the model as well as the three two-factor interactions. Similarly, if four factors are joined by all six possible lines, it may be appropriate to include the corresponding four-factor interaction as well as the three-factor and two-factor interactions.

The line graphs in Fig. 7.5 fall into two pieces. Line graph (a) represents the situation where \(A\) and \(B\) are thought to interact, as are \(C\) and \(D\). The model would include the \(AB\) and \(CD\) interaction effects, in addition to all main effects. Line graph (b) represents an experiment in which it is believed that \(A\) and \(B\) interact and also \(A\) and \(C\) and also \(B\) and \(C\). An appropriate model would include all main effects and the \(AC\), \(AB\), and \(BC\) interactions. The three-factor \(ABC\) interaction effect might also

Figure 7.4: \(ABC\)-interaction plots showing an \(ABC\)-interaction effectbe included in the model depending upon the type of interaction plots expected by the experimenter. Thus, a possible model would be

\[Y_{ijklt} = \mu + \alpha_{i} + \beta_{j} + \gamma_{k} + \delta_{l} + (\alpha\beta)_{ij} + (\alpha\gamma)_{ik} + (\beta\gamma)_{jk} + (\alpha\beta\gamma)_{ijk} + \epsilon_{ijklt}\.\]

#### Estimation of Factorial Contrasts

For an \(a\times b\times c\) factorial experiment and the three-way complete model, all treatment contrasts are of the form

\[\sum_{i}\sum_{j}\sum_{k}h_{ijk}\tau_{ijk}\ \ \ \text{with}\ \ \sum_{i}\sum_{j} \sum_{k}h_{ijk} = 0\,,\]

and are estimable when there is at least one observation per treatment combination.

A contrast in the main effect of \(A\) is any treatment contrast for which the coefficients \(h_{ijk}\) depend only on the level \(i\) of \(A\). For example, if we set \(h_{ijk}\) equal to \(p_{i}/(bc)\), with \(\Sigma p_{i}=0\), then the contrast \(\Sigma\Sigma\Sigma h_{ijk}\tau_{ijk}\) becomes

\[\sum_{i}p_{i}\overline{\tau}_{i..}=\sum_{i}p_{i}[\alpha_{i}+(\overline{\alpha \beta})_{i.}+(\overline{\alpha\gamma})_{i.}+(\overline{\alpha\beta\gamma})_{i..}]=\sum_{i}p_{i}\alpha_{i}^{*}\,.\]

We notice that a main-effect contrast for factor \(A\) can be interpreted only as an average over all of the interaction effects involving \(A\) in the model and, consequently, may not be of interest if any of these interactions are nonnegligible. The \(B\) and \(C\) main-effect contrasts are defined in similar ways.

An \(AB\) interaction contrast is any treatment contrast for which the coefficients \(h_{ijk}\) depend only on the combination \(ij\) of levels of \(A\) and \(B\), say \(h_{ijk}=d_{ij}/c\), and for which \(\sum_{i}d_{ij}=0\) for all \(j\) and \(\sum_{j}d_{ij}=0\) for all \(i\). An \(AB\) interaction contrast can be expressed as

\[\sum_{i}\sum_{j}d_{ij}\overline{\tau}_{ij.}=\sum_{i}\sum_{j}d_{ij}[(\alpha \beta)_{ij}+(\overline{\alpha\beta\gamma})_{ij.}]=\sum_{i}\sum_{j}d_{ij}( \alpha\beta)_{ij}^{*}\.\]

Thus, the \(AB\) interaction contrast can be interpreted only as an average over the \(ABC\) interaction and may not be of interest if the \(ABC\) interaction is nonnegligible. The \(AC\) and \(BC\) interaction contrasts are defined in similar ways.

An \(ABC\) interaction contrast is any contrast of the form

Figure 7.5: Separability plots

\[\sum_{i}\sum_{j}\sum_{k}h_{ijk}\tau_{ijk}=\sum_{i}\sum_{j}\sum_{k}h_{ijk}(\alpha \beta\gamma)_{ijk}\]

for which \(\sum_{i}h_{ijk}=0\) for all \(jk\), \(\sum_{j}h_{ijk}=0\) for all \(ik\), and \(\sum_{k}h_{ijk}=0\) for all \(ij\). When we investigated the interaction plot for \(ABC\) using Figs. 7.2-7.4, we compared the \(AB\) interaction at two different levels of factor \(C\). In other words, we looked at contrasts of the type

\[(\tau_{112}-\tau_{122}-\tau_{212}+\tau_{222})-(\tau_{111}-\tau_{121}-\tau_{211} +\tau_{221})\,.\]

If the levels 1 and 2 of \(A\) and \(B\) interact in the same way at each level of \(C\), then this \(ABC\) interaction contrast is zero. If all interaction contrasts of this type (for all levels of \(A\), \(B\), and \(C\)) are zero, then the \(ABC\) interaction is negligible.

When a sub-model, rather than a complete model, is used, parameters for the negligible interactions are removed from the above expressions. If the experiment involves more than three factors, then the above definitions can be generalized by including the additional subscripts on \(h_{ijk}\tau_{ijk}\) and averaging over the appropriate higher-order interactions.

As in Chap. 6, all contrasts can be represented by coefficient lists in terms of the main-effect and interaction parameters or in terms of the treatment combination parameters. This is illustrated in the next example.

#### _Example 7.2.1_ Coefficient lists for contrasts

Suppose that we have an experiment that involves four factors, \(A\), \(B\), \(C\), and \(D\), each to be examined at two levels (so that \(a=b=c=d=2\) and \(v=16\)). Suppose that a model that includes \(AB\), \(BC\), \(BD\), \(CD\), and \(BCD\) interactions is expected to provide a good description of the data; that is,

\[Y_{ijklt} = \mu+\alpha_{i}+\beta_{j}+\gamma_{k}+\delta_{l}+(\alpha\beta)_{ij}\] \[{}+(\beta\gamma)_{jk}+(\beta\delta)_{jl}+(\gamma\delta)_{kl}+( \beta\gamma\delta)_{jkl}+\epsilon_{ijklt}\,,\] \[\epsilon_{ijklt}\sim N(0,\sigma^{2})\,,\] \[\epsilon_{ijklt}{}^{\prime}\text{s are mutually independent},\]

\[t=1,\ldots,r_{ijkl},\quad i=1,2,\quad j=1,2,\quad k=1,2,\quad l=1,2\,.\]

The contrast that compares the two levels of \(C\) is

\[\overline{\tau}_{.2.}-\overline{\tau}_{.1.}\ =\ \gamma_{2}^{*}-\gamma_{1}^{*}\,,\]

where \(\gamma_{k}^{*}=\gamma_{k}+(\overline{\beta\gamma})_{.k}+(\overline{\gamma }\delta)_{k.}\). This contrast can be represented as a coefficient list \([-1,\ \ 1\ ]\) in terms of the parameters \(\gamma_{1}^{*}\) and \(\gamma_{2}^{*}\) or as

\[\frac{1}{8}[-1,\,-1,\ \ 1,\ \ 1,-1,\,-1,\ \ 1,\ \ 1,\ -1,-1,\ \ 1,\ \ 1,-1,\ \ 1,\ \ 1\ ]\]

in terms of the \(\tau_{ijkl}\). These are listed under the heading \(C\) in Table 7.1.Coefficient lists for the other main-effect contrasts in terms of the \(\tau_{ijkl}\) are also shown in Table 7.1. The treatment combinations in the table are listed in ascending order when regarded as 4-digit numbers. The main-effect contrast coefficients are \(-1\) when the corresponding factor is at level 1, and the coefficients are \(+1\) when the corresponding factor is at level 2, although these can be interchanged if contrasts such as \(\gamma_{1}^{*}-\gamma_{2}^{*}\) are 

[MISSING_PAGE_FAIL:230]

### Analysis--Equal Sample Sizes

For an experiment involving \(p\) factors, we can select a cell-means model or the equivalent \(p\)-way complete model, or any of the possible submodels. When the sample sizes are equal, the formulae for the degrees of freedom, least squares estimates, and sums of squares for testing hypotheses follow well-defined patterns. We saw in Chap. 6 that for an experiment with two factors, we obtain similar formulae for the least squares estimates of the contrasts \(\sum c_{i}\alpha_{i}\) in the two-way main-effects model and \(\sum c_{i}\alpha_{i}^{*}\) in the two-way complete model. Similarly, the sum of squares for \(A\) was of the same form in both cases. This is also true for experiments with more than two factors.

We now give a series of rules that can be applied to any complete model with equal sample sizes. The rules are illustrated for the _ABD_ interaction in an experiment involving four treatment factors \(A\), \(B\), \(C\), and \(D\), with corresponding symbols \(\alpha\), \(\beta\), \(\gamma\), and \(\delta\) and subscripts \(i\), \(j\), \(k\), and \(l\) to represent their effects on the response in a four-way complete model with \(r\) observations per treatment combination. The corresponding rules for submodels are obtained by dropping the relevant interaction terms from the complete model. When the sample sizes are not equal, the formulae are more complicated, and we will analyze such experiments only via a computer package (see Sects. 7.6 and 7.7).

**Rules for Estimation and Hypothesis Testing--Equal Sample Sizes**

1. Write down the name of the main effect or interaction of interest and the corresponding numbers of levels and subscripts. Example: _ABD_; numbers of levels \(a\), \(b\), and \(d\); subscripts \(i\), \(j\), and \(l\).
2. The number of degrees of freedom \(\nu\) for a factorial effect is the product of the "number of levels minus one" for each of the factors included in the effect. Example: For _ABD_, \(\nu=(a-1)(b-1)(d-1)\).
3. Multiply out the number of degrees of freedom and replace each letter with the corresponding subscript. Example: For _ABD_, \(\text{df}=abd-ab-ad-bd+a+b+d-1\), which gives \(ijl-ij-il-jl+i+j+l-1\).
4. The sum of squares for testing the hypothesis that a main effect or an interaction is negligible is obtained as follows. Use each group of subscripts in rule 3 as the subscripts of a term \(\overline{y}\), averaging over all subscripts not present and keeping the same signs. Put the resulting estimate in brackets, square it, and sum over all possible subscripts. To expand the parentheses, square each term in the parentheses, keep the same signs, and sum over all possible subscripts.

Example: \[ss(ABD) = rc\sum_{i}\sum_{j}\sum_{l}(\overline{y}_{ijIJ.}-\overline{y}_{ij...}- \overline{y}_{i..l.}-\overline{y}_{.j.l.}\] \[\qquad\qquad\qquad\qquad+\overline{y}_{i....}+\overline{y}_{.j...}+ \overline{y}_{...l.}-\overline{y}_{.....})^{2}\] \[= rc\sum_{i}\sum_{j}\sum_{l}\overline{y}_{ijIJ.}^{2}-rcd\sum_{i}\sum_{j} \overline{y}_{ij...}^{2}-rbc\sum_{i}\sum_{l}\overline{y}_{i.l.}^{2}\] \[\qquad-rac\sum_{j}\sum_{l}\overline{y}_{.j.l.}^{2}+rbcd\sum_{i} \overline{y}_{i....}^{2}+racd\sum_{j}\overline{y}_{.j...}^{2}\] \[\qquad+rabc\sum_{l}\overline{y}_{...l.}^{2}-rabcd\overline{y}_{..... }^{2}\,.\]
5. The total sum of squares _sstot_ is the sum of all the squared deviations of the data values from their overall mean. The total degrees of freedom is \(n-1\), where \(n\) is the total number of observations. \[\text{Example: }\qquad sstot = \sum_{i}\sum_{j}\sum_{k}\sum_{l}\sum_{t}(y_{ijklt}-\overline{y}_{..... })^{2}\] \[= \sum_{i}\sum_{j}\sum_{k}\sum_{l}\sum_{t}y_{ijklt}^{2}-n\overline{ y}_{.....}^{2}\,,\] \[n-1 = abcdr-1\,.\]
6. The error sum of squares _ssE_ is _sstot_ minus the sums of squares for all other effects in the model. The error degrees of freedom df is \(n-1\) minus the degrees of freedom for all of the effects in the model. For a complete model, df = \(n-v\), where \(v\) is the total number of treatment combinations. Example: \[ssE = sstot-ssA-ssB-ssC-ssD\] \[\qquad-ss(AB)-ss(AC)-\cdots-ss(BCD)-ss(ABCD)\,,\] \[df = (n-1)-(a-1)-(b-1)-\cdots-(a-1)(b-1)(c-1)(d-1)\,.\]
7. The mean square for an effect is the corresponding sum of squares divided by the degrees of freedom. Example: \[ms(ABD) = ss(ABD)/((a-1)(b-1)(d-1))\,,\] \[msE = ssE/df\]

[MISSING_PAGE_FAIL:233]

11. The variance of an estimable contrast for a factorial effect is obtained by adding the squared contrast coefficients, dividing by the product of \(r\) and the numbers of levels of all factors not present in the effect, and multiplying by \(\sigma^{2}\). Example: \(\text{Var}\Big{(}\sum_{i}\sum_{j}\sum_{l}h_{ijl}(\alpha\beta\delta)^{*}_{ijl} \Big{)}=\Big{(}\sum_{i}\sum_{j}\sum_{l}h^{2}_{ijl}/(cr)\Big{)}\,\sigma^{2}\).
12. The "sum of squares" for testing the null hypothesis \(H_{0}^{c}\) that a contrast is zero is the square of the normalized contrast estimate. Example: The sum of squares for testing the null hypothesis that the contrast \(\sum\sum\sum h_{ijl}(\alpha\beta\delta)^{*}_{ijl}\) is zero against the alternative hypothesis that the contrast is nonzero is the square of the least squares estimate of the normalized contrast \(\sum\sum\sum h_{ijl}(\alpha\beta\delta)^{*}_{ijl}/\sqrt{\sum\sum\sum h^{2}_{ijl }/(cr)}\) ; that is, \[ssc=\frac{\Big{(}\sum_{i}\sum_{j}\sum_{l}h_{ijl}\overline{y}_{ijl,l}\Big{)}^{2 }}{\sum_{i}\sum_{j}\sum_{l}h^{2}_{ijl}/(cr)}\.\]
13. The decision rule for testing the null hypothesis \(H_{0}^{c}\) that an estimable contrast is zero, against the alternative hypothesis that the contrast is nonzero, is \[\text{reject }H_{0}^{c}\text{ if}\frac{ssc}{msE}>F_{1,df,\alpha/m}\,\] where \(ssc\) is the square of the normalized contrast estimate, as in rule 12; \(msE\) is the error mean square; \(df\) is the number of error degrees of freedom; \(\alpha\) is the overall Type I error probability; and \(m\) is the number of preplanned hypotheses being tested.
14. Simultaneous confidence intervals for contrasts in the treatment combinations can be obtained from the general formula (4.4.20), p. 83, with the appropriate critical coefficients for the Bonferroni, Scheffe, Tukey, and Dunnett methods. Example: For the four-way complete model, the general formula for simultaneous 100(\(1-\alpha\))% confidence intervals for a set of contrasts of the form \(\Sigma\,\Sigma\,\Sigma\,\Sigma c_{ijkl}\tau_{ijkl}\) is \[\Sigma\,\Sigma\,\Sigma\,\Sigma c_{ijkl}\tau_{ijkl}\in\Big{(}\Sigma\,\Sigma\, \Sigma\,\Sigma c_{ijkl}\overline{y}_{ijkl}.\pm w\,\sqrt{msE\,\left(\Sigma\, \Sigma\,\Sigma\,\Sigma c_{ijkl}^{2}/r\right)}\,\] where the critical coefficient, \(w\), is \[w_{B}=t_{df,\alpha/2m}\ \ ;\ \ w_{s}=\sqrt{(v-1)F_{v-1,df,\alpha}}\ \ ;\] \[w_{T}=q_{v,df,\alpha}/\sqrt{2}\ \ ;\ \ w_{D2}=|t|^{(0.5)}_{v-1,df, \alpha}\ \ ;\] for the four methods, respectively, and \(v\) is the number of treatment combinations, and \(df\) is the number of error degrees of freedom.

15. Simultaneous confidence intervals for the true mean effects of the treatment combinations in the complete model can be obtained from the general formula (4.3.12), p. 76, with the appropriate critical coefficients for the Bonferroni or Scheffe methods. Example: For the four-way complete model, the general formula for simultaneous \(100(1-\alpha)\%\) confidence intervals for true mean effects of the treatment combinations \(\mu+\tau_{ijkl}\) is \[\mu+\tau_{ijkl}\in\left(\overline{y}_{ijkl}.\pm w\;\sqrt{msE/r}\right)\,,\] where the critical coefficient, \(w\), is \[w_{B}=t_{df,\alpha/(2v)}\;\;\;\text{or}\;\;\;w_{s}=\sqrt{v\;F_{v,df,\alpha}}\] for the Bonferroni and Scheffe methods, respectively.
16. Simultaneous \(100(1-\alpha)\%\) confidence intervals for contrasts in the levels of a single factor can be obtained by modifying the formulae in rule 14. Replace \(v\) by the number of levels of the factor of interest, and \(r\) by the number of observations on each level of the factor of interest. Example: For the four-way complete model, the general formula for simultaneous confidence intervals for contrasts \(\sum_{i}c_{i}\overline{\tau}_{i\ldots}=\sum_{i}\alpha_{i}^{*}\) in \(A\) is \[\sum_{i}c_{i}\alpha_{i}^{*}\in\left(\sum_{i}c_{i}\overline{y}_{i\ldots}\pm w \;\sqrt{msE\left(\sum_{i}c_{i}^{2}/(bcdr)\right)}\right)\,,\] where the critical coefficients for the five methods are, respectively, \[w_{B}=t_{df,\alpha/(2m)}\;\;;\;\;w_{s}=\sqrt{(a-1)F_{a-1,df,\alpha}}\;\;;\;\;w _{T}=q_{a,df,\alpha}/\sqrt{2}\;\;;\] \[w_{D1}=w_{H}=t_{a-1,df,\alpha}^{(0.5)}\;\;;\;\;w_{D2}=|t|_{a-1,df,\alpha}^{(0.5)}\;\;;\] where \(df\) is the number of error degrees of freedom.

### A Real Experiment--Popcorn-Microwave Experiment

The experiment described in this section was run by Jianjian Gong, Chongqing Yan, and Lihua Yang in 1992 to compare brands of microwave popcorn. The details in the following checklist have been extracted from the experimenters' report.

**The Design Checklist**

1. **Define the objectives of the experiment**. The objective of the experiment was to find out which brand gives rise to the best popcorn in terms of the proportion of popped kernels. The experiment was restricted to popcorn produced in a microwave oven.

2. **Identify all sources of variation**. 1. Treatment factors and their levels. The first treatment factor was "brand." Three levels were selected, including two national brands (levels 1 and 2) and one local brand (level 3). These brands were the brands most commonly used by the experimenters and their colleagues. All three brands are packaged for household consumers in boxes of 3.5 ounce packages, and a random selection of packages was used in this experiment. Power of the microwave oven was identified as a possible major source of variation and was included as a second treatment factor. Three available microwave ovens had power ratings of 500, 600, and 625 W. The experimenters used only one oven for each power level. This means that their conclusions could be drawn only about the three ovens in the study and not about power levels in general. Popping time was taken as a third treatment factor. The usual instructions provided with microwave popcorn are to microwave it until rapid popping slows to 2 to 3 seconds between pops. Five preliminary trials using brand 3, a 600 W microwave oven, and times equally spaced from 3 to 5 min suggested that the best time was between 4 and 5 min. Hence, time levels of 4, 4.5, and 5 min were selected for the experiment and coded 1-3, respectively. 2. Experimental units The experiment was to be run sequentially over time. The treatment combinations were to be examined in a completely random order. Consequently, the experimental units were the time slots that were to be assigned at random to the treatment combinations. 3. Blocking factors, noise factors, and covariates. Instead of randomly ordering the observations on all of the treatment combinations, it might have been more convenient to have taken the observations oven by oven. In this case, the experiment would have been a "split-plot design" (see Sect. 2.4.4) with ovens representing the blocks. In this experiment, no blocking factors or covariates were identified by the experimenters. The effects of noise factors, such as room temperature, were thought to be negligible and were ignored. 4. **Choose a rule by which to assign the experimental units to the treatments**. A completely randomized design was indicated. The time-slots were randomly assigned to the brand-power-time combinations. Popcorn packages were selected at random from a large batch purchased by the experimenters to represent each brand. Changes in quality, if any, of the packaged popcorn over time could not be detected by this experiment. 5. **Specify measurements to be made, the experimental procedure, and the anticipated difficulties**. A main difficulty for the experimenters was to choose the response variable. They considered weight, volume, number, and percentage of successfully popped kernels as possible response variables. In each case, they anticipated difficulty in consistently being able to classify kernels as popped or not. To help control such variation or inconsistency in the measurement process, a single experimenter made all measurements. For measuring weight, the experimenters needed a more accurate scale than was available, since popcorn is very light. They decided against measuring volume, since brands with smaller kernels would appear to give less volume, as the popcorn would pack more easily into a measuring cylinder. The percentage, rather than number, of successfully popped kernels for each package was selected as the response variable.
* **Run a pilot experiment**. The experimenters ran a very small pilot experiment to check their procedure and to obtain a rough estimate of the error variance. they collected observations on only 9 treatment combinations. Using a three-way main-effects model, they found that the overall average popping rate was about 70% and the error standard deviation was a little less than 10.7%. The highest popping rate occurred when the popping time was at its middle level (4.5 min), suggesting that the range of popping times under consideration was reasonable. Results for 600 and 625 W microwave ovens were similar, with lower response rates for the 500 W microwave oven. However, since all possible interactions had been ignored for this preliminary analysis, the experimenters were cautious about drawing any conclusions from the pilot experiment.
* **Specify the model**. For their main experiment, the experimenters selected the three-way complete model, which includes all main effects and interactions between the three treatment factors. They assumed that the packages selected to represent each brand would be very similar, and package variability for each brand could be ignored.
* **-- revisited. Define the objectives of the experiment**. Having identified the treatment factors, response variables, etc., the experimenters were able to go back to step (a) and reformalize the objectives of the experiment. They decided that the three questions of most interest were:
* Which combination of brand, power, and time will produce the highest popping rate? (Thus, pairwise comparisons of all treatment combinations were required.)
* Which brand of popcorn performs best overall? (Pairwise comparison of the levels of brand, averaging over the levels of power and time, was required.)
* How do time and power affect response? (Pairwise comparison of time-power combinations, averaging over brands, was required. Also, main-effect comparisons of power and time were required.)
* **Outline the analysis**. Tukey's method of simultaneous confidence intervals for pairwise comparisons was to be used separately at level 99% for each of the above five sets of contrasts, giving an experimentwise confidence level of at least 95%.
* **Calculate the number of observations that need to be taken**. The data from the pilot study suggested that 10.7% would be a reasonable guess for the error standard deviation. This was calculated using a main-effects model rather than the three-way complete model, but we would expect a model with more terms to reduce the estimated error 

[MISSING_PAGE_FAIL:238]

If the equivalent cell-means model is used, the null hypothesis of no difference between the treatment combinations would be rejected at significance level \(\alpha=0.07\). This is shown in the row of Table 7.3 labeled "Treatments." Since the design is equireplicate, the main effects and interactions are estimated independently, and their sums of squares add to the treatment sum of squares. The corresponding numbers of degrees of freedom likewise add up.

Figure 7.6 shows an interaction plot for the factors "Brand" and "Time." The plot suggests that use of time level 2, namely 4.5 min, generally gives a higher popping rate for all three brands. Using level 2 of time, brands 1 and 2 appear to be better than brand 3. The two national brands thus appear to be better than the local brand. Brand 1 appears to be less sensitive than brand 2 to the popping time. (We say that brand 1 appears to be _more robust_ to changes in popping time.) Unless this perceived difference is due to error variability, which does not show on the plot, brand 1 is the brand to be recommended.

Having examined the analysis of variance table and Fig. 7.6, the most interesting issue seems to be that the differences in the brands might not be the same at the different popping times. This is not one of the comparisons that had been preplanned at step (g) of the checklist. It is usually advisable to include in the plan of the analysis the use of Scheffe's multiple comparisons for all contrasts that look interesting after examining the data. If we had done this at overall 99% confidence level, then the experimentwise error rate would have been at least 94%. Interaction contrasts and their least squares estimates are defined in rules 9 and 10, p. 211. The interaction contrast of most interest is, perhaps,

\[\overline{\tau}_{1.2}-\overline{\tau}_{1.3}-\overline{\tau}_{2.2}+\overline{ \tau}_{2.3}\,,\]

\begin{table}
\begin{tabular}{c c c c c c} \hline \multicolumn{2}{c}{Brand (\(i\))} & \multicolumn{2}{c}{Power (\(j\))} & \multicolumn{2}{c}{Time (\(k\))} \\ \cline{3-6}  & & 1 & 2 & 3 \\ \hline
1 & 1 & 73.8, 65.5 & 70.3, 91.0 & 72.7, 81.9 \\
1 & 2 & 70.8, 75.3 & 78.7, 88.7 & 74.1, 72.1 \\
2 & 1 & 73.7, 65.8 & 93.4, 76.3 & 45.3, 47.6 \\
2 & 2 & 79.3, 86.5 & 92.2, 84.7 & 66.3, 45.7 \\
3 & 1 & 62.5, 65.0 & 50.1, 81.5 & 51.4, 67.7 \\
3 & 2 & 82.1, 74.5 & 71.5, 80.0 & 64.0, 77.0 \\ \hline  & & \(\overline{y}_{\cdot 1.}=72.9000\) & \(\overline{y}_{\cdot 2.}=79.8667\) & \(\overline{y}_{\cdot 3.}=63.8167\) \\ \hline \end{tabular}
\end{table}
Table 7.2: Percentage \(y_{ijkl}\) of kernels popped—popcorn–microwave experiment

\begin{table}
\begin{tabular}{c c c c c c} \hline \multicolumn{2}{c}{Source of variation} & \multicolumn{2}{c}{Degrees of freedom} & \multicolumn{2}{c}{Sum of squares} & \multicolumn{2}{c}{Mean square} & Ratio & \(p\)-value \\ \hline B & 2 & 331.1006 & 165.5503 & 1.89 & 0.1801 \\ P & 1 & 455.1111 & 455.1111 & 5.19 & 0.0351 \\ T & 2 & 1554.5756 & 777.2878 & 8.87 & 0.0021 \\ B*P & 2 & 196.0406 & 98.0203 & 1.12 & 0.3485 \\ B*T & 4 & 1433.85which compares the differences in brands 1 and 2 at popping times 2 and 3. This has least squares estimate

\[\overline{y}_{1.2.}-\overline{y}_{1.3.}-\overline{y}_{2.2.}+\overline{y}_{2.3.}=82.17 5-75.20-86.65+51.225=-28.45\,.\]

The importance of preplanning will now become apparent. Using Scheffe's method (rule 14) at overall level 99%, a confidence interval for this contrast is given by

\[\sum_{i}\sum_{k}c_{ik}\overline{y}_{i.k.} \pm w_{S}\sqrt{msE\left(\sum_{i}\sum_{k}c_{ik}^{2}/(br)\right)}\] \[=-28.45 \pm \sqrt{17F_{17,18,0.1}}\sqrt{87.6594\ (4/4)}\] \[=-28.45 \pm 69.69\quad=\ (-96.41,\ 39.52)\.\]

Our popping rates are percentages, so our minimum significant difference is 69%. This is far too large to give any useful information. The resulting interval gives the value of the interaction contrast as being between \(-96.4\%\) and 39.5%! Had this contrast been preplanned for at individual confidence level 99%, we would have used the critical value \(w_{B}=t_{18,0.005}=2.878\) instead of \(w_{S}=7.444\), and we would have obtained a minimum significant difference of about 30%, leading to the interval \((-55.40,\,-1.50)\). Although still wide, this interval would have given more information, and in particular, it would have indicated that the interaction contrast was significantly different from zero.

The other important effect that showed up in the analysis of variance table was the effect of the different popping times (4, 4.5, or 5 min). Comparisons of popping times did feature as one of the preplanned sets of multiple comparisons, and consequently, we use Tukey's method (rule 16) for pairwise differences \(\gamma_{k}-\gamma_{u}\) at overall level 99%. The minimum significant difference is

\[\text{msd}=w_{T}\sqrt{msE\ \Sigma c_{k}^{2}/(abr)}=(q_{3,18,.01}/\sqrt{2})\ \sqrt{(87.6594)(2/12)}=12.703\,.\]

The average percentages of popped kernels for the three popping times are shown in Table 2 as

\[\overline{y}_{..1.}=72.9000\,,\quad\overline{y}_{..2.}=79.8667\,,\quad\overline{y}_{..3.}=63.8167\,,\]

so the three confidence intervals are

Figure 7.6: Interaction plot for factors “brand” and “time” averaged over “power” for the popcorn–microwave experiment

\[\gamma_{1}-\gamma_{2}\in(-6.9667\pm 12.7030) =(-5.736,19.670)\;,\] \[\gamma_{1}-\gamma_{3}\in(9.0833\pm 12.7030) =(-3.620,21.786)\;,\] \[\gamma_{2}-\gamma_{3}\in(16.0500\pm 12.7030) =(3.347,28.753)\;.\]

We see that at an experimentwise confidence level of at least 94%, use of popping time 2 (4.5 min) produces on average between 3.35% and 28.75% more popcorn than use of popping time 3 (5 min).

The other questions asked by the experimenters appear to be of less interest, and we will omit these. The experimentwise confidence level is still at least 94%, even though we have chosen not to calculate all of the preplanned intervals.

### One Observation per Cell

If the complete model is used for a factorial experiment with one observation per cell, then there are no degrees of freedom available to estimate the error variance. This problem was discussed in Sect. 6.7, where one possible method of analysis was described. The method relies on being able to identify a number of negligible contrasts, which are then excluded from the model. The corresponding sums of squares and degrees of freedom are used to estimate the error variance. With this approach, confidence intervals can be constructed and hypothesis tests conducted. An example with four treatment factors that are believed not to interact with each other is presented in the next section.

Two alternative approaches for the identification of nonnegligible contrasts are provided in the subsequent sections. In Sect. 7.5.2 we show an approach based on the evaluation of a half-normal probability plot of a set of contrast estimates, and in Sect. 7.5.3 we discuss a more formalized approach. These two approaches work well under effect sparsity, that is, when most of the treatment contrasts under examination are negligible.

#### Analysis Assuming that Certain Interaction Effects are Negligible

For a single replicate factorial experiment, if the experimenter knows ahead of time that certain interactions are negligible, then by excluding those interactions from the model, the corresponding degrees of freedom can be used to estimate the error variance. It must be recognized, however, that if interactions are incorrectly assumed to be negligible, then _msE_ will be inflated, in which case the results of the experiment may be misleading.

\begin{table}
\begin{tabular}{c c c c c c} \hline \(ABCD\) & Advance & \(y=\log(\text{advance})\) & \(ABCD\) & Advance & \(y=\log(\text{advance})\) \\ \hline
1111 & 1.68 &.2253 & 2111 & 1.98 &.2967 \\
1112 & 2.07 &.3160 & 2112 & 2.44 &.3874 \\
1121 & 4.98 &.6972 & 2121 & 5.70 &.7559 \\
1122 & 7.77 &.8904 & 2122 & 9.43 &.9745 \\
1211 & 3.28 &.5159 & 2211 & 3.44 &.5366 \\
1212 & 4.09 &.6117 & 2212 & 4.53 &.6561 \\
1221 & 9.97 &.9987 & 2221 & 9.07 &.9576 \\
1222 & 11.75 & 1.0700 & 2222 & 16.30 & 1.2122 \\ \hline \end{tabular}
\end{table}
Table 7.4: Data for the drill advance experiment 

#### Example 7.5.1 Drill advance experiment

Daniel (1976) described a single replicate \(2\times 2\times 2\times 2\) experiment to study the effects of four treatment factors on the rate of advance of a small stone drill. The treatment factors were "load on the drill" (_A_), "flow rate through the drill" (_B_), "speed of rotation" (_C_), and "type of mud used in drilling" (_D_). Each factor was observed at two levels, coded 1 and 2. The author examined several different transformations of the response and concluded that the log transform was one of the more satisfactory ones. In the rest of our discussion, \(y_{i}jkl\) represents the log (to the base 10) of the units of drill advance, as was illustrated in the original paper. The data are shown in Table 7.4.

In many experiments with a number of treatment factors, experimenters are willing to believe that some or all of the interactions are very small. Had that been the case here, the experimenter would have used the four-way main-effects model. (Analysis of this experiment without assuming negligible interactions is discussed in Example 7.5.2, p. 222.)

Degrees of freedom and sums of squares are given by rules 2 and 4 in Sect. 7.3. For example, the main effect of \(B\) has \(b-1\) degrees of freedom and

\[ssB\ =\ acd\sum_{i}\left(\overline{y}_{.j..}-\overline{y}....\right)^{2}\ =\ acd\sum_{i}\overline{y}_{.j..}^{2}-acbd\overline{y}....^{2}\,.\]

The sums of squares for the other effects are calculated similarly and are listed in the analysis of variance table, Table 7.5. The error sum of squares shown in Table 7.5 is the total of all the eleven (negligible) interaction sums of squares and can be obtained by subtraction, as in rule 6, p. 210:

\[ssE=sstot-ssA-ssB-ssC-ssD=0.01998\,.\]

Similarly, the number of error degrees of freedom is the total of the \(15-4=11\) interaction degrees of freedom. An estimate of \(\sigma^{2}\) is therefore \(msE=ssE/11=0.0018\). Since \(F_{1,11,..01}=9.65\), the null hypotheses of no main effects of \(B\), \(C\), and \(D\) would all have been rejected at overall significance level \(\alpha\leq 0.04\). Alternatively, from a computer analysis we would see that the _p_-values for \(B\), \(C\), and \(D\) are each less than or equal to an individual significance level of \(\alpha^{*}=0.01\).

Confidence intervals for the \(m=4\) main-effect contrasts using Bonferroni's method at an overall level of at least 95% can be calculated from rule 16. From rules 10 and 11 on p. 211, the least squares estimate for the contrast that compares the effects of the high and low levels of \(B\) is \(\overline{y}_{.2..}-\overline{y}_{.1..}\), with variance \(\sigma^{2}(2/8)\), giving the confidence interval

\[\left(\overline{y}_{.2..}-\overline{y}_{.1..}\pm w_{B}\ \sqrt{msE\ (2/8)} \right)\,\]

\begin{table}
\begin{tabular}{c c c c c c} \hline Source of variation & Degrees of freedom & Sum of squares & Mean square & Ratio & _p_-value \\ \hline \(A\) & 1 & 0.01275 & 0.01275 & 7.02 & 0.0226 \\ \(B\) & 1 & 0.25387 & 0.25387 & 139.74 & 0.0001 \\ \(C\) & 1 & 1.00550 & 1.00550 & 553.46 & 0.0001 \\ \(D\) & 1 & 0.08045 & 0.08045 & 44.28 & 0.0001 \\ Error & 11 & 0.01998 & 0.00182 & & \\ \hline Total & 15 & 1.37254 & & & \\ \hline \end{tabular}
\end{table}
Table 7.5: Analysis of variance for the drill advance experimentwhere the critical coefficient is

\[w_{B}=t_{11,..025/4}=t_{11,..00625}\approx z+(z^{3}+z)/((4)(11))\approx 2.911\,,\]

from (4.4.22), p. 83, and

\[\text{msd}=w_{B}\,\sqrt{\text{ms}E\ (2/8)}=2.911\,\sqrt{(0.00182)/4}=0.062\,.\]

Now, \(\overline{y}_{\,2..}=0.820\), \(\overline{y}_{\,1..}=0.568\), so the confidence interval for the \(B\) contrast is

\[(0.252\pm 0.062)\approx(0.190,\,0.314)\,,\]

where the units are units of log drill advance. Confidence intervals for the other three main effects comparing high with low levels can be calculated similarly as

\[\begin{array}{ll}A:0.056\pm 0.062&=&(-0.006,\,0.118)\,,\\ C:0.501\pm 0.062&=&(\,0.439,\,0.563)\,,\\ D:0.142\pm 0.062&=&(\,0.080,\,0.204)\,.\end{array}\]

We see that the high levels of \(B\), \(C\), \(D\) give a somewhat higher response in terms of log drill advance (with overall confidence level at least 95%), whereas the interval for \(A\) includes zero. 

#### Analysis Using Half-Normal Probability Plot of Effect Estimates

For a single replicate factorial experiment, with \(v\) treatment combinations, one can find a set of \(v-1\) orthogonal contrasts. When these are normalized, the contrast estimators all have variance \(\sigma^{2}\). If the assumptions of normality, equal variances, and independence of the response variables are approximately satisfied, the estimates of negligible contrasts are like independent observations from a normal distribution with mean zero and variance \(\sigma^{2}\). If we were to plot the normalized contrast estimates against their normal scores (in the same way that we checked for normality of the error variables in Chap. 5), the estimates of negligible effects would tend to fall nearly on a straight line. Any contrast for which the corresponding estimate would appear to be far from the line would be considered to be nonnegligible. The sign of such a nonnegligible contrast could be positive or negative and this depends upon which level of the factor is labeled as the high level and which is labeled as the low level. For many factors (especially qualitative factors), these designations are arbitrary, and so it is common to use a _half-normal probability plot_ for detecting nonnegligible contrasts. This is obtained by plotting the _absolute values_ of the normalized contrast estimates against their _half-normal scores._

Half-normal scores are percentiles of the half-normal distribution with \(\sigma=1\), corresponding to the distribution of the absolute value of a standard normal random variable. In particular, the \(q\)th half-normal score for \(m=v-1\) contrast absolute estimates is the value \(\xi_{q}\) for which

\[P(Z\leq\xi_{q})=0.5*[1+q/(m+1)],\]

where \(Z\) is a standard normal random variable. Hence, the \(q\)th half-normal score is

\[\xi_{q}=\Phi^{-1}[0.5*(1+q/(m+1))]\,, \tag{7.5.4}\]where \(\Phi\) is the cumulative distribution function (cdf) of the standard normal distribution.

If the model assumptions are approximately satisfied, and if the estimated effects are all negligible, then the half-normal plot should show points roughly on a straight line through the origin with slope equal to \(\sigma\). However, if any of the effects are large, then their estimates should stand out as relatively large, creating a nonlinear pattern. Provided that there is effect sparsity--namely, all but a few contrast estimates are expected to be negligible--it is not difficult to pick out the nonnegligible contrasts. We note that it is possible to use a half-normal probability plot for non-normalized contrasts provided that they all have the _same variance_, so that the line of negligible contrasts still has slope equal to the common contrast standard deviation.

#### _Example 7.5.2_ Drill advance experiment, continued

The data for the drill advance experiment were given in Table 7.4 in Example 7.5.1. The experiment involved treatment factors "load" (\(A\)), "flow" (\(B\)), "speed" (\(C\)), and "mud" (\(D\)) and response "log(drill advance)" (\(Y\)). If we have no information about which factors are likely to be negligible, we would use the four-way complete model or the equivalent cell-means model:

\[\begin{array}{c}Y_{ijkl}=\mu+\tau_{ijkl}+\epsilon_{ijkl}\;,\\ \epsilon_{ijkl}\sim N(0,\sigma^{2})\,,\\ \epsilon^{\prime}_{ijkl}\mbox{s mutually independent}\,,\\ i=1,2;\;\;\;j=1,2;\;\;k=1,2;\;\;l=1,2\,.\end{array}\]

The contrast coefficients for the four main effects and some of the interactions in such a cell-means model were listed in Table 7.1, p. 208. The contrast coefficients for the interactions can be obtained by multiplying together the corresponding main-effect coefficients. Each contrast is normalized by dividing the coefficients by \(\sqrt{\Sigma c_{ijkl}^{2}/r}=\sqrt{16}\) rather than by the divisors of Table 7.1. For example, the normalized \(BCD\) interaction contrast has coefficient list

\[\frac{1}{4}[-1,\;\;1,\;\;1,-1,\;\;1,-1,\;\;1,-1,\;\;1,\;\;1,-1,\;\;1,-1,\;\;1\;]\,.\]

The least squares estimate of the normalized \(BCD\) interaction contrast is then

\[\frac{1}{4}[-(0.2253)+(0.3160)+\cdots-(0.9576)+(1.2122)] = -0.0300\,.\]

The 15 normalized factorial contrast estimates are given in Table 7.6, and the half-normal probability plot of these estimates is shown in Fig. 7.7, with the main effect estimates labeled. Observe that all the estimates fall roughly on a straight line, except for the estimates for the main-effects of factors \(D\), \(B\), and \(C\). Hence, these three main effects appear to be nonnegligible.

In the construction of the half-normal probability plot, the contrasts must be scaled to have the same variance, and normalization is one way to achieve this. When _all factors_ have two levels, and when the contrasts are written in terms of the treatment combination parameters as in Table 7.1, their least squares estimators will all have the same variance, as long as the _same divisor_ is used for every contrast. A popular selection for divisor is \(v/2\), which is the natural divisor for main-effect contrasts comparing the average treatment combination effects at the two levels of a factor. Thus, rather than using divisor \(\sqrt{16}\) in Example 7.5.2, we could have used divisor \(v/2=8\). If the divisor \(v/2\) is used, the estimators all have variance \(4\sigma^{2}/v\). If no divisor is used, the estimators all have variance \(v\sigma^{2}\). As long as the variances are all equal, the half-normal probability plot can be used to identify the important contrasts. In _all other_ sizes of experiment, the contrast coefficients are not all \(\pm 1\), and we recommend that all contrasts be normalized so that their estimators all have variance \(\sigma^{2}\).

#### Analysis Using Confidence Intervals

In this section, an alternative to the half-normal probability plot is presented for the analysis of a single replicate factorial experiment. As with the half-normal probability plot, we require a set of \(m\) orthogonal contrasts and effect sparsity, and we make no assumptions as to _which_ effects are negligible. The procedure provides confidence intervals for the \(m\) contrasts with a simultaneous confidence level of at least 100(\(1-\alpha\))%. For the moment, we recode the treatment combinations as 1, 2,..., \(v\), their effects as \(\tau_{1}\), \(\tau_{2}\),...\(\tau_{v}\), and we generically denote each of the \(m\) contrasts by \(\sum c_{i}\tau_{i}\).

First, let \(d\) equal the integer part of \((m+1)/2\), which is \(m/2\) if \(m\) is even and is \((m+1)/2\) if \(m\) is odd. The method requires that there be at least \(d\) negligible effects (effect sparsity). In general, this will be true if at least one of the factors has no effect on the response (and so does not interact with any of the other factors) or if most of the higher-order interactions are negligible.

We take each of the \(m\) contrasts in turn. For the \(k\)th contrast \(\sum c_{i}\tau_{i}\), we calculate its least squares estimate \(\sum c_{i}y_{i}\) and its sum of squares \(ssc_{k}\), using rules 10 and 12, p. 211. We then calculate the _quasi mean squared errormsQ\({}_{k}\)_ for the \(k\)th contrast by taking the average of the \(d\) smallest of \(ssc_{1}\),..., \(ssc_{k-1}\), \(ssc_{k+1}\),..., \(ssc_{m}\) (that is, the smallest \(d\) contrast sums of squares ignoring the \(k\)th).

The _Voss-Wang method_ gives simultaneous 100(\(1-\alpha\))% confidence intervals for the \(m\) contrasts, the confidence interval for the \(k\)th contrast being

\begin{table}
\begin{tabular}{c c c c c c c} \hline Effect: & \(A\) & \(B\) & \(C\) & \(D\) & & & \\ Estimate: & 0.1129 & 0.5039 & 1.0027 & 0.2836 & & & \\ \hline Effect: & \(AB\) & \(AC\) & \(AD\) & \(BC\) & \(BD\) & \(CD\) \\ Estimate: & \(-0.0298\) & 0.0090 & 0.0581 & \(-0.0436\) & \(-0.0130\) & 0.0852 \\ \hline Effect: & \(ABC\) & \(ABD\) & \(ACD\) & \(BCD\) & \(ABCD\) & & \\ Estimate: & 0.0090 & 0.0454 & 0.0462 & \(-0.0300\) & 0.0335 & & \\ \hline \end{tabular}
\end{table}
Table 6: Normalized contrast estimates for the drill advance experiment

Figure 7.7: Half-normal probability plot of normalized contrast absolute estimates for the drill advance experiment

\[\sum c_{i}\tau_{i} \in \left(\sum c_{i}y_{i}\pm w_{V}\sqrt{msQ_{k}\sum_{i}c_{i}^{2}}\right)\;. \tag{7.5.5}\]

The critical coefficients \(w_{V}=v_{m,d,\alpha}\) are provided in Appendix A.11. The critical values \(v_{m,d,\alpha}\) were obtained by Voss and Wang (1999) as the square root of the percentile corresponding to \(\alpha\) in the right-hand tail of the distribution of

\[V^{2}=\max\;\left\{SSC_{k}/MSQ_{k}\right\}\;,\]

where the maximum is over \(k=1,2,\ldots,m\).

#### _Example 7.5.3_Drill advance experiment, continued

Consider again the single replicate drill advance experiment of Examples 7.5.1 and 7.5.2 with four factors having two levels each. We can find \(m=15\) orthogonal factorial contrasts, nine of which are shown in Table 7.1, p. 208. The Voss-Wang method of simultaneous confidence intervals, described above, is reasonably effective as long as there are at least \(d=8\) negligible contrasts in this set.

For an overall 95% confidence level, the critical coefficient is obtained from Appendix A.11 as \(w_{V}=v_{15,8,0.05}=9.04\). Selecting divisors \(v/2=8\) for each contrast, we obtain the least squares estimates in Table 7.7.

The sums of squares for the 15 contrasts are also listed in Table 7.7 in descending order. For the contrasts corresponding to each of the seven largest sums of squares, the quasi mean squared error is composed of the eight smallest contrast sums of squares; that is,

\[\text{ms}Q_{k}=(0.0000808+\cdots+0.0020571)/8=0.0009004\,,\]

and the minimum significant difference for each of these seven contrasts is

\begin{table}
\begin{tabular}{c c c c c} \hline Effect & \(ssc_{k}\) & \(msQ_{k}\) & Estimate & \(\text{ms}d_{k}\) \\ \hline \(C\) & 1.0054957 & 0.0009004 & 0.5014 & 0.1356 \\ \(B\) & 0.2538674 & 0.0009004 & 0.2519 & 0.1356 \\ \(D\) & 0.0804469 & 0.0009004 & 0.1418 & 0.1356 \\ \(A\) & 0.0127483 & 0.0009004 & 0.0565 & 0.1356 \\ \(CD\) & 0.0072666 & 0.0009004 & 0.0426 & 0.1356 \\ \(AD\) & 0.0033767 & 0.0009004 & 0.0291 & 0.1356 \\ \(ACD\) & 0.0021374 & 0.0009004 & 0.0231 & 0.1356 \\ \(ABD\) & 0.0020571 & 0.0009105 & 0.0227 & 0.1364 \\ \(BC\) & 0.0019016 & 0.0009299 & \(-0.0218\) & 0.1378 \\ \(ABCD\) & 0.0011250 & 0.0010270 & 0.0168 & 0.1449 \\ \(BCD\) & 0.0008986 & 0.0010553 & \(-0.0150\) & 0.1468 \\ \(AB\) & 0.0008909 & 0.0010563 & \(-0.0149\) & 0.1469 \\ \(BD\) & 0.0001684 & 0.0011466 & \(-0.0065\) & 0.1531 \\ \(ABC\) & 0.0000812 & 0.0011575 & 0.0045 & 0.1538 \\ \(AC\) & 0.0000808 & 0.0011575 & 0.0045 & 0.1537 \\ \hline \end{tabular}
\end{table}
Table 7.7: Confidence interval information for the drill advance experiment \[\text{msd}_{k}=v_{15,8,0.05}\sqrt{msQ_{k}\ (16/(8\times 8))}=(9.04)\sqrt{0.0009004 \times 0.25}\approx 0.1356\,.\]

The quasi mean squared errors for the contrasts corresponding to the eight smallest sums of squares are modestly larger, leading to slightly larger minimum significant differences and correspondingly wider intervals. All contrast estimates and minimum significant differences are summarized in Table 7.

The four largest contrast estimates in absolute value are 0.5014 for \(C\), 0.2519 for \(B\), 0.1418 for \(D\), and 0.0565 for \(A\), giving the intervals

\[\begin{array}{llll}\text{For $C$ :}&0.5014\pm 0.1356&=&(\,0.3658,0.6370)\,,\\ \text{For $B$ :}&0.2519\pm 0.1356&=&(\,0.1163,0.3875)\,,\\ \text{For $D$ :}&0.1418\pm 0.1356&=&(\,0.0062,0.2774)\,,\\ \text{For $A$ :}&0.0565\pm 0.1356&=&(-0.0791,0.1921)\,.\end{array}\]

Thus, in the 95% simultaneous set, the intervals for the main-effect contrasts of \(C\), \(B\), and \(D\) exclude zero and are declared to be the important effects. The intervals for \(A\) and for all of the interaction contrasts include zero, so we conclude that these contrasts are not significantly different from zero. Notice that our conclusion agrees with that drawn from the half-normal probability plot. The benefit of the Voss-Wang method is that we no longer need to guess which contrast estimates lie on the straight line, and also that we have explicit confidence intervals for the magnitudes of the nonnegligible contrasts. 

### Using SAS Software

The analysis of experiments with three or more factors and at least one observation per cell uses the same types of SAS commands as illustrated for two factors in Sect. 6.8. In Sect. 7.6.1, we illustrate the additional commands needed to obtain a half-normal probability plot of the contrast estimates in the drill advance experiment, and in Sect. 7.6.2, we illustrate computations for the Voss-Wang confidence intervals. In Sect. 7.6.3, we show the complications that can arise when one or more cells are empty.

#### Half-Normal Probability Plots of Contrast Estimates

In Table 7.8, we show a SAS program for producing a half-normal probability plot similar to that of Fig. 7.7, p. 223, but for the unnormalized contrast estimates of the drill advance experiment. The levels of \(A\), \(B\), \(C\), and \(D\) together with the responses ADVANCE are entered via the INPUT statement in the first DATA statement. A log transformation is then taken so that the response Y used in the analysis is the log of the units of drill advance. Note that the function LOG10() calculates log to the base 10, whereas LOG() would calculate log to the base \(e\), which is the more usual transformation. The coded factor levels 1 and 2 are converted to contrast coefficients \(-0.5\) and \(+0.5\), respectively (e.g., \(\mathbb{A}=\mathbb{A}\) - 1.5). These coefficients could have been entered directly via the INPUT statement, as shown in Table 6.14, p. 184. The interaction coefficients are obtained by multiplication to also have values \(\pm 0.5\) (e.g., \(\mathtt{AB}=2^{\star}\mathbb{A}^{\star}\mathbb{B}\)). The contrast coefficients are printed as columns similar to those in Table 7.1, p. 208, but with values \(\pm 0.5\).

The regression procedure, PROC REG, is used to compute regression coefficient estimates, which are the desired contrast estimates. Though unnormalized, these estimates can be shown to have common variance \(\sigma^{2}/4\). The option OUTET outputs these contrast estimates to a new data set DRILL2, with one row and many variables. Since the OUTET option saves more variables than needed, a copy of DRILL2 is made which only keeps the variables with the contrast estimates. The NOPRINT option suppresses printing of the procedure's output. (See Chap. 8 for more information about regression.)

In order to be able to plot the estimates, we need them as the different values of a single variable. This is achieved by PROC TRANSPOSE, which turns the single row of the data set DRILL2 into a column in the new data set DRILL3. The resulting least squares estimates are listed as values of the variable EST1. The absolute estimates are then computed and sorted. The absolute estimates could have been normalized by multiplying by two, though we have not done so here.

In the final DATA step, the half-normal scores corresponding to the values of EST1 are calculated as in (7.5.4) the PROBIT function being the inverse cumulative distribution function (cdf) of the standard normal distribution. This final data set is then printed.

Finally, the last procedure in Table 7.8, the statistical graphics plotting procedure PROC SGPLOT, draws a high resolution plot of the absolute contrast estimates versus the half-normal scores. Assuming

\begin{table}
\begin{tabular}{c} DATA DRILL; \\ INPUT A B C D ADVANCE; \\ Y = LOG10(ADVANCE); * log to base 10; \\ * Compute contrast coefficients +/-0.5; \\ A = A - 1.5; B = B - 1.5; C = C - 1.5; D = D - 1.5; \\ AB = 2*A*B; AC = 2*A*C; AD = 2*A*D; BC = 2*B*C; BD = 2*B*D; \\ CD = 2*C*D; \\ ABC = 4*A*B*C; ABD = 4*A*B*D; ACD = 4*A*C*D; BCD = 4*B*C*D; \\ LINES; \\
1 1 1 1 1.68 \\ : : : : : \\
2 2 2 2 16.30 \\ PROC PRINT; \\ \end{tabular}
\end{table}
Table 7.8: SAS program for a half-normal probability plot for the drill advance 24 experiment effect sparsity, the nonnegligible contrasts are those whose estimates do not lie along a straight line through the origin.

#### Voss-Wang Confidence Interval Method

The SAS program in Table 7.9 does most of the computations needed to obtain the Voss-Wang simultaneous confidence intervals (7.5.5) used for analysis of a single-replicate experiment (Sect. 7.5.3). Using the data of the drill advance experiment, the program starts with the DRILL data set created in the program in Table 7.8.

The first call of PROC GLM fits the complete model, providing the estimates and sum of squares for each of the 15 effects, matching the values given in Table 7.7 (p. 224). While this is sufficient information to facilitate applying the Voss-Wang method by hand, the rest of the program provides additional useful computations based on the results of the first procedure call.

First though, a few comments regarding the calls of PROC GLM. With no CLASS statement, PROC GLM fits a regression model, as did PROC REG in Sect. 7.6.1. Analogously, by again using contrast coefficients \(\pm 0.5\), the resulting regression coefficient estimates are again the desired contrast estimates displayed in Table 7.7. The option SS1, while unnecessary, requests output of the Type I sums of squares, thereby suppressing output of the matching Type III sums of squares. The output delivery system statement ODS, also unnecessary, selectively limits output by ODS table name.

Now, given the results of the first call of PROC GLM, consider using SAS software for additional computations for formula (7.5.5). For the \(k\)th effect, the corresponding quasi mean squared error

\begin{table}
\begin{tabular}{l} \hline \hline  • Use the data set DRILL from the prior program; \\ DATA DRILL; SET DRILL; \\  • Fit complete model to obtain the m=15 effect sums of squares; \\ PROC GLM; \\ MODEL Y = A B C D AB AC AD BC BD CD ABC ABD ACD BCD ASCD / SS1; \\ ODS select ModelANOVA ParameterEstimates; \\  • The models fit below depend on the results of the above GLM procedure; \\  • CIs for C, B, D, A, CD, AD, and ACD: compute estimates and standard \\  • errors by omitting the (other) d=8 effects with the 8 smallest SSs; \\ PROC GLM; \\ MODEL Y = C B D A CD AD ACD / SS1; \\ ODS select OverallANOVA ParameterEstimates; \\  • CI for ABC: compute est and stde by omitting d=8 other effects; \\ PROC GLM; \\ MODEL Y = C B D A CD AD BC / SS1; \\ ODS select OverallANOVA ParameterEstimates; \\  • Continue as above for the six remaining effects; \\ \hline \hline \end{tabular}
\end{table}
Table 7.9: SAS program for the Voss–Wang method for the drill advance experiment is most easily calculated as the error mean square obtained from the submodel that omits the terms corresponding to the \(d\) smallest contrast sums of squares besides \(ssc_{k}\). The second and subsequent calls of PROC GLM illustrate these computations for some of the effects.

The second call of PROC GLM fits the model excluding the \(d=8\) effects with the smallest sums of squares from the first call. This yields the value \(mse=msQ_{k}=0.00090004\) given in Table 7.7, needed to compute the confidence intervals (7.5.5) for the other seven effects \(C\), \(B\), \(D\), \(A\), \(CD\), \(AD\) and \(ACD\). Moreover, for each of these seven effects, the SAS software provides a standard error value \(0.01500370\). While this is not a standard error per se, since \(msQ_{k}\) is not an estimate of \(\sigma^{2}\), it is the value of \(\sqrt{msQ_{k}\sum_{i}c_{i}^{2}}\) in formula (7.5.5). The critical values \(v_{m,d,\alpha}\) for the Voss-Wang method are not directly available through SAS, so the intervals must be completed by hand.

The third call of GLM provides the information to compute the confidence interval (7.5.5) for the effect \(ABD\). Since \(ABD\) had one of the eight smallest sums of squares, \(ABD\) is included in the model in place of the term \(ACD\) that had the next smallest sum of squares. This call yields \(mse=msQ_{k}=0.00091049\), matching the value given in Table 7.7, and standard error value \(0.01508716\) for \(ABD\).

Similarly, the fourth call of GLM provides the corresponding information to compute the confidence interval (7.5.5) for the effect \(BC\), and additional calls could be made for the six remaining effects.

#### Experiments with Empty Cells

We now illustrate the use of SAS software for the analysis of an experiment with empty cells. No new SAS procedures or commands are introduced, but the empty cells can cause complications. For illustration, we use the following experiment.

#### _Example 7.6.1_Rail weld experiment

S. M. Wu (1964) illustrated the usefulness of two-level factorial designs using the data listed in the SAS program of Table 7.10. Under investigation were the effects of three factors--ambient temperature (\(T\)), wind velocity (\(V\)), and rail steel bar size (\(S\))--on the ultimate tensile strength of welds. The factor levels were \(0^{\circ}\) and \(70^{\circ}\)F for temperature, 0 and 20 miles per hour for wind velocity, and 4/11 and 11/11 in. for bar size, each coded as levels 1 and 2, respectively. Only six of the possible eight treatment combinations were observed, but \(r=2\) observations were taken on each of these six.

Some SAS commands for analyzing the rail weld experiment are presented in Table 7.10. Notice that rather than listing the two observations for each treatment combination on separate lines, we have listed them as Y1 and Y2 on the same line. We have then combined the observations into the response variable Y. The new variable REP, which will be ignored in the model, is merely a device to keep the observations distinct. This method of input is often useful if the data have been stored in a table, with the observations for the same treatment combinations listed side by side, as in Table 7.2, p. 216.

The three-way complete model is requested in the first call of PROC GLM in Table 7.10. The output is shown in Fig. 7.8. With two cells empty, there are data on only six treatment combinations, so there are only five degrees of freedom available for comparing treatments. This is not enough to measure the three main effects, the three two-factor interactions, and the three-factor interaction. This is indicated in the output, since two effects have zero degrees of freedom. The ESTIMATE statement for the contrast under the first call of PROC GLM generates no output. Instead, it generates a note in the SAS log indicating that the contrast is not estimable.

The only model that can be used is one that uses at most five degrees of freedom. Of course, this should be anticipated ahead of time during step (g) of the checklist (Chap. 2). Figure 7.9 illustrates with a solid ball at the corresponding corners of the cube the treatment combinations for which data are 

[MISSING_PAGE_FAIL:251]

\begin{table}
\begin{tabular}{c c c c c c c c} TC & \(T\) & \(V\) & \(TV\) & \(S\) & \(TS\) & \(VS\) & \(TVS\) \\
111 & \(-1\) & \(-1\) & \(1\) & \(-1\) & \(1\) & \(-1\) \\
112 & \(-1\) & \(-1\) & \(1\) & \(1\) & \(-1\) & \(-1\) & \(1\) \\
211 & \(1\) & \(-1\) & \(-1\) & \(-1\) & \(-1\) & \(1\) & \(1\) \\
212 & \(1\) & \(-1\) & \(-1\) & \(1\) & \(1\) & \(-1\) & \(-1\) \\
221 & \(1\) & \(1\) & \(1\) & \(-1\) & \(-1\) & \(-1\) & \(-1\) \\
221 & \(1\) & \(1\) & \(1\) & \(-1\) & \(-1\) & \(-1\) & \(-1\) \\
222 & \(1\) & \(1\) & \(1\) & \(1\) & \(1\) & \(1\) & \(1\) \\ \end{tabular}
\end{table}
Table 7.11: Contrast coefficients for the observed treatment combinations (T.C.) in the rail weld experiment

Figure 7.8: Output from the first call of PROC GLM for the rail weld experiment

Figure 7.9: Treatment combinations included in the design of the rail weld experiment

### Using R Software

The analysis of experiments with three or more factors and at least one observation per cell uses the same types of R commands as illustrated for two factors in Sect. 6.9. In Sect. 7.7.1, we illustrate the additional commands needed to obtain a half-normal probability plot of the normalized contrast estimates in the drill advance experiment, and in Sect. 7.7.2, we illustrate computations for the Voss-Wang confidence intervals. In Sect. 7.7.3, we show the complications that can arise when one or more cells are empty.

#### Half-Normal Probability Plots of Contrast Estimates

In Table 7.12, we show an R program for producing a half-normal probability plot similar to that of Fig. 7.7, p. 223, for the normalized contrast estimates of the drill advance experiment. The levels of \(A\), \(B\), \(C\), and \(D\) together with the responses Advance are read from file into the data set drill.data. A log transformation is then taken so that the response y = log10(Advance) used in the analysis is the log of the units of drill advance. Note that the function log10() calculates log to the base 10, whereas log() would calculate log to the base \(e\), which is the more usual transformation. Also in the second block of code, the coded factor levels 1 and 2 are converted to contrast coefficients \(-1\) and \(+1\), respectively, (e.g. for each factor, 2*(1) - 3 -> -1 and 2*(2) - 3 -> +1). These coefficients could have been entered directly into and read directly from the data file.

In the second block of code, the linear model function lm fits the linear regression model y ~ A*B*C*D, saving the fitted model coefficient estimates and other information as model1. The syntax A*B*C*D causes all main effect and interaction coefficients for A, B, C, and D to be included in the model as regressors or predictors of y. The interaction coefficients are obtained by multiplication to also have values \(\pm 1\) (e.g., AB = A*B). The statement model1$coefficients

Figure 7.10: Output from the second call of PROC GLMdisplays the regression coefficient estimates which are half the value of the contrast estimates, including the intercept estimate. (See Chap. 8 for more information about regression.)

The last block of code calls the qqnorm.aov function of the gplots package. This function takes the estimates of the coefficients excluding the intercept, normalizes them, then generates the desired half-normal plot, plotting the normalized absolute contrast estimates versus the half-normal scores. Assuming effect sparsity, the nonnegligible contrasts are those whose estimates do not lie along a straight line through the origin.

#### Voss-Wang Confidence Interval Method

The R program in Table 7.13 illustrates computation of the Voss-Wang simultaneous confidence intervals (7.5.5) for analysis of a single-replicate experiment (Sect. 7.5.3), using the data of the drill advance experiment. The levels of \(A\), \(B\), \(C\), and \(D\) together with the responses Advance are read from file into the data set drill.data, and the response y = log10(Advance)--the log base 10 of Advance--is added to the data set. The levels of the factors _A_-_D_ are then converted from 1 and 2 to -1 and +1, respectively.

In the second block of code, the linear model function lm is used to fit the linear regression model y ~ A*B*C*D, saving the results as model1. The model is a regression model because the factors are not factor variables (See Chap. 8). The syntax A*B*C*D causes all main effects and interactions involving the variables \(A\), \(B\), \(C\) and \(D\) to be included in the model. The information saved includes the regression coefficient estimate and corresponding Type I sum of square for each of the 15 effects. The regression coefficients represent half the corresponding treatment effects of interest, because of the use of contrast coefficients + which are 2 units apart. The statement

 estimate = 2*(model1Scoefficients[2:16])

doubles the coefficient estimates to obtain the usual treatment contrast (effect) estimates (i.e. the difference of two averages), discards the first coefficient estimate corresponding to the intercept, and saves the 15 treatment contrast estimates as estimate. If one would display the analysis of variance

\begin{table}
\begin{tabular}{c} \# Input data for A, B, C, D and Advance \\ drill.data = read.table(*data/drill.advance.txt*, header=T) \\ \# Compute log advance, and convert levels 1 and 2 to coeff’s -1 and 1, resp. \\ drill.data = within(drill.data, \\ { y = log10(Advance); A = 2*A-3; B = 2*B-3; C = 2*C-3; D = 2*D-3 }) \\ head(drill.data, 3) \\ \end{tabular}
\end{table}
Table 7.12: R program for a half-normal probability plot for the drill advance 24 experiment 

[MISSING_PAGE_FAIL:255]

compute the \(i\)th value msQ[i] for msQ, sse is assigned the value of the sum of the eight smallest sums of squares. For the \(i\)th effect, msQ[i] is the average of the eight smallest sums of squares, excluding the value SS[i] corresponding to the effect. The first for statement assigns the common value msQ[i]=sse/8 to each of the first seven cells of msQ, since the corresponding effects do not have sum of squares SS[i] in the smallest eight. The second for statement computes msQ[i] for each of the last eight effects, i.e. for \(i=8,\ldots,15\), where msQ[i] for the \(i\)th effect excludes the corresponding sum of squares SS[i] but includes the ninth smallest, SS[7]. The estimates were scaled to correspond to estimators with variance \(\sigma^{2}/4\) so, using the quasi mean squared error msQ like an estimate of \(\sigma^{2}\), the standard errors are estimated as stde = sqrt(msQ/4). While these are not standard errors per se, they are the values of \(\sqrt{msQ_{k}\sum_{i}c_{i}^{2}}\) in formula (7.5.5). So, for each effect, the minimum significant difference is msd = 9.04*stde, where the critical value \(v_{15,8,0.05}=9.04\) is obtained from Appendix A.11. The lower and upper confidence limit columns LCL and UCL are then computed as estimate=msQ. Finally, the pertinent information is column-bound and displayed in the bottom of Table 7.13, with values rounded to five decimal places.

#### Experiments with Empty Cells

We now illustrate the use of R software for the analysis of an experiment with empty cells. No new R procedures or commands are introduced, but the empty cells can cause complications. For illustration, we use the following experiment.

#### _Example 7.7.1_Rail weld experiment

Wu (1964) illustrated the usefulness of two-level factorial designs using the data listed in Table 7.11. Under investigation were the effects of three factors--ambient temperature (\(T\)), wind velocity (\(V\)), and rail steel bar size (\(S\))--on the ultimate tensile strength of welds. The factor levels were \(0^{\circ}\) and \(70^{\circ}\)F for temperature, 0 and 20 miles per hour for wind velocity, and 4/11 and 11/11 in. for bar size, each coded as levels 1 and 2, respectively. Only six of the possible eight treatment combinations were observed, but \(r=2\) observations were taken on each of these six.

Some R commands for analyzing the rail weld experiment are presented in Table 7.14. In the first block of code, the data are read from file into the data set rail.data, factor variables are added to the data set, then three lines of data are displayed.

In the second block of code, an attempt is made to fit the three-way complete model, and lsmeans is used in an attempt to estimate the main effect of temperature T. Partial output is shown in Table 7.15. With two cells empty, there are data on only six treatment combinations, so there are only five degrees of freedom available for comparing treatments. This is not enough to measure the three main effects, the three two-factor interactions, and the three-factor interaction. This is indicated by the analysis of variance table, since it includes only five degrees of freedom for effects, with the effects fT:fS and fT:fV:fS unlisted. Also, the estimate of the least squares mean for \(T=1\) is listed as not applicable (NA) because it is not estimable, due to the lack of data at two of the four \(VS\) combinations at level 1 of \(T\). Consequently, the command

\[\texttt{summary}(\texttt{contrast}(\texttt{lsmT},\texttt{ list}(\texttt{T=c(-1,1))}),\texttt{ infer=c(T,T)})\]

is also non-applicable so generates no output.

To estimate contrasts, one must use a model with at most five estimable degrees of freedom. Of course, this should be anticipated ahead of time during step (g) of the checklist (Chap. 2). Figure 7.9 (p. 230) illustrates with a solid ball at the corresponding corners of the cube the treatment combinationsfor which data are collected. One might guess that the _TV_ interaction effect is not estimable, since data are only collected at three of the four combinations of levels of these two factors.

One possibility is to exclude from the complete model those interactions for which the type I degrees of freedom are zero, namely the _TV_ and _TVS_ interaction effects. The contrast coefficient lists for the seven factorial effects are shown in Table 16. It is clear that the \(T\) and \(V\) contrasts are not orthogonal to the _TV_ interaction contrast, and that the \(S\), _TS_, and _VS_ contrasts are not orthogonal to the _TVS_ interaction contrast. Consequently, the incorrect omission of _TV_ and _TVS_ from the model will bias the estimates of all the other contrasts. If we do decide to exclude both the _TV_ and _TVS_ interaction effects, then the model is of the form

\[Y_{ijkl}=\mu+\alpha_{i}+\beta_{j}+\gamma_{k}+(\alpha\gamma)_{ik}+(\beta\gamma)_ {ji}+\epsilon_{ijkl}\,.\]

We illustrate analysis of this model beginning with the third block of code in Table 14. The aov function fits the above model, saving the results as model2. The options statement imposes "sum

\begin{table}
\begin{tabular}{c} \# Input data for T V S y \\ rail.data = read.table(*data/rail.weld.txt*, header=T) \\ \# Create factor variables, then display first 3 lines of rail.data \\ rail.data = within(rail.data, \\ { fT = factor(T); fV = factor(V); fS = factor(S) }) \\ head(rail.data, 3) \\ \end{tabular}
\end{table}
Table 14: R program for the rail weld experiment with two empty cellsto zero" constraints on least squares estimates as needed to generate the correct Type III analysis of variance. The anova and dropl statements generate Type I and Type III analyses, respectively, shown in the top of Table 7.17.

The contrasts for \(T\) and \(V\) are not orthogonal to each other, but they can be estimated (although with a small positive correlation). Similar comments apply to the \(S\), \(TS\), and \(VS\) contrasts. The lsmeans, summary, and contrast statements of the lsmeans package are used to estimate least square means and contrasts, and also for multiple comparisons of the levels of a factor or the combinations of levels of multiple factors. Appropriate syntax is illustrated by the last three blocks of code in Table 7.14. Sample output for factor \(T\), including least squares means and the pairwise contrast, is given in the bottom of Table 7.17.

\begin{table}
\begin{tabular}{c c c c c c c c} \hline TC & \(T\) & \(V\) & \(TV\) & \(S\) & \(TS\) & \(VS\) & \(TVS\) \\ \hline
111 & \(-1\) & \(-1\) & \(1\) & \(-1\) & \(1\) & \(-1\) \\
112 & \(-1\) & \(-1\) & \(1\) & \(-1\) & \(-1\) & \(1\) \\
211 & \(1\) & \(-1\) & \(-1\) & \(-1\) & \(1\) & \(1\) \\
212 & \(1\) & \(-1\) & \(-1\) & \(1\) & \(1\) & \(-1\) \\
221 & \(1\) & \(1\) & \(-1\) & \(-1\) & \(-1\) & \(-1\) \\
222 & \(1\) & \(1\) & \(1\) & \(1\) & \(-1\) & \(-1\) & \(-1\) \\
222 & \(1\) & \(1\) & \(1\) & \(1\) & \(1\) & \(1\) & \(1\) \\ \hline \end{tabular}
\end{table}
Table 7.16: Contrast coefficients for the observed treatment combinations (TC) in the rail weld experiment

\begin{table}
\begin{tabular}{c c c c c} \hline TC & \(T\) & \(V\) & \(TV\) & \(S\) & \(TS\) & \(VS\) & \(TVS\) \\ \hline
111 & \(-1\) & \(-1\) & \(1\) & \(-1\) & \(1\) & \(-1\) \\
112 & \(-1\) & \(-1\) & \(1\) & \(-1\) & \(-1\) & \(1\) \\
211 & \(1\) & \(-1\) & \(-1\) & \(-1\) & \(1\) & \(1\) \\
212 & \(1\) & \(-1\) & \(-1\) & \(1\) & \(1\) & \(-1\) \\
221 & \(1\) & \(1\) & \(-1\) & \(-1\) & \(-1\) & \(-1\) \\
222 & \(1\) & \(1\) & \(1\) & \(1\) & \(1\) & \(1\) & \(1\) \\ \hline \end{tabular}
\end{table}
Table 7.15: Output from 3-way complete model for the rail weld experiment * > anova(model2) # Type I ANOVA

Analysis of Variance Table

Response: y  Df Sum Sq Mean Sq F value Pr(>F)  fT 1 138 138.2 1.99 0.21  fV 1 79 79.4 1.14 0.33  fS 1 0 0.0 0.00 0.99  fT:fs 1 107 106.7 1.53 0.26  fV:fs 1 25 25.2 0.36 0.57  Residuals 6 418 69.6

 > drop1(model2, ~., test="F") # Type III ANOVA

 Single term deletions

 Model:  y ~ fT + fV + fs + fT:fs + fV:fs  Df Sum of Sq RSS AIC F value Pr(>F)  <none> 418 54.6  fT 1 214.2 632 57.6 3.08 0.13  fV 1 79.4 497 54.7 1.14 0.33  fS 1 29.6 447 53.4 0.43 0.54  fT:fs 1 131.2 549 55.9 1.88 0.22  fV:fs 1 25.2 443 53.3 0.36 0.57

 > lsmT = lsmeans(model2, ~ fT); lsmT

 fT lsmean SE df lower.CL upper.CL  1 80.15 5.1100 6 67.646 92.654  2 90.50 2.9502 6 83.281 97.719

 Results are averaged over the levels of: fV, fs  Confidence level used: 0.95

Consistent with the results of the Type III analysis of variance, none of the contrasts estimates generated by the R program in Table 7.14 would appear particularly strong, (only one is shown in Table 7.14). 

## Exercises

1. For the following hypothetical data sets of Sect. 7.2.2 reproduced below, draw interaction plots to evaluate the \(BC\) and \(ABC\) interaction effects, with levels of \(B\) on the horizontal axis and levels of

\begin{table}
\begin{tabular}{c c c c c} \hline \hline \multicolumn{2}{c}{} & \multicolumn{1}{c}{\(>\) anova(model2) \# Type I ANOVA} \\ \multicolumn{2}{c}{Analysis of Variance Table} \\ \multicolumn{2}{c}{Response: y  Df Sum Sq Mean Sq F value Pr(>F)} \\ \multicolumn{2}{c}{fT} & 1 & 138 & 138.2 & 1.99 & 0.21 \\ \multicolumn{2}{c}{fV} & 1 & 79 & 79.4 & 1.14 & 0.33 \\ \multicolumn{2}{c}{fS} & 1 & 0 & 0.0 & 0.00 & 0.99 \\ \multicolumn{2}{c}{fT:fs} & 1 & 107 & 106.7 & 1.53 & 0.26 \\ \multicolumn{2}{c}{fV:fs} & 1 & 25 & 25.2 & 0.36 & 0.57 \\ \multicolumn{2}{c}{Residuals} & 6 & 418 & 69.6 & & \\ \hline \hline \end{tabular}
\end{table}
Table 7.17: Partial output from the second call of aovfor labels. In each case, comment on the apparent presence or absence of \(BC\) and \(ABC\) interaction effects. 1. \(ijk\ :\ 111\) 112 121 122 211 212 221 222 311 312 321 322 \(\overline{\hat{y}}_{ijk.}\ :\ 3.0\) 4.0 1.5 2.5 2.5 3.5 3.0 4.0 3.0 4.0 1.5 2.5 \(ijk\ :\ 111\) 112 121 122 211 212 221 222 311 312 321 322 \(\overline{\hat{y}}_{ijk.}\ :\ 3.0\) 2.0 1.5 4.0 2.5 3.5 3.0 4.0 3.0 5.0 3.5 6.0
2. In planning a five-factor experiment, it is determined that the factors \(A\), \(B\), and \(C\) might interact and the factors \(D\) and \(E\) might interact but that no other interaction effects should be present. Draw a line graph for this experiment and give an appropriate model.
3. Consider an experiment with four treatment factors, \(A\), \(B\), \(C\), and \(D\), at \(a\), \(b\), \(c\), and \(d\) levels, respectively, with \(r\) observations per treatment combination. Assume that the four-way complete model is a valid representation of the data. Use the rules of Sect. 7.3 to answer the following. 1. Find the number of degrees of freedom associated with the \(AC\) interaction effect. 2. Obtain an expression for the sum of squares for \(AC\). 3. Give a rule for testing the hypothesis that the \(AC\) interaction is negligible against the alternative hypothesis that it is not negligible. How should the results of the test be interpreted, given the other terms in the model? 4. Write down a contrast for measuring the \(AC\) interaction. Give an expression for its least squares estimate and associated variance. 5. Give a rule for testing the hypothesis that your contrast in part (d) is negligible.
4. **Popcorn-microwave experiment, continued** In the popcorn-microwave experiment of Sect. 7.4 (p. 213), the experimenters studied the effects of popcorn brand, microwave oven power, and cooking time on the percentage of popped kernels in packages of microwave popcorn. Suppose that, rather than using a completely randomized design, the experimenters first collected all the observations for one microwave oven, followed by all observations for the other microwave oven. Would you expect the assumptions on the three-way complete model to be satisfied? Why or why not?
5. **Weathering experiment** An experiment is described in the paper "Accelerated weathering of marine fabrics"(Moore, M. A. and Epps, H. H., _Journal of Testing and Evaluation_ 20, 1992, 139-143). The purpose of the experiment was to compare the effects of different types of weathering on the breaking strength of marine fabrics used for sails. The factors of interest were \(F\): Fabric at 3 levels (1 = polyester, 2 = acrylic, 3 = nylon). \(E\): Exposure conditions (1 = continuous light at 62.7 degC, 2 = alternating 30 min light and 15 min condensation). \(A\): Exposure levels (1 = 1200 AFU, 2 = 2400 AFU, 3 = 3600 AFU). \(D\): Direction of cut of the fabric (1 = warp direction, 2 = filling direction). In total there were \(v=3\times 2\times 3\times 2\) = 36 treatment combinations, and \(r\) = 2 observations were taken on each. The response variable was "percent change in breaking strength of fabric after exposure to weathering conditions." The average response for each of the 36 treatment combinations is shown in Table 7.18. The error mean square was calculated to be 6.598 with 36 degrees of freedom.

1. How would you decide whether or not the error variables have approximately the same variance for each fabric? 2. Using the cell-means model, test the hypothesis \(H_{0}:[\tau_{1}=\cdots=\tau_{36}]\) against the alternative hypothesis \(H_{A}:[\)at least two \(\tau_{i}\)'s differ\(]\). What can you conclude? 3. Write down a contrast in the treatment combinations that compares the polyester fabric with the nylon fabric. Is your contrast estimable? 4. If your contrast in (c) is estimable, give a formula for the least squares estimator and its variance. Otherwise, go to part (e). 5. Assuming that you are likely to be interested in a very large number of contrasts and you want your overall confidence level to be 95%, calculate a confidence interval for any pairwise comparison of your choosing. What does the interval tell you? 6. Calculate a 90% confidence bound for \(\sigma^{2}\). 7. If you were to repeat this experiment and you wanted your confidence interval in (e) to be of length at most 20%, how many observations would you take on each treatment combination?
6. **Weathering experiment, continued** Suppose you were to analyze the weathering experiment described in Exercise 5 using a four-way complete model. 1. What conclusions can you draw from the analysis of variance table? 2. Give an explicit formula for testing that the _FA_-interaction is negligible. 3. Would confidence intervals for differences in fabrics be of interest? If not, why not? If so, how would they be interpreted? Give a formula for such confidence intervals assuming that these intervals are preplanned and are the only intervals envisaged, and the overall level is to be at least 99%. 4. In the original paper, the authors write "Fabric direction (\(D\)) had essentially no effect on percent change in breaking strength for any of the fabrics." Do you agree with this statement? Explain. 
\begin{table}
\begin{tabular}{c c c c c c} \hline Exposure & AFU & Direction & & Fabric (F) \\ (E) & (A) & (D) & 1 & 2 & 3 \\ \hline
1 & 1 & 1 & \(-43.0\) & \(-1.7\) & \(-74.7\) \\  & & 2 & \(-46.1\) & \(+11.7\) & \(-86.7\) \\  & 2 & 1 & \(-45.3\) & \(-4.2\) & \(-87.9\) \\  & & 2 & \(-51.3\) & \(+10.0\) & \(-97.9\) \\  & 3 & 1 & \(-53.3\) & \(-5.1\) & \(-98.2\) \\  & & 2 & \(-54.5\) & \(+7.5\) & \(-100.0\) \\
2 & 1 & 1 & \(-48.1\) & \(-6.8\) & \(-85.0\) \\  & & 2 & \(-43.6\) & \(-3.3\) & \(-91.7\) \\  & 2 & 1 & \(-52.3\) & \(-4.2\) & \(-100.0\) \\  & & 2 & \(-53.8\) & \(-3.3\) & \(-100.0\) \\  & 3 & 1 & \(-56.5\) & \(-5.9\) & \(-100.0\) \\  & & 2 & \(-56.4\) & \(-6.7\) & \(-100.0\) \\ \hline \end{tabular} _Source_ Moore and Epps (1992). Copyright © ASTM. Reprinted with permission

\end{table}
Table 18: Percent change in breaking strength of fabrics after exposure 7. **Coating experiment** P. Saravanan, V. Selvarajan, S. V. Joshi, and G. Sundararajan (2001, _Journal of Physics D: Applied Physics_) described an experiment to study the effect of different spray parameters on thermal spray coating properties. In the experiment, the authors attempted to produce high-quality alumina (Al2O3) coatings by controlling the fuel ratio (factor \(A\) at 1:2.8 and 1:2.0), carrier gas flow rate (factor \(B\) at 1.33 and 3.21L s-1), frequency of detonations (factor \(C\) at 2 and 4 Hz), and spray distance (factor \(D\) at 180 and 220 mm). To quantify the quality of the coating, the researchers measured multiple response variables. In this example we will examine the porosity (vol. %). The data are shown in Table 7.19. 1. Assuming that 3- and 4-factor interactions are negligible, outline an analysis that you would wish to perform for such an experiment (step (g) of the checklist; see Chap. 2). 2. Check the assumptions on your model. 3. Carry out the analysis that you outlined in part (a), including drawing any interaction plots that may be of interest. State your conclusions clearly.
8. **Paper towel strength experiment** Burt Beiter, Doug Fairchild, Leo Russo, and Jim Wirtley, in 1990, ran an experiment to compare the relative strengths of two similarly priced brands of paper towel under varying levels of moisture saturation and liquid type. The treatment factors were "amount of liquid" (factor \(A\), with levels 5 and 10 drops coded 1 and 2), "brand of towel" (factor \(B\), with levels coded 1 and 2), and "type of liquid" (factor \(C\), with levels "beer" and "water" coded 1 and 2). A 2 x 2 x 2 factorial experiment with \(r\) = 3 was run in a completely randomized design. The resulting data, including run order, are given in Table 7.20. 1. The experimenters assumed only factors \(A\) and \(B\) would interact. Specify the corresponding model. 2. List all treatment contrasts that are likely to be of primary interest to the experimenters. 3. Use residual plots to evaluate the adequacy of the model specified in part (a). 4. Provide an analysis of variance table for this experiment, test the various effects, show plots of significant main effects and interactions, and draw conclusions.

\begin{table}
\begin{tabular}{c c c c c c c c c} \hline \(A\) & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 \\ \(B\) & 2 & 2 & 2 & 2 & 1 & 1 & 1 & 1 \\ \(C\) & 2 & 2 & 1 & 1 & 2 & 2 & 1 & 1 \\ \(D\) & 2 & 1 & 2 & 1 & 2 & 1 & 2 & 1 \\ _y__ijkl_ & 5.95 & 4.57 & 4.03 & 2.17 & 3.43 & 1.02 & 4.25 & 2.13 \\ \hline \(A\) & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\ \(B\) & 2 & 2 & 2 & 2 & 1 & 1 & 1 & 1 \\ \(C\) & 2 & 2 & 1 & 1 & 2 & 2 & 1 & 1 \\ \(D\) & 2 & 1 & 2 & 1 & 2 & 1 & 2 & 1 \\ _y__ijkl_ & 12.28 & 9.57 & 6.73 & 6.07 & 8.49 & 4.92 & 6.95 & 5.31 \\ \hline \end{tabular} _Source_ Data adapted from Saravanan et al. (2001). Published by the Journal of Physics D: Applied Physics

\end{table}
Table 7.19: Data for the coating experiment * Construct confidence intervals for each of the treatment contrasts that you listed in part (b), using an appropriate method of multiple comparisons. Discuss the results.
9. **Rocket experiment** S. R. Wood and D. E. Hartvigsen describe an experiment in the 1964 issue of _Industrial Quality Control_ on the testing of an auxiliary rocket engine. According to the authors, the rocket engine must be capable of satisfactory operation after exposure to environmental conditions encountered during storage, transportation, and the in-flight environment. Four environmental factors were deemed important. These were vibration (Factor \(A\); absent, present, coded 0, 1), temperature cycling (Factor \(B\); absent, present, coded 0, 1), altitude cycling (Factor \(C\); absent, present, coded 0, 1) and firing temperature/altitude (Factor \(D\), 4 levels, coded 0, 1, 2, 3). The response variable was "thrust duration," and the observations are shown in Table 7.21, where _Ck_ and _Dl_ denote the _k_th level of \(C\) and the _l_th level of \(D\), respectively. The experimenters were willing to assume that the 3-factor and 4-factor interactions were negligible. 1. State a reasonable model for this experiment, including any assumptions on the error term. 2. How would you check the assumptions on your model? 3. Calculate an analysis of variance table and test any relevant hypotheses, stating your choice of the overall level of significance and your conclusions. 4. Levels 0 and 1 of factor \(D\) represent temperatures -75degF and 170degF, respectively at sea level. Level 2 of \(D\) represents -75degF at 35,000 ft. Suppose the experimenters had been interested in

\begin{table}
\begin{tabular}{c c c c c c c c c} \hline  & & \multicolumn{3}{c}{\(C_{0}\)} & \multicolumn{3}{c}{\(C_{1}\)} \\ \cline{3-10} \(A\) & \(B\) & \(D\)0 & \(D\)1 & \(D\)2 & \(D\)3 & \(D\)0 & \(D\)1 & \(D\)2 & \(D\)3 \\ \hline
0 & 0 & 21.60 & 11.54 & 19.09 & 13.11 & 21.60 & 11.50 & 21.08 & 11.72 \\
0 & 1 & 21.09 & 11.14 & 21.31 & 11.26 & 22.17 & 11.32 & 20.44 & 12.82 \\
1 & 0 & 21.60 & 11.75 & 19.50 & 13.72 & 21.86 & 9.82 & 21.66 & 13.03 \\
1 & 1 & 19.57 & 11.69 & 20.11 & 12.09 & 21.86 & 11.18 & 20.24 & 12.29 \\ \hline Total & 83.86 & 46.12 & 80.01 & 50.18 & 87.49 & 43.82 & 83.42 & 49.86 \\ \hline \end{tabular} _Source_ Wood and Hartvigsen (1973). Copyright © 1964 American Society for Quality. Reprinted with permission

\end{table}
Table 7.20: Data for paper towel strength experiment: \(A\) = “amount of liquid,” \(B\) = “brand of towel,” and \(C\) = “liquid type”

[MISSING_PAGE_FAIL:264]

respectively. The experimenters were willing to assume that the 4-factor and 5-factor interactions were negligible. 1. Test any relevant hypotheses, at a 0.05 overall level of significance, and state your conclusions. 2. Draw an interaction plot for the \(AE\) interaction. Does the plot show what you expected it to show? Why or why not? (Mention \(AE\), \(A\), and \(E\).) 3. The spectrometer manual recommends that the placement of the sample be at level 2. Using level 2 as a control level, give confidence intervals comparing the other placements with the control placement. You may assume that these comparisons were preplanned. State which method you are using and give reasons for your choice. Use an overall confidence level of at least 98% for these two intervals. 4. Test the hypotheses of no linear and quadratic trends in the manganese measurements due to temperature. Use a significance level of 0.01 for each test.
11. **Antifungal antibiotic experiment** M. Gupte and P. Kulkarni (2003, _Journal of Chemical Technology and Biotechnology_) described an experiment to maximize the yield of an antifungal antibiotic from the isolate _Thermononospora sp MTCC 3340_. The researchers examined the effect of the three factors temperature of incubation (factor \(A\) at 25, 30, and 37 C), concentration of carbon (factor \(B\) at 2, 5, and 7.5%), and concentration of nitrogen (factor \(C\) at 0.5, 1, and 3%) on the antifungal yield which was measured in terms of activity against _Candida albicans_, a type of fungus that can be detrimental to humans. The data are shown in Table 7.23. 1. Construct appropriate plots to assess whether any of the main effects seem to have a significant effect on the response. What do you conclude? 2. What assumption regarding interactions did you make while drawing your conclusion in part (a)? 3. Construct an appropriate plot to asses the significance of two-way interactions. Do any two-way interactions seem to have a significant effect on the response? If so, does this affect your conclusions from part (c)? 4. Suppose there is reason to believe that the three factors do not jointly interact. Fit a model that includes all main effects and two-way interactions. What effects do you find to be significant? How does this compare with your conjectures from part (c)? 5. Do the assumptions of normality and equal error variances hold for the model considered in part (d)? Are there any outliers?
12. **Antifungal antibiotic experiment, continued** Consider the data from Table 7.23, but without assuming that the three-factor interaction is negligible. Also, for the purposes of this particular exercise, we change the third levels of factors \(A\) and \(B\) to be 35 and 8, respectively, so that their levels are equally spaced. 1. Make a table similar to that of Table 7.1, p. 208, with the first column containing the 27 treatment combinations for the antifungal antibiotic experiment in ascending order. List the contrast coefficients for the main effect trend contrasts: Linear \(A\), Quadratic \(A\), Linear \(B\), and Quadratic \(B\). Also list the contrast coefficients for the interaction trend contrasts Linear \(A\times\) Linear \(B\), Linear \(A\times\) Quadratic \(B\), Quadratic \(A\times\) Linear \(B\), Quadratic \(A\times\) Quadratic \(B\).

[MISSING_PAGE_FAIL:266]

[MISSING_PAGE_FAIL:267]

16. **Ice melting experiment** An experiment to gain a better understanding of the role of various substances in melting ice was run in 2004 by Shuangling He, Mimi Lou, Xiaozhou Xiong, Li Yu, and Yihong Zhao. For each observation, a 10 ml block of ice was placed into water containing a given concentration of sugar, or salt, or a sugar and salt mix. The melting time for the ice block was measured in seconds and then converted to minutes. The three factors of interest were shape of ice block (factor \(A\) with levels 1 - lozenge, 2 - cylinder, and 3 - cube), solute (factor \(B\) with levels 1 - sugar, 2 - salt, and 3 - equal parts sugar and salt), and concentration (factor \(C\) at 5%, 10% 15%, 20%; coded 1, 2, 3, 4).

The experiment was run as a completely randomized design and the resulting data are shown in Table 7.26. There are two observations on each treatment combination.

\begin{table}
\begin{tabular}{c c c c|c c c|c c} Concentration & \multicolumn{6}{c|}{Lozenge} \\  & \multicolumn{3}{c|}{Sugar} & \multicolumn{3}{c|}{Salt} & \multicolumn{3}{c}{Sugar/Salt} \\
5\% & 54.25 & 53.33 & 37.17 & 37.50 & 42.75 & 43.83 \\
10\% & 52.50 & 52.25 & 28.33 & 28.83 & 39.33 & 40.00 \\
15\% & 47.25 & 48.00 & 21.17 & 21.33 & 35.83 & 37.00 \\
20\% & 43.83 & 44.33 & 15.50 & 16.33 & 25.50 & 26.17 \\ Concentration & \multicolumn{6}{c|}{Cylinder} \\  & \multicolumn{3}{c|}{Sugar} & \multicolumn{3}{c|}{Salt} & \multicolumn{3}{c}{Sugar/Salt} \\
5\% & 87.00 & 85.83 & 64.33 & 62.83 & 76.50 & 77.17 \\
10\% & 83.50 & 82.00 & 51.83 & 51.50 & 67.08 & 67.33 \\
15\% & 78.50 & 79.50 & 36.00 & 37.33 & 55.50 & 55.67 \\
20\% & 69.00 & 67.83 & 25.00 & 25.50 & 45.83 & 46.50 \\ Concentration & \multicolumn{6}{c|}{Cube} \\  & \multicolumn{3}{c|}{Sugar} & \multicolumn{3}{c|}{Salt} & \multicolumn{3}{c}{Sugar/Salt} \\
5\% & 65.83 & 65.00 & 54.00 & 53.17 & 55.17 & 54.83 \\
10\% & 61.83 & 62.50 & 42.50 & 43.83 & 47.00 & 48.50 \\
15\% & 57.50 & 58.67 & 33.00 & 32.50 & 43.50 & 44.83 \\
20\% & 54.50 & 55.00 & 27.50 & 28.33 & 36.71. Explain briefly what you would randomize if you were running this experiment and why randomization might be important here. 2. If the experiment had to be run in two labs with a different technician in each lab, how would you change the design and the randomization? 3. Use the three-way complete model (7.2.2) and state the error assumptions on the model. Check these assumptions are valid. 4. Test the single hypothesis that lozenge shaped ice blocks melt faster than the other two shapes on average (averaged over solutes and concentrations). State your null and alternative hypotheses and use significance level 0.01. 5. Now consider the equivalent cell-means model shown in (7.2.1) with the error assumptions that you listed in part (c) and \(i=1,2,3;\;\;j=1,2,3;\;\;k=1,2,3,4;\;\;t=1,2\). 1. Give a formula for a set of 95% set of confidence intervals for the true differences in the effects of the treatment combinations. Which method are you using? 2. Using the method in (i), calculate a confidence interval for the difference between the melting times for a cylinder-shaped ice block with 5% concentration of sugar, and a cube-shaped ice block with 20% concentration of salt. 6. Obtain a 90% upper confidence bound for \(\sigma^{2}\).

### 8.1 Introduction

In each of the previous chapters we were concerned with experiments that were run as completely randomized designs for the purpose of investigating the effects of one or more treatment factors on a response variable. Analysis of variance and methods of multiple comparisons were used to analyze the data. These methods are applicable whether factor levels are qualitative or quantitative.

In this chapter, we consider an alternative approach for quantitative factors, when the set of possible levels of each factor is real-valued rather than discrete. We restrict attention to a single factor and denote its levels by \(x\). The mean response \(E[Y_{x\,l}]\) is modeled as a polynomial function of the level \(x\) of the factor, and the points \((x,\,E[Y_{x\,l}])\) are called the _response curve_. For example, if \(E[Y_{x\,l}]=\beta_{0}+\beta_{1}x\) for unknown parameters \(\beta_{0}\) and \(\beta_{1}\), then the mean response is a linear function of \(x\) and the response curve is a line, called the _regression line_. Using data collected at various levels \(x\), we can obtain estimates \(\hat{\beta}_{0}\) and \(\hat{\beta}_{1}\) of the intercept and slope of the line. Then \(\hat{y}_{x}=\hat{\beta}_{0}+\hat{\beta}_{1}x\) provides an estimate of \(E[Y_{x\,l}]\) as a function of \(x\), and it can be used to estimate the mean response or to predict the values of new observations for any factor level \(x\), including values for which no data have been collected. We call \(\hat{y}_{x}\) the _fitted model_ or the _estimated mean response_ at the level \(x\).

In Sect. 8.2, we look at polynomial regression and the fit of polynomial response curves to data. Estimation of the parameters in the model, using the method of least squares, is discussed in the optional Sect. 8.3. In Sect. 8.4, we investigate how well a regression model fits a given set of data via a "lack-of-fit" test. In Sect. 8.5, we look at the analysis of a simple linear regression model and test hypotheses about the values of the model parameters. Confidence intervals are also discussed. The general analysis of a higher-order polynomial regression model using a computer package is discussed in Sect. 8.6. Investigation of linear and quadratic trends in the data via orthogonal polynomials is the topic of optional Sect. 8.7. An experiment is examined in detail in Sect. 8.8, and analysis using the SAS and R software packages is done in Sects. 8.9 and 8.10, respectively.

Polynomial regression methods can be extended to experiments involving two or more quantitative factors. The mean response \(E[Y_{x\,l}]\) is then a function of several variables and defines a _response surface_ in three or more dimensions. Specialized designs are usually required for fitting response surfaces, and consequently, we postpone their discussion to Chap. 16.

### Models

The standard model for polynomial regression is

\[Y_{xt}= \beta_{0}+\beta_{1}x+\beta_{2}x^{2}+\cdots+\beta_{p}x^{p}+\epsilon_{ xt}\,, \tag{8.2.1}\] \[\epsilon_{xt}\sim N(0,\sigma^{2})\,,\] \[\epsilon_{xt}\,\text{'s are mutually independent}\] \[t=1,\ldots,r_{x};\;\;x=x_{1},\ldots,x_{v}.\]

The treatment factor is observed at \(v\) different levels \(x_{1},\ldots,x_{v}\). There are \(r_{x}\) observations taken when the treatment factor is at level \(x\), and \(Y_{xt}\) is the response for the \(t\)th of these. The responses \(Y_{xt}\) are modeled as independent random variables with mean

\[E[Y_{xt}]=\beta_{0}+\beta_{1}x+\beta_{2}x^{2}+\cdots+\beta_{p}x^{p}\,,\]

which is a \(p\)th-degree polynomial function of the level \(x\) of the treatment factor. Since \(\epsilon_{xt}\sim N(0,\,\sigma^{2})\), it follows that

\[Y_{xt}\sim N(\beta_{0}+\beta_{1}x+\beta_{2}x^{2}+\cdots+\beta_{p}x^{p},\; \sigma^{2})\,.\]

Typically, in a given experiment, the exact functional form of the true response curve is unknown. In polynomial regression, the true response curve is assumed to be well approximated by a polynomial function. If the true response curve is relatively smooth, then a low-order polynomial function will often provide a good model, at least for a limited range of levels of the treatment factor.

If \(p=1\) in the polynomial regression function, we have the case known as _simple linear regression_, for which the mean response is

\[E[Y_{xt}]=\beta_{0}+\beta_{1}x\,,\]

which is a linear function of \(x\). This model assumes that an increase of one unit in the level of \(x\) produces a mean increase of \(\beta_{1}\) in the response, and is illustrated in Fig. 8.1. At each value of \(x\), there is a normal distribution of possible values of the response, the mean of which is the corresponding point, \(E[Y_{xt}]=\beta_{0}+\beta_{1}x\), on the regression line and the variance of which is \(\sigma^{2}\).

Consider now the data plotted in Fig. 8.2, for which polynomial regression might be appropriate. Envisage a normal distribution of possible values of \(Y_{xt}\) for each level \(x\), and a smooth response curve connecting the distribution of their means, \(E[Y_{xt}]\). It would appear that a quadratic response curve

Figure 8.1: Simple linear regression modelmay provide a good fit to these data. This case, for which

\[E[Y_{xt}]=\beta_{0}+\beta_{1}x+\beta_{2}x^{2},\]

is called _quadratic regression_. If this model is adequate, the fitted quadratic model can be used to estimate the value of \(x\) for which the mean response is maximized, even though it may not occur at one of the \(x\) values for which data have been collected.

Although regression models can be used to estimate the mean response at values of \(x\) that have not been observed, estimation outside the range of observed \(x\) values must be done with caution. There is no guarantee that the model provides a good fit outside the observed range.

If observations are collected for \(v\) distinct levels \(x\) of the treatment factor, then any polynomial regression model of degree \(p\leq v-1\) (that is, with \(v\) or fewer parameters) can be fitted to the data. However, it is generally preferable to use the simplest model that provides an adequate fit. So for polynomial regression, lower-order models are preferred. Higher-order models are susceptible to _overfit_, a circumstance in which the model fits the data too well at the expense of having the fitted response curve vary or fluctuate excessively between data points. Over-fit is illustrated in Fig. 8.3, which contains plots for a simple linear regression model and a sixth-degree polynomial regression model, each fitted to the same set of data. The sixth-degree polynomial model provides the better fit in the sense of providing a smaller value for the sum of squared errors. However, since we may be looking at natural fluctuation of data around a true linear model, it is arguable that the simple linear regression model is actually a better model--better for predicting responses at new values of \(x\), for example. Information concerning the nature of the treatment factor and the response variable may shed light on which model is more likely to be appropriate.

### Least Squares Estimates

Once data are available, we can use the method of least squares to find estimates \(\hat{\beta}_{j}\) of the parameters \(\beta_{j}\) of the chosen regression model. The fitted model is then

\[\hat{y}_{x}=\hat{\beta}_{0}+\hat{\beta}_{1}x+\hat{\beta}_{2}x^{2}+\cdots+\hat{ \beta}_{p}x^{p}\,,\]

and the error sum of squares is

\[\text{ss}E\,=\,\,\sum_{x}\sum_{t}(y_{xt}-\hat{y}_{x})^{2}\,.\]

Figure 8.2: Three hypothetical observations \(y_{xt}\) at each of five treatment factor levels

The number of error degrees of freedom is the number of observations minus the number of parameters in the model; that is, \(n\,-\,(p\,+\,1)\). The mean squared error,

\[\text{msE}=\sum_{x}\sum_{t}(y_{xt}-\hat{y}_{x})^{2}/(n\,-\,p\,-\,1)\,,\]

provides an unbiased estimate of \(\sigma^{2}\).

In the following optional section, we obtain the least squares estimates of the parameters \(\beta_{0}\) and \(\beta_{1}\) in a simple linear regression model. However, in general we leave the determination of least squares estimates to a computer, since the formulae are not easily expressed without the use of matrices, and the hand computations are generally tedious. An exception to this occurs with the use of orthogonal polynomial models, discussed in Sect. 8.7.

##### Checking Model Assumptions

Having made an initial selection for the degree of polynomial model required in a given scenario, the model assumptions should be checked. The first assumption to check is that the proposed polynomial model for \(E[Y_{xt}]\) is indeed adequate. This can done either by examination of a plot of the residuals versus \(x\) or by formally testing for model lack of fit. The standard test for lack of fit is discussed in Sect. 8.4.

If no pattern is apparent in a plot of the residuals versus \(x\), this indicates that the model is adequate. Lack of fit is indicated if there is a clear function-like pattern. For example, suppose a quadratic model is fitted but a cubic model is needed. Any linear or quadratic pattern in the data would then be explained by the model and would not be evident in the residual plot, but the residual plot would show the pattern of a cubic polynomial function unexplained by the fitted model (see Fig. 8.4).

Residual plots can also be used to assess the assumptions on the random error terms in the model in the same way as discussed in Chap. 5. The residuals are plotted versus run order to evaluate independence of the error variables, plotted versus fitted values \(\hat{y}_{x}\) to check the constant variance assumption and to check for outliers, and plotted versus the normal scores to check the normality assumption.

If the error assumptions are not valid, the fitted line still provides a model for mean response. However, the results of confidence intervals and hypothesis tests can be misleading. Departures from normality are generally serious problems only when the true error distribution has long tails or when prediction of a single observation is required. Nonconstant variance can sometimes be corrected via transformations, as in Chap. 5, but this may also change the order of the model that needs to be fitted.

If no model assumptions are invalidated, then analysis of variance can be used to determine whether or not a simpler model would suffice than the one postulated by the experimenter (see Sect. 8.6).

Figure 8.3: Data and fitted linear and sixth-degree polynomial regression models

### Least Squares Estimation (Optional)

In this section, we derive the normal equations for a general polynomial regression model. These equations can be solved to obtain the set of least squares estimates \(\hat{\beta}_{j}\) of the parameters \(\beta_{j}\). We illustrate this for the case of simple linear regression.

#### Normal Equations

For the _p_th-order polynomial regression model (8.2.1), the normal equations are obtained by differentiating the sum of squared errors

\[\sum_{x}\sum_{t}e_{xt}^{2}=\sum_{x}\sum_{t}(y_{xt}-\beta_{0}-\beta_{1}x-\cdots- \beta_{p}x^{p})^{2}\]

with respect to each parameter and setting each derivative equal to zero. For example, if we differentiate with respect to \(\beta_{j}\), set the derivative equal to zero, and replace each \(\beta_{i}\) with \(\hat{\beta}_{i}\), we obtain the _j_th normal equation as

\[\sum_{x}\sum_{t}x^{j}y_{xt}=\sum_{x}\sum_{t}x^{j}\left(\hat{\beta}_{0}+x\hat{ \beta}_{1}+\cdots+x^{p}\hat{\beta}_{p}\right)\,. \tag{8.3.2}\]

We have one normal equation of this form for each value of \(j\), \(j=0\), \(1\), \(\ldots\), \(p\). Thus, in total, we have \(p+1\) equations in \(p+1\) unknowns \(\hat{\beta}_{j}\). Provided that the number of levels of the treatment factor exceeds the number of parameters in the model (that is, \(v\geq p+1\)), there is a unique solution to the normal equations giving a unique set of least squares estimates, with the result that all parameters are estimable.

Figure 8.4: Plots for a quadratic polynomial regression model fitted to data from a cubic model

#### Least Squares Estimates for Simple Linear Regression

For the simple linear regression model, we have \(p=1\), and there are two normal equations obtained from (8.3.2) with \(j=0\), \(1\). These are

\[\sum_{x}\sum_{t}y_{xt} = n\hat{\beta}_{0}+\sum_{x}\sum_{t}x\hat{\beta}_{1}\,,\] \[\sum_{x}\sum_{t}xy_{xt} = \sum_{x}\sum_{t}x\hat{\beta}_{0}+\sum_{x}\sum_{t}x^{2}\hat{\beta}_ {1}\,,\]

where \(n=\Sigma_{x}r_{x}\) denotes the total number of observations in the experiment. Dividing the first equation by \(n\), we obtain

\[\hat{\beta}_{0}=\overline{y}_{\ldots}-\hat{\beta}_{1}\overline{x}_{\ldots}\,, \tag{8.3.3}\]

where \(\overline{x}_{\ldots}=\sum_{x}r_{x}x/n\). Substituting this into the second equation gives

\[\hat{\beta}_{1}=\frac{\sum_{x}\sum_{t}xy_{xt}-n\overline{x}_{\ldots}\overline{ y}_{\ldots}}{ss_{xx}}\,, \tag{8.3.4}\]

where \(ss_{xx}=\sum_{x}r_{x}(x-\overline{x}_{\ldots})^{2}\).

### Test for Lack of Fit

We illustrate the lack-of-fit test via the quadratic regression model

\[E[Y_{xt}]=\beta_{0}+\beta_{1}x+\beta_{2}x^{2}\,.\]

If data have been collected for only three levels \(x=x_{1},x_{2},x_{3}\) of the treatment factor, then the fitted model \(\hat{y}_{x}=\hat{\beta}_{0}+\hat{\beta}_{1}x+\hat{\beta}_{2}x^{2}\) will pass through the sample means \(\overline{y}_{x}\). computed at each value of \(x\). This means that the predicted response \(\hat{y}_{x}\) at the observed values of \(x\) is \(\hat{y}_{x}=\overline{y}_{x}\). (for \(x=x_{1},x_{2},x_{3}\)). This is the same fit as would be obtained using the one-way analysis of variance model, so we know that it is the best possible fit of a model to the data in the sense that no other model can give a smaller sum of squares for error, ssE.

If observations have been collected at more than three values of \(x\), however, then the model is unlikely to fit the data perfectly, and in general, \(\hat{y}_{x}\neq\overline{y}_{x}\).. If the values \(\hat{y}_{x}\) and \(\overline{y}_{x}\). are too far apart relative to the amount of variability inherent in the data, then the model does not fit the data well, and there is said to be model _lack of fit_. In other words, in our example, the quadratic function is not sufficient to model the mean response \(E[Y_{xt}]\).

If there is replication at one or more of the \(x\)-values, and if data are collected at more than three \(x\)-values, then it is possible to conduct a test for lack-of-fit of the quadratic model. The null hypothesis is that the quadratic model is adequate for modeling mean response; that is,

\[H_{0}^{Q}:E[Y_{xt}]=\beta_{0}+\beta_{1}x+\beta_{2}x^{2}\,.\]

The alternative hypothesis is that a more general model (the one-way analysis of variance model) is needed; that is,

\[H_{A}^{Q}:E[Y_{xt}]=\mu+\tau_{x}\,,\]where \(\tau_{x}\) is the effect on the response of the treatment factor at level \(x\). We fit the quadratic regression model and obtain \(ssE\) and \(msE=ssE/(n-3)\). Now, \(MSE\) is an unbiased estimator of the error variance if the quadratic model is correct, but otherwise it has expected value larger than \(\sigma^{2}\).

At each level \(x\) where more than one observation has been taken, we can calculate the sample variance \(s_{x}^{2}\) of the responses. Each sample variance \(s_{x}^{2}\) is an unbiased estimator of the error variance, \(\sigma^{2}\), and these can be pooled to obtain the _pooled sample variance_,

\[s_{p}^{2}=\left[\sum_{x}(r_{x}-1)s_{x}^{2}\right]/(n-v)\,. \tag{8.4.5}\]

Provided that the assumption of equal error variances is valid, the pooled sample variance is an unbiased estimator of \(\sigma^{2}\) even if the model does not fit the data well. This pooled sample variance is called the _mean square for pure error_ and denoted by _msPE_. An alternative way to compute _msPE_ is as the mean square for error obtained by fitting the one-way analysis of variance model.

The test of lack of fit, which is the test of \(H_{0}^{Q}\) versus \(H_{A}^{Q}\), is based on a comparison of the two fitted models (the quadratic model and the one-way analysis of variance model), using the difference in the corresponding error sums of squares. We write \(ssE\) for the error sum of squares obtained from the quadratic regression model and \(ssPE\) for the error sum of squares from the one-way analysis of variance model. Then the _sum of squares for lack of fit_ is

\[ssLOF=ssE-ssPE\,.\]

The sum of squares for pure error has \(n-v\) degrees of freedom associated with it, whereas the sum of squares for error has \(n-(p+1)=n-3\) (since there are \(p+1=3\) parameters in the quadratic regression model). The number of degrees of freedom for lack of fit is therefore \((n-3)-(n-v)=v-3\). The corresponding _mean square for lack of fit_,

\[msLOF=ssLOF/(v-3),\]

measures model lack of fit because it is an unbiased estimator of \(\sigma^{2}\) if the null hypothesis is true but has expected value larger than \(\sigma^{2}\) otherwise.

Under the polynomial regression model (8.2.1) for \(p=2\), the decision rule for testing \(H_{0}^{Q}\) versus \(H_{A}^{Q}\) at significance level \(\alpha\) is

\[\text{reject }H_{0}^{Q}\text{ if }\,msLOF/msPE>F_{v-3,n-v,\alpha}\,.\]

In general, a polynomial regression model of degree \(p\) can be tested for lack of fit as long as \(v>p+1\) and there is replication for at least one of the \(x\)-levels. A test for lack of fit of the \(p\)th-degree polynomial regression model is a test of the null hypothesis

\[H_{0}^{p}:\{\,E[Y_{xI}]=\beta_{0}+\beta_{1}x+\cdots+\beta_{p}x^{p};\,\,\,\,x=x _{1},\ldots,x_{v}\,\}\]

versus the alternative hypothesis

\[H_{A}^{p}:\{\,E[Y_{xI}]=\mu+\tau_{x};\,\,\,\,x=x_{1},\ldots,x_{v}\,\}\,.\]

The decision rule at significance level \(\alpha\) is \[\text{reject }H_{0}^{P}\text{ \ if \ }msLOF/msPE>F_{v-p-1,n-v,\alpha}\text{,}\]

where

\[msLOF=ssLOF/(v-p-1)\text{ \ \ \ and \ \ }ssLOF=ssE-ssPE\text{.}\]

Here, \(ssE\) is the error sum of squares obtained by fitting the polynomial regression model of degree \(p\), and \(ssPE\) is the error sum of squares obtained by fitting the one-way analysis of variance model.

#### _Example 8.4.1_ Lack-of-fit test for quadratic regression

In this example we conduct a test for lack of fit of a quadratic polynomial regression model, using the hypothetical data that were plotted in Fig. 8.2 (p. 251). Table 8.1 lists the \(r=3\) observations for each of \(v=5\) levels \(x\) of the treatment factor, together with the sample mean and sample variance. The pooled sample variance (8.4.5) is

\[s_{p}^{2}=msPE=\sum_{x}2s_{x}^{2}/(15-5)=13.2747\text{,}\]

and the sum of squares for pure error is therefore

\[ssPE=(15-5)msPE=132.7471\text{.}\]

Alternatively, this can be obtained as the sum of squares for error from fitting the one-way analysis of variance model.

The error sum of squares \(ssE\) is obtained by fitting the quadratic polynomial regression model using a computer program (see Sects. 8.9 and 8.10 for achieving this via SAS and R software, respectively). We obtain \(ssE=162.8013\). Thus

\[ssLOF=ssE-ssPE=162.8013-132.7471=30.0542\]

with

\[v-p-1=5-2-1=2\]

\begin{table}
\begin{tabular}{c c c c c c} \hline Source of variation & Degrees of freedom & Sum of squares & Mean square & Ratio & \(p\)-value \\ \hline Lack of fit & 2 & 30.0542 & 15.0271 & 1.13 & 0.3604 \\ Pure error & 10 & 132.7471 & 13.2747 & & \\ Error & 12 & 162.8013 & & & \\ \hline \end{tabular}
\end{table}
Table 8.2: Test for lack of fit of quadratic regression model for hypothetical data

\begin{table}
\begin{tabular}{l|l|l|l|l|l} \(x\) & \multicolumn{3}{c|}{\(y_{xt}\)} & \(\overline{y}_{x.}\) & \(s_{x}^{2}\) \\ \hline
10 & 69.42 & 66.07 & 71.70 & 69.0633 & 8.0196 \\
20 & 79.91 & 81.45 & 85.52 & 82.2933 & 8.4014 \\
30 & 88.33 & 82.01 & 84.43 & 84.9233 & 10.1681 \\
40 & 62.59 & 70.98 & 64.12 & 65.8967 & 19.9654 \\
50 & 25.86 & 32.73 & 24.39 & 27.6600 & 19.8189 \\ \hline \end{tabular}
\end{table}
Table 8.1: Hypothetical data for one continuous treatment factor degrees of freedom. The test for lack of fit is summarized in Table 8.2. Since the \(p\)-value is large, there is no significant lack of fit. The quadratic model seems to be adequate for these data. 

### Analysis of the Simple Linear Regression Model

Suppose a linear regression model has been postulated for a given scenario, and a check of the model assumptions finds no significant violations including lack of fit. Then it is appropriate to proceed with analysis of the data.

It was shown in the optional Sect. 8.3 that the least squares estimates of the intercept and slope parameters in the simple linear regression model are

\[\hat{\beta}_{0}=\overline{y}_{\ldots}-\hat{\beta}_{1}\overline{x}_{\ldots}\quad \text{and}\quad\hat{\beta}_{1}=\frac{\sum_{x}\sum_{t}xy_{xt}-n\overline{x}_{ \ldots}\overline{y}_{\ldots}}{ss_{xx}}\,, \tag{8.5.6}\]

where \(\overline{x}_{\ldots}=\sum_{x}r_{x}x/n\) and \(ss_{xx}=\sum_{x}r_{x}(x-\overline{x}_{\ldots})^{2}\). The corresponding estimators (random variables), which we also denote by \(\hat{\beta}_{0}\) and \(\hat{\beta}_{1}\), are normally distributed, since they are linear combinations of the normally distributed random variables \(Y_{xt}\). In Exercise 1, the reader is asked to show that the variances of \(\hat{\beta}_{0}\) and \(\hat{\beta}_{1}\) are equal to

\[\text{Var}(\hat{\beta}_{0})=\sigma^{2}\left(\frac{1}{n}+\frac{\overline{x}_{ \ldots}^{2}}{ss_{xx}}\right)\ \ \text{and}\ \text{Var}(\hat{\beta}_{1})=\sigma^{2}\left(\frac{1}{ss_{xx}}\right)\,. \tag{8.5.7}\]

If we estimate \(\sigma^{2}\) by

\[\text{m}sE=\frac{\sum_{x}\sum_{t}(y_{xt}-(\hat{\beta}_{0}+\hat{\beta}_{1}x))^{ 2}}{n-2}\,, \tag{8.5.8}\]

it follows that

\[\frac{\hat{\beta}_{0}-\beta_{0}}{\sqrt{\text{m}sE\,\left(\frac{1}{n}+\frac{ \overline{x}_{\ldots}^{2}}{ss_{xx}}\right)}}\sim t_{n-2}\ \ \text{and}\ \frac{\hat{\beta}_{1}-\beta_{1}}{\sqrt{\text{m}sE\,\left(\frac{1}{ss_{xx}}\right)}}\sim t_{n-2}\,.\]

Thus, the decision rule at significance level \(\alpha\) for testing whether or not the intercept is equal to a specific value \(a\) (\(H_{0}^{\text{i}\text{i}\text{t}}:\{\beta_{0}=a\}\) versus \(H_{A}^{\text{i}\text{t}}:\{\beta_{0}\neq a\}\)) is

\[\text{reject}\ H_{0}^{\text{i}\text{t}}\ \ \ \text{if}\ \ \ \frac{\hat{\beta}_{0}-a}{\sqrt{\text{m}sE\,\left(\frac{1}{n}+\frac{\overline{x}_{\ldots}^{2}}{ss_{xx}}\right)}}>t_{n-2,\alpha/2}\ \ \text{or}\ <t_{n-2,1-\alpha/2}\,. \tag{8.5.9}\]

The decision rule at significance level \(\alpha\) for testing whether or not the slope of the regression model is equal to a specific value \(b\) (\(H_{0}^{\text{s}\text{l}\text{p}}\):\(\{\beta_{1}=b\}\) versus \(H_{A}^{\text{s}\text{l}\text{p}}\):\(\{\beta_{1}\neq b\}\)) is

\[\text{reject}\ H_{0}^{\text{s}\text{l}\text{p}}\ \ \text{if}\ \ \ \frac{\hat{\beta}_{1}-b}{\sqrt{\text{m}sE\,\left(\frac{1}{ss_{xx}}\right)}}>t_{n-2,\alpha/2}\ \ \text{or}\ <t_{n-2,1-\alpha/2}\,. \tag{8.5.10}\]

Corresponding one-tailed tests can be constructed by choosing the appropriate tail of the \(t\) distribution and replacing \(\alpha/2\) by \(\alpha\).

Confidence intervals at individual confidence levels of \(100(1-\alpha)\)% for \(\beta_{0}\) and \(\beta_{1}\) are, respectively,

\[\hat{\beta}_{0}\ \ \pm\ \ t_{n-2,\alpha/2}\sqrt{\text{ms}E\left(\frac{1}{n}+ \frac{\overline{x}_{\ldots}^{2}}{\text{ss}_{xx}}\right)} \tag{8.5.11}\]

and

\[\hat{\beta}_{1}\ \ \pm\ \ t_{n-2,\alpha/2}\sqrt{\text{ms}E\left(\frac{1}{\text{ss}_{xx}}\right)}\,. \tag{8.5.12}\]

We can use the regression line to estimate the expected mean response \(E[Y_{xx}]\) at any particular value of \(x\), say \(x_{a}\); that is,

\[\widehat{E}[Y_{x_{a}t}]=\hat{y}_{x_{a}}=\hat{\beta}_{0}+\hat{\beta}_{1}x_{a}\,.\]

The variance associated with this estimator is

\[\text{Var}(\hat{Y}_{x_{a}})=\sigma^{2}\,\left(\frac{1}{n}+\frac{(x_{a}- \overline{x}_{\ldots})^{2}}{\text{ss}_{xx}}\right)\,.\]

Since \(\hat{Y}_{x_{a}}\) is a linear combination of the normally distributed random variables \(\hat{\beta}_{0}\) and \(\hat{\beta}_{1}\), it, too, has a normal distribution. Thus, if we estimate \(\sigma^{2}\) by msE given in (8.5.8), we obtain a \(100(1-\alpha)\)% confidence interval for the expected mean response at \(x_{a}\) as

\[\hat{\beta}_{0}+\hat{\beta}_{1}x_{a}\ \ \pm\ \ t_{n-2,\alpha/2}\,\sqrt{\text{ms}E \left(\frac{1}{n}+\frac{(x_{a}-\overline{x}_{\ldots})^{2}}{\text{ss}_{xx}} \right)}\,. \tag{8.5.13}\]

A confidence "band" for the entire regression line can be obtained by calculating confidence intervals for the mean response at all values of \(x\). Since this is an extremely large number of intervals, we need to use Scheffe's method of multiple comparisons. So, a \(100(1-\alpha)\)% confidence band for the regression line is given by

\[\hat{\beta}_{0}+\hat{\beta}_{1}x_{a}\ \ \pm\ \ \sqrt{2F_{2,n-2,\alpha}}\,\sqrt{ \text{ms}E\,\left(\frac{1}{n}+\frac{(x_{a}-\overline{x}_{\ldots})^{2}}{\text{ ss}_{xx}}\right)}\,. \tag{8.5.14}\]

The critical coefficient here is \(w=\sqrt{2\ F_{2,n-2,\alpha}}\) rather than the value \(w=\sqrt{(v-1)\ F_{v-1,n-v,\alpha}}\) that we had in the one-way analysis of variance model, since there are only two parameters of interest in our model (instead of linear combinations of \(v-1\) pairwise comparisons) and the number of error degrees of freedom is \(n-2\) rather than \(n-v\).

Finally, we note that it is also possible to use the regression line to predict a future observation at a particular value \(x_{a}\) of \(x\). The predicted value \(\hat{y}_{x_{a}}\) is the same as the estimated mean response at \(x_{a}\) obtained from the regression line; that is,

\[\hat{y}_{x_{a}}=\hat{\beta}_{0}+\hat{\beta}_{1}x_{a}\,.\]

The variance associated with this prediction is larger by an amount \(\sigma^{2}\) than that associated with the estimated mean response, since the model acknowledges that the data values are distributed around their mean according to a normal distribution with variance \(\sigma^{2}\). Consequently, we may adapt (8.5.13) to obtain a \(100(1-\alpha)\)_% prediction interval_ for a future observation at \(x_{a}\), as follows:\[\hat{\beta}_{0}+\hat{\beta}_{1}x_{a}\ \ \pm\ \ t_{n-2,1-\alpha/2}\,\sqrt{\text{msE}\,\left(1+\frac{1}{n}+\frac{(x_{a}-\overline{x}_{.})^{2}}{\text{ss}_{xx}}\right)}\,. \tag{8.5.15}\]

Alternatively, the prediction interval follows, because

\[\frac{\hat{Y}_{x_{a}}-Y_{x_{a}}}{\sqrt{\text{msE}\,\left(1+\frac{1}{n}+\frac{(x_{a}-\overline{x}_{.})^{2}}{\text{ss}_{xx}}\right)}}\sim t(n-2)\]

under our model.

##### _Example 8.5.1_ Heart-lung pump experiment, continued

In Example 4.2.3, p. 73, a strong linear trend was discovered in the fluid flow rate as the number of revolutions per minute increases in a rotary pump head of an Olson heart-lung pump. Consequently, a simple linear regression model may provide a good model for the data. The data are reproduced in Table 8.3. It can be verified that

\[\overline{x}_{.}\ =\ \sum_{x}r_{x}x/n\ =\ [5(50)+3(75)+5(100)+2(125)+5(150)]/20\ =\ 98.75\,,\]

and

\[\overline{y}_{.}=2.2986\ \text{ and }\sum_{x}\sum_{t}xy_{xt}=5212.8\,.\]

So,

\[\text{ss}_{xx} =\ [5(-48.75)^{2}+3(-23.75)^{2}+5(1.25)^{2}+2(26.25)^{2}+5(51.25)^{2}]\] \[=\ 28,093.75\,,\]

giving

\[\hat{\beta}_{1} =\ [5212.8\ -\ 20(98.75)(2.2986)]/[28,093.75]\] \[=\ 673.065/28,093.75\ =\ 0.02396\,.\]

The mean square for error (8.5.8) for the regression model is best calculated by a computer package. It is equal to \(\text{msE}=0.001177\), so the estimated variance of \(\hat{\beta}_{1}\) is

\[\text{Var}(\hat{\beta}_{1})\ =\ \text{msE}/\text{ss}_{xx}\ =\ (0.001177)/28,093.75\ =\ 0.00000042\,.\]

\begin{table}
\begin{tabular}{c c c c c c} \hline rpm & \multicolumn{5}{c}{Liters per minute} \\ \hline
50 & 1.158 & 1.128 & 1.140 & 1.122 & 1.128 \\
75 & 1.740 & 1.686 & 1.740 & & \\
100 & 2.340 & 2.328 & 2.328 & 2.340 & 2.298 \\
125 & 2.868 & 2.982 & & & \\
150 & 3.540 & 3.480 & 3.510 & 3.504 & 3.612 \\ \hline \end{tabular}
\end{table}
Table 8.3: Fluid flow in liters/minute for the heart–lung pump experiment A 95% confidence interval for \(\beta_{1}\) is then given by (8.5.12), as

\[\begin{array}{rcl}0.02396&\pm&t_{18,.025}\sqrt{0.00000042}\,,\\ 0.02396&\pm&(2.101)(0.00020466)\,,\\ &&(\,0.02353,\,\,0.02439\,)\,.\end{array}\]

To test the null hypothesis \(H_{0}^{\rm slp}:\{\beta_{1}=0\}\), against the one-sided alternative hypothesis \(H_{A}^{\rm slp}:\{\beta_{1}>0\}\) that the slope is greater than zero at significance level \(\alpha=0.01\), we use a one-sided version of the decision rule (8.5.10) and calculate

\[\frac{\hat{\beta}_{1}-0}{\sqrt{{\rm ms}E\left(\frac{1}{{\rm ss}_{xx}}\right)}} \,=\,\,\frac{0.02396}{0.00020466}\,\,=\,\,117.07\,,\]

and since this is considerably greater than \(t_{18,0.01}=2.552\), we reject \(H_{0}^{\rm slp}\). We therefore conclude that the slope of the regression line is greater than zero, and the fluid flow increases as the revolutions per minute increase. 

### Analysis of Polynomial Regression Models

#### Analysis of Variance

Suppose a polynomial regression model has been postulated for a given experiment, and the model assumptions appear to be satisfied, including no significant lack of fit. Then it is appropriate to proceed with analysis of the data. A common objective of the analysis of variance is to determine whether or not a lower-order model might suffice. One reasonable approach to the analysis, which we demonstrate for the quadratic model (\(p=2\)), is as follows.

First, test the null hypothesis \(H_{0}^{L}:\beta_{2}=0\) that the highest-order term \(\beta_{2}x^{2}\) is not needed in the model so that the simple linear regression model is adequate. If this hypothesis is rejected, then the full quadratic model is needed. Otherwise, testing continues and attempts to assess whether an even simpler model is suitable. Thus, the next step is to test the hypothesis \(H_{0}:\beta_{1}=\beta_{2}=0\). If this is rejected, the simple linear regression model is needed and adequate. If it is not rejected, then \(x\) is apparently not useful in modeling the mean response.

Each test is constructed in the usual way, by comparing the error sum of squares of the full (quadratic) model with the error sum of squares of the reduced model corresponding to the null hypothesis being true. For example, to test the null hypothesis \(H_{0}^{L}:\beta_{2}=0\) that the simple linear regression model is adequate versus the alternative hypothesis \(H_{A}^{L}\) that the linear model is not adequate, the decision rule at significance level \(\alpha\) is

\[{\rm reject}\ H_{0}^{L}\quad{\rm if}\quad{\rm ms}(\beta_{2})/{\rm ms}E>F_{1,n- v,\alpha}\,,\]

where the mean square \({\rm ms}(\beta_{2})={\rm ss}(\beta_{2})/1\) is based on one degree of freedom, and

\[{\rm ss}(\beta_{2})={\rm ss}E_{1}-{\rm ss}E_{2}\,,\]

where \({\rm ss}E_{1}\) and \({\rm ss}E_{2}\) are the error sums of squares obtained by fitting the models of degree one and two, respectively.

Similarly, the decision rule at significance level \(\alpha\) for testing \(H_{0}:\beta_{1}=\beta_{2}=0\) versus the alternative hypothesis that \(H_{0}\) is false is

\[\text{reject }H_{0}\quad\text{if}\quad\text{ms}(\beta_{1},\beta_{2})/\text{msE}>F_{2,n-v,\alpha}\,,\]

where the mean square \(\text{ms}(\beta_{1},\beta_{2})=\text{ss}(\beta_{1},\beta_{2})/2\) is based on 2 degrees of freedom, and

\[\text{ss}(\beta_{1},\beta_{2})=(\text{ssE}_{0}-\text{ssE}_{2})/2\,,\]

and \(\text{ssE}_{0}\) and \(\text{ssE}_{2}\) are the error sums of squares obtained by fitting the models of degree zero and two, respectively.

The tests are generally summarized in an analysis of variance table, as indicated in Table 8.4 for the polynomial regression model of degree \(p\). In the table, under sources of variability, "Model" is listed rather than "\(\beta_{1},\ldots,\beta_{p}\)" for the test of \(H_{0}:\beta_{1}=\cdots=\beta_{p}=0\), since this is generally included as standard output in a computer package. Also, to save space, we have written the error sum of squares as \(\text{ssE}\) for the full model, rather than indicating the order of the model with a subscript \(p\). Analysis of variance for quadratic regression (\(p=2\)) is illustrated in the following example.

#### Analysis of variance for quadratic regression

Consider the hypothetical data in Table 8.1, p. 256, with three observations for each of the levels \(x=10\), 20, 30, 40, 50. For five levels, the quartic model is the highest-order polynomial model that can be fitted to the data. However, a quadratic model was postulated for these data, and a test for lack of fit of the quadratic model, conducted in Example 8.4.1, suggested that this model is adequate.

The analysis of variance for the quadratic model is given in Table 8.5. The null hypothesis \(H_{0}^{L}:\{\beta_{2}=0\}\) is rejected, since the \(p\)-value is less than 0.0001. So, the linear model is not adequate, and the quadratic model is needed. This is no surprise, based on the plot of the data shown in Fig. 8.5. Now, suppose the objective of the experiment was to determine how to maximize mean response. From the data plot, it appears that the maximum response occurs within the range of the levels \(x\) that were observed. The fitted quadratic regression model can be obtained from a computer program, as illustrated in Sects. 8.9 and 8.10 for the SAS and R programs, respectively. The fitted model is

\begin{table}
\begin{tabular}{c c c c c} \hline Source of variation & Degrees of freedom & Sum of square & Mean squares & Ratio \\ \hline \(\beta_{p}\) & 1 & \(\text{ssE}_{p-1}-\text{ssE}\) & \(\text{ms}(\beta_{p})\) & \(\text{ms}(\beta_{p})/\text{msE}\) \\ \(\beta_{p-1}\), \(\beta_{p}\) & 2 & \(\text{ssE}_{p-2}-\text{ssE}\) & \(\text{ms}(\beta_{p-1}\), \(\beta_{p})\) & \(\text{ms}(\beta_{p-1}\), \(\beta_{p})/\text{msE}\) \\ \(\vdots\) & \(\vdots\) & \(\vdots\) & \(\vdots\) & \(\vdots\) \\ \(\beta_{2}\), \(\ldots\), \(\beta_{p}\) & \(p-1\) & \(\text{ssE}_{1}-\text{ssE}\) & \(\text{ms}(\beta_{2}\), \(\ldots\), \(\beta_{p})\) & \(\text{ms}(\beta_{2}\), \(\ldots\), \(\beta_{p})/\text{msE}\) \\ Model & \(p\) & \(\text{ssE}_{0}-\text{ssE}\) & \(\text{ms}(\beta_{1}\), \(\ldots\), \(\beta_{p})\) & \\  & & & \(\text{ms}(\beta_{1}\), \(\ldots\), \(\beta_{p})/\text{msE}\) & \\ Error & \(n-p-1\) & \(\text{ssE}\) & \(\text{msE}\) & \\ Total & \(n-1\) & \(\text{sstot}\) & & \\ \hline \end{tabular}
\end{table}
Table 8.4: Analysis of variance table for polynomial regression model of degree \(p\). Here \(\text{ssE}_{b}\) denotes the error sum of squares obtained by fitting the polynomial regression model of degree \(b\)\[\hat{y}_{x}=33.43333+4.34754x-0.08899{x^{2}}\,,\]

and is plotted in Fig. 8.5 along with the raw data. The fitted curve achieves its maximum value when \(x\) is around 24.4, which should provide a good estimate of the level \(x\) that maximizes mean response. Further experimentation involving levels around this value could now be done. 

The adequacy of a regression model is sometimes assessed in terms of the proportion of variability in the response variable that is explained by the model. This proportion, which is the ratio of the model sum of squares to the sum of squares total, is called the _coefficient of multiple determination_, or the \(R\)2_-value_. In the notation of Table 8.4,

\[R^{2}=(\text{ssE}_{0}-\text{ssE})/\text{sstot}=\text{ss}(\beta_{1},\ldots,\beta _{p})/\text{sstot}\,. \tag{8.6.1}\]

For simple linear regression,

\[R^{2}=\text{ss}(\beta_{1})/\text{sstot}\]

is called the _coefficient of determination_, and in this case \(R^{2}=\text{r}^{2}\), where

\[\text{r}=\text{ss}_{xy}/\sqrt{\text{ss}_{xx}\text{ss}_{yy}}\]

is the _sample correlation coefficient_, or _Pearson product-moment correlation coefficient_.

#### Confidence Intervals

When the model is fitted via a computer program, the least squares estimates of \(\hat{\beta}_{j}\) and their corresponding standard errors (estimated standard deviations) usually form part of the standard computer

\begin{table}
\begin{tabular}{c c c c c} \hline Source of variation & Degrees of freedom & Sum of square & Mean squares & Ratio & \(p\)-value \\ \hline \(\beta_{2}\) & 1 & 3326.2860 & 3326.2860 & 245.18 & 0.0001 \\ Model & 2 & 6278.6764 & 3139.3382 & 231.40 & 0.0001 \\ Error & 12 & 162.8013 & 13.5668 & & \\ Total & 14 & 6441.4777 & & & \\ \hline \end{tabular}
\end{table}
Table 8.5: Analysis of variance for the quadratic model

Figure 8.5: Quadratic polynomial regression model fitted to hypothetical data

output. If the model assumptions are satisfied, then

\[\frac{\hat{\beta}_{j}-\beta_{j}}{\sqrt{\widehat{\text{Var}}\left(\hat{\beta}_{j} \right)}}\sim t_{n-p-1}\,.\]

Individual confidence intervals can be obtained for the model parameters, as we illustrated in Sect. 8.5 for the simple linear regression model. The general form is

\[\hat{\beta}_{j}\ \ \pm\ \ t_{n-2,\alpha/2}\,\sqrt{\widehat{\text{Var}}\left( \hat{\beta}_{j}\right)}\,.\]

Most programs will also allow calculation of the estimated mean response at any value of \(x=x_{a}\) together with its standard error, and also calculation of the predicted response at \(x=x_{a}\) plus its standard error. Confidence and prediction intervals for these can again be calculated using the \(t_{n-p-1}\) distribution. The confidence interval formula for mean response at \(x=x_{a}\) is

\[\hat{\beta}_{0}+\hat{\beta}_{1}x_{a}+\cdots+\hat{\beta}_{p}x_{a}^{p}\ \ \pm\ \ t_{n-p-1,\alpha/2}\,\sqrt{\widehat{\text{Var}}\left(\hat{Y}_{x_{a}}\right)}\]

and the prediction interval formula for a new observation at \(x=x_{a}\) is

\[\hat{\beta}_{0}+\hat{\beta}_{1}x_{a}+\cdots+\hat{\beta}_{p}x_{a}^{p}\ \ \pm\ \ t_{n-p-1,\alpha/2}\,\sqrt{\widehat{\sigma}^{2}+\widehat{\text{Var}}\left(\hat{Y}_{x_{a}}\right)}\,.\]

The overall confidence level for all the intervals combined should be computed via the Bonferroni method as usual. A confidence band for the regression line is obtained by calculating confidence intervals for the estimated mean response at all values of \(x\), using the critical coefficient for Scheffe's method; that is,

\[\hat{\beta}_{0}+\hat{\beta}_{1}x+\cdots+\hat{\beta}_{p}x^{p}\ \ \pm\ \ \sqrt{(p+1)\ F_{p+1,n-p-1,\alpha}}\,\sqrt{\widehat{\text{Var}}\left(\hat{Y}_{x}\right)}\,.\]

### Orthogonal Polynomials and Trend Contrasts (Optional)

The normal equations for polynomial regression were presented in Eq. (8.3.2). It was noted that solving the equations can be tedious. However, the factor levels can be transformed in such a way that the least squares estimates have a simple algebraic form and are easily computed. Furthermore, the parameter estimators become uncorrelated and are multiples of the corresponding trend contrast estimators. This transformation is illustrated in this section for simple linear regression and for quadratic regression, when the factor levels \(x\) are equally spaced with equal numbers \(r\) of observations per level.

#### Simple Linear Regression

Consider the simple linear regression model, for which

\[Y_{xI}=\beta_{0}+\beta_{1}x+\epsilon_{xI}\,;\ \ \ x=x_{1},\ldots,x_{y};\ \ \ t=1,\ldots,r\,. \tag{8.7.17}\]

[MISSING_PAGE_EMPTY:8220]

trend effect under the one-way analysis of variance model

\[Y_{it}=\mu+\tau_{i}+\epsilon_{it}\,;\,\,\,\,i=1,\,2,\,3\,;\,\,\,\,\,t=1,\,2\,,\]

where \(\tau_{i}\) is the effect on the response of the \(i\)th coded level of the treatment factor. The one difference is that in the first case, the model is the linear regression model (\(p=1\)), while in the second case, the model is the one-way analysis of variance model, which is equivalent to a model of order \(p=v-1=2\). Thus the two models will not yield the same mean squared error, so the \(F\)-statistics will not be identical.

#### Quadratic Regression

Consider the quadratic regression model, for which

\[Y_{xt}=\beta_{0}+\beta_{1}x+\beta_{2}x^{2}+\epsilon_{xt}\,. \tag{8.7.19}\]

Assume that the treatment levels \(x=x_{1},\ldots,x_{v}\) are equally spaced, with \(r\) observations per level. To achieve orthogonality of estimates, it is necessary to transform both the linear and the quadratic independent variables.

Let \(z_{x}=x-\overline{x}_{..}\) as in the case of simple linear regression, so that again \(\sum_{x}z_{x}=0\). Similarly, define

\[z_{x}^{(2)}=z_{x}^{2}-\sum_{x}z_{x}^{2}/v\,.\]

Then \(\sum_{x}z_{x}^{(2)}=0\). Also, writing \(z_{i}\) for the \(i\)th value of \(z_{x}\) in rank order, we note that since the levels \(x\) are equally spaced,

\[z_{i}=-z_{v+1-i}\,\,\,\,\text{and}\,\,\,\,z_{i}^{(2)}=z_{v+1-i}^{(2)}\,,\]

so \(\sum_{x}z_{x}z_{x}^{(2)}=0\). These conditions give uncorrelated parameter estimators. To see this, consider the transformed model

\[Y_{xt}=\beta_{0}^{*}+\beta_{1}^{*}z_{x}+\beta_{2}^{*}z_{x}^{(2)}+\epsilon_{xt}\,. \tag{8.7.20}\]

The normal equations (8.3.2) become

\[\begin{array}{ll}\sum_{x}\sum_{t}y_{xt}=\sum_{x}\sum_{t}\left(\hat{\beta}_{0 }^{*}+z_{x}\hat{\beta}_{1}^{*}+z_{x}^{(2)}\hat{\beta}_{2}^{*}\right)&=vr\hat{ \beta}_{0}^{*}\,,\\ \sum_{x}\sum_{t}z_{x}y_{xt}=\sum_{x}\sum_{t}z_{x}\left(\hat{\beta}_{0}^{*}+z_{ x}\hat{\beta}_{1}^{*}+z_{x}^{(2)}\hat{\beta}_{2}^{*}\right)&=r\sum_{x}z_{x}^{(2)} \hat{\beta}_{1}^{*}\,,\\ \sum_{x}\sum_{t}z_{x}^{(2)}y_{xt}=\sum_{x}\sum_{t}z_{x}^{(2)}\left(\hat{\beta} _{0}^{*}+z_{x}\hat{\beta}_{1}^{*}+z_{x}^{(2)}\hat{\beta}_{2}^{*}\right)&=r\sum _{x}(z_{x}^{(2)})^{2}\hat{\beta}_{2}^{*}\,.\end{array}\]

The least squares estimates, obtained by solving the normal equations, are

\[\hat{\beta}_{0}^{*}=\overline{y}_{..}\,,\,\,\,\,\,\,\hat{\beta}_{1}^{*}=\frac {\sum_{x}\sum_{t}z_{x}y_{xt}}{r\sum_{x}z_{x}^{2}}\,,\,\,\,\,\,\,\hat{\beta}_{2 }^{*}=\frac{\sum_{x}\sum_{t}z_{x}^{(2)}y_{xt}}{r\sum_{x}(z_{x}^{(2)})^{2}}\,.\]

The estimators \(\hat{\beta}_{0}^{*}\) and \(\hat{\beta}_{1}^{*}\) are unchanged from the simple linear regression model (8.7.18), so they remain uncorrelated. Similarly, \(\hat{\beta}_{0}^{*}\) and \(\hat{\beta}_{2}^{*}\) are uncorrelated, because \[\text{Cov}\left(Y_{..},\ \ \sum_{x}\sum_{t}z_{x}^{(2)}Y_{xt}\right)=r\sigma^{2} \sum_{x}z_{x}^{(2)}=0.\]

Observe that \(\text{Cov}(\hat{\beta}_{1}^{*},\hat{\beta}_{2}^{*})\) is also zero, since it is proportional to

\[\text{Cov}\left(\sum_{x}\sum_{t}z_{x}Y_{xt},\sum_{x}\sum_{t}z_{x}^{(2)}Y_{xt} \right)=r\sigma^{2}\sum_{x}z_{x}z_{x}^{(2)}=0.\]

The transformed variables \(z_{x}\) and \(z_{x}^{(2)}\) are called _orthogonal polynomials_, because they are polynomial functions of the levels \(x\) and give rise to uncorrelated parameter estimators \(\hat{\beta}_{0}^{*},\hat{\beta}_{1}^{*}\), and \(\hat{\beta}_{2}^{*}\). It was illustrated in the previous subsection on simple linear regression that the values \(z_{x}\) are multiples of the coefficients of the linear trend contrast. Likewise, the values \(z_{x}^{(2)}\) are multiples of the coefficients of the quadratic trend contrast. For example, suppose we have \(r=17\) observations on the equally spaced levels

\[x_{1}=12,\ \ \ x_{2}=18,\ \ \ x_{3}=24,\ \ \ x_{4}=30\,.\]

Then \(z_{x}=x-\overline{x}_{..}\), so

\[z_{12}=-9,\ \ \ z_{18}=-3,\ \ \ z_{24}=3,\ \ \ z_{30}=9\,.\]

These are 3 times the linear trend contrast coefficients listed in Appendix A.2. Also, \(\sum_{x}z_{x}^{2}/v=45\), so

\[z_{12}^{(2)}=36,\ \ \ z_{18}^{(2)}=-36,\ \ \ z_{24}^{(2)}=-36,\ \ \ z_{30}^{(2)}=36\,,\]

which are 36 times the quadratic trend contrasts.

As in the simple linear regression case, one can likewise show that the least squares estimates \(\hat{\beta}_{1}^{*}\) and \(\hat{\beta}_{2}^{*}\) are constant multiples of the corresponding linear and quadratic trend contrast estimates \(\hat{\tau}_{3}-\hat{\tau}_{1}\) and \(\hat{\tau_{1}}-2\hat{\tau}_{2}+\hat{\tau}_{3}\) that would be used in the one-way analysis of variance model. Consequently, the sums of squares for testing no quadratic trend and no linear trend are the same, although again, the error mean square will differ.

#### Comments

We have illustrated via two examples the equivalence between the orthogonal trend contrasts in analysis of variance and orthogonal polynomials in regression analysis for the case of equispaced, equireplicated treatment levels. While both are convenient tools for data analysis, identification of orthogonal trend contrasts and orthogonal polynomials can be rather complicated for higher-order trends, unequally spaced levels, or unequal numbers of observations per level. Fortunately, analogous testing information can also be generated by fitting appropriate full and reduced models, as was discussed in Sect. 8.6.1. This is easily accomplished using computer regression software. Use of SAS and R software for such tests will be illustrated in Sects. 8.9 and 8.10.

### A Real Experiment--Bean-Soaking Experiment

The bean-soaking experiment was run by Gordon Keeler in 1984 to study how long mung bean seeds ought to be soaked prior to planting in order to promote early growth of the bean sprouts. The experiment was run using a completely randomized design, and the experimenter used a one-wayanalysis of variance model and methods of multiple comparisons to analyze the data. In Sect. 8.8.2, we present the one-way analysis of variance, and then in Sect. 8.8.3, we reanalyze the data using polynomial regression methods.

#### Checklist

The following checklist has been drawn from the experimenter's report.

1. **Define the objectives of the experiment.** The objective of the experiment is to determine whether the length of the soaking period affects the rate of growth of mung bean seed sprouts. The directions for planting merely advise soaking overnight, and no further details are given. As indicated in Fig. 8.6, I expect to see no sprouting whatsoever for short soaking times, as the water does not have sufficient time to penetrate the bean coat and initiate sprouting. Then, as the soaking time is increased, I would expect to see a transition period of sprouting with higher rates of growth as water begins to penetrate the bean coat. Eventually, the maximum growth rate would be reached due to complete saturation of the bean. A possible decrease in growth rates could ensue from even longer soaking times due to bacterial infection and "drowning" the bean.
2. **Identify all sources of variation**.
1. Treatment factors and their levels. There is just one treatment factor in this experiment, namely soaking time. A pilot experiment was run to obtain an indication of suitable times to be examined in the main experiment. The pilot experiment examined soaking times from 0.5 to 16 h. Many beans that had been soaked for less than 6 h failed to germinate, and at 16 h the saturation point had not yet been reached. Consequently, the five equally spaced soaking times of 6, 12, 18, 24 and 30 h will be selected as treatment factor levels for the experiment.
2. Experimental units. The experimental units are the mung bean seeds selected at random from a large sack of approximately 10,000 beans.
3. Blocking factors, noise factors, and covariates. Sources of variation that could affect growth rates include: individual bean differences; protozoan, bacterial, fungal, and viral parasitism; light; temperature; humidity; water quality. Differences between beans will hopefully balance out in the random assignment to soaking times. Light, temperature, humidity, and water quality will be kept constant for all beans in the experiment. Thus, no blocking factors or covariates will be needed in the model. Bacterial infection could differ from one treatment factor level to another due to soaking the beans in different baths. However, if the beans assigned to different treatment factor levels are soaked in the same bath, this introduces the possibility of a chemical signal from beans ready to germinate to the still dormant beans that sprouting conditions are prime. Consequently, separate baths will be used.
4. **Choose a rule by which to assign experimental units to treatments**. A completely randomized design will be used with an equal number of beans assigned to each soaking time.

* **Specify the measurements to be made, the experimental procedure, and the anticipated difficulties**. The soaking periods will be started at 6-h intervals, so that the beans are removed from the water at the same time. They will then be allowed to grow in the same environmental conditions for 48 h, when the lengths of the bean sprouts will be measured (in millimeters). The main difficulty in running the experiment is in controlling all the factors that affect growth. The beans themselves will be randomly selected and randomly assigned to soaking times. Different soaking dishes for the different soaking times will be filled at the same time from the same source. On removal from the soaking dishes, the beans will be put in a growth chamber with no light but high humidity. During the pilot experiment, the beans were rinsed after 24 h to keep them from dehydrating. However, the procedure cannot be well controlled from treatment to treatment, and will not be done in the main experiment. A further difficulty is that of accurately measuring the shoot length.
* **Run a pilot experiment**. A pilot study was run and the rest of the checklist was completed. As indicated in step (b), the results were used to determine the soaking times to be included in the experiment.
* **Specify the model**. The one-way analysis of variance model (3.3.1) will be used, and the assumptions will be checked after the data are collected.
* **Outline the analysis**. Confidence intervals for the pairwise differences in the effects of soaking time on the 48-h shoot lengths will be calculated. Also, in view of the expected results, linear, quadratic and cubic trends in the shoot length will be examined. Tukey's method will be used for the pairwise comparisons with \(\alpha_{1}=0.01\), and Bonferroni's method will be used for the three trend contrasts with overall level \(\alpha_{2}\leq 0.01\). The experimentwise error rate will then be at most 0.02.

Figure 8.6: Anticipated results from the bean-soaking experiment

* **Calculate the number of observations that need to be taken**. Using the results of the pilot experiment, a calculation showed that 17 observations should be taken on each treatment (see Example 4.5.1, p. 93).
* **Review the above decisions. Revise, if necessary**. Since 17 observations could easily be taken for the soaking time, there was no need to revise the previous steps of the checklist.

The experiment was run, and the resulting data are shown in Table 8.6. The data for soaking time 6 h have been omitted from the table, since none of these beans germinated.

The data are plotted in Fig. 8.7 and show that the trend expected by the experimenter is approximately correct. For the soaking times included in the study, sprout length appears to increase with soaking time, with soaking times of 18, 24, and 30 h yielding similar results, but a soaking of time of only 12 h yielding consistently shorter sprout

\begin{table}
\begin{tabular}{c c c c c c c c c c} \hline Soaking time (h) & \(r\) & Length (mm) & Average length & Sample variance \\ \hline
12 & 17 & 5 & 11 & 8 & 11 & 4 & 4 & 5.9412 & 7.0588 \\  & & 8 & 3 & 6 & 4 & 7 & 3 & & \\  & & 5 & 4 & 6 & 9 & 3 & & & \\
18 & 17 & 11 & 16 & 18 & 24 & 18 & 18 & 18.4118 & 12.6324 \\  & & 21 & 14 & 21 & 19 & 17 & 24 & & \\  & & 14 & 20 & 16 & 20 & 22 & & & \\
24 & 17 & 17 & 16 & 26 & 18 & 14 & 24 & 19.5294 & 15.6397 \\  & & 18 & 14 & 24 & 26 & 21 & 21 & & \\  & & 22 & 19 & 14 & 19 & 19 & & & \\
30 & 17 & 20 & 18 & 22 & 20 & 21 & 17 & 21.2941 & 8.5956 \\  & & 16 & 23 & 25 & 19 & 21 & 20 & & \\  & & 27 & 25 & 22 & 23 & 23 & & & \\ \hline \end{tabular}
\end{table}
Table 8.6: Length of shoots of beans after 48 h for the bean-soaking experiment

Figure 8.7: Plot of sprout length \(y_{xt}\) against soaking time \(x\) for the bean-soaking experiment

#### One-Way Analysis of Variance and Multiple Comparisons

The experimenter used Tukey's method with a 99% simultaneous confidence level to compare the effects of soaking the beans for 12, 18, 24, or 30 h. The formula for Tukey's method for the one-way analysis of variance model was given in (4.4.28) as

\[\tau_{i}-\tau_{s}\in\left(\overline{y}_{i.}-\overline{y}_{s.}\pm w_{T}\sqrt{ \left(\frac{2}{r}\right)\text{m}\text{s}E}\right),\]

where \(w_{T}=q_{v,n-v,\alpha}/\sqrt{2}\).

The treatment sample means are shown in Table 8.6. There are \(r=17\) observations on each of the \(v=4\) levels of the treatment factor. The formula for the sum of squares for error in the one-way analysis of variance model was given in (3.4.5), p. 39. Using the data in Table 8.6 we have

\[\text{m}\text{s}E=\text{s}\text{s}E/(n-v)=10.9816\,.\]

From Table A.8, \(q_{4,64,0.01}=4.60\). Thus, in terms of the coded factor levels, the 99% simultaneous confidence intervals for pairwise comparisons are

\[\tau_{4}-\tau_{3}\in(-1.93,\ \ 5.46)\,,\ \ \tau_{3}-\tau_{2}\in(-2.58,\ \ 4.81)\,,\] \[\tau_{4}-\tau_{2}\in(-0.81,\ \ 6.58)\,,\ \ \tau_{3}-\tau_{1}\in\ \ \ (9.89,\ 17.29)\,,\] \[\tau_{4}-\tau_{1}\in\ (11.66,\ 19.05)\,,\ \ \tau_{2}-\tau_{1}\in\ \ \ (8.77,\ 16.17)\,.\]

From these, we can deduce that soaking times of 18, 24, and 30 h yield significantly longer sprouts on average after 48 h than does a soaking time of only 12 h. The three highest soaking times are not significantly different in their effects on the sprout lengths, although the plot (Fig. 8.7) suggests that the optimum soaking time might approach or even exceed 30 h.

The one-way analysis of variance for the data is given in Table 8.7 and includes the information for testing for linear, quadratic, and cubic trends. The coefficients for the trend contrasts, when there are \(v=4\) equally spaced levels and equal sample sizes, are listed in Table A.2. The linear contrast is \([-3,\ -1,\ \ 1,\ \ 3]\), and the hypothesis of no linear trend is \(H_{0}^{L}:\{-3\tau_{1}-\tau_{2}+\tau_{3}+3\tau_{4}=0\}\). Obtaining the treatment sample means from Table 8.6, the estimate of the linear trend is

\[\sum_{i}c_{i}\overline{y}_{i}=-3\overline{y}_{1.}-\overline{y}_{2.}+\overline {y}_{3.}+3\overline{y}_{4.}=47.1765\,,\]

with associated variance

\[\Sigma_{i}(c_{i}^{2}/r)\sigma^{2}=(1/17)(9+1+1+9)\sigma^{2}=(20/17)\sigma^{2}\,.\]

The sum of squares is calculated from (4.3.14), p. 77; that is,

\[\text{s}\text{s}\text{c}=\left(\sum_{i}c_{i}\overline{y}_{i.}\right)^{2}/ \left(\sum_{i}c_{i}^{2}/17\right).\]

So, the sum of squares for the linear trend is\[\text{ssc}=(47.1765)^{2}/(20/17)=1891.78.\]

The quadratic and cubic trends correspond to the contrasts [ 1, -1, -1, 1 ] and [-1, 3, -3, 1 ], respectively, and their corresponding sums of squares are calculated in a similar way and are listed in Table 8.7. If we test the hypotheses that each of these three trends is zero with an overall significance level of \(\alpha=0.01\) using the Bonferroni method, then, using (4.4.24) on p. 84 for each trend, the null hypothesis that the trend is zero is rejected if \(\text{ssc}/\text{msE}>F_{1,64,0.01/3}\). This critical value is not tabulated, but since \(F_{1,64,0.0033}=t_{1,64,0.00166}^{2}\), it can be approximated using (4.4.22) as follows:

\[t_{1,64,0.00166}\approx 2.935+(2.935^{3}+2.935)/(4\times 64)=3.0454,\]

so the critical value is \(F_{1,64,0.0033}\approx 9.2747\). (Alternatively, the critical value could be obtained from a computer package using the "inverse cumulative distribution function" of the \(F\)-distribution.)

To test the null hypothesis \(H_{0}^{L}\) that the linear trend is zero against the alternative hypothesis \(H_{A}^{L}:-3\tau_{1}-\tau_{2}+\tau_{3}+3\tau_{4}\neq 0\) that the linear trend is nonzero, the decision rule is to

\[\text{reject }H_{0}\text{ if }\text{ssc}/\text{msE}=172.27>F_{1,64,.0033} \approx 9.2747\,.\]

Thus, using a simultaneous significance level \(\alpha=0.01\) for the three trends, the linear trend is determined to be nonzero.

The corresponding test ratios for the quadratic and cubic trends are given in Table 8.7. There is sufficient evidence to conclude that the linear, quadratic, and cubic trends are all significantly different from zero. The probability that one or more of these hypotheses would be incorrectly rejected by this procedure is at most \(\alpha=0.01\).

#### Regression Analysis

In the previous subsection, the bean-soaking experiment was analyzed using the one-way analysis of variance and multiple comparison methods. In this subsection, we reanalyze the experiment using regression analysis. Since there are four levels of the treatment factor "soaking time," the highest-order polynomial regression model that can be (uniquely) fitted to the data is the cubic regression model, namely,

\begin{table}
\begin{tabular}{c c c c c c} \hline Source of variation & Degrees of freedom & Sum of squares & Mean square & Ratio & \(p\)-value \\ \hline Soaking time & 3 & 2501.29 & 833.76 & 75.92 & 0.0001 \\ Linear trend & 1 & 1891.78 & 1891.78 & 172.27 & 0.0001 \\ Quadratic trend & 1 & 487.12 & 487.12 & 44.36 & 0.0001 \\ Cubic trend & 1 & 122.40 & 122.40 & 11.15 & 0.0014 \\ Error & 64 & 702.82 & 10.98 & & \\ Total & 67 & 3204.12 & & & \\ \hline \end{tabular}
\end{table}
Table 8.7: One-way ANOVA for the bean-soaking experiment \[Y_{xt}=\beta_{0}+\beta_{1}x+\beta_{2}x^{2}+\beta_{3}x^{3}+\epsilon_{xt}\;,\]

\[\epsilon_{xt}\sim N(0,\sigma^{2})\;,\]

\[\epsilon_{xt}\text{'s}\,\text{are mutually independent}\;,\]

\[x=12,\,18,\,24,\,30;\quad t=1,\,\ldots,\,17.\]

Using the data given in Table 8.6, the fitted model can be obtained from a computer program (see Sects. 8.9 and 8.10) as

\[\hat{y}_{x}=-101.058824+15.475490x-0.657680x^{2}+0.009259x^{3}\;.\]

Table 8.8 contains the analysis of variance for the bean experiment data based on the cubic regression model. The cubic model provides the same fit as does the one-way analysis of variance model, since \(p+1=v=4\). Thus, \(\hat{y}_{x}=\overline{y}_{x}\). for \(x=12,\,18,\,24,\,30\), and the number of degrees of freedom, the sum of squares, and the mean square for the major sources of variation--the treatment factor ("Model"), error, and total--are the same in the regression analysis of variance as in the one-way analysis of variance. It is not possible to test for model lack of fit, since the postulated model is of order \(p=3=v-1\). We can, however, test to see whether a lower-order model would suffice.

We first test the null hypothesis \(H_{0}^{Q}:\beta_{3}=0\), or equivalently, that the quadratic regression model \(E[Y_{xt}]=\beta_{0}+\beta_{1}x+\beta_{2}x^{2}\) would provide an adequate fit to the data. The result of the test is summarized in Table 8.8. The test ratio is 11.15 with a \(p\)-value of 0.0014. So, we reject \(H_{0}^{Q}\) and conclude that the cubic model is needed. Since the cubic regression model provides the same fit as the analysis of variance model, this test is identical to the test that the cubic trend contrast is zero in the one-way analysis of variance, shown in Table 8.7.

If \(H_{0}^{Q}:\beta_{3}=0\) had not been rejected, then the next step would have been to have tested the null hypothesis \(H_{0}^{L}:\beta_{2}=\beta_{3}=0\), or equivalently, that the simple linear regression model is adequate. If neither \(H_{0}^{Q}:\beta_{3}=0\) nor \(H_{0}^{L}:\beta_{2}=\beta_{3}=0\) had been rejected, the next step would have been to have tested \(H_{0}:\beta_{1}=\beta_{2}=\beta_{3}=0\).

Based on the previous analysis, the cubic model is needed to provide an adequate fit to the data. Figure 8.8 illustrates the cubic model fitted to the data. We may now see the dangers of using a model to predict the value of the response beyond the range of observed \(x\) values. The cubic model predicts that mean sprout length will increase rapidly as soaking time is increased beyond 30 h! Clearly, this model is extremely unlikely to be reliable for extrapolation beyond 30 h.

Recall that Tukey's method of multiple comparisons did not yield any significant differences in mean response between the soaking times of 18, 24, and 30 h. Yet the plot of the data in Fig. 8.8 suggests that a trend over these levels might well exist. There is a lot of variability inherent in the data that prevents significant differences between the soaking times from being detected. Nevertheless, a

\begin{table}
\begin{tabular}{c c c c c c} \hline Source of variation & Degrees of freedom & Sum of squares & Mean square & Ratio & \(p\)-value \\ \hline \(\beta_{3}\) & 1 & 122.40 & 122.40 & 11.15 & 0.0014 \\ \(\beta_{2},\,\beta_{3}\) & 2 & 609.52 & 304.76 & 27.76 & 0.0001 \\ Model & 3 & 2501.29 & 833.76 & 75.92 & 0.0001 \\ Error & 64 & 702.82 & 10.98 & & \\ Total & 67 & 3204.12 & & & \\ \hline \end{tabular}
\end{table}
Table 8.8: Cubic regression ANOVA for the bean-soaking experiment followup experiment examining soaking times from 18 to, say, 48 h might provide the information needed to determine the best range of soaking times.

### Using SAS Software

Polynomial regression models can be fitted using the SAS regression procedure PROC REG. The procedure provides least squares estimates of the regression parameters. Predicted (fitted) values and residuals can be saved to an output data set, as can 95% confidence limits for mean response, 95% prediction limits for new observations for given treatment levels \(x\), and corresponding standard errors.

A sample SAS program to analyze the data from the bean-soaking experiment of Sect. 8.8 is shown in Table 8.9. In the first DATA statement, the variables \(x^{2}\) and \(x^{3}\) are created for the cubic regression model. PROC REG is used to fit the cubic regression model, and the output is shown in Fig. 8.9.

An analysis of variance table is automatically generated and includes information needed for testing the hypothesis that the treatment factor "soaking time" has no predictive value for mean growth length, namely, \(H_{0}:\{\beta_{1}=\beta_{2}=\beta_{3}=0\}\). The information for this test is listed with source of variation "Model". We see that the _p_-value is less than 0.0001, so \(H_{0}\) would be rejected.

Below the analysis of variance table, parameter estimates for the fitted model are given. Using these, we have the fitted cubic regression model

\[\hat{y}_{x}=-101.05882+15.47549x-0.65768x^{2}+0.00926x^{3}\,.\]

The standard error of each estimate is also provided, together with the information for conducting a \(t\)-test of each individual hypothesis \(H_{0}:\{\beta_{i}=0\}\), \(i=1,2,3\).

Inclusion of the option SS1 in the MODEL statement of PROC REG causes printing of the Type I (sequential) sums of squares in the output. Each Type I sum of squares is the variation explained by entering the corresponding variable into the model, given that the previously listed variables are already in the model. For example, the Type I sum of squares for X is ssE0 - ssE1, where ssE0 is the error sum of squares for the model with \(E[Y_{xI}]=\beta_{0}\), and ssE1 is the error sum of squares for the simple linear regression model E[\(Y_{xI}]=\beta_{0}+\beta_{1}x\); that is,

\[\text{ss}(\beta_{1}|\beta_{0})=\text{ss}E_{0}-\text{ss}E_{1}=1891.77647\,.\]

Likewise, the Type I sum of squares for X2 is the difference in error sums of squares for the linear and quadratic regression models; that is,

Figure 8.8: Plot of data and fitted cubic polynomial regression model for the bean-soaking experiment

\[\text{ss}(\beta_{2}|\beta_{0},\,\beta_{1})=\text{ss}E_{1}-\text{ss}E_{2}=487.11765\,,\]

and for X3, the Type I sum of squares is the difference in error sums of squares for the quadratic and cubic regression models; that is,

\[\text{ss}(\beta_{3}|\beta_{0},\,\beta_{1},\,\beta_{2})=\text{ss}E_{2}-\text{ss}E=122.40000\,,\]

where we have written ssE for the error sum of squares for the full cubic model (rather than ssE3). Thus, the ratio used to test the null hypothesis \(H_{0}^{Q}:\{\beta_{3}=0\}\) versus \(H_{A}^{Q}:\{\beta_{3}\neq 0\}\) is

\[\text{ss}(\beta_{3})/\text{ms}E=\text{ss}(\beta_{3}|\beta_{0},\,\beta_{1},\, \beta_{2})/\text{ms}E=122.4/10.98162=11.1459\,.\]The output of the TEST statement labeled QUAD provides the same information, as well as the \(p\)-value 0.0014. The null hypothesis \(H_{0}^{Q}\) is thus rejected, so the quadratic model is not adequate--the cubic model is needed. Hence, there is no reason to test further reduced models, but the information for such tests will be discussed for illustrative purposes.

To test \(H_{0}^{L}:\beta_{2}=\beta_{3}=0\), the full model is the cubic model and the reduced model is the linear model, so the numerator sum of squares of the test statistic is

\begin{table}
\begin{tabular}{l} DATA BEAN; \\  INPUT X LENGTH; \\  X2 = X**2; X3 = X**3; \\  LINES; \\  l2 5 \\  12 12 8 \\  : \\  30 23 \\  30 23 \\  ; \\  * create extra x-values for plotting the fitted curve; \\  DATA TOPLOT; \\  DO X = 8 TO 34; X2 = X**2; X3 = X**3; \\  LENGTH =.; * *.’ denotes a missing value;  OUTPUT; \\  END; * X loop; \\  * concatenate data sets BEAN and TOPLOT; \\  DATA; SET BEAN TOPLOT; \\  * do the analysis; \\ PROC REG; MODEL LENGTH = X X2 X3 / SS1; \\  QUAD: TEST X3 = 0; * test adequacy of quadratic model; \\  LINER: TEST X2 = 0, X3 = 0; * test adequacy of linear model; \\  OUTPUT PREDICTED = LHT RESIDUAL = E \\  L95M = L95M U95M = U95M STDP = STDM \\  L95 = L95I U95 = U95I STDI = STDI; \\  * plot the data and fitted model, overlayed on one plot; \\  PROC SGPLOT; \\  SCATTER Y = LENGTH X = X / LEGENDLABEL = ’Observed data’ \\  MARKEREATTRS = (SIZE = 0.25cm COLOR = BLACK); \\  SCATTER Y = LHT X = X / LEGENDLABEL = ’Cubic model fit’ \\  MARKEREATTRS = (SYMBOL = SQUARE SIZE = 0.25cm COLOR = BLACK); \\  YAXIS LABEL = ’Sprout length (mm)’ VALUES = (-20 TO 30 by 5); \\  XAXIS LABEL = ’Soaking time (hrs)’ VALUES = (8 TO 36 by 4); \\  * 95\% confidence intervals and standard errors for mean response; \\  PROC PRINT; VAR X L95M LHT U95M STDM; \\  * 95\% prediction intervals and standard errors for new observations; \\  PROC PRINT; VAR X L95I LHT U95I STDI; \\  * generate residual plots; \\  PROC RANK NORMAL = BLOM; VAR E; RANKS NSCORE; \\  PROC SGPLOT; SCATTER Y = E X = X; \\  PROC SGPLOT; SCATTER Y = E X = LHT; \\  PROC SGPLOT; SCATTER Y = E X = NSCORE; \\ \end{tabular}
\end{table}
Table 8.9: SAS program for analysis of the bean-soaking experiment 

[MISSING_PAGE_EMPTY:8232]

Subsequently, though the results are not shown here, the head command would display the first six rows of data, showing for example that the data set contains the two variables x and Length, then the dimension command would reveal that the data set contains 68 observations, and a scatterplot of the data would be generated.

In the second block of code, the linear model function lm is used to fit the cubic, quadratic, and linear regression models, saving the respective results as model3, model2 and model1, and related commands are used to generate the output shown in Tables 8.11 and 8.12. Since the data set contains the soaking time, \(x\), the syntax I(x\({}^{\wedge}\)2) allows inclusion of the quadratic term \(x^{2}\) as a predictor variable in a model without creating a corresponding variable in the data set, and likewise I(x\({}^{\wedge}\)3) for the cubic term \(x^{3}\). The command summary(model3) displays the parameter least squares estimates shown in the middle of Table 8.11. From these, we have the fitted cubic regression model

\[\hat{y}_{x}=-101.05882+15.47549x-0.65768x^{2}+0.00926x^{3}\,.\]

The standard error of each estimate is also provided, together with the information for conducting a \(t\)-test of each individual hypothesis \(H_{0}:\{\beta_{i}=0\}\), \(i=1,2,3\).

The summary command also generates the analysis of variance \(F\)-test of the hypothesis that the treatment factor "soaking time" has no predictive value for mean growth length, namely, \(H_{0}:\{\beta_{1}=\beta_{2}=\beta_{3}=0\}\). The information for this test is listed after "F-statistic". We see that the \(p\)-value is very small, only \(2\times 10^{-16}\), so \(H_{0}\) would be rejected.

Having saved the results of the cubic fit as model3, the statement anova(model3) causes display of the Type I (sequential) sums of squares, provided in an analysis of variance table in the bottom of Table 8.11. Each Type I sum of squares is the variation explained by entering the corresponding variable into the model, given that the previously listed variables are already in the model. For example, the Type I sum of squares for x is ss\(E_{0}-\)ss\(E_{1}\), where ss\(E_{0}\) is the error sum of squares for the model with \(E[Y_{xt}]=\beta_{0}\), and ss\(E_{1}\) is the error sum of squares for the simple linear regression model E[\(Y_{xt}]=\beta_{0}+\beta_{1}x\); that is,

\[\text{ss}(\beta_{1}|\beta_{0})=\text{ss}E_{0}-\text{ss}E_{1}\approx 1892\,.\]

Likewise, the Type I sum of squares for x\({}^{\wedge}\)2 is the difference in error sums of squares for the linear and quadratic regression models; that is,

\[\text{ss}(\beta_{2}|\beta_{0},\,\beta_{1})=\text{ss}E_{1}-\text{ss}E_{2} \approx 487\,,\]

and for x\({}^{\wedge}\)3, the Type I sum of squares is the difference in error sums of squares for the quadratic and cubic regression models; that is,

\[\text{ss}(\beta_{3}|\beta_{0},\,\beta_{1},\,\beta_{2})=\text{ss}E_{2}-\text{ ss}E\approx 122\,,\]

where we have written ssE for the error sum of squares for the full cubic model (rather than ss\(E_{3}\)). Thus, the ratio used to test the null hypothesis \(H_{0}^{Q}:\{\beta_{3}=0\}\) versus \(H_{A}^{Q}:\{\beta_{3}\neq 0\}\) is

\[\text{ss}(\beta_{3})/\text{ms}E=\text{ss}(\beta_{3}|\beta_{0},\,\beta_{1},\, \beta_{2})/\text{ms}E\approx 122/11\approx 11.2\,,\]

with corresponding \(p\)-value 0.0014. The null hypothesis \(H_{0}^{Q}\) is thus rejected, so the quadratic model is not adequate--the cubic model is needed. The same information is generated by the statement anova(model2, model3), which compares the reduced quadratic and full cubic models, with output shown in the top of Table 8.12. Since the cubic model is needed, there is no reason to test further reduced models, but the information for such tests will be discussed for illustrative purposes.

To test \(H_{0}^{L}:\beta_{2}=\beta_{3}=0\), the full model is the cubic model and the reduced model is the simple linear regression model, so the numerator sum of squares of the test statistic computed from the Type I sums of squares is

\begin{table}
\begin{tabular}{l} bean.data = read.table(‘data/bean.txt’’, header=T) \\ head(bean.data); dim(bean.data); plot(Length ~~ x, data=bean.data) \\ \# Fit regression models and generate ANOVA info \\ model3 = lm(Length ~~ x + I(x^2) + I(x^3), data=bean.data) \# Fit cubic model \\ summary(model3) \# Display least squares estimates, overall F test \\ anova(model3) \# Display type 1 SS \\ \# Would a lower order model suffice? \\ model2 = lm(Length ~~ x + I(x^2), data=bean.data) \# Fit quadratic model \\ model1 = lm(Length ~~ x, data=bean.data) \# Fit simple linear reg model \\ anova(model2, model3) \# Can cubic term be dropped? \\ anova(model1, model3) \# Can both cubic and quadratic terms be dropped? \\ \# Compute predicted values, CIs, PIs, and std errors for x=8, 8.01,...., 34 \\ \# Set up a grid of x‘s for prediction: x=8, 8.01, 8.02,...., 34 \\ xPred = data.frame(x=seq(8, 34, 0.01)) \\ \# Calculate fitted values, 95\$ CIs for mean response, se.fit \\ preds = predict(model3, xPred, se.fit=T, interval=c(‘confidence’’)) \\ \# Calculate 95\$ PIs for new observations \\ preds2 = predict(model3, xPred, interval = c(‘prediction’’)) \\ \# preds; preds2 \# (Reader: display preds and preds2 to see contents) \\ se.fit = preds\$se.fit \# to remove ‘preds’’ from column header name \\ \# Compute standard error for prediction \\ rmse = preds\$residual.scale \# used to compute se.pred \\ se.pred = sqrt(preds\$se.fit’’2 + rmse’’2) \\ \# Consolidate results for display \\ stats = cbind(xPred, preds\$fit, se.fit, preds2[,2:3], se.pred) \\ head(stats) \# display first six rows of results \\ \# Plot data (length vs x), plus fitted model for x=8:34 \\ plot(Length ~~ x, xlim = c(8, 34), ylim = c(-10, 30), data=bean.data) \\ lines(xPredSx, predsSfit[, 1]) \\ \# Some plots to check model assumptions \\ bean.dataSe = residuals(model3); \# Obtain residuals \\ bean.dataSpred = fitted(model3) \# Obtain predicted values \\ \# Plot residuals vs x \\ plot(e ~~ x, ylab = *Residuals’’, las=1, xaxt=‘n’’, data=bean.data) \\ axis(1, at = c(12,18,24,30)); abline(h=0) \\ \# Plot residuals vs predicted values \\ plot(e ~~ pred, xlim=c(5,25), las=1, xaxt=‘n’’, data=bean.data, \\ xlab=‘Predicted Values’’, ylab = *Residuals’’) \\ axis(1, at=seq(5,25,5)); abline(h=0) \\ \# Normal probability plot of residuals \\ qnorm(model3$res, ylim=c(-10,10), xlim=c(-4,4)); abline(h=0, v=0) \\ \end{tabular}
\end{table}
Table 8.10: R program for analysis of the bean-soaking experiment \[\text{ss}(\beta_{2},\beta_{3}) = ssE_{1}-ssE = ss(\beta_{2}|\beta_{0},\beta_{1})+ss(\beta_{3}|\beta_{0},\beta_{1}, \beta_{2})\] \[\approx 487+122 = 609\,,\]

and the decision rule for testing \(H_{0}^{L}\) against the alternative hypothesis \(H_{A}^{L}\) that the cubic model is needed is

\[\text{reject }H_{0}^{L}\text{ if }\text{ ms}(\beta_{2},\beta_{3})/\text{msE}>F_{2,64,\alpha}\,,\]

where

\[\text{ms}(\beta_{2},\beta_{3})=\text{ss}(\beta_{2},\beta_{3})/2\,.\]

The information for this test of adequacy of the simple linear regression model is also generated by the statement anova (model1, model3), with results shown in the bottom of Table 8.12. Here, the numerator sum of squares is rounded to 610, yielding \(F=27.8\) and \(p=2.1\times 10^{-09}\).

The third block of code in Table 8.10 saves a grid of \(x\) values from 8 to 34 in step of 0.01 in a data set xPred, in order to compute confidence and prediction intervals at these \(x\) values. The predict function is called twice, each time using the results of the cubic fit saved as model3. For each \(x\) value in the grid, the first call of predict computes the predicted length, the standard error for predicting mean length, and the 95% confidence interval for mean response, saving these results asvadjust preds. By

\begin{table}
\begin{tabular}{l l l l l} \hline \hline  & \multicolumn{2}{c}{\(>\) \# Fit regression models and generate ANOVA info} & \multicolumn{2}{c}{\(>\) model3 = lm(Length – x + I(x^{2}) + I(x^{3}), data=bean.data) \# Fit cubic model} & \multicolumn{2}{c}{\(>\) summary(model3) \# Display least squares estimates, overall F test} \\ \multicolumn{2}{l}{Call:} & \multicolumn{2}{c}{lm(formula = Length – x + I(x^{2}) + I(x^{3}), data = bean.data)} & \multicolumn{2}{c}{} \\ \multicolumn{2}{l}{Residuals:} & \multicolumn{2}{c}{Min} & \multicolumn{2}{c}{1Q Median} & \multicolumn{2}{c}{3Q Max} & \multicolumn{2}{c}{\(-\)7.412 -2.029 -0.412 2.059 6.471} & \multicolumn{2}{c}{} \\ \multicolumn{2}{l}{Coefficients:} & \multicolumn{2}{c}{Estimate Std. Error t value Pr(\textgreater{}|t|)} & \multicolumn{2}{c}{} \\ \multicolumn{2}{l}{(Intercept) -101.05882} & \multicolumn{2}{c}{21.87851} & \multicolumn{2}{c}{\(-\)4.62 0.000019} & \multicolumn{2}{c}{\(\times\)} \\ \multicolumn{2}{l}{x} & \multicolumn{2}{c}{15.47549} & \multicolumn{2}{c}{3.49667} & \multicolumn{2}{c}{4.43 0.000038} & \multicolumn{2}{c}{\(\times\)} \\ \multicolumn{2}{l}{I(x^{2}) -0.65768} & \multicolumn{2}{c}{0.17508} & \multicolumn{2}{c}{-3.76 0.00037} & \multicolumn{2}{c}{I(x^{3})} & \multicolumn{2}{c}{0.00926} & \multicolumn{2}{c}{\(\times\)} \\ \multicolumn{2}{l}{} \\ \multicolumn{2}{l}{Residual standard error: 3.31 on 64 degrees of freedom} & \multicolumn{2}{c}{Multiple R-squared: 0.781, Adjusted R-squared: 0.77} & \multicolumn{2}{c}{F-statistic: 75.9 on 3 and 64 DP, p-value: \textless{}2e-16} & \multicolumn{2}{c}{} \\ \multicolumn{2}{l}{F-statistic: 75.9 on 3 and 64 DP, p-value: \textless{}2e-16} & \multicolumn{2}{c}{} \\ \multicolumn{2}{l}{\(>\) anova(model3) \# Display type 1 SS} & \multicolumn{2}{c}{Analysis of Variance Table} & \multicolumn{2}{c}{Response: Length} & \multicolumn{2}{c}{Df Sum Sq Mean Sq F value Pr(\textgreater{}F)} & \multicolumn{2}{c}{} \\ \multicolumn{2}{l}{x} & \multicolumn{2}{c}{1} & \multicolumn{2}{c}{1892} & \multicolumn{2}{c}{172.3 \textless{} 2e-16} & \multicolumn{2}{c}{} \\ \multicolumn{2}{l}{I(x^{2}) 1 & \multicolumn{2}{c}{1} & \multicolumn{2}{c}{487} & \multicolumn{2}{c}{487} & \multicolumn{2}{c}{44.4 7.3e-09} & \multicolumn{2}{c}{\(\times\)} \\ \multicolumn{2}{l}{I(x^{3}) 1 & \multicolumn{2}{c}{1} & \multicolumn{2}{c}{122} & \multicolumn{2}{c}{11.2} & \multicolumn{2}{c}{0.0014} & \multicolumn{2}{c}{\(\times\)} \\ \multicolumn{2}{l}{Residuals 64 & 703 & 11 & & & \\ \hline \hline \end{tabular}
\end{table}
Table 8.11: Output generated for the cubic model displaying preds, one would see that the predicted values and confidence limits are saved as the three columns of the object predsSfit, the standard error is saved as the lone column of predsSse.fit, and the root mean squared error is saved as a scalar as predsSresidual.scale. Due to the "prediction" option, the second call of predict computes the predicted length and the 95% prediction interval for a new observation for each \(x=8,\ldots,34\), saving these results as the three columns of preds2. The standard error for prediction is not provided directly, but is subsequently computed for each \(x\) from the standard error for estimation of mean length for the given \(x\) value and from the common root mean squared error value, both available from preds. The column bind command cbind is used to combine the desired information into the columns of the object stats. These could be printed or plotted, though we do not do so here.

The output of the plot function in the fourth block of code is not shown here, but is similar to the plot show in Fig. 8.8. The plot command causes the raw data to be plotted. Then the lines subcommand augments the plot with the line corresponding to the predicted values at the grid points \(x=8,\)\(8.01,\)\(8.02,\)\(\ldots,34\), giving a sense of the fitted cubic polynomial regression curve.

In this example, it is not possible to test for lack of fit of the cubic model, since data were collected at only four \(x\)-levels. If we had been fitting a quadratic model, then a lack-of-fit test would have been possible. An easy way to generate the relevant output using the R software is as follows. Anyplace after saving the fitted quadratic model as model2 in the second block of code, add the following code.

```
bean.data$fA=factor(bean.data$x)  modelA=lm(Length~fA,data=bean.data)  anova(model2,modelA))
```

The first command adds a factor variable fA to the data set, the second fits the one-way model with a different mean for each \(x\) value (i.e. for each level of fA), and the third generates the \(F\)-test for lack of fit by comparing the reduced quadratic model to the full one-way model, which is the fullest model one can fit here.

Statements for generation of residual plots for checking the error assumptions are included in the sample R program in Table 8.10, but the output is not shown here.

\begin{table}
\begin{tabular}{l l} \textgreater{} \# Would a lower order model suffice? \\ \textgreater{} model2 = lm(Length~x+I(x^2),data=bean.data) \# Fit quadratic model \\ \textgreater{} model1 = lm(Length~x,data=bean.data) \# Fits simple linear reg model \\ \textgreater{} anova(model2,model3) \# Can cubic term be dropped? \\ Analysis of Variance Table \\ Model 1: Length~x+I(x^2) Model2:Length~x+I(x^2)+I(x^3) \\  Res.DfRSSDfSumofSqFPr(>F) \\
1 & 65 825 \\
2 & 64 703 1 122 11.2 0.0014 \\ \textgreater{} anova(model1,model3) \# Can both cubic and quadratic terms be dropped? \\ Analysis of Variance Table \\ Model 1: Length~x

Model 2: Length~x+I(x^2)+I(x^3) \\  Res.DfRSSDfSumofSqFPr(>F) \\
1 & 66 1312 \\
2 & 64 703 2 610 27.8 2.1e-09 \\ \end{tabular}
\end{table}
Table 8.12: Output generated for the cubic model (continued)

## Exercises

1. For the simple linear regression model \[\text{E}[Y_{xt}]=\beta_{0}+\beta_{1}x\,\] the least squares estimators \(\hat{\beta}_{0}\) and \(\hat{\beta}_{1}\) for the parameters \(\beta_{0}\) and \(\beta_{1}\) are given in (8.5.6), p. 257. Show that their variances are \[\text{Var}(\hat{\beta}_{0})=\sigma^{2}\left(\frac{1}{n}+\frac{\overline{x}_{...}^{2}}{s\overline{s}_{xx}}\right)\ \ \text{and}\ \text{Var}(\hat{\beta}_{1})=\sigma^{2}\left(\frac{1}{s\overline{s}_{xx}}\right)\,\] where \(s\overline{s}_{xx}=\sum_{x}r_{x}(x-\overline{x}_{..})^{2}\), as given in (8.5.7).
2. **Bicycle experiment, continued** The bicycle experiment was run to compare the crank rates required to keep a bicycle at certain speeds, when the bicycle (a Cannondale SR400) was in twelfth gear on flat ground. The speeds chosen were \(x=5\), 10, 15, 20, and 25 mph. The data are given in Table 8.13. (See also Exercise 6 of Chap. 5.) 1. Fit the simple linear regression model to the data, and use residual plots to check the assumptions of the simple linear regression model. 2. If a transformation of the data is needed, choose a transformation, refit the simple linear regression model, and check for lack of fit. 3. Using your results from parts (a) and (b), select a model for the data. Use this model to obtain an estimate for the mean crank rate needed to maintain a speed of 18 mph in twelfth gear on level ground. 4. Calculate a 95% confidence interval for the mean crank rate needed to maintain a speed of 18 mph in twelfth gear on level ground. 5. Find the 95% confidence band for the regression line. Draw a scatter plot of the data and superimpose the regression line and the confidence band on the plot. 6. Would you be happy to use your model to estimate the mean crank rate needed to maintain a speed of 35 mph in twelfth gear on level ground. Why or why not? 7.

[MISSING_PAGE_FAIL:303]

3. Use residual plots to check the assumptions of the quadratic model. 4. Test whether the quadratic term is needed in the model. 5. Use the fitted quadratic model to estimate the number of grams of sulfamerazine per 100 pounds of fish to maximize the mean amount of hemoglobin in the blood of the brown trout.
5. **Bean-soaking experiment, continued** Use residual plots to check the assumptions of the cubic regression model for the data of the beam-soaking experiment. (The data are in Table 8.6, p. 269).
6. **Bean-soaking experiment, continued** Suppose the experimenter in the bean-soaking experiment of Sect. 8.8 had presumed that the quadratic regression model would be adequate for soaking times ranging from 12 to 30 h. 1. Figure 8.8, p. 273, shows the fitted response curve and the standardized residuals each plotted against soaking time. Based on these plots, discuss model adequacy. 2. Test the quadratic model for lack of fit.
7. **Orthogonal polynomials** Consider an experiment in which an equal number of observations are collected for each of the treatment factor levels \(x=10\), 20, 30, 40, 50. 1. Compute the corresponding values \(z_{x}\) for the linear orthogonal polynomial, and determine the rescaling factor by which the \(z_{x}\) differ from the coefficients of the linear trend contrast. 2. Compute the values \(z_{x}^{(2)}\) for the quadratic orthogonal polynomial, and determine the rescaling factor by which the \(z_{x}^{(2)}\) differ from the coefficients of the quadratic trend contrast. 3. Use the data of Table 8.1 and the orthogonal polynomial coefficients to test that the quadratic and linear trends are zero. 4. Using the data of Table 8.1 and a statistical computing package, fit a quadratic model to the original values. Test the hypotheses \[H_{0}^{L}:\{\beta_{2}=0\}\quad\text{ and }\quad H_{0}:\{\beta_{1}=\beta_{2}=0\}\] against their respective two-sided alternative hypotheses. Compare the results of these tests with those in (c).
8. **Orthogonal polynomials** Consider use of the quadratic orthogonal polynomial regression model (8.7.20), p. 265, for the data at levels 18, 24, and 30 of the bean-soaking experiment--the data are in Table 8.6, p. 269. 1. Compute the least squares estimates of the parameters. 2. Why is it not possible to test for lack of fit of the quadratic model? 3. Give an analysis of variance table and test the hypothesis that a linear model would provide an adequate representation of the data.

## 9 Heart-lung pump experiment, continued

In Example 8.5.1, p. 259, we fitted a linear regression model to the data of the heart-lung pump experiment. We rejected the null hypothesis that the slope of the line is zero.

1. Show that the numerator sum of squares for testing \(H_{0}:\{\beta_{1}=0\}\) against the alternative hypothesis \(H_{A}:\{\beta_{1}\neq 0\}\) is the same as the sum of squares ssc that would be obtained for testing that the linear trend is zero in the analysis of variance model (the relevant calculations were done in Example 4.2.3, p. 73).
2. Obtain a 95% confidence band for the regression line.
3. Calculate a 99% prediction interval for the fluid flow rate at 100 revolutions per minute.
4. Estimate the intercept \(\beta_{0}\). This is not zero, which suggests that the fluid flow rate is not zero at 0 rpm. Since this should not be the case, explain what is happening.

### 9.1 Introduction

In Chaps. 3-7, we used completely randomized designs and analysis of variance to compare the effects of one or more treatment factors on a response variable. If nuisance factors are expected to be a major source of variation, they should be taken into account in the design and analysis of the experiment. If the values of the nuisance factors can be measured in advance of the experiment or controlled during the experiment, then they can be taken into account at the design stage using blocking factors, as discussed in Chap. 10. Analysis of covariance, which is the topic of this chapter, is a means of adjusting the analysis for nuisance factors that cannot be controlled and that sometimes cannot be measured until the experiment is conducted. The method is applicable if the nuisance factors are related to the response variable but are themselves unaffected by the treatment factors.

For example, suppose an investigator wants to compare the effects of several diets on the weights of month-old piglets. The response (weight at the end of the experimental period) is likely to be related to the weight at the beginning of the experimental period, and these weights will typically be somewhat variable. To control or adjust for this prior weight variability, one possibility is to use a block design, dividing the piglets into groups (or blocks) of comparable weight, then comparing the effects of diets within blocks. A second possibility is to use a completely randomized design with response being the weight gain over the experimental period. This loses information, however, since heavier piglets may experience higher weight gain than lighter piglets, or vice versa. It is preferable to include the prior weight in the model as a variable, called a _covariate_, that helps to explain the final weight.

The model for a completely randomized design includes the effects of the treatment factors of interest, together with the effects of any nuisance factors (covariates). _Analysis of covariance_ is the comparison of treatment effects, adjusting for one or more covariates. Standard analysis of covariance models and assumptions are discussed in Sect. 9.2. Least squares estimates are derived in Sect. 9.3. Sections 9.4 and 9.5 cover analysis of covariance tests and confidence interval methods for the comparison of treatment effects. Analysis using software is illustrated using SAS and R software in Sects. 9.6 and 9.7, respectively.

### 9.2 Models

Consider an experiment conducted as a completely randomized design to compare the effects of the levels of \(v\) treatments on a response variable \(Y\). Suppose that the response is also affected by a nuisancefactor (covariate) whose value \(x\) can be measured during or prior to the experiment. Furthermore, suppose that there is a linear relationship between \(E[Y]\) and \(x\), with the same slope for each treatment. Then, if we plot \(E[Y]\) versus \(x\) for each treatment separately, we would see parallel lines, as illustrated for two treatments in Fig. 10(a). A comparison of the effects of the two treatments can be done by comparison of mean response at any value of \(x\). The model that allows this type of analysis is the analysis of covariance model:

\[Y_{it}=\mu+\tau_{i}+\beta x_{it}+\epsilon_{it}\,, \tag{11}\] \[\epsilon_{it}\sim N(0,\sigma^{2})\,,\] \[\epsilon_{it}{}^{\prime}\text{s}\text{ are mutually independent}\,,\] \[t=1,2,\ldots,r_{i};\quad i=1,\ldots,v\,.\]

In this model, the effect of the \(i\)th treatment is modeled as \(\tau_{i}\), as usual. If there is more than one treatment factor, then \(\tau_{i}\) represents the effect of the \(i\)th treatment combination and could be replaced by main-effect and interaction parameters. The value of the covariate on the \(t\)th time that treatment \(i\) is observed is written as \(x_{it}\), and the linear relationship between the response and the covariate is modeled as \(\beta x_{it}\) as in a regression model. It is important for the analysis that follows that the value \(x_{it}\) of the covariate not be affected by the treatment--otherwise, comparison of treatment effects at a common \(x\)-value would not be meaningful.

A common alternative form of the analysis of covariance model is

\[Y_{it}=\mu^{*}+\tau_{i}+\beta(x_{it}-\overline{x}_{..})+\epsilon_{it}\,, \tag{11}\]

in which the covariate values have been "centered." The two models are equivalent for comparison of treatment effects. The slope parameter \(\beta\) has the same interpretation in both models. In model (11), \(\mu+\tau_{i}\) denotes the mean response when \(x_{it}=\overline{x}_{..}\), whereas in model (11), \(\mu^{*}+\tau_{i}\) denotes the mean response when \(x_{it}=0\), with the parameter relationship \(\mu^{*}=\mu-\beta\tilde{x}_{..}\) Model (11) is often used to reduce computational problems and is a little easier to work with in obtaining least squares estimates.

Figure 10: Linear and quadratic parallel response curves

#### Checking Model Assumptions and Equality of Slopes

In addition to the usual assumptions on the error variables, the analysis of covariance model (9.2.2) assumes a linear relationship between the covariate and the mean response, with the same slope for each treatment, as illustrated in Fig. 9.1a. It is appropriate to start by checking for model lack of fit.

Lack of fit can be investigated by plotting the residuals versus the covariate for each treatment on the same scale. If the plot looks nonlinear for any treatment, then a linear relationship between the response and covariate may not be adequate. If each plot does look linear, one can assess whether the slopes are comparable. A formal test of equality of slopes can be conducted by comparing the fit of the analysis of covariance model (9.2.2) with the fit of the corresponding model that does not require equal slopes, for which

\[Y_{it}=\mu+\tau_{i}+\beta_{i}(x_{it}-\overline{x}_{..})+\epsilon_{it}. \tag{9.2.3}\]

If there is no significant lack of fit of the model, then plots of the residuals versus run order, predicted values, and normal scores can be used as in Chap. 5 to assess the assumptions of independence, equal variances, and normality of the random error terms.

#### Model Extensions

The analysis of covariance model (9.2.1) can be generalized in various ways that we will mention here but not consider further.

If the effect of the covariate is not linear, then \(\beta x\) can be replaced with a higher-order polynomial function \(\beta_{1}x+\beta_{2}x^{2}+\cdots+\beta_{p}x^{p}\) to adequately model the common shape of the response curves for each treatment, analogous to the polynomial response curve models of Chap. 8. For example, parallel quadratic response curves for two treatments are shown in Fig. 9.1b.

If there is more than one covariate, the single covariate term can be replaced by an appropriate polynomial function of all the covariates. For example, for two covariates \(x_{1}\) and \(x_{2}\), the second-order function

\[\beta_{1}x_{1}+\beta_{2}x_{2}+\beta_{12}x_{1}x_{2}+\beta_{11}x_{1}^{2}+\beta_{ 22}x_{2}^{2}\]

might be used, analogous to the polynomial response surface models of Chap. 16. Centered forms of these functions can also be obtained (see Sect. 8.7).

### Least Squares Estimates

We now obtain the least squares estimates for the parameters in the analysis of covariance model, and then illustrate the need to use adjusted means to compare treatment effects.

#### Normal Equations (Optional)

To obtain the least squares estimates of the parameters in model (9.2.2), we need to minimize the sum of squared errors,

\[\sum_{i=1}^{v}\sum_{l=1}^{r_{l}}e_{it}^{2}=\sum_{i=1}^{v}\sum_{l=1}^{r_{l}} \left(y_{it}-\mu-\tau_{l}-\beta(x_{it}-\overline{x}_{..})\right)^{2}\.\]Differentiating this with respect to each parameter in turn and setting the corresponding derivative equal to zero gives the normal equations as

\[y_{..} = n\hat{\mu}+\sum_{i=1}^{v}r_{i}\hat{\tau}_{i}\;, \tag{9.3.4}\] \[y_{i.} = r_{i}(\hat{\mu}+\hat{\tau}_{i})+\hat{\beta}\sum_{t=1}^{r_{i}}(x_{ it}-\overline{x}_{..}),\;\;i=1,\ldots,v\;,\] (9.3.5) \[\sum_{i=1}^{v}\sum_{t=1}^{r_{i}}y_{it}(x_{it}-\overline{x}_{..}) = \sum_{i=1}^{v}\sum_{t=1}^{r_{i}}(\hat{\mu}+\hat{\tau}_{i})(x_{it} -\overline{x}_{..})\] \[+\sum_{i=1}^{v}\sum_{t=1}^{r_{i}}\hat{\beta}(x_{it}-\overline{x}_ {..})^{2}\;.\]

There are \(v+2\) normal equations and \(v+2\) unknown parameters. However, Eq. (9.3.4) is the sum of the \(v\) equations given in (9.3.5), since \(\Sigma r_{i}=n\) and \(\Sigma\,\Sigma\,(x_{it}-\overline{x}_{..})=0\). Thus, the normal equations are not linearly independent, and the equations do not have a unique solution. However, the \(v+1\) equations in (9.3.5) and (9.3.6) are linearly independent and can be solved to obtain the unique least squares estimates for \(\beta\), \(\mu+\tau_{1}\), \(\ldots\), \(\mu+\tau_{v}\) given in the next subsection.

#### Least Squares Estimates and Adjusted Treatment Means

Under model (9.2.2) the expected value

\[E[\overline{Y}_{i.}]=\mu+\tau_{i}+\beta(\overline{x}_{i.}-\overline{x}_{..})\]

is an estimate of the mean response of the \(i\)th treatment when the value of the covariate \(x_{it}\) is \(\overline{x}_{i.}\). So, unless the covariate means \(\overline{x}_{i.}\) all happen to be equal, the difference of response means \(\overline{y}_{i.}-\overline{y}_{s.}\) does not estimate \(\tau_{i}-\tau_{s}\) and cannot be used to compare treatment effects. The least squares estimates of the parameters in the model are obtained by solving the normal equations in optional Sect. 9.3.1 and are

\[\hat{\mu}+\hat{\tau}_{i} = \overline{y}_{i.}-\hat{\beta}(\overline{x}_{i.}-\overline{x}_{..} )\;,\;i=1,\ldots,v\;, \tag{9.3.7}\] \[\hat{\beta} = \text{sp}_{xy}^{*}/\text{ss}_{xx}^{*}, \tag{9.3.8}\]

where

\[\text{sp}_{xy}^{*}=\sum_{i=1}^{v}\sum_{t=1}^{r_{i}}(x_{it}-\overline{x}_{i.}) (y_{it}-\overline{y}_{i.})\quad\text{and}\quad\text{ss}_{xx}^{*}=\sum_{i=1}^{v }\sum_{t=1}^{r_{i}}(x_{it}-\overline{x}_{i.})^{2}\;.\]

In this notation, ss can be read as "sum of squares" and sp as "sum of products." In Exercise 2, the reader is asked to verify that \(E[\hat{\beta}]=\beta\). Consequently,

\[E[\hat{\mu}+\hat{\tau}_{i}]=\mu+\tau_{i}\;.\]The least squares estimators \(\hat{\mu}+\hat{\tau}_{l}\) therefore estimate the mean response for the \(i\)th treatment at the value of the covariate equal to \(\overline{x}_{..}\). We call the estimates \(\hat{\mu}+\hat{\tau}_{l}\) the _adjusted means_, since they adjust the response mean \(\overline{y}_{i.}\) by the amount \(\hat{\beta}(\overline{x}_{i.}-\overline{x}_{..})\), which is equivalent to measuring the responses at the same point on the covariate scale. The need for this adjustment is illustrated in the following example.

#### _Example 9.3.1_ Adjusted versus unadjusted means

Table 9.1 contains hypothetical data arising from two treatments at various values of the covariate. Using Eqs. (9.3.7) and (9.3.8), one can show that the corresponding fitted model is

\[\hat{y}_{it}=\hat{\mu}+\hat{\tau}_{l}+0.5372(x_{ij}-60)\;,\]

where

\[\hat{\mu}+\hat{\tau}_{1}=62.5416\;\;\text{and}\;\;\hat{\mu}+\hat{\tau}_{2}=48.2 516\;.\]

The data and fitted model are plotted in Fig. 9.2. Observe that treatment one has the larger effect, and correspondingly the higher fitted line. However if the treatment effects were estimated as \(\overline{y}_{1.}\) and \(\overline{y}_{2.}\), it would appear that treatment two has the larger effect, since it has the larger unadjusted mean:

\[\overline{y}_{2.}=61.68>\overline{y}_{1.}=49.11.\]

This bias in the treatment effect estimates is due to the relative values of \(\overline{x}_{1.}\) and \(\overline{x}_{2.}\).

These data provide an exaggerated illustration of the need for adjustment of treatment sample means in analysis of covariance. 

### Analysis of Covariance

For a completely randomized design and analysis of covariance model (9.2.2), a _one-way analysis of covariance_ is used to test the null hypothesis \(H_{0}:\{\tau_{1}=\tau_{2}=\cdots=\tau_{v}\}\) against the alternative hypothesis \(H_{A}\) that at least two of the \(\tau_{l}\)'s differ. The test is based on the comparison of error sums of squares under the full and reduced models. If the null hypothesis is true with common treatment effect \(\tau_{l}=\tau\), then the reduced model is

\begin{table}
\begin{tabular}{c c c c c c c} \hline \(i\) & \(x_{it}\) & & \(y_{it}\) & & \(\overline{x}_{i.}\) & \(\overline{y}_{i.}\) \\ \hline
1 & 20 & 44.29 & 39.51 & 42.87 & 35 & 49.11 \\  & 30 & 44.48 & 48.39 & 49.14 & & \\  & 40 & 50.24 & 51.63 & 46.55 & & \\  & 50 & 57.75 & 59.23 & 55.23 & & \\
2 & 70 & 48.67 & 56.79 & 52.03 & 85 & 61.68 \\  & 80 & 57.68 & 67.25 & 52.88 & & \\  & 90 & 62.04 & 66.12 & 64.39 & & \\  & 100 & 63.54 & 72.49 & 76.33 & & \\ \hline \end{tabular}
\end{table}
Table 9.1: Hypothetical analysis of covariance data \[Y_{it}=\mu+\tau+\beta(x_{it}-\overline{x}_{..})+\epsilon_{it}\,.\]

This is similar to a simple linear regression model, with constant \(\beta_{0}=\mu+\tau\), slope \(\beta_{1}=\beta\), and with regressor \(x_{it}\) centered. Thus, if we replace \(x\) by \(x_{it}-\overline{x}_{..}\) in the formula (8.5.6), p. 257, and the average \(\overline{x}_{..}\) in (8.5.6) by the averaged centered value \(0\), the least squares estimates under the reduced model are

\[\hat{\mu}+\hat{\tau}=\overline{y}_{..}\quad\text{and}\quad\hat{\beta}=\text{sp} _{xy}/\text{ss}_{xx}\,,\]

where

\[\text{sp}_{xy}\ =\ \sum_{i=1}^{v}\sum_{t=1}^{r_{i}}(x_{it}-\overline{x}_{..})y_ {it}\ =\ \sum_{i=1}^{v}\sum_{t=1}^{r_{i}}(x_{it}-\overline{x}_{..})(y_{it}- \overline{y}_{..})\]

and

\[\text{ss}_{xx}\ =\ \sum_{i=1}^{v}\sum_{t=1}^{r_{i}}(x_{it}-\overline{x}_{..})^ {2}\,.\]

So,

\[\text{ssE}_{0} =\sum_{i}\sum_{t}\Big{(}y_{it}-\hat{\mu}-\hat{\tau}-\hat{\beta}(x _{it}-\overline{x}_{..})\Big{)}^{2} \tag{9.4.9}\] \[=\sum_{i}\sum_{t}\big{(}y_{it}-\overline{y}_{..}-\text{sp}_{xy}(x _{it}-\overline{x}_{..})/\text{ss}_{xx}\big{)}^{2}\] \[=\text{ss}_{yy}-(\text{sp}_{xy})^{2}/\text{ss}_{xx}\,,\]

where \(\text{ss}_{yy}=\sum_{i}\sum_{t}(y_{it}-\overline{y}_{..})^{2}\). The number of degrees of freedom for error is equal to the number of observations minus a degree of freedom for the constant \(\mu+\tau\) and one for the slope \(\beta\); that is, \(n-2\).

Under the full analysis of covariance model (9.2.2), using the least squares estimates given in Eqs. (9.3.7) and (9.3.8), the error sum of squares is \[\text{ss}E = \sum_{i}\sum_{t}\left(y_{it}-\hat{\mu}-\hat{\tau}_{i}-\hat{\beta}(x_ {it}-\overline{x}_{..})\right)^{2} \tag{9.4.10}\] \[= \sum_{i}\sum_{t}\left(y_{it}-\overline{y}_{i..}+\hat{\beta}( \overline{x}_{i..}-\overline{x}_{..})-\hat{\beta}(x_{it}-\overline{x}_{..}) \right)^{2}\] \[= \sum_{i}\sum_{t}\left((y_{it}-\overline{y}_{i..})-\hat{\beta}(x_ {it}-\overline{x}_{i..})\right)^{2}\] \[= \text{ss}_{yy}^{*}-\hat{\beta}(\text{sp}_{xy}^{*})\ \ \ =\ \ \text{ss}_{yy}^{*}-(\text{sp}_{xy}^{*})^{2}/\text{ss}_{xx}^{*}\,,\]

where

\[\text{ss}_{xx}^{*} = \sum_{i}\sum_{t}(x_{it}-\overline{x}_{i..})^{2}\,,\] \[\text{ss}_{yy}^{*} = \sum_{i}\sum_{t}(y_{it}-\overline{y}_{i..})^{2}\,,\] \[\text{sp}_{xy}^{*} = \sum_{i}\sum_{t}(x_{it}-\overline{x}_{i..})(y_{it}-\overline{y}_{i..})\,.\]

The values \(\text{ss}_{xx}^{*}\) and \(\text{ss}_{yy}^{*}\) can be obtained from a computer program as the values of \(\text{ss}E\) fitting the one-way analysis of variance models with \(x_{it}\) and \(y_{it}\) as the response variables, respectively. The number of error degrees of freedom is \(n-v-1\) (one less than the error degrees of freedom under the analysis of variance model due to the additional parameter \(\beta\)).

The sum of squares for treatments \(\text{ss}(T|\beta)\) is the difference in the error sums of squares under the reduced and full models,

\[\text{ss}(T|\beta) = \text{ss}E_{0}-\text{ss}E\] \[= \left(\text{ss}_{yy}-(\text{sp}_{xy})^{2}/\text{ss}_{xx}\right)- \left(\text{ss}_{yy}^{*}-(\text{sp}_{xy}^{*})^{2}/\text{ss}_{xx}^{*}\right)\,.\]

The difference in the error degrees of freedom for the reduced and full models is

\[(n-2)-(n-v-1)=v-1\,.\]

We denote the corresponding mean square by

\[\text{ms}(T|\beta)=\text{ss}(T|\beta)/(v-1)\,.\]

If the null hypothesis is true, then

\[\text{MS}(T|\beta)/\text{MS}E\sim F_{v-1,n-v-1}\,,\]

so we can obtain a decision rule for testing \(H_{0}:\{\tau_{1}=\tau_{2}=\cdots=\tau_{v}\}\) against \(H_{A}:\{\tau_{i}\text{ not all equal}\}\) as

\[\text{reject }H_{0}\ \ \text{if}\ \ \text{ms}(T|\beta)/\text{ms}E>F_{v-1,n-v-1,\alpha}\]

at chosen significance level \(\alpha\). The information for testing equality of the treatment effects is typically summarized in an analysis of covariance table such as that shown in Table 9.2.

The table also includes information for testing the null hypothesis \(H_{0}:\{\beta=0\}\) against the alternative hypothesis \(H_{A}:\{\beta\neq 0\}\). The reduced model for this test is the one-way analysis of variance model (3.3.1), for which \(Y_{it}=\mu+\tau_{i}+\epsilon_{it}\). From Chap. 3, the corresponding error sum of squares is

\[{\rm ss}{\rm E}_{0}=\sum_{i}\sum_{t}(y_{it}-\overline{y}_{i.})^{2}={\rm ss}^{*}_ {yy}\,,\]

and the number of error degrees of freedom is \(n-v\). The error sum of squares for the full model is given in (9.4.10). Denoting the difference in error sums of squares by \({\rm ss}(\beta|T)\), we have

\[{\rm ss}(\beta|T)={\rm ss}{\rm E}_{0}-{\rm ss}{\rm E}=({\rm sp}^{*}_{xy})^{2}/{ \rm ss}^{*}_{xx}=\hat{\beta}^{2}{\rm ss}^{*}_{xx}\,.\]

The difference in the error degrees of freedom is \((n-v)-(n-v-1)=1\), so the corresponding mean square, \({\rm ms}(\beta|T)\), has the same value \({\rm ss}(\beta|T)\). Under the assumptions of the analysis of covariance model (9.2.2), if \(H_{0}:\{\beta=0\}\) is true, then

\[{\rm MS}(\beta|T)/{\rm MSE}\sim F_{1,n-v-1}\,.\]

Thus, the decision rule for testing \(H_{0}:\{\beta=0\}\) against \(H_{A}:\{\beta\neq 0\}\), at significance level \(\alpha\), is

\[{\rm reject}\ H_{0}\ \ {\rm if}\ \ {\rm ms}(\beta|T)/{\rm ms}{\rm E}>F_{1,n-v-1,\alpha}\,.\]

#### _Example 9.4.1_ Balloon experiment, continued

Consider the balloon experiment of Meily Lin, in which she compared the effects of four colors on balloon inflation time. In Example 5.5.1, p. 108, the standardized residuals were plotted against the run order of the observations. The plot, reproduced in Fig. 9.3, shows a clear linear decreasing trend in the residuals. This trend indicates a definite lack of independence in the error terms under the one-way analysis of variance model, but the trend can be eliminated by including the run order as a covariate in the model.

The analysis of covariance table for this experiment is shown in Table 9.3. Residual plots for checking the model assumptions will be discussed in Sects. 9.6 and 9.7 and reveal no anomalies.

\begin{table}
\begin{tabular}{c c c c c} \hline Source of variation & Degrees of freedom & Sum of squares & Mean squares & Ratio \\ \hline \(T|\beta\) & \(v-1\) & \({\rm ss}(T|\beta)\) & \(\frac{{\rm ss}(T|\beta)}{v-1}\) & \(\frac{{\rm ms}(T|\beta)}{{\rm ms}{\rm E}}\) \\ \(\beta|T\) & 1 & \({\rm ss}(\beta|T)\) & \({\rm ss}(\beta|T)\) & \(\frac{{\rm ms}(\beta|T)}{{\rm ms}{\rm E}}\) \\ Error & \(n-v-1\) & \({\rm ss}{\rm E}\) & \({\rm ms}{\rm E}\) & \\ Total & \(n-1\) & \({\rm ss}_{yy}\) & & \\ \hline \multicolumn{5}{c}{Formulae} \\ \hline \({\rm ss}(T|\beta)=\left({\rm ss}_{yy}-({\rm sp}_{xy})^{2}/{\rm ss}_{xx}\right)- \left({\rm ss}^{*}_{yy}-({\rm sp}^{*}_{xy})^{2}/{\rm ss}^{*}_{xx}\right)\) & & & \\ \({\rm ss}(\beta|T)=({\rm sp}^{*}_{xy})^{2}/{\rm ss}^{*}_{xx}\) & & & \\ \({\rm ss}_{xx}=\sum_{i}\sum_{t}(x_{it}-\overline{x}_{\cdot})^{2}\) & & & \({\rm ss}_{yy}=\sum_{i}\sum_{t}(y_{it}-\overline{y}_{\cdot})^{2}\) \\ \({\rm sp}_{xy}=\sum_{i}\sum_{t}(x_{it}-\overline{x}_{\cdot})(y_{it}-\overline{y}_{\cdot})\) & & & \({\rm ss}^{*}_{xx}=\sum_{i}\sum_{t}(x_{it}-\overline{x}_{i\cdot})^{2}\) \\ \({\rm sp}^{*}_{xy}=\sum_{i}\sum_{t}(x_{it}-\overline{x}_{i\cdot})(y_{it}- \overline{y}_{\cdot})\) & & & \({\rm ss}^{*}_{yy}=\sum_{i}\sum_{t}(y_{it}-\overline{y}_{\cdot})^{2}\) \\ \hline \end{tabular}
\end{table}
Table 9.2: Analysis of covariance for one linear covariateThe decision rule for testing equality of the treatment effects is to

\[\text{reject }H_{0}:\{\tau_{1}=\cdots=\tau_{v}\}\;\;\text{if }\;\;\text{ms}(T|\beta)/\text{ms}E=6.32\;>\;F_{3,27,\alpha}\,.\]

Since \(F_{3,27.01}=4.60\), the null hypothesis is rejected at significance level \(\alpha=0.01\), and we can conclude that there is a difference in inflation times for the different colors of balloon.

Of secondary interest is the test of \(H_{0}:\{\beta=0\}\) against \(H_{A}:\{\beta\neq 0\}\). The decision rule is to reject the null hypothesis if \(\text{ms}(\beta|T)/\text{ms}E=17.95>F_{1,27,\alpha}\). Again, the null hypothesis is rejected at significance level \(\alpha=0.01\), since \(F_{1,27,.01}=7.68\). We may conclude that the apparent linear trend in the inflation times due to order is a real trend and not due to random error.

### Treatment Contrasts and Confidence Intervals

#### Individual Confidence Intervals

Since \(\mu+\tau_{i}\) is estimable under model (9.2.2), any treatment contrast \(\sum_{i}c_{i}\tau_{i}\) (\(\sum_{i}c_{i}=0\)) is also estimable. From (9.3.7), \(\sum_{i}c_{i}\tau_{i}\) has least squares estimator

\[\sum_{i}c_{i}\hat{\tau}_{i}=\sum_{i}c_{i}(\hat{\mu}+\hat{\tau}_{i})=\sum_{i}c_ {i}\left(\overline{Y}_{i.}-\hat{\beta}(\tilde{x}_{i.}-\tilde{x}_{..})\right)= \sum_{i}c_{i}\left(\overline{Y}_{i.}-\hat{\beta}\tilde{x}_{i.}\right)\,. \tag{9.5.12}\]

(The term \(\Sigma c_{i}\hat{\beta}\tilde{x}_{..}\) is zero, since \(\Sigma c_{i}=0\).) Now, \(\text{Var}\left(\overline{Y}_{i.}\right)=\sigma^{2}/r_{i}\), and it can be shown that \(\text{Var}(\hat{\beta})=\sigma^{2}/\text{ss}_{xx}^{\text{s}}\) and \(\text{Cov}(\overline{Y}_{i.},\hat{\beta})=0\). Using these results and (9.5.12), the variance of \(\sum_{i}c_{i}\hat{\tau}_{i}\) is

\begin{table}
\begin{tabular}{c c c c c} \hline Source of variation & Degrees of freedom & Sum of squares & Mean squares & Ratio \\ \hline \(T|\beta\) & 3 & 127.679 & 42.560 & 6.32 \\ \(\beta|T\) & 1 & 120.835 & 120.835 & 17.95 \\ Error & 27 & 181.742 & 6.731 & \\ Total & 31 & 430.239 & & \\ \hline \end{tabular}
\end{table}
Table 9.3: Analysis of covariance for the balloon experiment

Figure 9.3: Residual plot for the balloon experiment

\[\text{Var}\left(\sum_{i}c_{i}\hat{\tau}_{i}\right) =\text{Var}\left(\sum_{i}c_{i}\overline{Y}_{i.}\right)+\text{Var} \left(\hat{\beta}\sum_{i}c_{i}\overline{x}_{i.}\right)\] \[=\sigma^{2}\left(\sum_{i}\frac{c_{i}^{2}}{r_{i}}\right)+\left( \frac{\sigma^{2}}{s\overline{s}_{xx}^{*}}\right)\left(\sum_{i}c_{i}\overline{x }_{i.}\right)^{2}.\]

So, the estimated variance is

\[\widehat{\text{Var}}(\Sigma c_{i}\hat{\tau}_{i})=\text{m}\text{s}\text{E}\left( \sum_{i}\frac{c_{i}^{2}}{r_{i}}+\frac{\left(\sum_{i}c_{i}\overline{x}_{i.} \right)^{2}}{s\overline{s}_{xx}^{*}}\right). \tag{9.5.13}\]

From (9.5.12), the least squares estimator \(\sum_{i}c_{i}\hat{\tau}_{i}\) is a function of \(\overline{Y}_{i.}\) and \(\hat{\beta}\). Since \(Y_{ij}\) has a normal distribution, both \(\overline{Y}_{i.}\) and \(\hat{\beta}\) are normally distributed. Consequently, \(\sum_{i}c_{i}\hat{\tau}_{i}\) also has a normal distribution. Also, \(\text{MSE}/\sigma^{2}\) has a chi-squared distribution with \(n-v-1\) degrees of freedom. Then, for any treatment contrast \(\sum_{i}c_{i}\tau_{i}\), it follows that

\[\frac{\sum c_{i}\hat{\tau}_{i}-\sum c_{i}\tau_{i}}{\sqrt{\widehat{\text{Var}}( \sum c_{i}\hat{\tau}_{i})}}\sim t_{n-v-1}.\]

So, a \(100(1-\alpha)\)% confidence interval for \(\sum_{i}c_{i}\tau_{i}\) is

\[\sum_{i}c_{i}\tau_{i}\in\left(\sum_{i}c_{i}\hat{\tau}_{i}\ \pm\ t_{n-v-1, \alpha/2}\sqrt{\widehat{\text{Var}}\left(\sum_{i}c_{i}\hat{\tau}_{i}\right)} \right). \tag{9.5.14}\]

#### Multiple Comparisons

The multiple comparison methods of Bonferroni and Scheffe are applicable in the analysis of covariance setting. However, since the adjusted treatment means \(\hat{\mu}+\hat{\tau}_{i}=\overline{Y}_{i.}-\hat{\beta}(\overline{x}_{i.}- \overline{x}_{..})\) are not independent unless the \(\overline{x}_{i.}\) are all equal, the methods of Tukey and Dunnett are not known to apply. It is believed that Tukey's method does still control the experimentwise confidence level in this case, but there is no known proof of this conjecture.

Confidence intervals are obtained as

\[\sum_{i}c_{i}\tau_{i}\in\left(\sum_{i}c_{i}\hat{\tau}_{i}\ \pm\ w\sqrt{\widehat{\text{Var}}\left(\sum_{i}c_{i}\hat{\tau}_{i}\right)}\right)\, \tag{9.5.15}\]

where \(w\) is the appropriate critical coefficient. For the Bonferroni method and \(m\) predetermined treatment contrasts, \(w=t_{n-v-1,\alpha/2m}\). For the Scheffe method for all treatment contrasts, \(w=\sqrt{(v-1)F_{v-1,n-v-1,\alpha}}\). Formulae for the estimate \(\Sigma c_{i}\hat{\tau}_{i}\) and the corresponding estimated variance are given in Eqs. (9.5.12) and (9.5.13).

#### Balloon experiment, continued

We now illustrate the Scheffe method of multiple comparisons to obtain simultaneous 95% confidence intervals for all pairwise treatment comparisons for the balloon experiment of Example 9.4.1. (The data are in Table 3.13, p. 68.) For pairwise comparisons, the confidence intervals are obtained from (9.5.15),

\[\tau_{i}-\tau_{s}\in\left(\hat{\tau}_{i}-\hat{\tau}_{s}\;\pm\;\sqrt{3F_{3,27,.05} }\sqrt{\hat{\mathsf{Var}}(\hat{\tau}_{i}-\hat{\tau}_{s})}\right)\;,\]

where \(\hat{\tau}_{i}-\hat{\tau}_{s}=(\overline{y}_{i.}-\overline{y}_{s.})-\hat{\beta }(\overline{x}_{i.}-\overline{x}_{s.})\). The treatment and covariate means are

\[\begin{array}{l}\overline{y}_{1.}=18.337,\quad\overline{y}_{2.}=22.575,\quad \overline{y}_{3.}=21.875,\quad\overline{y}_{4.}=18.187,\\ \overline{x}_{1.}=16.250,\quad\overline{x}_{2.}=15.625,\quad\overline{x}_{3.} =17.500,\quad\overline{x}_{4.}=16.625,\end{array}\]

and from (9.3.8), we obtain

\[\hat{\beta}=\mathrm{sp}_{xy}^{*}/\mathrm{s}\mathrm{s}_{xx}^{*}=-572.59/2713.3= -0.21103\,.\]

Now, msE = 6.731 from Table 9.3, so

\[\widehat{\mathsf{Var}}(\hat{\tau}_{i}-\hat{\tau}_{s}) =\text{msE}\Bigg{(}\frac{1}{8}+\frac{1}{8}+\frac{(\overline{x}_{i.}-\overline{x}_{s.})^{2}}{\mathrm{s}\mathrm{s}\mathrm{s}_{xx}^{*}}\Bigg{)}\] \[=(6.731)\Bigg{(}0.25+\frac{(\overline{x}_{i.}-\overline{x}_{s.})^ {2}}{2713.3}\Bigg{)}\] \[=1.68275+(0.00248)\,(\overline{x}_{i.}-\overline{x}_{s.})^{2}\;.\]

Using the critical coefficient \(w=\sqrt{3F_{3,27,.05}}=\sqrt{3\times 2.96}\), one can obtain the confidence interval information given in Table 9.4. The estimated difference exceeds the minimum significant difference

\[\text{msd}=w\sqrt{\widehat{\mathsf{Var}}(\hat{\tau}_{i}-\hat{\tau}_{s})}\;\; \text{with}\;\;w=\sqrt{3F_{3,27,.05}}\]

for the first two and last two comparisons. One can conclude from the corresponding confidence intervals that the mean time to inflate balloons is longer for color 2 (yellow) than for colors 1 and 4 (pink and blue), and the mean inflation time for color 3 (orange) is longer than for color 4 (blue). At a slightly lower confidence level, we would also detect a difference in mean inflation times for colors 3 and 1 (orange and pink). The corresponding six intervals with overall confidence level 95% are

\begin{table}
\begin{tabular}{c c c c c} \hline \(i\) & \(s\) & \(\hat{\tau}_{i}-\hat{\tau}_{s}\) & \(\sqrt{\widehat{\mathsf{Var}}(\hat{\tau}_{i}-\hat{\tau}_{s})}\) & msd \\ \hline
1 & 2 & \(-4.106\) & 1.298 & 3.868 \\
1 & 3 & \(-3.801\) & 1.299 & 3.871 \\
1 & 4 & 0.071 & 1.297 & 3.865 \\
2 & 3 & 0.304 & 1.301 & 3.877 \\
2 & 4 & 4.176 & 1.298 & 3.868 \\
3 & 4 & 3.872 & 1.298 & 3.868 \\ \hline \end{tabular}
\end{table}
Table 9.4: Scheffe pairwise comparisons for the balloon experiment; overall confidence level is 95%\(\tau_{2}-\tau_{1}\in(\ \ 0.238,7.974),\quad\tau_{3}-\tau_{1}\in(-0.070,7.672),\quad\tau_{4}-\tau_{1}\in(-3.936,3.794),\)

\(\tau_{2}-\tau_{3}\in(-3.573,4.181),\quad\tau_{2}-\tau_{4}\in(\ \ 0.308,8.044),\quad\tau_{3}-\tau_{4}\in(\ \ 0.004,7.740).\)

Whenever the data are used to determine or modify the model, the confidence levels and error rates associated with any subsequent analyses of the same data will not be exactly as stated. Such is the case for the analyses presented in Example 9.5.1 for the balloon experiment, since the covariate "run order" was included in the model as a result of a trend observed in the residuals from the original analysis of variance model. Thus, although Scheffe's method was used, we cannot be certain that the overall level of the confidence intervals in Example 9.5.1 is exactly 95%.

### Using SAS Software

Table 9.5 contains a sample SAS program for performing a one-way analysis of covariance involving a single covariate with a linear effect. The program uses the data from the balloon experiment discussed in Examples 9.4.1 and 9.5.1. The data are given in Table 3.13, p. 68. The experimenter was interested in comparing the effects of four colors (pink, yellow, orange, and blue) on the inflation time of balloons, and she collected eight observations per color. The balloons were inflated one after another by the same person. Residual analysis for the one-way analysis of variance model showed a linear trend in the residuals plotted against run order (Fig. 9.3, p. 293). Hence, run order is included in the model here as a linear covariate. To obtain the "centered" form of the model, as in model (9.2.2), a centered variable has been created immediately after the INPUT statement, using the SAS statement

\(\mathtt{X}=\mathtt{RUNORDER}-16.5\);

where 16.5 is the average value of RUNORDER.

In Table 9.5, PROC GLM is used to generate the analysis of covariance. The output is shown in Fig. 9.4. The treatment factor COLOR has been included in the CLASS statement to generate a parameter \(\tau_{i}\) for each level of the treatment factor "color," while the covariate \(\mathtt{X}\) has been excluded from the class statement so that it is included in the model as a regressor, or covariate, as in model (9.2.2). To obtain the "uncentered" form of the model, as in model (9.2.1), the variable RUNORDER would replace \(\mathtt{X}\) throughout the program. The output in Fig. 9.4 would not change, since only the definition of the constant in the model has been altered.

The information for testing the null hypotheses \(H_{0}^{T}:\{\tau_{1}=\cdots=\tau_{4}\}\) against \(H_{A}^{T}:\{H_{0}^{T}\) not true\(\}\) and \(H_{0}:\{\beta=0\}\) against \(H_{A}:\{\beta\neq 0\}\) is in Fig. 9.4 under the heading Type IIISS. Specifically, \(\text{ss}(T|\beta)=127.678829\) and \(\text{ss}(\beta|T)=120.835325\). The corresponding ratio statistics and \(p\)-values are listed under F Value and \(\mathtt{Pr}>\mathtt{F}\), respectively. Since the \(p\)-values are very small, both null hypotheses would be rejected for any reasonable overall significance level. Thus, there are significant differences in the effects of the four colors on inflation time after adjusting for linear effects of run order. Also, there is a significant linear trend in mean inflation as a function of run order after adjusting for the treatment effects. The least squares estimate for \(\beta\) is negative (\(\hat{\beta}=-0.211\)), so the trend is decreasing, as we saw in Fig. 9.3.

The Type I and Type III sums of squares for color are similar but not quite equal, indicating that the treatment effects and the covariate effect are not independent. This is because the comparison of treatment effects is a comparison of the adjusted means, which do depend on \(\beta\), since the covariate means \(\overline{x}_{i}\) are not all equal for these data.

ESTIMATE statements under PROC GLM are used to generate the least squares estimate and estimated standard error for each pairwise comparison of treatment effects and for the coefficient \(\beta\) of the covariate. The standard errors of each \(\hat{\tau}_{i}-\hat{\tau}_{j}\) are not quite equal but are all approximately 1.30. To compare all treatment effects pairwise using Scheffe's method and a simultaneous 95% confidence level, the calculations proceed as shown in Example 9.5.1.

The OUTPUT statement under PROC GLM and the procedures PROC STANDARD, PROC RANK, and PROC SGPLOT are used as they were in Chap. 5 to generate four residual plots. The resulting plots (not shown) show no problems with the model assumptions. Of special note, the plot of the residuals against run order in Fig. 9.5 no longer shows any trend, so the linear run order covariate has apparently adequately modeled any run order dependence in the observations.

\begin{table}
\begin{tabular}{l} DATA; \\  INPUT RUNORDER COLOR INTFIME; \\  X = RUNORDER - 16.5; \\  LINES; \\  1 1 22.0 \\  2 3 24.6 \\  3 1 20.3 \\  4 4 19.8 \\  : : \\  30 1 19.3 \\  31 1 15.9 \\  32 3 20.3 \\ ; \\ PROC GLM; \\  CLASS COLOR; \\  MODEL INTFIME = COLOR X; \\  ESTIMATE ’1-2’ COLOR 1 –1 0 0; \\  ESTIMATE ’1-3’ COLOR 1 0 –1 0; \\  ESTIMATE ’1-4’ COLOR 1 0 0 –1; \\  ESTIMATE ’2-3’ COLOR 0 1 –1 0; \\  ESTIMATE ’2-4’ COLOR 0 1 0 –1; \\  ESTIMATE ’3-4’ COLOR 0 0 1 –1; \\  ESTIMATE ’BETA’ X 1; \\  OUTPUT OUT=B P=PRED R=Z; \\  PROC STANDARD STD=1; \\  VAR 2; \\  PROC RANK NORMAL=BLOM OUT=C; \\  VAR 2; \\  RANKS NSCORE; \\  PROC SGPLOT; \\  SCATTER Y = Z X = RUNORDER; \\  YAXIS VALUES = (-2 TO 2 BY 1); \\  XAXIS LABEL = "Run Order" VALUES = (0 TO 35 BY 5); \\  PROC SGPLOT; SCATTER Y = Z X = PRED; \\  PROC SGPLOT; SCATTER Y = Z X = COLOR; \\  PROC SGPLOT; SCATTER Y = Z X = NSCORE; \\ \end{tabular}
\end{table}
Table 9.5: SAS program for analysis of covariance—Balloon experiment A test for equality of slopes as discussed in Sect. 9.2.1 can be generated using the SAS statements

PROC GLM; CLASS COLOR;  MODEL INFTIME = COLOR X COLOR*X; The interaction term COLOR*X will be significantly different from zero if the linear run order trends are not the same for each color.

Fig. 9.4: Output from SAS PROC GLM

### Using R Software

Table 9.6 contains a sample R program for performing a one-way analysis of covariance involving a single covariate with a linear effect. The program uses the data from the balloon experiment discussed in Examples 9.4.1 and 9.5.1. The data are given in Table 3.13, p. 68. The experimenter was interested in comparing the effects of four colors (pink, yellow, orange, and blue) on the inflation time of balloons, and she collected eight observations per color. The balloons were inflated one after another by the same person. Residual analysis for the one-way analysis of variance model showed a linear trend in the residuals plotted against run order (Fig. 9.3, p. 293). Hence, run order is included in the model here as a linear covariate. To obtain the "centered" form of the model, as in model (9.2.2), a centered variable x has been created after reading the data from file, using the R statement

x = Order - 16.5

within balloon.data, where 16.5 is the average value of Order.

In the second block of code in Table 9.6, the linear models function lm and related functions are used to generate the analysis of covariance. Selected output is shown in Table 9.7. The factor variable fc has been included in the model to generate a parameter \(\tau_{l}\) for each level of the treatment factor "color," while the covariate x, because it is a numeric variable but not a factor variable, is included in the model as a regressor, or covariate, as in model (9.2.2). To obtain the "uncentered" form of the model, as in model (9.2.1), the variable Order would replace x throughout the program. The output in Table 9.7 would not change, since only the definition of the constant in the model would be altered.

The information for testing the null hypotheses \(H_{0}^{T}:\{\tau_{1}=\cdots=\tau_{4}\}\) against \(H_{A}^{T}:\{H_{0}^{T}\) not true\(\}\) and \(H_{0}:\{\beta=0\}\) against \(H_{A}:\{\beta\neq 0\}\) is in Table 9.7 under the drop1 command that generates it. Specifically, the Type I sums of squares are \(\text{ss}(T|\beta)\approx 128\) and \(\text{ss}(\beta|T)\approx 121\). The corresponding ratio statistics and \(p\)-values are listed under F value and PR(>F), respectively. Since the \(p\)-values are very small, both null hypotheses would be rejected for any reasonable overall significance level. Thus, there are significant differences in the effects of the four colors on inflation time after adjusting for linear effects of run order. Also, there is a significant linear trend in mean inflation as a function of run order after adjusting for the treatment effects. The least squares estimate for \(\beta\) is negative (\(\hat{\beta}=-0.2110\)), so the trend is decreasing, as we saw in Fig. 9.3.

The command anova (modell) generates type 3 sums of squares and the corresponding analysis of variance tables. The \(p\)-values for color for the Type I and Type III tests are similar but not identical,

Figure 9.5: SAS plot of \(z_{it}\) against run orderindicating that the corresponding Type I and Type III sums of squares are not quite equal, though both values have rounded to 128. This discrepancy, though minor, indicates that the treatment effects and the covariate effect are not independent. This is because the comparison of treatment effects is a comparison of the adjusted means, which do depend on \(\beta\), since the covariate means \(\overline{x}_{i.}\) are not all equal for these data.

The least squares means function lsameans and the corresponding summary statement in the third block of code are used to compare all treatment effects pairwise using Scheffe's method and a simultaneous 95% confidence level (by default), generating the simultaneous 95% confidence intervals and related information shown at the bottom of Fig. 4. These results correspond to those of Example 9.5.1. The standard errors of each \(\hat{\tau}_{i}-\hat{\tau}_{j}\) are not quite equal but are all approximately 1.30, so the widths of the confidence intervals obtained by Scheffe's method will be similar but not identical.

In the last block of code in Table 9.6, the saved predicted and residual values are used as they were in Chap. 5 to generate four residual plots. The resulting plots (not shown) show no problems with the model assumptions. Of special note, the plot of the residuals against run order (not shown here; see Fig. 9.5 for the same plot created in SAS) no longer shows any trend, so the linear run order covariate has apparently adequately modeled any run order dependence in the observations.

A test for equality of slopes as discussed in Sect. 9.2.1 can be generated using the R statements

 model2 = lm(Time ~ fc + x + fc:x, data=balloon.data)  anova(model1, model2) The interaction term fc:x will be significantly different from zero if the linear run order trends are not the same for each color.

\begin{table}
\begin{tabular}{l} balloon.data = read.table(‘data/balloon.txt’’, header=T) \\ head(balloon.data, 3) \\ balloon.data = within(balloon.data, \\ {x = Order - 16.5; FC = factor(Color) }) \\ options(contrasts = c(‘contr.sum’’, ‘contr.poly’’)) \\ model1 = lm(Time ~ fc + x, data=balloon.data) \\ summary(model1) \# LSE etc. for covariate, model F-test \\ dropl(model1, ~~., test=‘F’’) \# Type 3 tests \\ anova(model1) \# Type 1 tests \\ \# Multiple comparisons: Scheffe’s method \\ library(lsameans) \\ lsmC = lsameans(model1, ~~ fc) \\ summary(contrast(lsmC, method=‘pairwise’’, adjust=‘Scheffe’’), \\ infer=c(T,T)) \\ \# Residual plots \\ balloon.data = within(balloon.data, \\ {pred=fitted(model1); =resid(model1); z=e/sd(e); \\ n=length(e); q=rank(e); nscore=qnorm((q-0.375)/(n+0.25)) }) \\ plot (z ~ Order, data=balloon.data); abline(h=0) \\ plot (z ~ Pred, data=balloon.data); abline(h=0) \\ plot (z ~ Color, data=balloon.data); abline(h=0) \\ plot (z ~ nscore, data=balloon.data); qqline(balloon.data$z) \\ \end{tabular}
\end{table}
Table 9.6: R program for analysis of covariance—Balloon experiment 

[MISSING_PAGE_FAIL:322]

4. Test for equality of the treatment effects, using a significance level of \(\alpha=0.05\). Discuss the results. 5. Construct a 95% confidence interval for the difference in treatment effects. Discuss the results.
2. (optional) Assume that the analysis of covariance model (9.2.2) holds, so that \(Y_{it}=\mu+\tau_{l}+\beta(x_{it}-\overline{x}_{..})+\epsilon_{it}\). 1. Compute \(E[Y_{it}]\). 2. Verify that \(\text{sp}_{xY}^{*}=\sum_{i}\sum_{t}(x_{it}-\overline{x}_{i})Y_{it}\), given that \(\text{sp}_{xY}^{*}=\sum_{i}\sum_{t}(x_{it}-\overline{x}_{i}.)(Y_{it}- \overline{Y}_{i}.)\). 3. Show that \(E[\hat{\beta}]=\beta\), where \(\hat{\beta}=\text{sp}_{xY}^{*}/\text{ss}_{xx}^{*}\) and \(\text{ss}_{xx}^{*}=\sum_{i}\sum_{t}(x_{it}-\overline{x}_{i}.)^{2}\). 4. Verify that \(\text{Var}(\hat{\beta})=\sigma^{2}/\text{ss}_{xx}^{*}\) and \(\text{Cov}(\overline{Y}_{i}.,\hat{\beta})=0\). 5. Verify that \(E[\hat{\mu}+\hat{\tau}_{l}]=\mu+\tau_{i}\), where \(\hat{\mu}+\hat{\tau}_{l}=\overline{Y}_{i..}-\hat{\beta}(\overline{x}_{i..}- \overline{x}_{..})\). 6. Using the results of (c) and (e), argue that \(\mu+\tau_{l}\) and \(\beta\) and all linear combinations of these are estimable.
3. **Zinc plating experiment** The following experiment was used by C. R. Hicks (1965), _Industrial Quality Control_, to illustrate the possible bias caused by ignoring an important covariate. The experimental units consisted of 12 steel brackets. Four steel brackets were sent to each of three vendors to be zinc plated. The response variable was the thickness of the zinc plating, in hundred-thousandths of an inch. The thickness of each bracket before plating was measured as a covariate. The data are reproduced in Table 9.8. 1. Plot \(y_{it}\) versus \(x_{it}\), using the vendor index \(i\) as the plotting symbol. Discuss the relationship between plating thickness and bracket thickness before plating. Based on the plot, discuss appropriateness of the analysis of covariance model. Based on the plot, discuss whether there appears to be a vendor effect. 2. Fit the analysis of covariance model (9.2.1) or (9.2.2) to the data. 3. Plot the residuals against the covariate, predicted values, and normal scores. Use the plots to evaluate model assumptions. 4. Test for equality of slopes, using a level of significance \(\alpha=0.05\). 5. Test for equality of the vendor effects, using a significance level \(\alpha=0.05\). 6. Fit the analysis of variance model to the data, ignoring the covariate. 7. Using analysis of variance, ignoring the covariate, test for equality of the vendor effects using a significance level \(\alpha=0.05\). 8.

\begin{table}
\begin{tabular}{c c c c c c c} \hline  & & \multicolumn{4}{c}{Vendor} \\  & & 1 & & 2 & & 3 \\ \cline{2-7} \(t\) & \(x_{1t}\) & \(y_{1t}\) & \(x_{2t}\) & \(y_{2t}\) & \(x_{3t}\) & \(y_{3t}\) \\ \hline
1 & 110 & 40 & 60 & 25 & 62 & 27 \\
2 & 75 & 38 & 75 & 32 & 90 & 24 \\
3 & 93 & 30 & 38 & 13 & 45 & 20 \\
4 & 97 & 47 & 140 & 35 & 59 & 13 \\ \hline \end{tabular}
\end{table}
Table 9.8: Bracket thickness \(x_{it}\) and plating thickness \(y_{it}\) in \(10^{-5}\) inches for three vendors (Hicks 1965)* Compare and discuss the results of parts (e) and (g). For which model is ms_E_ smaller? Which model gives the greater evidence that vendor effects are not equal? What explanation can you offer for this?
4. **Paper towel absorbancy experiment** S. Bortnick, M. Hoffman, K.K. Lewis and C. Williams conducted a pilot experiment in 1996 to compare the effects of two treatment factors, brand and printing, on the absorbancy of paper towels. Three brands of paper towels were compared (factor \(A\) at 3 levels). For each brand, both white and printed towels were evaluated (factor \(B\), 1=white, 2=printed). For each observation, water was dripped from above a towel, which was horizontally suspended between two pairs of books on a flat surface, until the water began leaking through to the surface below. The time to collect each observation was measured in seconds. Absorbancy was measured as the number of water drops absorbed per square inch of towel. The rate at which the water droplets fell to the towel was measured (in drops per second) as a covariate. The data are reproduced in Table 9.9. 1. Plot absorbancy versus rate, using the treatment level as the plotting symbol. Based on the plot, discuss appropriateness of the analysis of covariance model, and discuss whether there appear to be treatment effects. 2. Fit the one-way analysis of covariance model to the data. 3. Plot the residuals against the covariate, run order, predicted values, and normal scores. Use the plots to evaluate model assumptions. 4. Test for equality of slopes, using a level of significance \(\alpha=0.05\). 5. Test for equality of treatment effects, using a significance level \(\alpha=0.05\). 6. Conduct a two-way analysis of covariance. Test the main effects and interactions for significance.
5. **Catalyst experiment, continued** The catalyst experiment was described in Exercise 5 of Chap. 5. The data were given in Table 5.18, p. 134. There were twelve treatment combinations consisting of four levels of reagent, which we may recode as \(A=1,\ B=2,\ C=3,\ D=4\), and three levels of catalyst, which we may recode as \(X=1,\ Y=2,\ Z=3\), giving the treatment combinations \(11,\ 12,\ 13,\ 21,\ \ldots,43\). The order of observation of the treatment combinations is also given in Table 5.18. 1.

\begin{table}
\begin{tabular}{c c c c c c c c} \hline Run & Treatment & _AB_ & Drops & Time & Area & Rate & Absorbancy \\ \hline
1 & 2 & 12 & 89 & 50 & 121.00 & 1.780 & 0.7355 \\
2 & 4 & 22 & 28 & 15 & 99.00 & 1.867 & 0.2828 \\
3 & 2 & 12 & 47 & 22 & 121.00 & 2.136 & 0.3884 \\
4 & 1 & 11 & 82 & 42 & 121.00 & 1.952 & 0.6777 \\
5 & 5 & 31 & 54 & 30 & 123.75 & 1.800 & 0.4364 \\
6 & 1 & 11 & 74 & 37 & 121.00 & 2.000 & 0.6116 \\
7 & 4 & 22 & 29 & 14 & 99.00 & 2.071 & 0.2929 \\
8 & 6 & 32 & 80 & 41 & 123.75 & 1.951 & 0.6465 \\
9 & 3 & 21 & 25 & 11 & 99.00 & 2.272 & 0.2525 \\
10 & 3 & 21 & 27 & 12 & 99.00 & 2.250 & 0.2727 \\
11 & 6 & 32 & 83 & 40 & 123.75 & 2.075 & 0.6707 \\
12 & 5 & 31 & 41 & 19 & 123.75 & 2.158 & 0.3313 \\ \hline \end{tabular}
\end{table}
Table 9.9: Data for the paper tower absorbance experiment * Fit a two-way complete model to the data and plot the residuals against the time order. If you are happy about the independence of the error variables, then check the other assumptions on the model and analyze the data. Otherwise, go to part (b).
* Recode the treatment combinations as \(1,\ 2,\ \ldots,\ 12\). Fit an analysis of covariance model (9.2.1) or (9.2.2) to the data, where the covariate \(x_{it}\) denotes the time in the run order at which the \(t\)th observation on the \(i\)th treatment combination was made. Check all of the assumptions on your model, and if they appear to be satisfied, analyze the data.
* Plot the adjusted means of the twelve treatment combinations in such a way that you can investigate the interaction between the reagents and catalysts. Test the hypothesis that the interaction is negligible.
* Check the model for lack of fit; that is, investigate the treatment \(\times\) time interaction. State your conclusions.

### 10.1 Introduction

In step (b)(iii) of the checklist in Chap. 2, we raised the possibility that an experiment may involve one or more nuisance factors that, although not of interest to the experimenter, could have a major effect on the response. We classified these nuisance factors into three types: blocking factors, noise factors, and covariates. Different types of nuisance factors lead to different types of analyses, and the choice between these is revisited in Sect. 10.2.

The cotton-spinning experiment of Sect. 2.3, p. 13, illustrates some of the considerations that might lead an experimenter to include a blocking factor in the model and to adopt a block design. The most commonly used block designs are the complete block designs. These are defined in Sect. 10.3 and their randomization is illustrated. Models, multiple comparisons, and analysis of variance for randomized complete block designs in which each treatment is observed once in each block are given in Sect. 10.4 and those for more general complete block designs in Sect. 10.6. Model assumption checks are outlined briefly in Sect. 10.7. An analysis of the cotton-spinning experiment is described in Sect. 10.5 and, in Sect. 10.8, we illustrate the analysis of a complete block design with factorial treatment combinations. Analyses of complete block designs using the SAS and R computer packages are discussed in Sects. 10.9 and 10.10, respectively.

### 10.2 Blocks, Noise Factors or Covariates?

It is not always obvious whether to classify a nuisance factor as a blocking factor, a covariate, or a noise factor. The decision will often be governed by the goal of the experiment.

Nuisance factors are classified as _noise factors_ if the objective of the experiment is to find settings of the treatment factors whose response is least affected by varying the levels of the nuisance factors. Settings of noise factors can usually be controlled during an experiment but are uncontrollable outside the laboratory. We will give some examples illustrating noise factors in Chap. 15.

_Covariates_ are nuisance factors that cannot be controlled but can be measured prior to, or during, the experiment. Sometimes covariates are of interest in their own right, but when they are included in the model as nuisance variables, their effects are used to adjust the responses so that treatments can be compared as though all experimental units were identical (see Chap. 9).

A _block design_ is appropriate when the goal of the experiment is to compare the effects of different treatments averaged over a range of different conditions. The experimental units are grouped into setsin such a way that two experimental units in the same set are similar and can be measured under similar experimental conditions, but two experimental units in different sets are likely to give rise to quite different measurements even when assigned to the same treatment. The sets of similar experimental units are called _blocks_, and the conditions that vary from block to block form the levels of the _blocking factor_. The intent of blocking is to prevent large differences in the experimental units from masking differences between treatment effects, while at the same time allowing the treatments to be examined under different experimental conditions.

The levels of a blocking factor may be the values of a covariate that has been measured prior to the experiment and whose values are used to group the experimental units. More often, however, the levels of a blocking factor are groupings of characteristics that cannot be conveniently measured. For example, grouping the time slots in the same day into the same block, as was done for the cotton-spinning experiment in Sect. 2.3, ensures that environmental conditions within a block are fairly similar without the necessity of measuring them.

Since the levels of the blocking factor do not necessarily need to be measured, the block design is very popular. Agricultural experimenters may know that plots close together in a field are alike, while those far apart are not alike. Industrial experimenters may know that two items produced by one machine have similar characteristics, while those produced by two different machines are somewhat different. Medical experimenters may know that measurements taken on the same subject will be alike, while those taken on different subjects will not be alike. Consequently, blocks may be formed without actually knowing the precise levels of the blocking factor. Some more examples are given in the next section and throughout the chapter.

### 10.3 Design Issues

#### Block Sizes

Although it is perfectly possible for the numbers of experimental units in each block to be unequal, the most common setting, and the only one that we will examine here, is when the blocks are of the same size. We will use \(b\) to represent the number of blocks and \(k\) to represent the common block sizes.

Sometimes the block sizes are naturally defined, and sometimes they need to be specifically selected by the experimenter. In a bread-baking experiment, for example, the experimental units are the baking tins in different positions in the oven. If the temperature cannot be carefully controlled, there may be a temperature gradient from the top shelf to the bottom shelf of the oven, although the temperature at all positions within a shelf may be more or less constant. If the measured response is affected by temperature, then experimental units on the same shelf are alike, but those on different shelves are different. There is a natural grouping of experimental units into blocks defined by the shelf of the oven. Thus, the shelves are the blocks of experimental units and represent the levels of the blocking factor "temperature." The number \(b\) of blocks is the number of shelves in the oven. The block size \(k\) is the number of baking tins that can be accommodated on each shelf.

Block size is not always dictated by the experimental equipment. The size often needs to be determined by the judgment of the experimenter. For example, the data in Fig. 10.1 were gathered in a pilot experiment by Bob Belloto in the Department of Pharmacy at The Ohio State University. The data show the readings obtained by a breathalyzer for a given concentration of alcohol. Notice how the readings decrease over time. Likely causes for this decrease include changes in atmospheric conditions, evaporation of alcohol, and deterioration of the breathalyzer filters. In other experiments, such trends in the data can be caused by equipment heating over time, by variability of batches of raw material, by experimenter fatigue, etc.

The block sizes for the breathalyzer experiment were chosen to be five, that is, the first five observations would be in one block, the next five in the next block, and so on. The reason for the choice was twofold. First, it can be seen from Fig. 10.1 that the observations in the pilot experiment seem to be fairly stable in groups of five. Secondly, the experiment was to be run by two different technicians, who alternated shifts, and five observations could be taken per shift. Thus the blocking factor was factorial in nature, and its levels represented combinations of time and technicians.

It is not uncommon in industry for an experiment to be automatically divided into blocks according to time of day as a precaution against changing experimental conditions. A pilot experiment using a single treatment such as that in the breathalyzer experiment is an ideal way of determining the necessity for blocking. If blocks were to be created when they are not needed, hypothesis tests would be less powerful and confidence intervals would be wider than those obtained via a completely randomized design.

#### Complete Block Design Definitions

Having decided on the block size and having grouped the experimental units into blocks of similar units, the next step is to assign the units to the levels of the treatment factors. The worst possible assignment of experimental units to treatments is to assign all the units within a block to one treatment, all units within another block to a second treatment, and so on. This assignment is bad because it does not allow the analysis to distinguish block differences from treatment differences. The effects of the treatment factors and the effects of the blocking factor are said to be _confounded_.

The best possible assignment is one that allocates to every treatment the same number of experimental units per block. This can be achieved only when the block size \(k\) is a multiple of \(v\), the number of treatments. Such designs are called _complete block designs_, and in the special case of \(k=v\), they have historically been called _randomized complete block designs_ or, simply, _randomized block designs_. The historical name is unfortunate, since all block designs need to be randomized. Nevertheless, we will retain the name randomized complete block design for block size \(k=v\) and use the name _general complete block design_ for block size a larger multiple of \(v\).

If the block size is not a multiple of \(v\), then the block design is known as an _incomplete block design_. This term is sometimes reserved for the smaller designs where \(k<v\), but we will find it convenient to classify all designs as either complete or incomplete. Incomplete block designs are more complicated to design and analyze than complete block designs, and we postpone their discussion to Chap. 11. For

Figure 10.1: Pilot data for the breathalyzer experiment

complete block designs, every treatment is observed \(s=v/k\) times in every block, and so is observed \(r=bs\) times in the experiment.

#### The Randomized Complete Block Design

A _randomized complete block design_ is a design with \(v\) treatments (which may be factorial treatment combinations) and with \(n=bv\) experimental units grouped into \(b\) blocks of \(k=v\) units in such a way that units within a block are alike and units in different blocks are substantially different. The \(k=v\) experimental units within each block are randomly assigned to the \(v\) treatments so that each treatment is assigned one unit per block. Thus, each treatment appears once in every block (\(s=1\)) and \(r=b\) times in the design.

##### 2.3.1 \(\mathtt{Bread}\)-\(\mathtt{baking}\) experiment

An experimenter wishes to compare the shelf life of loaves made from \(v=4\) different bread doughs, coded 1, 2, 3, 4. An oven with three shelves will be used, and each shelf is large enough to take four baking tins. A temperature difference is anticipated between the different shelves but not in different positions within a shelf. The oven will be used twice, giving a total of six blocks defined by shelf/run of the oven, and the block size is \(k=4\) defined by the four positions on each shelf: FL, FR, BL, BR (front left, front right, back left, back right).

Since the block size is the same as the number of treatments, a randomized complete block design can be used. The experimental units (positions) in each block (shelf/run) are assigned at random to the four levels of the treatment factor (doughs) using the procedure described in Sect. 3.2, p. 31, for each block separately. For example, suppose we obtain the four 2-digit random numbers 74, 11, 39, 68 from a computer random number generator, or from Table 1, and associate them in this order with the four treatments to be observed once each in block 1. If we now sort the random numbers into ascending order, the treatment codes are sorted into the order 2, 3, 4, 1. We can then allocate the experimental units in the order FL, FR, BL, BR to the randomly sorted treatments, and we obtain the randomized block shown in the first row of Table 10.1. The other randomized blocks in Table 10.1 are obtained in a similar fashion.

Notice that the randomization that we have obtained in Table 10.1 has allowed bread dough 1 to be observed four times in the back right position, and that dough 2 is never observed in this position. If a temperature difference in positions is present, then this could cause problems in estimating treatment differences, and the randomized complete block design is not the correct design to use. Instead, a row-column design (Chap. 12) should be used within each run of the oven.

\begin{table}
\begin{tabular}{c c c c c c c} \hline Block & Run & Shelf & FL & FR & BL & BR \\ \hline
1 & 1 & 1 & 2 & 3 & 4 & 1 \\
2 & & 2 & 1 & 2 & 3 & 4 \\
3 & & 3 & 4 & 3 & 2 & 1 \\
4 & 2 & 1 & 2 & 4 & 3 & 1 \\
5 & & 2 & 2 & 4 & 1 & 3 \\
6 & & 3 & 3 & 2 & 4 & 1 \\ \hline \end{tabular}
\end{table}
Table 10.1: Example of a randomized complete block design 

#### The General Complete Block Design

A _general complete block design_ is a design with \(v\) treatments (which may be factorial treatment combinations) and with \(n=bvs\) experimental units grouped into \(b\) blocks of \(k=vs\) units in such a way that units within a block are alike and units in different blocks are substantially different. The \(k=vs\) experimental units within each block are randomly assigned to the \(v\) treatments so that each treatment is assigned \(s\) units per block. Thus, each treatment appears \(s\) times in every block and \(r=bs\) times in the design.

##### 2.3.2 \(\mathsf{DCIS}\) experiment

An experiment was run by Matthew Darr, David Holman, Nasser Kashou, and Angela Wendel in 2006 to examine the variability of a Dynamic Inline Conveyor Scale (DCIS). The DCIS is an automated system for weighing individual pieces of large fruit (for example, watermelons) while they are conveyed from one location to another. The device uses an optical switch to trigger the weighing system, a load cell to perform the weighing operation and a computer-based data recording system. The objective of the experiment was to reduce the variability associated with the recorded weight of each piece of fruit. The researchers decided to examine the effects of two treatment factors. Treatment factor \(A\) was the length of time during which the weight was recorded (with three levels: 50, 75, 100, milliseconds; coded 1, 2, 3). Treatment factor \(B\) was the position of the optical switch (with two levels; 1 inch and 2 inches from the end of the scale plate; coded 1, 2). Thus there were six treatments (treatment combinations), coded as follows:

\[\begin{array}{l} (50\,\text{millisec},\,1\,\text{inch})=1,\;\;\;(50\,\text{millisec},\,2\,\text{inch})=2,\\ (75\,\text{millisec},\,1\,\text{inch})=3,\;\;(75\,\text{millisec},\,2\,\text{inch})=4,\\ (100\,\text{millisec},\,1\,\text{inch})=5,\;(100\,\text{millisec},\,2\,\text{inch})=6,\end{array}\]

The currently employed setting was treatment 4 (time 75 milliseconds, switch at 2 inches from the scale plate). The experimenters wished to see if there was a better setting, while taking into account a range of possible lubrication levels of the conveyor system. Changing the lubrication levels was difficult and time consuming, so the experiment was run in two blocks at the extreme levels of lubrication. In block 1, the conveyor pan was completely saturated with oil lubricant and, in block 2, all lubricant was removed from the conveyor pan. In each block, there were \(s=2\) observations on each treatment. A random assignment of the \(k=sv=12\) experimental units (time slots) to the treatments within each block gave the following observation order:

\[\begin{array}{l} \text{Block1}:\;1\;5\;2\;4\;1\;5\;2\;6\;4\;3\;3\;6\\ \text{Block2}:\;3\;1\;2\;4\;2\;5\;6\;1\;5\;4\;3\;6\end{array}\]

For each observation on a specified treatment in a block, the response was a function, called "uncertainty", of the standard deviation of 30 weighings of a watermelon. The data are shown in Table 8 and discussed in Example 10.6.1. 

#### How Many Observations?

If the block size \(k=sv\) is pre-determined, we can calculate the number of blocks \(b\) that are required to achieve a confidence interval of given length, or a hypothesis test of desired power, in much the same way as we calculated sample sizes in Chap. 6. If the number of blocks \(b\) is fixed, but the blocksizes can be large, then the same techniques can be used to calculate \(s\) for a general complete block design. A calculation of the required number of blocks using confidence intervals is illustrated for a randomized complete block design in Sect. 10.5.2, and a calculation of the required block size using the power of a test is done in Sect. 10.6.3 for a general complete block design.

### Analysis of Randomized Complete Block Designs

#### Model and Analysis of Variance

The standard model for a randomized complete block design (with \(s=1\) observation on each treatment in each block) is

\[\begin{array}{l}Y_{hi}=\mu+\theta_{h}+\tau_{i}+\epsilon_{hi}\;,\\ \epsilon_{hi}\sim N(0,\sigma^{2})\;,\\ \epsilon_{hi}\mbox{'s are mutually independent },\\ h=1,\ldots,b;\quad i=1,\ldots,v\;,\end{array} \tag{10.4.1}\]

where \(\mu\) is a constant, \(\theta_{h}\) is the effect of the \(h\)th block, \(\tau_{i}\) is the effect of the \(i\)th treatment, \(Y_{hi}\) is the random variable representing the measurement on treatment \(i\) observed in block \(h\), and \(\epsilon_{hi}\) is the associated random error. We will call this standard model the _block-treatment model_.

Notice that the block-treatment model does not include a term for the interaction between blocks and treatments. If interaction effects were to be included in the model, there would be no degrees of freedom for error with which to estimate the error variance (cf. Sect. 6.7). In many blocked experiments, absence of block\(\times\)treatment interaction is a reasonable assumption. However, if interaction is suspected in a given experiment, then the block size must be increased to allow its estimation (as in Sect. 10.6).

The block-treatment model (10.4.1) looks similar to the two-way main-effects model (6.2.3) for two treatment factors in a completely randomized design with one observation per cell. Not surprisingly, then, the analysis of variance table in Table 10.2 for the randomized complete block design looks similar to the two-way analysis of variance table in Table 6.7, p. 170, for two treatment factors and one observation per treatment combination. There is, however, an important difference. In a completely randomized design, the experimental units are randomly assigned to the treatment combinations, and

\begin{table}
\begin{tabular}{c c c c c} \hline Source of variation & Degrees of freedom & Sum of squares & Mean square & Ratio \\ \hline Block & \(b-1\) & ss\(\theta\) & ms\(\theta=\frac{\text{ss}\theta}{b-1}\) & – \\ Treatment & \(v-1\) & ss\(T\) & ms\(T=\frac{\text{ss}T}{v-1}\) & ms\(T\) \\ Error & \(bv-b-v+1\) & ss\(E\) & ms\(E=\frac{\text{ss}E}{bv-b-v+1}\) & \\ Total & \(bv-1\) & sstot & & \\ \hline \multicolumn{5}{c}{Computational formulae} \\ \hline ss\(\theta=v\sum_{h}\overline{y}_{h\cdot}^{2}-bv\overline{y}_{\cdot\cdot}^{2}\) & sstot \(=\sum_{h}\sum_{i}y_{hi}^{2}-bv\overline{y}_{\cdot\cdot}^{2}\) & ms\(T=b\sum_{i}\overline{y}_{\cdot\cdot}^{2}-bv\overline{y}_{\cdot\cdot}^{2}\) & ss\(T=b\sum_{i}\overline{y}_{\cdot j}^{2}-bv\overline{y}_{\cdot\cdot}^{2}\) & ss\(E=\text{ss}\theta-\text{ss}\theta-\text{ss}T\) \\ \hline \end{tabular}
\end{table}
Table 10.2: Analysis of variance: randomized complete block design 

[MISSING_PAGE_FAIL:332]

given in Table 10.3 and are plotted in Fig. 10.2. The figure clearly suggests large subject differences, but no consistent treatment differences.

The analysis of variance is shown in Table 10.4. The value of ms\(\theta\) is 37 times larger than msE, indicating that blocking by subject has greatly reduced the error variance estimate. So a block design was a good choice for this experiment.

The null hypothesis of no difference in the protocols cannot be rejected at any reasonable selection of \(\alpha\), since msT/msE = 0.23. The ratio tells us that the average variability of the measurements from one protocol to another was four times smaller than the measurement error variability. This is unusual, since measurements from one protocol to another must include measurement error. The _p_-value is 0.7950, indicating that there is only a 20% chance that we would see a value this small or smaller when there is no difference whatsoever in the effects of the protocols. Thus, we should ask how well the model fits the data--perhaps treatment-block interaction is missing from the model and has been included incorrectly in the error variability. Even if this were the case, however, there is still no indication that protocols 2 and 3 provide higher RMR readings than protocol 1--in fact, for six of the nine subjects, one or both of these outpatient protocols resulted in lower readings than the inpatient protocol.

It is not possible to check the model assumptions of equal error variances for each cell because of the small amount of data. But we can check the equal-variance assumptions for the different levels of the treatment factor. We find that the variances of the unstandardized residuals are very similar for

\begin{table}
\begin{tabular}{c c c c}  & Protocol & \\ Subject & 1 & 2 & 3 \\
1 & 7131 & 6846 & 7095 \\
2 & 8062 & 8573 & 8685 \\
3 & 6921 & 7287 & 7132 \\
4 & 7249 & 7554 & 7471 \\
5 & 9551 & 8866 & 8840 \\
6 & 7046 & 7681 & 6939 \\
7 & 7715 & 7535 & 7831 \\
8 & 9862 & 10087 & 9711 \\
9 & 7812 & 7708 & 8179 \\ \end{tabular}
\end{table}
Table 10.3: Data for the resting metabolic rate experiment

Figure 10.2: Resting metabolic rates by protocol and subject

the three protocols. The normality assumption seems to be reasonable. The only possible outlier is the observation for protocol 1, subject 5, but its removal does not change the above conclusions.

In their article, the experimenters discuss possible reasons for the fact that their conclusions differ from those of previous studies. Reasons included the different age of the subjects (27-29 years rather than 64-67 years) and the fact that they provided transport to the laboratory for the outpatients, whereas previous studies had not. 

#### Multiple Comparisons

Since the block-treatment model (10.4.1) for the randomized complete block design is similar to the two-way main-effects model (6.2.3) for an experiment with two treatment factors and one observation per cell, the least squares estimator for each \(\mu+\theta_{h}+\tau_{i}\) (\(h=1,\ldots,b;\ i=1,\ldots,v\)) is similar to the estimator for each \(\mu+\alpha_{i}+\beta_{j}\) (\(i=1,\ldots,a;\ j=1,\ldots,b\)) in (6.5.26), p. 161, without the third subscript; that is,

\[\hat{\mu}+\hat{\theta}_{h}+\hat{\tau}_{i}=\overline{Y}_{h.}+\overline{Y}_{.i}- \overline{Y}_{.}. \tag{10.4.3}\]

It follows that any contrast \(\Sigma c_{i}\tau_{i}\) (with \(\Sigma c_{i}=0\)) in the treatment effects is estimable in the randomized complete block design and has least squares estimator

\[\Sigma c_{i}\hat{\tau}_{i}\ =\ \Sigma c_{i}\overline{Y}_{.i}\,\]

and least squares estimate \(\Sigma c_{i}\overline{y}_{.i}\) with corresponding variance \(\sigma^{2}(\Sigma c_{i}^{2}/b)\). As for the two-way main-effects model, all of the multiple comparison procedures of Chap. 4 are valid for treatment contrasts in the randomized complete block design. The formulae, adapted from (6.5.39), p. 166, are

\[\sum c_{i}\tau_{i}\ \ \ \in\ \ \left(\sum c_{i}\overline{y}_{.i}\pm w\sqrt{msE \sum c_{i}^{2}/b}\ \right), \tag{10.4.4}\]

where the critical coefficients for the Bonferroni, Scheffe, Tukey, and Dunnett methods are, respectively,

\[w_{B}=t_{bv-b-v+1,\alpha/2m}\ ;\ \ w_{S}=\sqrt{(v-1)F_{v-1,bv-b-v+1, \alpha}}\ ;\] \[w_{T}=q_{v,bv-b-v+1,\alpha}/\sqrt{2}\ ;\ \ w_{D2}=|t|_{v-1,bv-b-v+1,\alpha}^{(0.5)}. \tag{10.4.5}\]

##### Resting metabolic rate experiment, continued

In the resting metabolic rate experiment, described in Example 10.4.1, p. 311, all three pairwise comparisons in the \(v=3\) protocol effects were of interest prior to the experiment, together with the contrast that compares the inpatient protocol with the two outpatient protocols. This latter contrast

\begin{table}
\begin{tabular}{c c c c c c} \hline Source of variation & Degrees of freedom & Sum of squares & Mean square & Ratio & \(p\)-value \\ \hline Subject & 8 & 23,117,462.30 & 2,889,682.79 & – & – \\ Protocol & 2 & 35,948.74 & 17,974.37 & 0.23 & 0.7950 \\ Error & 16 & 1,235,483.26 & 77,217.70 & & \\ Total & 26 & 24,388,894.30 & & & \\ \hline \end{tabular}
\end{table}
Table 10.4: Analysis of variance for the resting metabolic rate experiment has coefficient list \([1,\,-\frac{1}{2},\,-\frac{1}{2}]\). Suppose that the experimenters had wished to calculate simultaneous 95% confidence intervals for these four contrasts. The formula is given in (10.4.4) and there are several possible choices for the critical coefficient. The Bonferroni method could be used for these specific four contrasts, whereas the Scheffe method would allow for any number of contrasts to be examined. From (10.4.5), the critical coefficients are

\[w_{S}=\sqrt{2F_{2,\,16,\,05}}=\sqrt{2(3.63)}=2.694\;\;\text{and}\;\;w_{B}=t_{16, \,05/(2m)}=t_{16,\,00625}\approx 2.783\;.\]

Hence, in this particular situation, the Scheffe method gives slightly tighter intervals as well as being more flexible. An alternative is to divide \(\alpha=0.05\) between a \(t\) interval for the fourth contrast and Tukey intervals for the pairwise comparisons. For example, a 99% \(t\) interval and 96% Tukey intervals would have critical coefficients

\[w_{t}=t_{16,\,01/2}=2.9208\;\;\text{and}\;\;w_{T}=q_{3,16,\,04}/\sqrt{2}=3.8117 /\sqrt{2}=2.6953\;,\]

and again the Scheffe method is preferable in this example.

For each pairwise comparison \(\tau_{i}-\tau_{p}\), we have \(\sum c_{i}^{2}=2\), so using the Scheffe method of multiple comparisons and msE = 77217.7 from Table 10.4, the interval becomes

\[\tau_{i}-\tau_{p}\in\left(\overline{y}_{.i}-\overline{y}_{.p}\;\pm\;2.694 \sqrt{(77217.7)(2)/9}\right)=\left(\overline{y}_{.i}-\overline{y}_{.p}\;\pm\;3 52.89\right)\;.\]

The treatment sample means are obtained from the data in Table 10.3 as

\[\overline{y}_{.1}=7927.7,\quad\overline{y}_{.2}=8015.2,\quad\overline{y}_{.3}= 7987.0\;,\]

the biggest difference being \(\overline{y}_{.2}-\overline{y}_{.1}=87.5\). Since all three intervals contain zero, we can assert with 95% confidence that no two protocols differ significantly in their effects on the resting metabolic rate.

Similarly, the Scheffe confidence interval for \(\tau_{1}-\frac{1}{2}(\tau_{2}+\tau_{3})\) is

\[\tau_{1}-\frac{1}{2}(\tau_{2}+\tau_{3}) \in \left(\overline{y}_{.1}-\frac{1}{2}(\overline{y}_{.2}+\overline{ y}_{.3})\right)\pm 2.694\sqrt{(77217.7)(1.5)/9}\] \[= \left(-73.44\pm 305.62\right)\;,\]

and again the interval contains zero. These results are expected in light of the failure in Example 10.4.1 to reject equality of treatment effects in the analysis of variance. 

### A Real Experiment--Cotton-Spinning Experiment

#### Design Details

The checklist for the cotton-spinning experiment was given in Sect. 2.3, p. 13. After considering several different possible designs, the experimenters settled on a randomized complete block design. Each experimental unit was the production of one full set of bobbins on a single machine with a single operator. A block consisted of a group of experimental units with the same machine, the same operator, and observed in the same week. Thus, the different levels of the blocking factor represented differences due to combinations of machines, operators, environmental conditions, and raw material. The block size was chosen to be six, as this was equal to the number of treatment combinations and also to the number of observations that could be taken on one machine in one week.

The treatment combinations were combinations of levels of two treatment factors, "flyer" and "degree of twist." Flyer had two levels, "ordinary" and "special." Twist had four levels, 1.63, 1.69, 1.78, and 1.90. For practical reasons, the combinations of flyer and twist equal to (ordinary, 1.63) and (special, 1.90) were not observed. We will recode the six treatment combinations that were observed as follows:

\[\begin{array}{l} {\text{(ordinary, 1.69)} = 1,\;({\text{ordinary, 1.78)}} = 2,\;({\text{ordinary, 1.90)}} = 3,} \\ {\text{(special, 1.63)}} = 4,\;\;\;({\text{special, 1.69)}} = 5,\;\;\;({\text{special, 1.78)}} = 6. \end{array}\]

The goal of the experiment was to investigate the effects of the flyers and degrees of twist on the breakage rate of cotton.

#### Sample-Size Calculation

Since the experimenters were interested in all pairwise comparisons of the effects of the treatment combinations, as well as some other special treatment contrasts, we will apply the Scheffe method of multiple comparisons at overall confidence level 95%. The experimenters initially wanted a confidence interval to indicate a difference in the effects of a pair of treatment combinations if the true difference was at least 2 breaks per 100 pounds of material. We will calculate the number of blocks that are needed to obtain a minimum significant difference of at most 2 for the Scheffe simultaneous confidence intervals for pairwise comparisons. Using (10.4.4) with \(v = 6\), \(\alpha = 0.05\), and \(\Sigma c_{i}^{2} = 2\), we need to find \(b\) such that

\[\sqrt{5F_{5,5b-5,0.05}}\,\sqrt{\text{msE}(2/b)} \leq 2\,.\]

The error variability \(\sigma^{2}\) was expected to be about 7 breaks2, so we need to find the smallest value of \(b\) satisfying

\[F_{5,5b-5,0.05} \leq \frac{4 \times b}{5 \times 7 \times 2} = \frac{2b}{35}\,.\]

Trial and error shows that \(b = 40\) will suffice.

Each block took a week to complete, and it was not clear how many machines would be available at any one time, so the experimenters decided that they would analyze the data after the first 13 blocks had been observed. With \(b = 13\), \(v = 6\), and a value of \(\sigma^{2}\) expected to be about 7 breaks2, the Scheffe 95% confidence intervals for pairwise comparisons have minimum significant difference equal to

\[\text{msd} = \sqrt{5F_{5,5(13-1),0.05}}\,\sqrt{7 \times (2/13)}\;\;\;=\;\;\;3.57\,,\]

nearly twice the target length. Thus, with msE = 7 and 13 blocks, a difference in treatment combinations \(i\) and \(p\) will be indicated if their observed average difference is more than 3.57 breaks per 100 pounds (with a probability of 0.95 of no false indications) rather than 2 breaks per 100 pounds.

#### Analysis of the Cotton-Spinning Experiment

The data for the first \(b = 13\) blocks observed in the experiment were shown in Table 2.3 (p. 16) and some of the data were plotted in Fig. 2.1. There is an indication of block differences over time. The low number of breaks tend to be in block 1, and the high number of breaks in blocks 11, 12, and 13. This suggests that blocking was worthwhile. This is also corroborated by the fact that ms\(\theta\) is nearly three times as large as msE (see Table 10.5).

[MISSING_PAGE_FAIL:337]

This confidence interval suggests that averaged over the middle two levels of twist, the ordinary flyer is worse than the special flyer, producing on average between about 1.5 and 5.8 more breaks per 100 pounds.

In Fig. 10.3, the treatment sample means \(\overline{y}_{.i}\) are plotted against the uncoded twist levels, with the open symbols (labels 1, 2, 3) indicating those treatments with the ordinary flyer, and the black symbols (labels 4, 5, 6) indicating the special flyer. This plot reveals informative patterns in the treatment means. In particular, it appears as if the mean number of breaks per 100 pounds decreases almost linearly as the amount of twist increases for the ordinary flyer (treatments 1, 2, 3), yielding consistently smaller means for each amount of twist. Notice that the levels of twist are not equally spaced, so we cannot use the contrast coefficients in Appendix A.2 to measure trends in the breakage rate due to increasing twist. We could use the formula (4.2.4) p. 73 to obtain the linear trend coefficients, but since a different three of the four levels of twist are observed for the two flyers, the analysis of a linear trend would be more useful if done for each flyer separately. For example, for the three levels of the ordinary flyer, the coefficients for the linear trend would be calculated as

\[13\times(x_{i}-1.79)=-1.300,-0.130,1.430,\,\text{respectively, where}1.79=\overline{x}=\sum_{i=1}^{3}13x_{i}/39,\]

and these become -10, -1, 11, respectively, when multiplied by the choice of constant 100/13. Using these integer coefficients, the estimate of the linear trend in the breakage rate due to increasing twist for the ordinary flyer is \(\sum_{i=1}^{3}c_{i}\overline{y}_{i}=-38.246\) with corresponding estimated standard deviation

\[\sqrt{\text{ms}E\sum_{i=1}^{3}c_{i}^{2}/r_{i}}=\sqrt{5.107\times 17.0767}=9.3387\,,\]

giving a ratio of \(-38.246/9.3387=-4.0954\). If we test, at level \(\alpha=0.01\), the hypothesis of no linear trend in the breakages due to increasing amounts of twist using the ordinary flyer against the alternative hypothesis that there is a decreasing linear trend, we would reject the null hypothesis in favor of the alternative since \(-4.0954<-t_{60,0.01}=-2.390\).

Sections 10.9 and 10.10 illustrate the use of the SAS and R software for obtaining the analyses presented in this section, together with corresponding analyses using either the factorial main effects model or the analogous model treating twist as a linear regressor, and also the lack-of-fit test of the latter model.

Figure 10.3: Mean number of breaks per 100 pounds for the cotton-spinning experiment

### Analysis of General Complete Block Designs

#### Model and Analysis of Variance

In this section we discuss general complete block designs with \(s>1\) observations on each treatment in each block. Having every level of the treatment factor observed more than once per block gives sufficient degrees of freedom to be able to measure a block \(\times\)treatment interaction if one is anticipated. Therefore, there are two standard models for the general complete block design, the _block-treatment model_ (without interaction)

\[Y_{hit}=\mu+\theta_{h}+\tau_{i}+\epsilon_{hit} \tag{10.6.7}\]

and the _block-treatment interaction model_, which includes the effect of block-treatment interaction:

\[Y_{hit}=\mu+\theta_{h}+\tau_{i}+(\theta\tau)_{hi}+\epsilon_{hit}. \tag{10.6.8}\]

In each case, the model includes the error assumptions

\[\epsilon_{hit}\sim N(0,\sigma^{2})\,\] \[\epsilon_{hit}\text{'s are mutually independent}\,\] \[t=1,\ldots,s\ ;\ h=1,\ldots,b\ ;\ i=1,\ldots,v.\]

The assumptions on these two models should be checked for any given experiment (see Sect. 10.7).

The block-treatment model (10.6.7) for a general complete block design is similar to the two-way main-effects model (6.2.3), and the block-treatment interaction model (10.6.8) is like the two-way complete model (6.2.2) for two treatment factors in a completely randomized design, each with \(s\) observations per cell. Analogously, the analysis of variance tables (Tables 10.6 and 10.7) for the block-treatment models, with and without interaction, look similar to those for the two-way main-effects and two-way complete models (Tables 6.4 and 6.7, pp. 159 and 170).

The decision rule for testing the null hypothesis \(H_{0}^{T}:\{\tau_{1}=\tau_{2}=\cdots=\tau_{v}\}\) that the treatment effects are equal against the alternative hypothesis \(H_{A}^{T}\) that at least two of the treatment effects differ is given by the decision rule

\[\text{reject}\ H_{0}^{T}\ \text{if}\ msT/msE>F_{v-1,df;\alpha}\, \tag{10.6.9}\]

where \(\alpha\) is the chosen significance level, and where msT, msE, and the error degrees of freedom, df, are obtained from Tables 10.6 or 10.7 as appropriate.

\begin{table}
\begin{tabular}{c c c c c} \hline Source of variation & Degrees of freedom & Sum of squares & Mean square & Ratio \\ \hline Block & \(b-1\) & ss\(\theta\) & – & – \\ Treatment & \(v-1\) & ssT & \(msT=\frac{ssT}{v-1}\) & \(\frac{msT}{msE}\) \\ Error & \(bvs-b-v+1\) & ssE & \(msE=\frac{ssE}{bvs-b-v+1}\) & \\ Total & \(bvs-1\) & sstot & & \\ \hline \multicolumn{5}{c}{Computational formulae} \\ \hline \(ss\theta=vs\ \sum_{h}\overline{y}_{h..}^{2}-bvs\ \overline{y}_{...}^{2}\) & & sstot \(=\sum_{h}\sum_{i}\sum_{t}y_{hit}^{2}-bvs\ \overline{y}_{...}^{2}\) \\ \(ssT=bs\sum_{i}\overline{y}_{i..}^{2}-bvs\ \overline{y}_{...}^{2}\) & & ssE \(=\) sstot\(-\) ss\(\theta-\) ssT \\ \hline \end{tabular}
\end{table}
Table 10.6: Analysis of variance for the general complete block design with negligible block \(\times\)treatment interaction and block size \(k=vs\)If the block\(\times\)treatment interaction term is included in the model, a test of the hypothesis \(H_{0}^{\theta T}:\{(\theta\tau)_{hi}-(\overline{\theta}\tau)_{h.}-(\overline{ \theta\tau})_{.i}+(\overline{\theta\tau})_{.}=0\;\;\text{for all}\,h,\,i\,\}\) against the alternative hypothesis \(H_{A}^{\theta T}\) that at least one interaction contrast is nonzero is given by

\[\text{reject}\;H_{0}^{\theta T}\;\;\text{if}\;\;\text{ms}\theta T/\text{ms}E>F_ {(b-1)(v-1),bv(s-1),\alpha} \tag{10.6.10}\]

for some chosen significance level \(\alpha\), where \(\text{ms}\theta T\) and \(\text{ms}E\) are obtained from Table 10.7. As usual, if the interaction is significantly different from zero, a test of equality of the treatment effects may not be of interest (unless done within each block separately). An evaluation of the usefulness of blocking in the experiment at hand can be made by comparing \(\text{ms}\theta\) with \(\text{ms}E\) as in Sect. 10.4.1.

##### 10.6.1 \(\text{DCIS}\) experiment, continued

The objective of the DCIS experiment, described in Example 10.3.2, was to reduce the variability in the DCIS weighing system. The setting currently employed was treatment 4 (time 75 milliseconds, and switch at 2 inches from the scale plate). The experiment was run as a general block design with \(s=2\) observations per treatment per block (the blocking factor levels were the amounts of conveyor pan lubrication). The responses ("uncertainty" calculated as a function of the standard deviation of 30 repeated weighings of a watermelon) are shown in Table 10.8 and plotted in Fig. 10.4.

A block-treatment interaction model (10.6.8) was fitted, so the block-treatment interaction is examined first. Figure 10.4 suggests that there might be a small interaction between block and treatment combination.

The analysis of variance table is shown in Table 10.9, and we see that \(\text{ms}\theta T=0.019\) and \(\text{ms}E=0.013\). Using (10.6.10), the hypothesis \(H_{0}^{\theta T}\) of negligible intera

\begin{table}
\begin{tabular}{c|c c c c c} \hline  & & Time, position (treatment) & & & \\ Block & 11 (1) & 12 (2) & 21 (3) & 22 (4) & 31 (5) & 32 (6) \\ \hline
1 & 0.637 & 0.174 & 0.886 & 0.378 & 0.396 & 0.386 \\  & 0.645 & 0.238 & 0.655 & 0.459 & 0.415 & 0.453 \\
2 & 0.675 & 0.187 & 0.528 & 0.270 & 0.594 & 0.799 \\  & 0.480 & 0.183 & 0.701 & 0.426 & 0.545 & 0.413 \\ \hline \end{tabular}
\end{table}
Table 10.8: Data for the DCIS weighing system if \(\text{ms}\theta T/\text{ms}E=1.46\) is larger than \(F_{5,12,\alpha}\) for some chosen significance level \(\alpha\). However, \(F_{5,12,.01}=9.89\), so there is not sufficient evidence to reject \(H_{0}^{\theta T}\) at level \(\alpha=0.01\). Notice that the \(p\)-value for the test is \(0.2726\), so in fact, no reasonable choice of \(\alpha\) would lead to rejection of \(H_{0}^{\theta T}\). So the block\(\times\)treatment interaction that appears in Fig. 10.4 could be due to error variability. From Table 10.9, \(\text{ms}T/\text{ms}E=9.41>F_{5,12,0.01}=5.06\), and we conclude that, averaged over the two blocks (levels of pan lubrication), there is a significant difference between the treatment combinations at level \(\alpha=0.01\). Figure 10.4 suggests that treatment 2 might be the best treatment in both blocks (and better than the current treatment 4). The overall significance level of the two tests is at most \(0.02\). 

#### Multiple Comparisons for the General Complete Block Design

##### No Interaction Term in the Model

The Bonferroni, Scheffe, Tukey, and Dunnett methods described in Sect. 4.4 can all be used for obtaining simultaneous confidence intervals for sets of treatment contrasts in a general complete block design. Since the block-treatment model (10.6.7), without interaction, is similar to the two-way main-effects model (6.2.3) with \(s\) observations per cell, formulae for multiple comparisons are similar to those given in (6.5.39), p. 166, with \(a\) replaced by \(v\) and \(r\) replaced by \(s\). Thus, a set of \(100(1-\alpha)\)% simultaneous confidence intervals for treatment contrast \(\Sigma c_{i}\tau_{i}\) is of the form

\[\sum c_{i}\tau_{i} \in \left(\sum c_{i}\overline{y}_{.i.}\pm w\sqrt{\text{ms}E\sum c_{i} ^{2}/bs}\right), \tag{10.6.11}\]

\begin{table}
\begin{tabular}{l c c c c} \hline Source of variation & Degrees of freedom & Sum of squares & Mean square & Ratio & \(p\)-value \\ \hline Block & 1 & 0.0003 & – & – & \\ Treatment & 5 & 0.6132 & 0.1226 & 9.41 & 0.0008 \\ Block \(\times\) Treatment & 5 & 0.0952 & 0.0190 & 1.46 & 0.2726 \\ Error & 12 & 0.1563 & 0.0130 & & \\ Total & 23 & 0.8649 & & & \\ \hline \end{tabular}
\end{table}
Table 9: Analysis of variance for the DCIS experiment

Figure 10.4: Response for the DCIS experiment

where the critical coefficients for the four methods are, respectively,

\[w_{B}=t_{df,\alpha/2m}\ \ ;\ \ w_{S}=\sqrt{(v-1)F_{v-1,df,\alpha}}\ \ ;\] \[w_{T}=q_{v,df,\alpha}/\sqrt{2}\ \ ;\ \ w_{D2}=|t|_{v-1,df,\alpha}^{(0.5)}\ \,\]

where \(n=bvs\) and \(df=n-b-v+1\).

#### Interaction Term Included in the Model

The block-treatment interaction model (10.6.8) for the general complete block design is similar to the two-way complete model (6.2.2), p. 142, for two treatment factors with \(s\) observations per cell. Consequently, formulae for confidence intervals for treatment comparisons, averaging over the block\(\times\)treatment interaction, are similar to those given in (6.4.18), p. 152, with \(a\) replaced by \(v\) and \(r\) replaced by \(s\). The general formula for a set of \(100(1-\alpha)\)% simultaneous confidence intervals for treatment contrasts is given by (10.6.11) above, but where the number of error degrees of freedom \(df\) in each of the critical coefficients is

\[df=(vbs-1)-(b-1)(v-1)-(b-1)-(v-1)=bv(s-1)=n-bv\,.\]

Treatment comparisons may not be of interest if treatments do interact with blocks, in which case within-block comparisons are likely to be preferred instead. These are similar to the simple contrasts of Sect. 6.3.1 and are most easily calculated via a cell-means representation of the model. If we write

\[\eta_{hi}=\theta_{h}+\tau_{i}+(\theta\tau)_{hi}\, \tag{10.6.12}\]

then the comparison of treatments \(i\) and \(p\) in block \(h\) is the contrast

\[\eta_{hi}-\eta_{hp}=(\theta_{h}+\tau_{i}+(\theta\tau)_{hi})-(\theta_{h}+\tau_{ p}+(\theta\tau)_{hp})\,.\]

In a general complete block design, there are equal numbers of observations on each treatment in each block so, for block \(h\), the least squares estimate of \(\sum_{i}c_{hi}\eta_{hi}\) is \(\sum_{i}c_{hi}\overline{\gamma}_{hi.}\) with corresponding variance ms\(E\sum_{i}c_{hi}^{2}/s\), giving confidence intervals for \(\sum_{i}c_{hi}\eta_{hi}\) of the form

\[\sum_{i=1}^{v}c_{hi}\eta_{hi}\in\left(\sum_{i=1}^{v}c_{hi}\overline{\gamma}_{ hi.}\pm\sqrt{\text{ms}E\sum_{i=1}^{v}c_{hi}^{2}/s}\right)\.\]

The critical coefficients are as for (10.6.11) but again with \(df=n-bv\) error degrees of freedom.

#### Example 10.6.2 Dcis experiment, continued

In the analysis of the DCIS experiment in Example 10.6.1, the block-treatment interaction appeared to be negligible, and so the experimenters had the choice of examining the treatment effects on the weight "uncertainty" averaged over blocks or examining the difference in the treatment effects for each block separately. The former would be of most interest if it is not possible to control the level of conveyor pan lubrication in an industrial setting, while the latter would be of interest if the amount of lubrication could be fixed. Here, as an example, we investigate the latter. Writing the effect of treatment \(i\) in block \(h\) as in (10.6.12), we look at the difference between the effects of treatments 2 (apparent best) and 4 (currently used) for each block separately, which compares times 50 and 75 milliseconds at position 2

[MISSING_PAGE_FAIL:343]

#### Example 10.6.3 Colorfastness experiment

The colorfastness experiment was planned by D-Y Duan, H. Rhee, and C. Song in 1990 to investigate the effects of the number of washes on the color change of a denim fabric. The experiment was to be carried out according to the guidelines of the American Association of Textile Chemists and Colorists Test 61-1980. The levels of the treatment factor were the number of times of laundering, and these were selected to be 1, 2, 3, 4, and 5.

The experimenters anticipated that there would be systematic differences in the way they made their color determinations, and consequently, they grouped the denim fabric swatches into blocks according to which experimenter was to make the determination. Thus the levels of the blocking factor denoted the experimenter, and there were \(b=3\) blocks. They decided to use a general complete block design and allowed the block size to be \(k=vs=5s\), where \(s\) could be chosen. Rightly or wrongly, they did not believe that experimenter fatigue would have a large effect on the results, and they were happy for the block sizes to be large.

They planned to use a block-treatment interaction model (10.6.8), and they wanted to test the null hypothesis of no treatment differences whether or not there was block x treatment interaction. Suppose the test was to be carried out at significance level 0.05, and suppose the experimenters wanted to reject the null hypothesis with probability 0.99 if there was a true difference of \(\Delta=0.5\) or more in the effect of the number of washes on color rating. They expected \(\sigma\) to be no larger than about 0.4.

We need to find the minimum value of \(s\) that satisfies equation (10.6.13); that is,

\[s\ \geq\ \frac{2v\sigma^{2}\phi^{2}}{b\Delta^{2}}\ =\ \frac{(2)(5)(0.4)^{2} \phi^{2}}{(3)(0.5)^{2}}\ =\ 2.13\phi^{2}\,.\]

The denominator (error) degrees of freedom for the block-treatment interaction model is \(\nu_{2}=bv(s-1)=15(s-1)\). First we locate that portion of Appendix Table A.7 corresponding to numerator degrees of freedom \(\nu_{1}=v-1=4\) and \(\alpha=0.05\). Then to achieve power \(\pi=0.99\), trial and error starting with \(s=100\) gives

\[\begin{array}{ccccc}s&15(s-1)&\phi&s=2.13\phi^{2}&\text{Action}\\ \hline 100&1485&2.25&10.78&\text{Round up to }s=11\\ 11&150&(\text{use 120})&2.325&11.51&\text{Round up to }s=12\\ 12&165&(\text{use 120})&2.325&11.51&\text{Stop, and use }s=12\\ \end{array}\]

So about \(s=12\) observations per treatment per block should be taken.

Instead, suppose that \(s\) had been fixed at \(s=4\), so that blocks were to be of size \(k=vs=20\), then the roles of \(b\) and \(s\) in (10.6.13) would have been reversed, so that

\[b\geq\frac{(2)(5)(.4)^{2}\phi^{2}}{(4)(.5)^{2}}=1.6\phi^{2}\,,\]

with \(\nu_{2}=(5)(3)b\). Then trial and error would lead to approximately \(b=9\). 

### Checking Model Assumptions

The assumptions on the block-treatment models (10.4.1) and (10.6.7) and on the block-treatment interaction model (10.6.8) for complete block designs need to be checked as usual. The assumptions on the error variables are that they have equal variances, are independent, and have a normal distribution. The form of the model must also be checked.

A visual check of an assumption of no block\(\times\)treatment interaction can be made by plotting \(\overline{y}_{hi}\) against the treatment factor levels \(i\) for each block \(h\) in turn. If the lines plotted for each block are parallel (as in plots (a)-(d) of Fig. 6.1, p. 140), then block\(\times\)treatment interaction is likely to be absent, and error variability is small. If the lines are not parallel, then either block\(\times\)treatment interaction is present or error variability is large.

For the block-treatment model (10.4.1) for the randomized complete block design, the (\(hi\))th residual is

\[\hat{e}_{hi}=y_{hi}-\hat{y}_{hi} = y_{hi}-\overline{y}_{h.}-\overline{y}_{.i}+\overline{y}_{.\ldots}\,.\]

For the block-treatment model (10.6.7) for the general complete block design, the (\(hit\))th residual is similar; that is,

\[\hat{e}_{hit}=y_{hit}-\hat{y}_{hit} = y_{hit}-\overline{y}_{h.}-\overline{y}_{.i.}+\overline{y}_{. \ldots}\,.\]

For the block-treatment interaction model (10.6.8), the (\(hit\))th residual is

\[\hat{e}_{hit}=y_{hit}-\hat{y}_{hit} = y_{hit}-\overline{y}_{hi.}\,.\]

The error assumptions are checked by residual plots, as summarized in Table 10.10 and described in Chap. 5.

### Factorial Experiments

When the treatments are factorial in nature, the treatment parameter \(\tau_{i}\) in the complete block design models (10.4.1), (10.6.7), and (10.6.8) can be replaced by main-effect and interaction parameters. Suppose, for example, we have an experiment with two treatment factors that is designed as a randomized complete block design--a situation similar to that of the cotton-spinning experiment of Sect. 10.5. In order not to confuse the number \(b\) of blocks with the number of levels of a treatment factor, we will label the two treatment factors as \(C\) and \(D\) with \(c\) and \(d\) levels respectively. If we retain the two digit codes for the treatment combinations, then the block-treatment model is

\[Y_{hijt}=\mu+\theta_{h}+\tau_{ij}+\epsilon_{hijt}\]

with the usual assumptions on the error variables. We can then express \(\tau_{ij}\), the effect of treatment combination \(ij\), in terms of \(\gamma_{i}\) (the effect of \(C\) at level \(i\)), \(\delta_{j}\) (the effect of \(D\) at level \(j\)), and (\(\gamma\delta\))\({}_{ij}\) (the effect of their interaction when \(C\) is at level \(i\) and \(D\) at level \(j\)); that is,

\[Y_{hijt}=\mu+\theta_{h}+\gamma_{i}+\delta_{j}+(\gamma\delta)_{ij}+\epsilon_{ hjlt}\,. \tag{10.8.14}\]

\begin{table}
\begin{tabular}{p{142.3pt}|p{142.3pt}} \hline To check for: & Plot residuals against: \\ \hline Independence & Order of observations (in space or time) \\ Equal variance, and Outliers & Predicted values \(\hat{y}_{hit}\), levels of treatment factor, levels of block factor \\ Normality & Normal scores (also plot separately for each treatment if \(r\) is large and for each block if \(k\) is large) \\ \hline \end{tabular}
\end{table}
Table 10.10: Checking error assumptions for a complete block design In a general complete block design with \(s>1\) observations per treatment combination per block, we may include in the model some or all of the block\(\times\)treatment interactions. For example, with two treatment factors, the block-treatment interaction model can be expressed as

\[Y_{hijt} = \mu + \theta_{h} + \gamma_{i} + \delta_{j} + (\gamma\delta)_{ij} + (\theta\gamma)_{hi}\] \[+ (\theta\delta)_{hj} + (\theta\gamma\delta)_{hij} + \epsilon_{hijt}\,,\]

In both (10.8.14) and (10.8.15), the model assumptions are

\[\epsilon_{hijt} \sim N(0,\,\sigma^{2})\,,\] \[\epsilon_{hijt}'\text{s are mutually independent}\,,\] \[t = 1,\ldots,s\;;\;h = 1,\ldots,b\;;\;i = 1,\ldots,c\;;\;j = 1,\ldots,d.\]

If there are more than two factors, the additional main effects and interactions can be added to the model in the obvious way.

#### _Example 10.8.1_ Banana experiment

The objectives section of the report of an experiment run in 1995 by K. Collins, D. Marriott, P. Kobrin, G. Kennedy, and S. Kini reads as follows:

Recently a banana hanging device has been introduced in stores with the purpose of providing a place where bananas can be stored in order to slow the ripening process, thereby allowing a longer time over which the consumer has to ingest them. Commercially, bananas are picked from trees while they are fully developed but quite green and are artificially ripened prior to transport. Once they are purchased and brought into the consumer's home, they are typically placed on a counter top and left there until they are either eaten or turn black, after which they can be thrown away or made into banana bread. Considering that the devices currently being marketed to hang bananas cost some money and take up counter space, it is of interest to us to determine whether or not they retard the ripening process.

While there exist many ways to measure the degree of banana ripening, perhaps the simplest method is via visual inspection. The banana undergoes a predictable transition from the unripened green color to yellow then to yellow speckled with black and finally to fully black. The percentage of black color can be quantified through computer analysis of photographs of the skins of the bananas.

The major objective of our experiment, then, is to determine whether or not any differences in the percentage of black skin exist between bananas that are treated conventionally, i.e., placed on a counter, and bananas that are hung up. As a minor objective, we would like to determine whether or not any difference exists in the percentage of black skin between bananas allowed to ripen in a normal day/night cycle versus those ripening in the dark such as might occur if placed in a pantry.

The unripened bananas were bought as a single batch from a single store. They were assigned at random to four treatment combinations, consisting of combinations of two 2-level factors. Factor \(C\) was Lighting conditions (1 = day/night cycle, 2 = dark closet). Factor \(D\) was Storage method (1 = hanging, 2 = counter-top). Twelve bananas were assigned at random to each treatment combination. After five days, the bananas were peeled and the skin photographed. The images from the photographic slides were traced by hand, and the percentage of blackened skin was calculated using an image analyzer on a computer. Three of the experimenters prepared the images for the image analyzer and, since they were unskilled, they decided to regard themselves as blocks in order to remove experimenter differences from the comparisons of the treatment combinations. They selected a general complete block design and assigned the treated bananas in such a way that \(s=4\) observations on each treatment combination were obtained by each experimenter. The treatment combinations were observed in a random order, and the resulting data are shown in Table 10.11.

Since the experimenters did not anticipate a block\(\times\)treatment interaction, they selected block-treatment model (10.8.14) to represent the data. The decision rule for testing the hypothesis \(H_{0}^{CD}\) of no interaction between the treatment factors Light and Storage (averaged over blocks), using a Type I error probability of \(\alpha=0.01\), is

\[\text{reject }H_{0}^{CD}\text{ if }\frac{\text{ms}(CD)}{\text{ms}E}>F_{(c-1)(d-1),df,0.01}\,,\]

where \(\text{ms}(CD)=\text{ss}(CD)/(c-1)(d-1)\) and both ss(CD) and the number of error degrees of freedom df are given in Table 10.12. Since there are equal numbers of observations per cell, these values can be obtained from rule 4 of Chap. 7, p. 209; that is,

\[\text{ss}(CD)=bs\sum_{i}\sum_{j}\vec{y}_{\cdot j.}^{2}-bds\sum_{i}\vec{y}_{\cdot \cdot\cdot\cdot}^{2}-bcs\sum_{j}\vec{y}_{\cdot\cdot\cdot j.}^{2}+bcs\,\vec{y}_{ \cdot\cdot\cdot\cdot}^{2}=24.0833,\]

and

\[df =(bcs-1)-(b-1)-(c-1)-(d-1)-(c-1)(d-1)\] \[=47-2-1-1-1=42\,.\]

Other sums of squares are obtained similarly. From Table 10.12, we can see that the mean square for blocks is much larger than the error mean square, so it was worthwhile designing this experiment as a block design. We also see that the mean square for the Light\(\times\)Storage interaction is a lot smaller than the error mean square. As mentioned in the context of the resting metabolic rate experiment (Example 10.4.1, p. 311), this is unusual when the model fits well since the Light and Storage

\begin{table}
\begin{tabular}{c c c c c c} \hline Source of variation & Degrees of freedom & Sum of squares & Mean square & Ratio & \(p\)-value \\ \hline Block (Experimenter) & 2 & 1255.79 & 627.89 & – & \\ \(C\) (Light) & 1 & 80.08 & 80.08 & 0.42 & 0.5218 \\ \(D\) (Storage) & 1 & 154.08 & 154.08 & 0.80 & 0.3754 \\ CD & 1 & 24.08 & 24.08 & 0.13 & 0.7250 \\ Error & 42 & 8061.88 & 191.95 & & \\ Total & 47 & 9575.92 & & & \\ \hline \end{tabular}
\end{table}
Table 10.12: Analysis of variance for the banana experiment

\begin{table}
\begin{tabular}{c c c c c c} \hline Experimenter (Block) & Light \(C\) & Storage \(D\) & \(y_{hijt}\), percentage of blackened skin \\ \hline I & 1 & 1 & 30 & 30 & 17 & 43 \\  & 1 & 2 & 43 & 35 & 36 & 64 \\  & 2 & 1 & 37 & 38 & 23 & 53 \\  & 2 & 2 & 22 & 35 & 30 & 38 \\ II & 1 & 1 & 49 & 60 & 41 & 61 \\  & 1 & 2 & 57 & 46 & 31 & 34 \\  & 2 & 1 & 20 & 63 & 64 & 34 \\  & 2 & 2 & 40 & 47 & 62 & 42 \\ III & 1 & 1 & 21 & 45 & 38 & 39 \\  & 1 & 2 & 42 & 13 & 21 & 26 \\  & 2 & 1 & 41 & 74 & 24 & 51 \\  & 2 & 2 & 38 & 22 & 31 & 55 \\ \hline \end{tabular}
\end{table}
Table 10.11: Percentage blackened banana skin measurements include the error measurement. It suggests that the error mean square may have been inflated by some other source of variability, such as block\(\times\)treatment interaction, that has been omitted from the model.

Interaction plots of the two factors Light and Storage (averaged over blocks) are shown in Fig. 10.5. There is no indication that hanging bananas (Storage level 1) might retard the ripening process. In fact, Storage level 1 seems to have given a higher percentage of blackened skin on average than Storage level 2. However, this apparent difference may be due to chance, as the treatment effects are not significantly different from each other. The experimenters commented that it was difficult to select the correct threshold levels for the image analysis and also that the bananas themselves seemed extremely variable. The experimenters felt that rather than draw firm conclusions at this stage, it might be worthwhile working to improve the experimental procedure to reduce variability and then to repeat the experiment. 

### Using SAS Software

The analysis of variance table for a complete block design can be obtained from any computer package that has an analysis of variance routine or a regression routine. It is good practice to enter the block term into the model before the terms for the treatment factors. Although the order does not matter for complete block designs, it does matter for the incomplete block designs in the next chapter.

Computer programs do not distinguish between block and treatment factors, so a test for the hypothesis of no block effects will generally be listed in the output. We suggest that the latter be ignored, and that blocking be considered to have been effective for the current experiment if ms\(\theta\) exceeds ms\(E\) (see Sect. 10.4.1).

Table 10.13 contains a SAS program illustrating analysis of a complete block design, using the data of the cotton-spinning experiment (Sect. 2.3, p. 13). Following input of the data, the first call of PROC GLM fits a block-treatment model to the data. Selected output is shown in Fig. 10.6. The TYPE I sums of squares (not shown) are equal to the TYPE III sums of squares since there is an equal number (\(s=1\)) of observations per block-treatment combination. If the block\(\times\)treatment interaction term had been included in the model, this would have been entered in the usual way as BLOCK*TRTMT. The first LSMEANS statement in Table 10.13 applies Tukey's method for comparing pairs of treatment

Figure 10.5: Interaction plot for the banana experiment

[MISSING_PAGE_EMPTY:8284]

effects (output not shown). The two ESTIMATE statements reproduce the calculations in Sect. 10.5 for comparing the two flyers at common levels of twist, and evaluating the linear trend in twist for the ordinary flyer.

The second call of PROC GLM in Table 10.13 replaces the treatment combination factor TRTMT with main-effects of FLYER and TWIST; this removes their interaction effect from the model. Selected output is shown in Fig. 10.7. Since not every combination of FLYER and TWIST was observed, the TYPE I and TYPE III sums of squares for the individual factors are not equal. The TYPE III sums of squares are used for hypothesis testing, and LSMEANS statements are used for confidence intervals. The reader may verify that the Bonferroni method provides tighter simultaneous 95% confidence intervals for TWIST pairwise comparisons than Scheffe's method (results not shown).

The plot of the mean response against twist for both flyer types in Fig. 10.3, p. 317, suggested the possibility that the number of breaks per 100 pounds could be modeled by a flyer effect and a linear twist effect. This can be evaluated by comparing the fit of the block-treatment model,

\[Y_{hi}=\mu+\theta_{h}+\tau_{i}+\epsilon_{hi}\]

(\(i=1,\ldots,6;\ h=1,\ldots,13\)), with the fit of the reduced model,

\[Y_{hjx}=\mu+\theta_{h}+\alpha_{j}+\gamma x+\epsilon_{hjx}\;,\]

where \(\alpha_{j}\) is the effect of flyer \(j\) (\(j=1,2\)) and \(x\) is the _uncoded_ amount of twist (cf. Chaps. 8 and 9). The fit of these models can easily be compared via the SAS software, either using two calls of the GLM procedure, one for each model, or using one call that sequentially includes both models. The first call of PROC GLM in Table 10.13 fitted the full block-treatment model, and the third call of PROC GLM fits the reduced model that includes the flyer effect and a linear regression in the levels of twist. Notice the similarity of the third call with the factorial main-effects model in the second call. The difference is that when TWIST is to be regarded as a linear regressor, it is omitted from the CLASS statement. The reduced model fits parallel linear regression lines, with intercepts adjusted for block and flyer effects. Selected output for the reduced model is shown in Fig. 10.8. Again, the TYPE I and TYPE III sums of squares are unequal, indicating that FLYER and TWIST cannot be estimated independently. The fourth call of PROC GLM sequentially includes both models and will be discussed shortly.

In the third call of PROC GLM in Table 10.13, the SOLUTION option requests that the solution to the normal equations is printed. The NOTE at the bottom of the SAS output in Fig. 10.8 alerts us to

Figure 10.7: SAS selected output for the factorial main-effects model—cotton-spinning experiment

the fact that the individual flyer effect parameters are not estimable, and the numbers given just above the note and labeled B are nonunique solutions to the normal equations. The contrast representing the difference in the effects of the two flyers _is_ estimable, and we can obtain its unique least squares estimate by taking the difference in the two values given for the individual flyers. This gives 3.8587, which matches the value obtained from the ESTIMATE statement. The difference in the effects of the two flyers is declared to be significantly different from zero, since the corresponding _p_-value is at most 0.0001. The slope coefficient of TWIST is estimated to be -14.1003, which, being negative, suggests that the breakages decrease as the twist increases. This slope is declared to be significantly different from zero, since the test of \(H_{0}:\gamma=0\) versus \(H_{A}:\gamma\neq 0\) has _p_-value at most 0.0001.

To test for lack of fit of the reduced model, the difference in the error sum of squares for the full and reduced models divided by the difference in the error degrees of freedom is the mean square for lack of fit, msLF (see Chap. 8). It provides the numerator of the test statistic for testing the null hypothesis \(H_{0}^{R}:\) {the reduced model is adequate} against the alternative hypothesis that the reduced model is not adequate. The decision rule is

\[\text{reject }H_{0}^{R}\text{ if msLF/msE} >F_{3,60,\alpha},\]

Figure 10.8: SAS program output for the reduced model—cotton-spinning experiment

where

\[\text{msLF}=\left[\text{ssE}(\text{reduced})-\text{ssE}(\text{full})\right]/\left[ \text{df}(\text{reduced})-\text{ df}(\text{full})\right].\]

For the cotton-spinning experiment,

\[\text{msLF}=(319.854-306.446)/(63-60)=4.469.\]

Since \(\text{msLF}/\text{msE}=4.469/5.10744=0.88<1\), we cannot reject \(H_{0}^{R}\) for any reasonable significance level \(\alpha\). Hence, the reduced model appears to provide an adequate fit to the data, making interpretation of the parameters in the reduced model meaningful.

One can obtain these calculations from SAS software directly. The model

\[\text{MODEL\ BREAK}=\text{BLOCK\ FLYER\ TWIST\ TRTMT};\]

in the fourth call of GLM in Table 10.13 sequentially includes both models, as the first three terms of the model give the reduced model, then the full model is obtained by inclusion of TRTMT. Since TRTMT has been entered into the model last, its Type I and III sums of squares will be the same, and the corresponding \(F\)-test

\[\text{Source\ DF\ Type\ III\ SS\ Mean\ Square\ F\ Value\ Pr}>F\] \[\text{TRTMT}\ \ \ 3\ \ 13.4082028\ \ \ 4.4694009\ \ 0.88\ \ 0.4591\]

is the test for lack of fit conducted above.

We note that this has been an exercise in model-building, and we can use the model to predict the breakage rates with either flyer over a range of values of twist. However, the model may not fit well for flyer 2 below a twist of 1.69 (see Fig. 10.3).

### Using R Software

The analysis of variance table for a complete block design can be obtained from any computer package that has an analysis of variance routine or a regression routine. It is good practice to enter the block term into the model before the terms for the treatment factors. Although the order does not matter for complete block designs, it does matter for the incomplete block designs in the next chapter.

Computer programs do not distinguish between block and treatment factors, so a test for the hypothesis of no block effects will generally be listed in the output. We suggest that the latter be ignored, and that blocking be considered to have been effective for the current experiment if \(\text{ms}\theta\) exceeds \(\text{ms}E\) (see Sect. 10.4.1).

Tables 10.14, 10.15, 10.16 and 10.17 contain statements of an R program and selected output illustrating analysis of a complete block design, using the data of the cotton-spinning experiment (Sect. 2.3, p. 13). In Table 10.14, following input of the data from the file cotton.spinning.txt and the creation of factor variables fBlock, fTrtmt, fFlyer, and fTwist, the call of the linear models function lm fits a block-treatment model to the data. If the block\(\times\)treatment interaction term had been included in the model, this would have been entered in the usual way as fBlock:fTrtmt. The anova statement generates the analysis of variance table shown. A dropl statement (see Sects. 6.9 and 7.7) would have produced the same results since there is one observation per block-treatment combination. The lsmeans function and first corresponding summary(contrast...) statement applies Tukey's method for comparing the treatment effects pairwise (results not shown). The second corresponding summary(contrast...) statement reproduces the calculations in Sect. 10.5 for comparing

[MISSING_PAGE_FAIL:353]

The plot of the mean response against twist for both flyer types in Fig. 10.3, p. 317, suggested the possibility that the number of breaks per 100 pounds could be modeled by a flyer effect and a linear twist effect. This can be evaluated by comparing the fit of the block-treatment model,

\[Y_{hi}=\mu+\theta_{h}+\tau_{i}+\epsilon_{hi}\]

(\(i=1,\,\ldots,\,6;\ h=1,\,\ldots,\,13\)), with the fit of the reduced model,

\[Y_{hjx}=\mu+\theta_{h}+\alpha_{j}+\gamma x+\epsilon_{hjx}\,,\]

where \(\alpha_{j}\) is the effect of flyer \(j\) (\(j=1,\,2\)) and \(x\) is the _uncoded_ amount of twist (cf. Chaps. 8 and 9). Comparing the fit of these models can be done easily in the R software, either using two calls of the lm function, one for each model, or using one call that sequentially includes both models. The call of lm in the center of Table 10.14 fitted the full block-treatment model, and the call of lm at the top of Table 10.16 fits the reduced model that includes the flyer effect and a linear regression in the levels of twist. This second lm call is similar to that in Table 10.15 for the the factorial main-effects model. The difference is that when twist is to be regarded as a linear regressor, it is entered as a numeric variable Twist--not as the factor variable fTwist. The reduced model fits parallel linear regression lines, with intercepts adjusted for block and flyer effects. Output for the reduced model is shown in Table 10.16. The type 1 and type 3 sums of squares generated by the respective anova and dropl commands are unequal, indicating that effects of fFlyer and fTwist cannot be estimated independently.

The summary command in Table 10.16 causes display of the least squares estimates of the model parameters. We only show one. The slope coefficient of Twist is estimated to be \(-14.100\), which, being negative, suggests that the breakages decrease as the twist increases. This slope is declared to

\begin{table}
\begin{tabular}{l} \textgreater{} \# Analysis with additive main effects \\ \textgreater{} model2 = lm(Break \textasciitilde{} fBlock + fFlyer + fTwist, data=cotton.data) \\ \textgreater{} dropl(model2, \textasciitilde{},\textasciitilde{}test=”F”) \\ \end{tabular} \\ \end{tabular}
\end{table}
Table 10.15: An R program and selected output, continued, for analysis of the cotton-spinning experiment: analysis of factorial main-effects model 

[MISSING_PAGE_FAIL:355]

[MISSING_PAGE_FAIL:356]

sequentially includes both models, as the first three terms of the model give the reduced model, then the full model is obtained by inclusion of fTrtmt. Since fTrtmt has been entered into the model last, its type 1 and 3 sums of squares will be the same, and the corresponding \(F\)-test is the desired lack-of-fit test. The command anova(model4) generates the type 1 sums of squares, including that for fTrtmt which is the test for lack of fit conducted above.

We note that this has been an exercise in model-building, and we can use the model to predict the breakage rates with either flyer over a range of values of twist. However, the model may not fit well for flyer 2 below a twist of 1.69 (see Fig. 10.3).

## Exercises

1. **Randomization** Conduct a randomization for a randomized complete block design with \(v=4\) treatments observed once (\(s=1\)) in each of \(b=5\) blocks.
2. **Randomization** Conduct a randomization for a general complete block design for \(v=3\) treatments each observed twice (\(s=2\)) in each of \(b=4\) blocks.
3. **DCIS experiment randomization** Suppose the DCIS experiment of Example 10.3.2, p. 309, had been designed as a randomized complete block designs with \(b=4\) blocks of size \(k=v=6\), so that each treatment is observed \(s=1\) time per block. Conduct a randomization of the treatments within each block and present the final design.
4. **Respiratory exchange ratio experiment** In the resting metabolic rate experiment introduced in Example 10.4.1, p. 311, the experimenters also measured respiratory exchange ratio, which is another measure of energy expenditure. The data for the second 30 minutes of testing are given in Table 10.18. 1. Evaluate the assumptions of the block-treatment model (10.4.1) for these data. 2. Construct an analysis of variance table and test for equality of the effects of the protocols on respiratory exchange ratio.

\begin{table}
\begin{tabular}{c c c c}  & \multicolumn{3}{c}{Protocol} \\ Subject & 1 & 2 & 3 \\
1 & 0.79 & 0.80 & 0.83 \\
2 & 0.84 & 0.84 & 0.81 \\
3 & 0.84 & 0.93 & 0.88 \\
4 & 0.83 & 0.85 & 0.79 \\
5 & 0.84 & 0.78 & 0.88 \\
6 & 0.83 & 0.75 & 0.86 \\
7 & 0.77 & 0.76 & 0.71 \\
8 & 0.83 & 0.85 & 0.78 \\
9 & 0.81 & 0.77 & 0.72 \\ \end{tabular}
\end{table}
Table 10.18: Respiratory exchange ratio data 3. Evaluate the usefulness of blocking. 4. Use the Scheffe method of multiple comparisons to construct simultaneous 99% confidence intervals for all pairwise comparisons of the protocols as well as the inpatient versus outpatient protocols corresponding to the contrast coefficient list [ 1, - \(\frac{1}{2}\), - \(\frac{1}{2}\) ].
5. **Light bulb experiment** P. Bist, G. Deshpande, T.-W. Kung, R. Laifa, and C.-H. Wang ran an experiment in 1995 to compare the light intensities of three different brands of light bulbs (coded 1, 2, 3), together with the effect of the percentage capacity (100% and 50%) of the bulb, the latter being controlled by a dimmer switch. Thus, there were \(v=6\) treatment combinations in total: \[\begin{array}{l} (100\%,\,\text{Brand}\ 1)=1,\ (100\%,\,\text{Brand}\ 2)=2,\ (100\%,\,\text{Brand}\ 3)=3,\\ (50\%,\,\text{Brand}\ 1)=4,\ \ (50\%,\,\text{Brand}\ 2)=5,\ \ (50\%,\,\text{Brand}\ 3)=6.\end{array}\] Two blocks were used (one per day), with all 60 watt bulbs observed in one block, and all 100 watt bulbs in the other. Four observations were taken on each of the \(v=6\) treatment combinations in each block. The response variable was the observed resistance of a photoresistor connected to the bulb, where high illumination corresponds to low resistance. The data (resistances) are shown in Table 10.19. 1. Fit a block-treatment-interaction model to the data and calculate an analysis of variance table. 2. Show that the null hypothesis of no block x treatment interaction would be rejected at level \(\alpha=0.005\). 3. Calculate a set of confidence intervals for pairwise differences in the treatments for each block separately. Specify the method that you are using and the overall confidence level. 4. In terms of the six treatment parameters, write down two contrasts representing the interaction between brand and percentage capacity (averaged over blocks). Test whether these contrasts are significantly different from zero. 5. Suppose that the purpose of the experiment was to determine the best brand (in terms of illumination) for each percentage capacity and for 100 watt bulbs. Which brand(s) would you recommend and why? 5.

\begin{table}
\begin{tabular}{c c c c c c c} \hline  & & \multicolumn{5}{c}{Treatments} \\ Block & 1 & 2 & 3 & 4 & 5 & 6 \\ \hline I & 314 (12) & 285 (3) & 350 (6) & 523 (2) & 460 (1) & 482 (7) \\ (60 watt) & 300 (13) & 296 (9) & 339 (8) & 497 (4) & 470 (5) & 498 (11) \\  & 310 (15) & 301 (10) & 360 (14) & 520 (18) & 488 (17) & 505 (19) \\  & 290 (22) & 292 (24) & 333 (16) & 510 (20) & 468 (21) & 490 (23) \\ II & 214 (28) & 196 (27) & 235 (42) & 303 (26) & 341 (32) & 342 (25) \\ (100 watt) & 205 (31) & 201 (29) & 247 (44) & 319 (30) & 350 (38) & 347 (33) \\  & 197 (35) & 197 (39) & 233 (46) & 305 (34) & 323 (41) & 352 (37) \\  & 204 (47) & 215 (40) & 244 (48) & 316 (36) & 343 (45) & 323 (43) \\ \hline \end{tabular}
\end{table}
Table 10.19: Resistances for the light bulb experiment. Low resistance implies high illumination. (Order of observations is shown in parentheses.)

[MISSING_PAGE_FAIL:359]

[MISSING_PAGE_FAIL:360]

4. At a significance level of 0.01, test the hypothesis that there is no quadratic trend in the number of characters recalled as the length of the study time increases. 5. Suppose that you (pre-)planned to calculate a set of 99% simultaneous confidence intervals for the pairwise comparisons of the three times of study. Explain whether you would use Bonferroni, Tukey, Scheffe, or Dunnett's method. 6. Calculate a 90% upper bound for the true value of \(\sigma^{2}\). 7. Write down the formula for a 95% confidence interval which compares the effect of no music versus classical music on the number of symbols recalled (averaged over the other factors). 8. Suppose now that you wished to design a larger experiment for the future, but with the same treatment combinations. The design will be a randomized complete block design with each of subjects seeing all 36 treatment combinations in a random order. If you require the confidence interval in part (g) to be no wider than 2.0, how many subjects would you recommend?
8. **Hypothetical chemical experiment** An experiment to examine the yield of a certain chemical was conducted in \(b=4\) different laboratories. The treatment factors of interest were \[A :\,\text{acid strength}\,(80\%\,\text{and}\,90\%,\,\text{ coded}\,1,\,2)\] \[B :\,\text{time allowed for reaction}\,(15\,\text{and}\,30\,\text{min},\,\text{ coded}\,1,\,2)\] \[C :\,\text{temperature}\,(50^{\circ}\,\text{and}\,75\,^{\circ}\text{C},\,\text{ coded}\,1,\,2)\] The experiment was run as a randomized complete block design with the laboratories as the levels of the blocking factor. The resulting data (yields in grams) are shown in Table 10.22. The goal of the experiment was to find the treatment combination(s) that give(s) the highest average yield. 1. Plot the data and comment on your chosen plots. 2. Fit a block-treatment model to these data and show that the assumptions on the model are approximately satisfied. 3. Suppose that the pre-plan was to calculate a 99% set of pairwise comparisons between the treatment combinations using Tukey's method, to calculate 99.5% intervals for the comparisons between the levels of A, B and C if these were not involved in interactions and a set of 99% intervals using Scheffe's method for any other contrasts that look interesting. The overall confidence level would then be at least 96.5%. List any contrasts that you would like to examine further after looking at the plots in part (a). 4. Calculate an analysis of variance table and test any hypotheses of interest, each at level 0.01. State your conclusions clearly. 5. Calculate confidence intervals for the contrasts specified in part (c), and state your conclusions. 6. The objective of the experiment was to find the combination that gives the highest yield. Using all the information that you have gathered, which treatment combination would you recommend? 
\begin{table}
\begin{tabular}{c c c c c c c c c} \hline Lab (Block) & \multicolumn{6}{c}{Treatment combinations} \\  & 111 & 112 & 121 & 122 & 211 & 212 & 221 & 222 \\ \hline
1 & 7.3 & 9.5 & 13.8 & 15.4 & 16.0 & 18.7 & 11.3 & 14.5 \\
2 & 8.8 & 11.3 & 15.3 & 17.7 & 17.9 & 20.8 & 12.0 & 15.4 \\
3 & 11.7 & 14.1 & 17.2 & 22.3 & 22.6 & 24.8 & 16.9 & 18.5 \\
4 & 6.2 & 8.3 & 11.2 & 15.4 & 16.8 & 17.4 & 8.2 & 12.5 \\ \hline \end{tabular}
\end{table}
Table 10.22: Data for the hypothetical chemical experiment 9. **Reaction time experiment, continued, (sample size)** The reaction time pilot experiment was described in Exercise 4, p. 100, and analyzed in Examples 6.4.3 and 6.4.5, pp. 153 and 160. The experiment was run to compare the speed of response of a human subject to audio and visual stimuli. The two treatment factors were "Cue Stimulus" at two levels "auditory" and "visual" (Factor \(A\), coded 1, 2), and "Cue Time" at three levels 5, 10, and 15 seconds between cue and stimulus (Factor \(B\), coded 1, 2, 3), giving a total of \(v=6\) treatment combinations. The pilot experiment used only one subject, for whom \(\mathit{msE}=0.00029\) seconds2 based on 12 degrees of freedom. An upper 95% confidence bound for the error variance was calculated in Example 6.4.2, p. 151, as \(\sigma^{2}\leq 0.000664\) seconds2. To be able to draw conclusions about these six treatment combinations, it is important for the main experiment to use a random sample of subjects from the population. 1. Consider using a randomized complete block design with \(b\) subjects representing blocks for the main experiment. Let the block sizes be \(k=6\), so that each treatment combination can be observed once for each subject. How many subjects are needed if the widths of simultaneous 99% confidence intervals for the pairwise comparisons of the treatment combinations need to be less than 0.01 seconds to be useful (that is, we require \(\mathit{msd}<0.005\) seconds)? 2. If \(b=4\) subjects were available, and a general complete block design were used with block size \(k=6s\), how many observations would be needed on each treatment in each block to satisfy the requirements of the confidence intervals in part (a)?
10. **Length perception experiment** The experiment was run by B. Millen, R. Shankar, K. Christoffersen, and P. Nevathia in 1996 to explore subjects' ability to reproduce accurately a straight line of given length. A 5 cm line (1.9685 inches) was drawn horizontally on an 11 x 8.5 in sheet of plain white paper. The sheet was affixed at eye level to a white projection screen located four feet in front of a table at which the subject was asked to sit. The subject was asked to reproduce the line on a sheet of white paper on which a border had been drawn. Subjects were selected from a population of university students, both male and female, between 20 and 30 years of age. The subjects were all right-handed and had technical backgrounds. There were six different borders representing the combinations of three shapes--square, circle, equilateral triangle (levels of factor \(C\), coded 1, 2, 3) and two areas--16 in2 and 9 in2 (levels of factor \(D\), coded 1, 2). The purpose of the experiment was not to see how close to the 5 cm that subjects could draw, but rather to compare the effects of the shape and area of the border on the length of the lines drawn. The subjects were all able to draw reasonably straight lines by hand, and one of the experimenters measured, to the nearest half millimeter, the distance between the two endpoints of each line drawn. Data from 14 of the subjects are shown as deviations from the target 5 cm in Table 10.23. 1. Fit a block-treatment model to the data using subjects as blocks and with six treatments representing the shape-area combinations. Check the error assumptions on your model. 2. Draw at least one graph and examine the data. 3. Write down contrasts in the six treatment combinations representing the following comparisons: 1. differences in the effects of area for each shape separately, 2. average difference in the effects of area, 3. average difference in the effects of shape.

[MISSING_PAGE_FAIL:363]

[MISSING_PAGE_FAIL:364]

[MISSING_PAGE_FAIL:365]

[MISSING_PAGE_FAIL:366]

[MISSING_PAGE_FAIL:367]

[MISSING_PAGE_FAIL:368]

### 11.1 Introduction

When an experiment needs to be run in blocks but, for practical reasons, the block size cannot be a multiple of the number of treatments, then a complete block design (Chap. 10) cannot be used--an _incomplete block design_ needs to be used instead. The incomplete block designs discussed in this chapter have block size smaller than the number of treatments, but larger block sizes can be obtained by adding one or more complete set of treatments to every block.

In Sect. 11.2, we discuss basic design issues of block size, randomization and estimability. Then, in Sect. 11.3, three useful and efficient types of incomplete block designs (balanced incomplete block designs, group divisible designs, and cyclic designs) are introduced. Analysis of incomplete block designs is described in Sect. 11.4, including some specific formulae for balanced incomplete block designs and group divisible designs. In Sect. 11.5, we describe and analyze an experiment that was designed as a cyclic group divisible design. Sample-size calculations are discussed in Sect. 11.6, and factorial experiments in incomplete block designs are considered in Sect. 11.7. In general, since not every combination of treatment and block is observed, incomplete block designs are most easily analyzed using computer software. Illustrations are given in Sect. 11.8 by SAS software and in Sect. 11.9 by R.

### 11.2 Design Issues

#### Block Sizes

Block sizes are dictated by the availability of groups of similar experimental units. For example, in the breathalyzer experiment examined in Sect. 10.3.1, p. 306, the block size was chosen to be \(k=5\). This choice was made because the pilot experiment indicated that experimental conditions were fairly stable over a time span of five observations taken close together, and also because five observations could be taken by a single technician in a shift. In other experiments, the block size may be limited by the capacity of the experimental equipment, the availability of similar raw material, the length of time that a subject will agree to remain in the study, the number of observations that can be taken by an experimenter before fatigue becomes a problem, and so on. Such restrictions on the block size may result in the blocks being too small for every treatment to be observed the same number of times in every block. The breathalyzer experiment required the comparison of \(v=36\) treatment combinations (twelve differentalcohol concentrations combined with three air-intake ports) of which only five would be observed per block. Skill was then needed in selecting the best design that would still allow all treatment contrasts to be estimable with high precision.

#### Design Plans and Randomization

All the designs that we discuss in this chapter are equireplicate; that is, every treatment (or treatment combination) is observed \(r\) times in the experiment. These tend to be the most commonly used designs, although nonequireplicate designs are occasionally used in practice.

We use the symbol \(n_{ih}\) to denote the number of times that treatment \(i\) is observed in block \(h\). In general, it is better to observe as many different treatments as possible in a block, since this tends to decrease the average variance of the contrast estimators. Therefore, when the block size is smaller than the number of treatments, each treatment should usually be observed either once or not at all in a block. Such block designs are called _binary,_ and every \(n_{ih}\) is either 0 or 1. For most purposes, the best binary designs are those in which pairs of treatments occur together in the same number (or nearly the same number) of blocks. These designs give rise to equal (or nearly equal) lengths of confidence intervals for pairwise comparisons of treatment effects.

There are three stages in designing an experiment with incomplete blocks. The first stage is to obtain as even a distribution as possible of treatment labels within the blocks. This results in an _experimental plan_. The plan in Table 11.1, for example, shows a design with \(b=8\) blocks (labeled I, II,..., VIII) each of size \(k=3\), which can be used for an experiment with \(v=8\) treatments (labeled 1,..., 8) each observed \(r=3\) times. The treatment labels are evenly distributed in the sense that no label appears more than once per block and pairs of labels appear together in a block either once or not at all, which is "as equal as possible".

The experimental plan is often called the "design," even though it is not ready for use until the random assignments have been made. There are three steps to the randomization procedure, as follows.

1. Randomly assign the block labels in the plan to the levels of the blocking factor(s).
2. Randomly assign the experimental units in a block to those treatment labels allocated to that block.
3. Randomly assign the treatment labels in the plan to the actual levels of the treatment factor.

The randomization procedure is illustrated in the following example.

##### Metal alloy experiment

Suppose an experiment is to be run to compare \(v=7\) compositions of a metal alloy in terms of tensile strength. Further, suppose that only three observations can be taken per day, and that the experiment must be completed within seven days. It may be thought advisable to divide the experiment into blocks, with each day representing a block, since different technicians may work on the experiment on different

\begin{table}
\begin{tabular}{l c c c c c c c} Block & \multicolumn{6}{c}{Block} \\ I & 1 & 3 & 8 & V & 5 & 7 & 4 \\ II & 2 & 4 & 1 & VI & 6 & 8 & 5 \\ III & 3 & 5 & 2 & VII & 7 & 1 & 6 \\ IV & 4 & 6 & 3 & VIII & 8 & 2 & 7 \\ \end{tabular}
\end{table}
Table 11: An incomplete block design with \(b=8\), \(k=3\), \(v=8\), \(r=3\)days and the laboratory temperature may vary from day to day. Thus, an incomplete block design with \(b=7\) blocks of size \(k=3\) and with \(v=7\) treatment labels is needed. The plan shown in the first two columns of Table 11.2 is of the correct size. It is binary, with every treatment appearing 0 or 1 times per block and \(r=3\) times in total. Also, all pairs of treatments occur together in a block exactly once, so the treatment labels are evenly distributed over the blocks. Randomization now proceeds in three steps.

Step (i): The block labels need to be randomly assigned to the 7 days. Suppose we obtain the following pairs of random digits from a random number generator or from Table A.1 and associate them with the blocks:

\[\begin{array}{l} {\text{Random digits: }}71366593920297\\ {\text{Block labels: }}\quad\text{I }\quad\text{II }\quad\text{III }\quad\text{IV }\quad\text{V }\quad\text{VI }\quad\text{VII}\end{array}\]

Then, sorting the random numbers into ascending order, the blocks of the plan are assigned to the seven days as in columns 3-5 of Table 11.2.

Step (ii): Now we randomly assign time slots within each day to the treatment labels. Again, using pairs of random digits either from a random number generator or from where we left off in Table A.1, we associate the random digits with the treatment labels as we illustrate here for the first three days:

\[\begin{array}{l} {\text{Day: }}\quad\text{Day 1}\quad\text{Day 2}\quad\text{Day 3}\\ {\text{Block: }}\quad\text{(Block VI) (Block II) (Block III)}\\ {\text{Random digits: }}\quad\text{50 29 03 65 34 30 74 56 88}\\ {\text{Treatment labels: }}\quad\text{6 7 2 2 2 3 5 3 4 6}\end{array}\]

Sorting the random numbers into ascending order for each day separately gives the treatment label order 2, 7, 6 for day 1, and 5, 3, 2 for day 2, and 4, 3, 6 for day 3, and so on. The design after step (ii) is shown in the last column in Table 11.2. A third set of random digits is now required to associate the treatment numbers in the plan with the 7 compositions of metal alloy. 

#### Estimation of Contrasts

The importance of selecting an experimental plan with an even distribution of treatment labels within the blocks, such as those in Tables 11.1 and 11.2, is to ensure that all treatment contrasts are estimable and that pairwise comparison estimators have similar variances. The plan shown in Table 11.3 is poor. Although all treatments appear \(r=3\) times in the design, some pairs of treatment labels (such as 1 and 3) occur together in two blocks, while other pairs (such as 1 and 2) never appear together. Worse

\begin{table}
\begin{tabular}{l c|c c c} Block label & Unrandomized design & Block label & Day & Design after step (i) & Design after step (ii) \\ I & 1 2 4 & VI & 1 & 6 7 2 & 2 7 6 \\ II & 2 3 5 & II & 2 & 2 3 5 & 5 3 2 \\ III & 3 4 6 & III & 3 & 3 4 6 & 4 3 6 \\ IV & 4 5 7 & I & 4 & 1 2 4 & 2 1 4 \\ V & 5 6 1 & V & 5 & 5 6 1 & 1 5 6 \\ VI & 6 7 2 & IV & 6 & 4 5 7 & 4 5 7 \\ VII & 7 1 3 & VII & 7 & 7 1 3 & 7 3 1 \\ \end{tabular}
\end{table}
Table 11.2: Randomization of an incomplete block design still, is that some blocks contain all the even-numbered treatment labels, and the other blocks contain all the odd-numbered labels. The result is that every pairwise comparison between an even-numbered and an odd-numbered treatment is not estimable. The design is said to be _disconnected_.

Disconnectedness can be illustrated through a _connectivity graph_ as follows. Draw a point for each treatment and then draw a line between every two treatments that occur together in any block of the design. The connectivity graph for the disconnected design in Table 11.3 is shown in Fig. 11.1a. Notice that the graph falls into two pieces. There is no line between any of the odd-labeled treatments and the even-labeled treatments.

A design is _connected_ if every treatment can be reached from every other treatment via lines in the connectivity graph. The connectivity graph for the connected design in Table 11.1 is shown in Fig. 11.1b and it can be verified that there is a path between every pair of treatments. For example, although treatments 1 and 5 never occur together in a block and so are not connected by a line, there is nevertheless a path from 1 to 4 to 5. _All contrasts in the treatment effects are estimable in a design if and only if the design is connected_. The connectivity graph therefore provides a simple means of checking estimability.

Although disconnected designs will be useful in Chap. 13 for single-replicate (\(r=1\)) factorial experiments arranged in blocks, they need never be used for experiments with at least two observations per treatment. All balanced incomplete block designs are connected, and so are most group divisible designs and cyclic designs. These three types of design are described next.

### Some Special Incomplete Block Designs

#### Balanced Incomplete Block Designs

A _balanced incomplete block design_ is a design with \(v\) treatment labels, each occurring \(r\) times, and with \(bk\) experimental units grouped into \(b\) blocks of size \(k<v\) in such a way that the units within a

\begin{table}
\begin{tabular}{l c c c c c c} Block & Block & Block \\ I & 1 & 3 & 5 & V & 5 & 7 & 1 \\ II & 2 & 4 & 6 & VI & 6 & 8 & 2 \\ III & 3 & 5 & 7 & VII & 7 & 1 & 3 \\ IV & 4 & 6 & 8 & VIII & 8 & 2 & 4 \\ \end{tabular}
\end{table}
Table 11.3: A disconnected incomplete block design with \(b=8\), \(k=3\), \(v=8\), \(r=3\)

Figure 11.1: Connectivity graphs to check connectedness of designs

block are alike and units in different blocks are substantially different. The plan of the design satisfies the following conditions:

1. Each treatment label appears either once or not at all in a block (that is, the design is binary).
2. Each pair of labels appears together in \(\lambda\) blocks, where \(\lambda\) is a fixed integer.

Block design randomization is carried out as illustrated in Sect. 11.2.2.

All balanced incomplete block designs have the desirable properties that all treatment contrasts are estimable and all pairwise comparisons of treatment effects are estimated with the same variance so that their confidence intervals are all the same length. Balanced incomplete block designs also tend to give the shortest confidence intervals on the average for any large number of contrasts. For these reasons, the balanced incomplete block design is a popular choice among experimenters. The main drawback is that such designs exist only for some choices of \(v\), \(k\), \(b\), and \(r\).

The design in Table 11.2 is a balanced incomplete block design for \(v=7\) treatments and \(b=7\) blocks of size \(k=3\). It can be seen that conditions (i) and (ii) are satisfied, with every pair of labels appearing together in exactly \(\lambda=1\) block. A second example of a balanced incomplete block design, prior to randomization, is shown in Table 11.4 for \(v=8\) treatments in \(b=14\) blocks of size \(k=4\). Again, conditions (i) and (ii) are satisfied, this time with \(\lambda=3\).

We can verify that the design in Table 11.1 (p. 350) with \(v=b=8\), \(r=k=3\) is not a balanced incomplete block design. Label 2, for example, appears in one block with each of labels 1, 3, 4, 5, 7, and 8 but never with label 6. The following simple argument shows that no balanced incomplete block design can possibly exist for this size of experiment. In a balanced incomplete block design with \(v=b=8\), \(r=k=3\), label 2, for example, must appear in \(r=3\) blocks in the design, and in each block there are \(k-1=2\) other labels. So label 2 must appear in a block with a total of \(r(k-1)=6\) other treatment labels. Consequently, if label 2 were to appear \(\lambda\) times with each of the other \(v-1=7\) labels, then \(7\lambda\) would have to be equal to \(r(k-1)=6\). This would require that \(\lambda=6/7=r(k-1)/(v-1)\). Since \(\lambda\) is not an integer, a balanced incomplete block design of this size cannot exist. However, for the size of design in Table 11.4, \(\lambda\) is an integer since \(\lambda=r(k-1)/(v-1)=7(3)/(7)=3\).

There are three necessary conditions for the existence of a balanced incomplete block design, all of which are easy to check. These are

\[\begin{split} vr&=bk\;,\\ r(k-1)&=\lambda(v-1)\;,\\ b&\geq v\;.\end{split} \tag{11.3.1}\]

\begin{table}
\begin{tabular}{l c c c c c c c c} Block & Treatments & Block & Treatments & & & & \\ I & 1 & 2 & 3 & 4 & VIII & 2 & 3 & 5 & 8 \\ II & 1 & 2 & 5 & 6 & IX & 2 & 3 & 6 & 7 \\ III & 1 & 2 & 7 & 8 & X & 2 & 4 & 5 & 7 \\ IV & 1 & 3 & 5 & 7 & XI & 2 & 4 & 6 & 8 \\ V & 1 & 3 & 6 & 8 & XII & 3 & 4 & 5 & 6 \\ VI & 1 & 4 & 5 & 8 & XIII & 3 & 4 & 7 & 8 \\ VII & 1 & 4 & 6 & 7 & XIV & 5 & 6 & 7 & 8 \\ \end{tabular}
\end{table}
Table 11.4: A balanced incomplete block design with \(v=8\), \(r=7\), \(b=14\), \(k=4\), \(\lambda=3\)The first condition is satisfied by all block designs with equal replication and equal block sizes. The second condition is obtained by the argument above, and the third condition is called Fisher's inequality. Although the three necessary conditions can be used to verify that a balanced incomplete block design of a given size may exist, they do not guarantee its existence. Lists of balanced incomplete block designs can be found in Cochran and Cox (1957, chapter 11) and Fisher and Yates (1973), or can be obtained by some computer packages (see, for example, PROC OPTEX in the SAS software, described in Sect. 11.8.1 and the ibd package in R, Sect. 11.9.1).

#### Group Divisible Designs

A _group divisible design_ is a design with \(v=g\ell\) treatment labels (for some integers \(g>1\) and \(\ell>1\)), each occurring \(r\) times, and \(bk\) experimental units grouped into \(b\) blocks of size \(k<v\) in such a way that the units within a block are alike and units in different blocks are substantially different. The plan of the design satisfies the following conditions:

1. The \(v=g\ell\) treatment labels are divided into \(g\) groups of \(\ell\) labels--any two labels within a group are called _first associates_ and any two labels in different groups are called _second associates_.
2. Each treatment label appears either once or not at all in a block (that is, the design is binary).
3. Each pair of first associates appears together in \(\lambda_{1}\) blocks.
4. Each pair of second associates appears together in \(\lambda_{2}\) blocks.

Block design randomization is carried out as in Sect. 11.2.2.

It will be seen in Sect. 11.4.5 that the values of \(\lambda_{1}\) and \(\lambda_{2}\) govern the lengths of confidence intervals for treatment contrasts. Generally, it is preferable to have \(\lambda_{1}\) and \(\lambda_{2}\) as close as possible, which ensures that the confidence intervals of pairwise comparisons are of similar lengths. Group divisible designs with \(\lambda_{1}\) and \(\lambda_{2}\) differing by one are usually regarded as the best choice of incomplete block design when no balanced incomplete block design exists.

An example of a group divisible design (prior to randomization) is the experimental plan shown in Table 11.1, p. 350. It has the following \(g=4\) groups of \(\ell=2\) labels:

\[(1,5),\quad(2,6),\quad(3,7),\quad(4,8).\]

Labels in the same group (first associates) never appear together in a block, so \(\lambda_{1}=0\). Labels in different groups (second associates) appear together in one block, so \(\lambda_{2}=1\).

A second example is given by the experimental plan in Table 11.5, and it has \(g=4\) groups of \(\ell=3\) labels:

\[(1,2,3),\quad(4,5,6),\quad(7,8,9),\quad(10,11,12),\]

and \(\lambda_{1}=3\), \(\lambda_{2}=1\) (which is not ideal since \(\lambda_{1}\) and \(\lambda_{2}\) differ by more than 1).

There are four necessary conditions for the existence of a group divisible design with chosen values of \(v=g\ell\), \(b\), \(k\), \(r\) namely,

\[g\ell r = bk\,,\] \[r(k-1) = \lambda_{1}(\ell-1)+\lambda_{2}\ell(g-1)\,,\] \[r \geq \lambda_{1}\,,\] \[rk \geq \lambda_{2}v\,,\]for integers \(\lambda_{1}\) and \(\lambda_{2}\).

All group divisible designs with \(\lambda_{2}=0\) should be avoided, since not all of the treatment contrasts are estimable. (It can be verified that the disconnected design of Table 11.3 is a group divisible design with groups (1, 3, 5, 7) and (2, 4, 6, 8) and with \(\lambda_{1}=2\) and \(\lambda_{2}=0\).) Lists of group divisible designs are given by Clatworthy (1973) and in the more recent references listed by Sinha (1991). Good block designs (which may or may not be group divisible) can be obtained by some computer packages (see, for example, PROC OPTEX in SAS software, Sect. 11.8.1 and the ibd package in R, Sect. 11.9.1).

#### Cyclic Designs

A _cyclic design_ is a design with \(v\) treatment labels, each occurring \(r\) times, and with \(bk\) experimental units grouped into \(b=v\) blocks of size \(k<v\) in such a way that the units within a block are alike and units in different blocks are substantially different. The experimental plan, using treatment labels 1, 2,..., \(v\), can be obtained as follows:

1. The first block, called the _initial block_, consists of a selection of \(k\) distinct treatment labels.
2. The second block is obtained from the initial block by _cycling the treatment labels_--that is, by replacing treatment label 1 with 2, 2 with 3,..., \(v-1\) with \(v\), and \(v\) with 1. The third block is obtained from the second block by cycling the treatment labels once more, and so on until the \(v\)th block is reached.

Block design randomization is carried out as in Sect. 11.2.2.

The group divisible design in Table 11.1 is also a cyclic design and has initial block (1, 3, 8). There are three cyclic designs in Table 11.6 all with block size \(k=4\). The first two have initial block (1, 2, 3, 6), but one has \(v=7\) treatment labels and the other has \(v=6\). The third design has initial block (1, 2, 3, 4) and \(v=7\). The first design is also a balanced incomplete block design with \(\lambda=2\). The second design has pairs of treatments occurring together in either \(\lambda_{1}=2\) or \(\lambda_{2}=3\) blocks, which results in only two possible lengths of confidence intervals for pairwise comparisons, but it is not a group divisible design since the treatment labels cannot be divided into groups of first associates. The third design is less good since pairs of treatments occur in \(\lambda_{1}=1\) or \(\lambda_{2}=2\) or \(\lambda_{3}=3\) blocks, resulting in three different lengths of confidence interval for pairwise comparisons.

A cyclic design can have as many as \(v/2\) different values of \(\lambda_{i}\), yielding as many as \(v/2\) different lengths of confidence intervals for pairwise comparisons of treatment effects. Again, if no balanced incomplete block design exists, the best designs are usually regarded as those with two values of \(\lambda_{i}\) which differ by one.

\begin{table}
\begin{tabular}{l c c c c c} Block & \multicolumn{5}{c}{Treatments} \\ I & 1 & 2 & 3 & 4 & 5 & 6 \\ II & 1 & 2 & 3 & 7 & 8 & 9 \\ III & 1 & 2 & 3 & 10 & 11 & 12 \\ IV & 4 & 5 & 6 & 7 & 8 & 9 \\ V & 4 & 5 & 6 & 10 & 11 & 12 \\ VI & 7 & 8 & 9 & 10 & 11 & 12 \\ \end{tabular}
\end{table}
Table 11.5: A group divisible design with \(v=12\), \(r=3\), \(b=6\), \(k=6\), \(\lambda_{1}=3\), \(\lambda_{2}=1\)Some cyclic designs have duplicate blocks, such as that with \(v=8\) and initial block (1, 4, 5, 8). These designs are useful when fewer than \(v\) blocks are required, since duplicate blocks can be ignored. Otherwise, designs with distinct blocks are usually better. Lists of cyclic designs are given by John et al. (1972), John (1981), and Lamacraft and Hall (1982).

### Analysis of General Incomplete Block Designs

#### Contrast Estimators and Multiple Comparisons

The standard block-treatment model for the observation on treatment \(i\) in block \(h\) in a binary incomplete block design is

\[\begin{array}{l} Y_{hi}=\mu+\theta_{h}+\tau_{i}+\epsilon_{hi}\;,\\ \epsilon_{hi}\sim N(0,\sigma^{2})\;,\\ \epsilon_{hi}\,\text{'s are mutually independent}\;,\\ h=1,\ldots,b\;;\;\;i=1,\ldots,v\;;\;\;(h,i)\text{ in the design}.\end{array}\]

The model, which assumes no block-treatment interaction, is almost identical to block-treatment model (10.4.1) for the randomized block design. The only difference is the phrase "\((h,i)\) in the design", which means that the model is applicable only to those combinations of block \(h\) and treatment \(i\) that are actually observed. The phrase serves as a reminder that not all treatments are observed in each block.

For every experiment, the assumptions on the model should be checked. However, when blocks do not contain every treatment, it is difficult to check the assumption of no block-treatment interaction by plotting the data block by block, as was recommended for complete block designs in Sect. 10.7. Thus, it is preferable that an incomplete block design be used only when there are good reasons for believing that treatment differences do not depend on the level of the blocking factor(s).

The least squares estimators for the treatment parameters in the model for an incomplete block design must include an adjustment for blocks, since some treatments may be observed in "better" blocks than others. This means that the least squares estimator for the pairwise comparison \(\tau_{p}-\tau_{i}\) is _not_ the _unadjusted estimator_\(\overline{Y}_{.p}-\overline{Y}_{.i}\) as it would be for a randomized complete block design. For example, if metal alloys 2 and 7 were to be compared via the balanced incomplete block design in the

\begin{table}
\begin{tabular}{c c c c c c}  & Design 1 & Design 2 & Design 3 \\ \(v=7\) & & \(v=6\) & & \(v=7\) \\ Block & Treatments & Block & Treatments & Block & Treatments \\
1 & 1 2 3 6 & 1 & 1 2 3 6 & 1 & 1 2 3 4 \\
2 & 2 3 4 7 & 2 & 2 3 4 1 & 2 & 2 3 4 5 \\
3 & 3 4 5 1 & 3 & 3 4 5 2 & 3 & 3 4 5 6 \\
4 & 4 5 6 2 & 4 & 4 5 6 3 & 4 & 4 5 6 7 \\
5 & 5 6 7 3 & 5 & 5 6 1 4 & 5 & 5 6 7 1 \\
6 & 6 7 1 4 & 6 & 6 1 2 5 & 6 & 6 7 1 2 \\
7 & 7 1 2 5 & & & 7 & 7 1 2 3 \\ \end{tabular}
\end{table}
Table 16: Cyclic designs with \(k=4\) generated by (1, 2, 3, 6) for \(v=7\) and \(v=6\), and generated by (1, 2, 3, 4) for \(v=7\)last column of Table 11.2, we see that alloy 2 is observed on days 1, 2, and 4, and alloy 7 is observed on days 1, 6, and 7. If we were to use \(\overline{Y}_{.2}-\overline{Y}_{.7}\) to estimate \(\tau_{2}-\tau_{7}\), it would be biased, since

\[E[\overline{Y}_{.2}-\overline{Y}_{.7}] = E[\frac{1}{3}(Y_{12}+Y_{22}+Y_{42})-\frac{1}{3}(Y_{17}+Y_{67}+Y_{ 77})]\] \[= \frac{1}{3}(3\mu+\theta_{1}+\theta_{2}+\theta_{4}+3\tau_{2})-\frac {1}{3}(3\mu+\theta_{1}+\theta_{6}+\theta_{7}+3\tau_{7})\] \[= (\tau_{2}-\tau_{7})+\frac{1}{3}(\theta_{2}+\theta_{4}-\theta_{6}- \theta_{7})\] \[\neq (\tau_{2}-\tau_{7}).\]

If the experimental conditions were to change over the course of the experiment in such a way that observations on the first few days tended to be higher than observations on the last few days, then \(\theta_{2}\) and \(\theta_{4}\) would be larger than \(\theta_{6}\) and \(\theta_{7}\). If the two alloys do not differ in their tensile strengths, then \(\tau_{2}=\tau_{7}\), but the above calculation shows that \(\overline{Y}_{.2}-\overline{Y}_{.7}\) would nevertheless be expected to be large. This could cause the experimenter to conclude erroneously that alloy 2 was stronger than alloy 7. Consequently, any estimator for \(\tau_{2}-\tau_{7}\) must contain an adjustment for the days on which the alloys were observed.

A general formula for a set of least squares solutions for the parameters \(\tau_{i}\) in the block-treatment model (11.4.2) adjusted for block differences can be shown to be

\[r(k-1)\hat{\tau}_{i}-\sum_{p\neq i}\lambda_{pi}\hat{\tau}_{p}=k\,Q_{i}\,,\quad \text{ for }i=1,\ldots,v, \tag{11.4.3}\]

when \(\sum_{i}\hat{\tau}_{i}=0\), \(\sum_{h}\hat{\theta}_{h}=0\) are used as the added equations (similar to Sect. 3.4.3). Here, \(\lambda_{pi}\) is the number of blocks containing both treatments \(p\) and \(i\), and a formula for calculating \(Q_{i}\) will be given in (11.4.7) in the next section. However, except in special cases, such as that of the balanced incomplete block design, expression (11.4.3) is difficult to solve for the individual \(\tau_{i}\) and is usually left for statistical software to calculate. Although the individual \(\tau_{i}\) are not uniquely estimable, all contrasts \(\sum_{i}c_{i}\tau_{i}\) are estimable if the design is connected, (see Sect. 11.2.3).

The Bonferroni and Scheffe methods of multiple comparisons can be used for simultaneous confidence intervals of estimable contrasts in all incomplete block designs. The method of Tukey is applicable for balanced incomplete block designs, and it is believed to be conservative (true value of \(\alpha\) smaller than stated) for other incomplete block designs, but this has not yet been proven. Dunnett's method can be used in balanced incomplete block designs but not in other incomplete block designs without modification to our tables. For each method, the formula for a set of \(100(1-\alpha)\%\) simultaneous intervals is

\[\sum_{i=1}^{v}c_{i}\tau_{i}\in\left(\sum_{i=1}^{v}c_{i}\hat{\tau}_{i}\pm w \sqrt{\widehat{\text{Var}}\!\left(\sum_{i=1}^{v}c_{i}\hat{\tau}_{i}\right)}\,\right) \tag{11.4.4}\]

exactly as in Sect. 4.4. The correct least squares estimate \(\sum c_{i}\hat{\tau}_{i}\), as well as the estimated variance \(\widehat{\text{Var}}(\sum c_{i}\hat{\tau}_{i})\) and the error degrees of freedom can be obtained from computer software for the design being used.

#### Analysis of Variance

For a connected incomplete block design with block-treatment model (11.4.2), the four rows in the center section of Table 11.7 show an outline of the analysis of variance obtained when the block factor is entered into the model before the treatment factor; the formulae are listed in the bottom section of the table. The unadjusted sum of squares for blocks, ss\(\theta\), is calculated in a similar way to the block sum of squares in a complete block design; that is

\[\text{ss}\theta=\sum_{h=1}^{b}B_{h}^{2}/k-G^{2}/(bk)\;, \tag{11.4.5}\]

where \(B_{h}\) is the sum of all observations in block \(h\), and \(G\) represents the "grand total" of all the observations. The _sum of squares for treatments adjusted for blocks_ (i.e. adjusted for the fact that not all treatments are in every block and some blocks are better than others) is

\[\text{ss}T_{\text{adj}}=\sum_{i=1}^{v}Q_{i}\hat{\tau}_{i}\;, \tag{11.4.6}\]

where \(\hat{\tau}_{i}\) is the least squares solution for \(\tau_{i}\) obtained from (11.4.3), and \(Q_{i}\) is the \(i\)th _adjusted treatment total_; that is,

\[Q_{i}=T_{i}-\frac{1}{k}\sum_{h=1}^{b}n_{hi}B_{h}\;, \tag{11.4.7}\]

where \(n_{hi}\) is 1 if treatment \(i\) is observed in block \(h\) and zero otherwise, \(B_{h}\) is defined above, and \(T_{i}\) is the sum of all observations on treatment \(i\). We could write the three quantities \(T_{i}\), \(B_{h}\) and \(G\) as \(y_{.i}\) and \(y_{.i}\) in the usual way. The reason for changing notation is as a reminder that some of the \(y_{hi}\) are not actually observed and the quantities \(T_{i}\), \(B_{h}\) and \(G\) are more accurately written as

\[T_{i}=\sum_{h=1}^{b}n_{hi}y_{hi}\;,\;\;\;B_{h}=\sum_{i=1}^{v}n_{hi}y_{hi}\;,\; \;\;\text{and}\;\;G=\sum_{h=1}^{b}\sum_{i=1}^{v}n_{hi}y_{hi}\;.\]

\begin{table}
\begin{tabular}{c c c c c} Source of variation & Degrees of freedom & Sum of squares & Mean square & Ratio \\ Blocks (adj) & \(b-1\) & ss\(\theta_{\text{adj}}\) & \(\text{ms}\theta_{\text{adj}}\) & \(-\) \\ Blocks (unadj) & \(b-1\) & ss\(\theta\) & \(-\) & \(-\) \\ Treatments (adj) & \(v-1\) & ss\(\text{T}_{\text{adj}}\) & \(\text{ms}\text{T}_{\text{adj}}\) & \(\frac{\text{ms}T_{\text{adj}}}{\text{msE}}\) \\ Error & \(bk-b-v+1\) & ssE & msE & \\ Total & \(bk-1\) & sstot & & \\ \end{tabular}
\end{table}
Table 11.7: Analysis of variance table for a binary incomplete block design with \(b\) blocks of size \(k\), and \(v\) treatment labels appearing \(r\) timesThe sum of squares for error, ssE, is

\[\text{ss}E=\text{sstot}-\text{ss}\theta-\text{ss}T_{\text{adj}}\,,\]

where sstot is defined as usual as

\[\text{sstot}=\sum_{h=1}^{b}\sum_{i=1}^{v}n_{hi}y_{hi}^{2}-G^{2}/(bk)\,.\]

Also as usual, the number of degrees of freedom for treatments is \(v-1\), the number of degrees of freedom for blocks is \(b-1\), and the number of degrees of freedom for error can be obtained by subtraction as

\[\text{df}=(n-1)-(b-1)-(v-1)=bk-b-v+1\,, \tag{11.4.8}\]

where \(n=bk\) is the total number of observations.

A test of \(H_{0}^{T}:\){all \(\tau_{i}\) are equal} against \(H_{A}^{T}:\){at least two of the \(\tau_{i}\)'s differ} is given by the decision rule

\[\text{reject }H_{0}^{T}\quad\text{if}\quad\frac{\text{ms}T_{\text{adj}}}{\text{ msE}}>F_{v-1,bk-b-v+1,\alpha}\]

for some chosen significance level \(\alpha\), where \(\text{ms}T_{\text{adj}}=\text{ss}T_{\text{adj}}/(v-1)\), and \(\text{msE}=\text{ssE}/(bk-b-v+1)\).

If evaluation of blocking for the purpose of planning future experiments is required, the quantity ss\(\theta\) in (11.4.5) _is not the correct value_ to use. It has not been adjusted for the fact that every block does not contain an observation on every treatment. In order to evaluate blocks, we would need the _adjusted block sum of squares_, ss\(\theta_{\text{adj}}\), whose formula is listed as the last entry in Table 11.7. Some computer packages will give this value under the heading "adjusted" or "Type III" sum of squares. If the program does not automatically generate the adjusted value, it can be obtained from a "sequential sum of squares" by entering treatments in the model before blocks.

#### Analysis of Balanced Incomplete Block Designs

The set of least squares solutions given in (11.4.3) for the treatment parameters \(\tau_{i}\) in the block-treatment model (11.4.2) for the balanced incomplete block design have a simple form:

\[\hat{\tau}_{i}=\frac{k}{\lambda v}Q_{i}\,,\quad\text{ for}\quad i=1,\ldots,v\,, \tag{11.4.9}\]

where \(\lambda\) is the number of times that every pair of treatments occurs together in a block, and \(Q_{i}\) is the adjusted treatment total, given in (11.4.7). Thus, the sum of squares for treatments adjusted for blocks in (11.4.6) becomes

\[ssT_{\text{adj}}=\sum_{i=1}^{v}\frac{k}{\lambda v}Q_{i}^{2}\,, \tag{11.4.10}\]

and the least squares estimator of contrast \(\sum c_{i}\tau_{i}\) is

\[\sum_{i=1}^{v}c_{i}\hat{\tau}_{i}=\frac{k}{\lambda v}\sum_{i=1}^{v}c_{i}Q_{i}\,. \tag{11.4.11}\]It can be shown that the corresponding variance can be calculated as

\[\text{Var}\left(\sum_{i=1}^{v}c_{i}\hat{\tau}_{i}\right)=\sum_{i=1}^{v}c_{i}^{2} \left(\frac{k}{\lambda v}\right)\sigma^{2}\,. \tag{11.4.12}\]

The Bonferroni, Scheffe, Tukey, and Dunnett methods of multiple comparisons can all be used for balanced incomplete block designs with degrees of freedom for error equal to \(df=bk-b-v+1\). The general formula (11.4.4) for simultaneous \(100(1-\alpha)\)% confidence intervals for a set of contrasts \(\Sigma c_{i}\tau_{i}\) becomes

\[\sum_{i=1}^{v}c_{i}\,\tau_{i}\in\left(\frac{k}{\lambda v}\sum_{i=1}^{v}c_{i}\,Q _{i}\,\pm\,w\,\sqrt{\sum_{i=1}^{v}c_{i}^{2}\,\left(\frac{k}{\lambda v}\right) \,\text{ms}E}\,\right)\,, \tag{11.4.13}\]

where the critical coefficients for the four methods are, respectively,

\[w_{B}=t_{bk-b-v+1,\alpha/2m}\,\,\,\,;\,\,\,\,w_{S}=\sqrt{(v-1)F_ {v-1,bk-b-v+1,\alpha}}\,\,\,;\] \[w_{T}=q_{v,bk-b-v+1,\alpha}/\sqrt{2}\,\,\,\,;\,\,\,\,w_{D2}=|t|_ {v-1,bk-b-v+1,\alpha}^{(0.5)}\,\,.\]

For testing \(m\) hypotheses of the general form \(H_{0}:\sum c_{i}\tau_{i}=0\) against the corresponding alternative hypotheses \(H_{a}:\sum c_{i}\tau_{i}\neq 0\), at overall significance level \(\alpha\), the decision rule using Bonferroni's method for preplanned contrasts is

\[\text{reject }H_{0}\text{ if }\frac{\text{ssc}_{\text{adj}}}{\text{ms}E}>F_ {1,bk-b-v+1,\alpha/m}\,, \tag{11.4.14}\]

and the decision rule using Scheffe's method is

\[\text{reject }H_{0}\text{ if }\frac{\text{ssc}_{\text{adj}}}{\text{ms}E}>(v-1) F_{1,bk-b-v+1,\alpha}\,, \tag{11.4.15}\]

where

\[\frac{\text{ssc}_{\text{adj}}}{\text{ms}E}=\frac{(\sum c_{i}\hat{\tau}_{i})^{ 2}}{\left(\frac{k}{\lambda v}\right)\,(\sum c_{i}^{2})\,\text{ms}E}=\frac{k( \sum c_{i}Q_{i})^{2}}{\lambda v(\sum c_{i}^{2})\text{ms}E}\,, \tag{11.4.16}\]

(cf. Sections 4.3.3 and 6.7.2).

As for the case of equireplicate completely randomized designs, two contrasts \(\Sigma c_{i}\tau_{i}\) and \(\Sigma d_{i}\tau_{i}\) are orthogonal in a balanced incomplete block design if \(\Sigma c_{i}d_{i}=0\). The adjusted treatment sum of squares can then be written as a sum of adjusted contrast sums of squares for a complete set of \((v-1)\) orthogonal contrasts. An example is given in the following section.

#### A Real Experiment--Detergent Experiment

An experiment to compare dishwashing detergent formulations was described by P. W. M. John in the journal _Technometrics_ in 1961. The experiment involved three base detergents and an additive. Detergent I was observed with 3, 2, 1, and 0 parts of the additive, giving four treatments, which we will code 1, 2, 3, and 4. Likewise, Detergent II was observed with 3, 2, 1, and 0 parts of the additive, giving an additional four treatments, which we will code 5, 6, 7, and 8. The standard detergent (Detergent III) with no additive served as a control treatment, which we will code as 9.

[MISSING_PAGE_FAIL:381]

Block-treatment model (11.4.2) for an incomplete block design was fitted to the data. The residual plots might lead us to question some of the error assumptions, but there are only 4 observations per treatment and these are all from different blocks, so it is difficult to make a proper assessment. We will proceed with the standard analysis for a balanced incomplete block design, recognizing that the stated significance levels and confidence levels are only approximate.

##### Plotting the Data Adjusted for Block Effects

In this detergent experiment, the treatment differences are fairly clear from the plot of the raw data in Fig. 11.2. However, if the block effects had been substantial, such a plot of the raw data could have painted a muddled picture. In such cases, the picture can be substantially improved by adjusting each observation for the block effects before plotting. The observation \(y_{hi}\) is adjusted for the block effects as follows,

\[y_{hi}^{*}=y_{hi}-(\hat{\theta}_{h}-\widehat{\overline{\theta}}_{.})\,,\]

where \((\hat{\theta}_{h}-\widehat{\overline{\theta}}_{.})\) is the least squares estimate of \((\theta_{h}-\widehat{\overline{\theta}}_{.})\). A SAS program that adjusts the observations for block effects and plots the adjusted observations is given in Sect. 11.8.3 and a corresponding R program in Sect. 11.9.3. It should be noted that since the variability due to block effects has been extracted, a plot of the adjusted observations will appear to exhibit less variability than really exists.

For this particular data set, the block differences are very small, so a plot of the adjusted data would provide information similar to that provided by the plot of the raw data in Fig. 11.2. In Fig. 11.3, the observations adjusted for blocks are plotted against "parts of additive" for each base detergent. It appears that the washing power decreases almost linearly as the amount of additive is decreased and also that the standard detergent is superior to the two test detergents.

##### Analysis

The analysis of variance table, given in Table 11.9, shows the treatment sum of squares and its decomposition into sums of squares for eight orthogonal contrasts. These contrasts are the linear, quadratic, and cubic trends for each of detergents I and II (as the amount of additive decreases), together with the "I Versus II" contrast that compares the effects of detergents I and II averaged over the levels of the additive, and the "control Versus others" contrast comparing the effect of the control detergent and the average effect of the other eight treatments. For example, the linear trend contrast for detergent I is \(-3\tau_{1}-\tau_{2}+\tau_{3}+3\tau_{4}\), where the contrast coefficients are obtained from Table A.2. The contrast comparing detergents I and II is the difference of averages contrast

Figure 11.3: Plot of adjusted observations for the detergent experiment

[MISSING_PAGE_EMPTY:8318]

contrast is

\[\sum_{i=1}^{9}c_{i}\hat{\tau}_{i}=\hat{\tau}_{9}-\frac{1}{8}\sum_{i=1}^{8}\hat{ \tau}_{i}=\frac{1}{3}\left(Q_{9}-\frac{1}{8}\sum_{i=1}^{8}Q_{i}\right)=11.375\,,\]

with associated estimated variance

\[\widehat{\rm Var}\left(\sum_{i=1}^{9}c_{i}\hat{\tau}_{i}\right)=\sum_{i=1}^{9} c_{i}^{2}\left(\frac{k}{\lambda v}\right){\rm ms}E=\left(1+\frac{8}{64}\right) \left(\frac{3}{9}\right)(0.82)=0.3075\,,\]

where \({\rm ms}E=0.82\) is obtained from Table 11.9. Using Scheffe's method of multiple comparisons at overall level 99%, a confidence interval for the control versus others contrast is then

\[11.375\pm\sqrt{8F_{8,16,0.01}}\sqrt{0.3075}=11.375\pm 3.093=(8.282,14.468),\]

showing that the control detergent washed between 8.3 and 14.5 more plates than the other detergents on average.

The sum of squares for treatments adjusted for blocks is obtained from (11.4.6), p. 358, as

\[{\rm ss}T_{\rm Adj}=\frac{k}{\lambda v}\sum Q_{i}^{2}=1086.81\,,\]

and since

\[\frac{{\rm ms}T_{\rm Adj}}{{\rm ms}E}=\frac{1086.81/8}{0.82}=164.85>F_{8,16,0.0 1}=3.89\,,\]

we reject the hypothesis of no treatment differences.

The eight orthogonal contrasts can be tested simultaneously using the method of Scheffe. For example, the confidence interval for the "control versus others" contrast calculated above as part of a 99% simultaneous set of intervals does not contain zero, so the hypothesis that the control treatment does not differ from the others would be rejected. The overall significance level for all such tests would be \(\alpha=0.01\). Equivalently, the contrasts can be tested by the Scheffe method using the decision rule (11.4.15), p. 360; that is,

\[{\rm reject}\ H_{0}:\sum_{i=1}^{v}c_{i}\tau_{i}=0\ \ {\rm if}\ \ \frac{{\rm ss}_{\rm Adj}}{{\rm ms}E}>8F_{8,df,01}\ =\ 31.12\,.\]

The ratios \({\rm ss}_{\rm Adj}/msE\) are provided in Table 11.9. Comparing their values with 31.12, we see that the linear trends are significantly different from zero for each of the base detergents I and II, as are the comparison of detergents I and II on average and the comparison of the control detergent with the average effects of the other 8 treatments. From significance of the linear trend contrasts, coupled with the direction of the trends, one can conclude that detergents I and II are better with larger amounts of additive.

We cannot use the unadjusted block sum of squares to evaluate the usefulness of blocking. We would need to calculate the adjusted block sum of squares as in Table 11.7, p. 358. Using the values in Table 11.9, this is

\[{\rm ss}\theta_{\rm adj}=1512.75-13.19-\left(\frac{1}{4}(79^{2}+67^{2}+\cdots+119^{2})-\frac{1}{36}69^{2}\right)\ =\ 10.06\,.\]So the adjusted block mean square is \(\text{ms}\theta_{\text{adj}}=10.06/11=0.91\), which is not much larger than the error mean square, \(\text{ms}E=0.82\), so the blocking did not help with increasing the power of the hypothesis tests. Nevertheless, it was natural to design this experiment as a block design, and the creation of blocks was a wise precaution against changing experimental conditions.

#### Analysis of Group Divisible Designs

Group divisible designs were described in Sect. 11.3.2, p. 354, and illustrations were shown in Tables 11.1 and 11.5. The least squares solution (obtained with added equations \(\sum_{i}\hat{\tau}_{i}=0,\sum_{h}\hat{\theta}_{h}=0\)) for the treatment parameters \(\tau_{i}\) adjusted for blocks can be shown to be

\[\hat{\tau}_{i}=\left[\frac{k}{(r(k-1)+\lambda_{1})v\lambda_{2}}\right]\times \left[(v\lambda_{2}+(\lambda_{1}-\lambda_{2}))\,Q_{i}+(\lambda_{1}-\lambda_{2 })\sum_{(1)}Q_{p}\right]\,, \tag{11.4.17}\]

where \(Q_{i}\) is the adjusted treatment total as in (11.4.7), p. 358, and where \(\sum_{(1)}Q_{p}\) denotes the sum of the \(Q_{p}\) corresponding to the treatment labels that are the first associates of treatment label \(i\).

The variance of the least squares estimator \(\Sigma c_{i}\hat{\tau}_{i}\) of an estimable contrast \(\Sigma c_{i}\tau_{i}\) is

\[\text{Var}\left(\sum_{i=1}^{v}c_{i}\hat{\tau}_{i}\right)=\sum_{i=1}^{v}c_{i}^{ 2}\,\,\text{Var}(\hat{\tau}_{i})\,+2\sum_{i=1}^{v-1}\sum_{p=i+1}^{v}c_{i}c_{p} \,\,\text{Cov}(\hat{\tau}_{i},\hat{\tau}_{p})\,,\]

where, for a group divisible design,

\[\text{Var}(\hat{\tau}_{i})=\frac{k[v\lambda_{2}+(\lambda_{1}-\lambda_{2})]}{v \lambda_{2}[v\lambda_{2}+l(\lambda_{1}-\lambda_{2})]}\sigma^{2}\]

and

\[\text{Cov}(\hat{\tau}_{i},\hat{\tau}_{p})=\left\{\begin{array}{ll}\frac{k( \lambda_{1}-\lambda_{2})\sigma^{2}}{v\lambda_{2}[v\lambda_{2}+l(\lambda_{1}- \lambda_{2})]}\,,&\text{if $i$ and $p$ are first associates,}\\ 0\,,&\text{if $i$ and $p$ are second associates.}\end{array}\right.\]

Using these quantities, the variance of the least squares estimator of the pairwise comparison \(\tau_{i}-\tau_{p}\) becomes

\[\text{Var}(\hat{\tau}_{i}-\hat{\tau}_{p})=\left\{\begin{array}{ll}\frac{2k \sigma^{2}}{[v\lambda_{2}+l(\lambda_{1}-\lambda_{2})]}\,,&\text{if $i$ and $p$ are first associates,}\\ \frac{2k[v\lambda_{2}+(\lambda_{1}-\lambda_{2})]\sigma^{2}}{v\lambda_{2}[v \lambda_{2}+l(\lambda_{1}-\lambda_{2})]}\,,&\text{if $i$ and $p$ are second associates.}\end{array}\right.\]

If \(\lambda_{1}\) and \(\lambda_{2}\) are as close in value as possible, then the variances for the pairwise comparisons will be as close as possible.

The Bonferroni and Scheffe methods of multiple comparisons can be used for group divisible designs. The Tukey method is believed to be conservative (true value of \(\alpha\) smaller than stated). The Dunnett method is not available using our tables, since the critical values can be used only for designs in which \(\text{Cov}(\hat{\tau}_{i},\hat{\tau}_{p})\) are equal for all \(i\) and \(p\). However, Dunnett intervals can be obtained from many computer packages (see, for example, Fig 11.7, p. 380, and Table 11.24, p. 387). The analysis of variance table for the group divisible design is that given in Table 11.7, p. 358, with \(\hat{\tau}_{i}\) as in (11.4.17)above. An example of an experiment designed as a group divisible design is discussed in Sect. 11.5. SAS and R programs are illustrated in Sects. 11.8 and 11.9 that can be used to analyze any group divisible design.

#### Analysis of Cyclic Designs

Cyclic designs were described in Sect. 11.3.3, p. 355, and illustrated in Tables 11.1 and 11.6. They are incomplete block designs that may or may not possess the properties of balanced incomplete block designs or group divisible designs. When they do not possess these properties, the least squares solutions \(\hat{\tau}_{l}\) have no simple form and are most easily obtained from computer software. The Bonferroni and Scheffe methods of multiple comparisons can be used for all cyclic designs.

In Sect. 11.5 we reproduce the checklist and analysis of an experiment that was designed as a cyclic group divisible design and, in Sects. 11.8 and 11.9, we illustrate SAS and R computer programs that can be used to analyze any cyclic incomplete block design.

### A Real Experiment--Plasma Experiment

The plasma experiment was run by Ernesto Barrios, Jin Feng, and Richard Kibombo in 1992 in the Engineering Research Center at the University of Wisconsin. The following checklist has been extracted from the experimenters' report. The design used was a cyclic group divisible design. Notice that the experimenters moved step (e) of the checklist forward. They had made a list of all potential sources of variation, but they needed a pilot experiment to help determine which sources they could control and which they could not.

#### Checklist

1. **Define the objectives of the experiment**. In physics, plasma is an ionized gas with essentially equal densities of positive and negative charges. It has long been known that plasma can effect desirable changes in the surface properties of materials. The purpose of this experiment is to study the effects of different plasma treatments of plastic pipet tips on the capillary action of the pipets. Capillary action concerns the movement of a liquid up the pipet--a small tube. Before a plasma treatment, the capillarity conduct of the tips is too narrow to permit water to move up. Changes in capillary action effected by plasma treatment can be measured by suspending the tip of a vertical pipet into a bed of water and measuring the height of the column of water in the tube.
2. **Run a pilot experiment**. At this stage we decided to make a test run to become familiar with the process of setting up and running the experiment, to determine the appropriate treatment factor levels, and to help identify the major sources of variation that could be controlled, and to identify other variables that might affect the response but which could not be controlled.
3. **Identify all sources of variation.** From the test run, we determined that pressure and voltage could not both be effectively controlled. More generally, it would be difficult to vary all of the variables initially listed (gas flow rate, type of gas, pressure, voltage, presence or absence of a ground shield, and exposure time of the pipet tips to the ionized gas).

The following factors were potential sources of variation.

* Experimenters. Despite the fact that all of the experimenters were to play certain roles during each run of the experiment, it was noted that most of the variation due to the personnel could be attributed to the person who connects the pipet tips to the gas tube in the ionization chamber and takes the readings of the final response using vernier calipers.
* Room conditions. It was thought that variations in both room temperature and atmospheric pressure could have an effect on response.
* Water purity. If the water used to measure the capillarity has a substantial amount of impurities, especially mineral salts, then the response may be greatly affected, either because of variability in cohesion and adhesion forces of different types of substances, or because of a reaction between the impurities (salts) and the pipet tips.
* Materials. Variability in the quality of both the pipet tips and the gases used is likely to introduce some variation in the response. Within an enclosed room such as a laboratory, the composition of air may vary significantly over time.

Taking into account the results of the pilot run, the following decisions were made.

1. Treatment factors and their levels. Scale down the variables of interest to three by keeping both the pressure and voltage constant at 100 mm Torres and 5 volts, respectively, and by keeping the ground shield on. Distilled water will be used to control for impurities in the water. Pipet tips from a single package will be used, so the pipets are more likely to be from the same batch and hence more likely to be homogeneous. The only factors that will make up the various treatment combinations are gas flow rate, type of gas, and exposure time. No attempt will be made to control for variation in the composition or purity of the gases used. (This variation will be subsumed into the error variability). Set the lower and upper levels of each factor far apart in order to make any (linear) effect more noticeable. Also, we decided to include only 6 of the 8 possible treatment combinations, as shown in Table 11.10.
2. Experimental units. The experimental units are the (combinations of) pipets and time order of observations.
3. Blocking factors, noise factors, and covariates. The two blocking factors are "experimenter" and "day." (No covariates or noise factors were included.)
4. **Specify a rule by which to assign the experimental units to the treatments**. The design will be an incomplete block design with blocks of size three, and three blocks of data will be collected on each of two days. We will use the cyclic design for \(v=6=b\) and \(k=3=r\) generated by the treatment labels 1, 4, 5. The labels in the design will be randomly assigned to the six treatment combinations, and the treatments within each block will be randomly ordered. (The selected cyclic design is shown in Table 11 in nonrandomized order so that the cyclic nature of the design can be seen more easily. The design also happens to be a group divisible design (see Exercise 14). The smallest balanced incomplete block design with \(v=6\) and \(k=3\) has \(r=5\) and \(b=10\) and would require more observations.)
5. **Specify the measurements to be made, the experimental procedure, and the anticipated difficulties**. The height of the water column will be measured for each pipet. In order to make the measurements as uniform as possible, a device has been constructed consisting of a rectangular sheet of plexiglass with a small hole in which to place the pipet tip. Placing this pipet holder on a water vessel suspendsabout 2 mm of the tip of the pipet into the water. After 60 seconds, a mark will be made on the pipet indicating the water level reached. The distance of the mark from the tip of the pipet will be measured using a vernier caliper with tenth of a millimeter precision. The experimental procedure for each observation is as follows: Place a pipet on the tube through which the plasma will flow, screw in a glass tube, turn on the pump and wait 40 seconds, open the Baratron, open the gas, turn a controller to auto, set the flow to a specified level, turn the pressure controller to auto and set the level, set the voltage, time the treatment, turn off flow and shut off the gas, set the pressure to open, wait until the pressure is less than 20, turn off the Baratron, turn off the pump, unscrew the glass tube, then (wearing a glove) take out the pipet, place the pipet in water (using the device for this purpose), and mark the height of the water column, then go on to the next observation. Anticipated difficulties: Differences in the way people would mark or measure the water column heights would cause variation. Running the experiment consistently.
* **Specify the model**. (The standard block-treatment model (11.4.2), p. 356, for an incomplete block design was specified.)
* **Outline the analysis**. An analysis of variance test for equality of the treatment effects will be performed. Then confidence intervals for all pairwise comparisons will be obtained, with a simultaneous 95% confidence level using the method of Scheffe. Model assumptions will be evaluated.
* **Calculate the number of observations to be taken**. (The number of observations was limited by the time available.)
* **Review the above decisions. Revise if necessary**. (No revisions were made at this stage.)

\begin{table}
\begin{tabular}{c c c c c} \hline \multicolumn{1}{c}{\multirow{2}{*}{Treatment}} & \multicolumn{4}{c}{Factors and levels} \\ \cline{2-5}  & Type of gas & exposure time (sec) & Gas flow rate (cc/sec) \\ \hline
1 & Argon & 180 & 10 \\
2 & Air & 180 & 10 \\
3 & Argon & 180 & 30 \\
4 & Argon & 60 & 30 \\
5 & Air & 60 & 30 \\
6 & Air & 60 & 10 \\ \hline \end{tabular}
\end{table}
Table 10: The six treatment combinations used in the plasma experiment

\begin{table}
\begin{tabular}{c c c c c c} \hline Block & Day & Experimenter & \multicolumn{3}{c}{Response (Treatment)} \\ \hline
1 & 1 & Feng & 0.482 (1) & 0.459 (4) & 0.458 (5) \\
2 & 1 & Barrios & 0.464 (2) & 0.465 (5) & 0.467 (6) \\
3 & 1 & Kibombo & 0.473 (3) & 0.472 (6) & 0.495 (1) \\
4 & 2 & Feng & 0.283 (4) & 0.325 (1) & 0.296 (2) \\
5 & 2 & Barrios & 0.410 (5) & 0.390 (2) & 0.248 (3) \\
6 & 2 & Kibombo & 0.384 (6) & 0.239 (3) & 0.350 (4) \\ \hline \end{tabular}
\end{table}
Table 11: Design and data for the plasma experiment 

## Results of the Experiment

During the experiment, an unexpected event occurred. A little tube through which the gas passes was broken, allowing for some leaking of gas. We realized this after our first day's runs and tried to fix this problem the next day, using tape, as a new tube was unavailable. As can be seen from the results, given in Table 11.11, the responses from the last nine runs, corresponding to the second day, were consistently smaller than those from the first nine runs. This underscores the advantage of using time as a blocking factor.

## Data Analysis

The analysis of variance is given in Table 11.12. It was obtained via a SAS computer program similar to the one in Table 11.18 in Sect. 11.8. The adjusted block mean square, \(\text{m}\text{s}\theta_{\text{adj}}=0.0161\), is twelve times larger than the error mean square, so blocking was certainly worthwhile.

The ratio \(\text{m}\text{s}T_{\text{adj}}/\text{m}\text{s}\text{s}\text{s}\text{s}\text{s} =2.99\) does not exceed the critical value \(F_{5,7,.05}=3.97\) for testing equality of the treatment effects at the 5% significance level (equivalently, the \(p\)-value is greater than 0.05). Based on this result, examination of any individual treatment contrasts may seem unwarranted. However, the broken tube discovered after the first day of runs is an important consideration in this experiment. It is quite possible that the treatments are not the same on day one as on day two, since the broken tube may change the gas flow rate or the type of gas to which the pipet is exposed. So, one must ask the question, "Is there anything to be salvaged from this experiment?"

If the broken tube has in fact changed the treatment effects, and if the breakage occurred after the first day's runs, then it might be most useful to analyze the data for day one or each day separately. The design for each day is no longer a cyclic design or a group divisible design, but it is a connected incomplete block designs and can still be analyzed by computer (see Sects. 11.8 and 11.9).

If a test of the null hypothesis \(H_{0}^{T}\) of equal treatment effects is conducted separately for each day's data, it can be verified that \(H_{0}^{T}\) would not be rejected at the 5% significance level for the data collected on day two but would be rejected for the data of day one.

The analysis of variance for day one is shown in Table 11.13. The test ratio is 853.40--which is larger than \(F_{5,1,.05}=230\). The mean square for blocks adjusted for treatments is 0.0000607, which

\begin{table}
\begin{tabular}{c c c c c c} \hline Source & Degrees of freedom & Sum of squares & Mean square & Ratio & \(p\)-value \\ \hline Blocks (adj) & 5 & 0.0805 & 0.0161 & – & – \\ \hline Blocks & 5 & 0.0992 & – & – & – \\ Treatments (adj) & 5 & 0.0196 & 0.0039 & 2.99 & 0.0932 \\ Error & 7 & 0.0092 & 0.0013 & & \\ Total & 17 & 0.1279 & & & \\ \hline \end{tabular}
\end{table}
Table 11.12: Analysis of variance table for the plasma experiment

\begin{table}
\begin{tabular}{c c c c c c} \hline Source & Degrees of freedom & Sum of squares & Mean square & Ratio & \(p\)-value \\ \hline Blocks (adj) & 2 & 0.0001213 & 0.0000607 & 364.00 & – \\ \hline Block & 2 & 0.0004029 & – & – & – \\ Treatments (adj) & 5 & 0.0007112 & 0.0001422 & 853.40 & 0.026 \\ Error & 1 & 0.0000002 & 0.0000002 & & \\ Total & 8 & 0.0011142 & & & \\ \hline \end{tabular}
\end{table}
Table 11.13: Analysis of variance for the plasma experiment—day one onlyis 364 times larger than msE, so blocking was helpful for the observations collected on day one. With only one degree of freedom for error, use of residuals to check model assumptions is of little value. Figure 1.4 shows the day-one observations adjusted for block effects, \(y_{hi}-(\hat{\theta}_{h}-\hat{\vec{\theta}}.)\) plotted against treatment. It appears that treatment 1 (Argon at 10 cc per second for 180 seconds) is very different from the other treatments.

Table 1.14 contains information for applying Scheffe's method of multiple comparisons to the day-one data, using a simultaneous 95% confidence level. The least squares estimates were obtained using SAS software (Sect. 11.8, p. 380, and Fig. 1.8). It can be seen that \(\hat{\tau}_{l}-\hat{\tau}_{p}\) is larger than the minimum significant difference for all pairwise comparisons with \(i=1\), but for none of the others. Consequently, the only confidence intervals that do not contain zero are those involving treatment 1. We conclude that based on the first day's data, treatment 1 is significantly better than each of the other 5 treatments and should be investigated further.

\begin{table}
\begin{tabular}{c c c c c} \hline \hline \(i\), \(p\) & \(\hat{\tau}_{l}-\hat{\tau}_{p}\) & \(\sqrt{\hat{\mathrm{Var}}}(\hat{\tau}_{l}-\hat{\tau}_{p})\) & msd & Significant \\ \hline
1, 2 & 0.025500 & 0.000646 & 0.0219 & yes \\
1, 3 & 0.021833 & 0.000553 & 0.0188 & yes \\
1, 4 & 0.023167 & 0.000553 & 0.0188 & yes \\
1, 5 & 0.024333 & 0.000471 & 0.0160 & yes \\
1, 6 & 0.022667 & 0.000471 & 0.0160 & yes \\
2, 3 & \(-\)0.003667 & 0.000745 & 0.0253 & \\
2, 4 & \(-\)0.002333 & 0.000745 & 0.0253 & \\
2, 5 & \(-\)0.001167 & 0.000553 & 0.0188 & \\
2, 6 & \(-\)0.002833 & 0.000553 & 0.0188 & \\
3, 4 & 0.001333 & 0.000745 & 0.0253 & \\
3, 5 & 0.002500 & 0.000646 & 0.0219 & \\
3, 6 & 0.000833 & 0.000553 & 0.0188 & \\
4, 5 & 0.001167 & 0.000553 & 0.0188 & \\
4, 6 & \(-\)0.000500 & 0.000646 & 0.0219 & \\
5, 6 & \(-\)0.001667 & 0.000471 & 0.0160 & \\ \hline \end{tabular}
\end{table}
Table 1.14: Pairwise comparisons for the plasma experiment using the Scheffe method and confidence level 95%—day one only

Figure 1.4: Plasma data adjusted for block effects—day one only

### Sample Sizes

Given the number of treatments \(v\) and the block size \(k\), how many blocks \(b\) are required to achieve confidence intervals of a specified length or a hypothesis test of specified power? Since for most purposes the balanced incomplete block design is the best incomplete block design when it is available, we start by calculating \(b\) and the treatment replication \(r=bk/v\) for this design. Then if a balanced incomplete block design cannot be found with \(b\) and \(r\) close to the calculated values, a group divisible, cyclic, or other incomplete block design can be considered. Since balanced incomplete block designs are the most efficient, other incomplete block designs would generally require \(b\) and \(r\) to be a little larger.

#### Sample size to achieve confidence interval length

Suppose Tukey's method for all pairwise comparisons will be used to analyze an experiment with \(v=5\) treatments and block size \(k=3\). It is thought unlikely that msE will be larger than 2.0 units2. Suppose that the experimenters want the length of simultaneous 95% confidence intervals for pairwise comparisons to be at most 3.0 units (that is, a minimum significant difference of at most 1.5). A balanced incomplete block design will ensure that the interval lengths will all be the same.

Using the fact that \(bk=vr\) for a block design, the error degrees of freedom (11.4.8) can be written as

\[\text{df}=bk-b-v+1=vr-vr/k-v+1\ =\ (v(k-1)r/k)-(v-1)\, \tag{11.6.18}\]

so, here, \(\text{df}=(10r/3)-4\). For a balanced incomplete block design, the minimum significant difference for a confidence interval for any pairwise treatment comparison, using Tukey's method with an overall 95% confidence level, is given in (11.4.13), p. 360 and, if we set \(\lambda=r(k-1)/(v-1)\) from (11.3.1), p. 353, this becomes

\[\text{msd}=(q_{v,\text{df},\,05}/\sqrt{2})\sqrt{2\left[\frac{k(v-1)}{rv(k-1)} \right]\,\text{msE}}\ =q_{5,\text{df},\,05}\sqrt{\frac{12}{5r}}\,\]

with \(\text{df}=(10r/3)-4\). For the msd to be at most 1.5 units, it is necessary that

\[12q^{2}/5r\geq 1.5^{2};\ \ \text{that is,}\ r\geq 1.0667q_{5,\text{df},\,05}^{2}\.\]

Trial and error shows that around 17-18 observations per treatment would be needed to satisfy the inequality; that is, 85-90 observations in total, which would require 28-30 blocks of size 3. A balanced incomplete block design exists with \(v=5\), \(k=3\), \(b=10\), \(r=6\) (all possible combinations of five treatments taken three at a time as blocks). Repeating this entire design three times would give a balanced incomplete block design with \(r=18\), which will give a minimum significant difference of about

\[q_{5,\,56,\,05}\sqrt{12/(5\times 18)}\ \approx\ 1.46\ <\ 1.5\.\]

#### Sample size to achieve specified power

Suppose a test of the null hypothesis \(H_{0}:\{\tau_{i}\text{ all equal}\}\) is required to detect a difference in the treatment effects of \(\Delta=2\) units with probability 0.95, using significance level \(\alpha=0.05\) for a balanced incomplete block design with \(v=5\) treatments and block size \(k=3\).

The least squares estimator \(\hat{\tau}_{l}-\hat{\tau}_{p}\) of a pairwise comparison contrast \(\tau_{l}-\tau_{p}\) for a balanced incomplete block design has variance given by (11.4.12), p. 360, with \(\Sigma c_{i}^{2}=2\). Also, from (11.3.1), p. 353, \(\lambda=r(k-1)/(v-1)\) so

\[\text{Var}(\Sigma c_{i}\hat{\tau}_{l})=2\frac{k}{\lambda v}\sigma^{2}=2\left[ \frac{k(v-1)}{rv(k-1)}\right]\sigma^{2}\,. \tag{11.6.19}\]

The number \(r\) of observations needed per treatment is calculated via a formula similar to (6.6.48), p. 171, with \(a=v\) and with \(2\sigma^{2}/b\) replaced by the variance (11.6.19); that is,

\[r=\frac{2v\sigma^{2}\phi^{2}}{\Delta^{2}}\left[\frac{k(v-1)}{v(k-1)}\right]= \frac{2\times 5\times\sigma^{2}\phi^{2}}{2^{2}}\left[\frac{3\times 4}{5\times 2} \right]\,.\]

Suppose that \(\sigma^{2}\) is believed to be at most 1.0 unit\({}^{2}\); then \(r=3\phi^{2}\). The power tables in Appendix A.7 can be used to find \(\phi^{2}\). The numerator degrees of freedom are \(\nu_{1}=v-1\) and the denominator degrees of freedom \(\nu_{2}\) are the error degrees of freedom (11.6.18). So for our example, \(\nu_{1}=4\) and \(\nu_{2}=(10r/3)-4\). Trial and error shows that about \(r=9\) observations per treatment are needed to satisfy the equality, requiring about \(b=15\) (\(=vr/k\)) blocks. A balanced incomplete block design exists with \(v=5\), \(k=3\), \(b=10\), \(r=6\) (all possible selections of three treatments taken as blocks). Repeating the entire design twice would give a balanced incomplete block design with \(r=12\), which would give more precision than required. Alternatively, one could use a computer program to seek a different type of incomplete block design with \(r=9\) and \(b=15\) (see Sects. 11.8.1 and 11.9.1, for example). 

To meet the requirements of each of Examples 11.6.1 and 11.6.2, the resulting designs needed to be large. However, in cases when \(\sigma^{2}\) is expected to be small and the block size can be large, the required number of blocks may be smaller than a balanced incomplete design or group divisible design can accommodate. Software such as that illustrated in Sects. 11.8.1 and 11.9.1 can be used to find other incomplete block designs that satisfy the requirements of the experiment.

### Factorial Experiments

#### Factorial Structure

Any incomplete block design can be used for a factorial experiment by taking the treatment labels to represent treatment combinations. The incomplete block designs that are the most suitable for factorial experiments allow the adjusted treatment sum of squares \(\text{ss}T_{\text{adj}}\) to be written as a sum of the adjusted sums of squares for main effects and interactions. Thus, for an experiment with two factors \(C\) and \(D\), for example, we would like to have

\[\text{ss}T_{\text{adj}}=\text{ss}C_{\text{adj}}+\text{ss}D_{\text{adj}}+\text{ ss}C\text{D}_{\text{adj}}\,.\]

Such block designs are said to have _factorial structure_.

One benefit of this property is that the computations for, and interpretation of, the analysis of variance are simplified. A design with factorial structure requires that main-effect and interaction contrast estimates be adjusted only for block effects. In designs without factorial structure, the contrast estimates have to be adjusted not only for blocks but also for contrasts in all the other main effects and interactions. Although computer software can handle this adjustment, uncorrelated estimates are much easier to interpret and are, therefore, preferred.

All balanced incomplete block designs have factorial structure, and the features are illustrated in the following example.

##### _Example 11.7.1_ Step experiment

An experiment was run by S. Guerlain, B. Busam, D. Huland, P. Taige, and M. Pavol in 1993 to investigate the effects on heart rate due to the use of a step machine. The experimenters were interested in checking the theoretical model that says that heart rate should be a function of body mass, step height, and step frequency. The experiment involved the two treatment factors "step height" (factor \(C\)) and "step frequency" (factor \(D\)). Levels of "step height" were 5.75 and 11.5 inches, coded 1 and 2. "Step frequency" had three equally spaced levels, 14, 21, and 28 steps per minute, coded 1, 2, 3. The response variable was pulse rate in beats per minute.

The experiment used \(b=6\) subjects as blocks, and each subject was measured under \(k=5\) of the \(v=6\) combinations of step height and step frequency. The design was a balanced incomplete block design with blocks corresponding to different combinations of subject, run timer, and pulse measurer. All pairs of treatment combinations appeared together in \(\lambda=4\) blocks. The data are shown in Table 11.15.

Writing the treatment combinations as two-digit codes, the block-treatment model (11.4.2), p. 356, becomes

\[Y_{hij}=\mu+\theta_{h}+\tau_{lj}+\epsilon_{hij}\,\]

and a set of least squares solutions for the treatment parameters adjusted for subject are given by (11.4.7) and (11.4.9), p. 358 and 359, with two-digit codes; that is,

\[\hat{\tau}_{ij}=\frac{k}{\lambda v}\,Q_{ij}=\frac{k}{\lambda v}\left[T_{ij}- \frac{1}{k}\sum_{h=1}^{b}n_{hij}\,B_{h}\right]\,\]

where \(T_{ij}\) is the total of the \(r=5\) observations on step height \(i\), step frequency \(j\), \(B_{h}\) is the total of the \(k=5\) observations on the \(h\)th subject; and \(n_{hij}\) is 1 if treatment combination \(ij\) is observed for subject \(h\) and is zero otherwise. We obtain

\[\begin{array}{ccccc}\hat{\tau}_{11}&\hat{\tau}_{12}&\hat{\tau}_{13}&\hat{ \tau}_{21}&\hat{\tau}_{22}&\hat{\tau}_{23}\\ -8.125&-7.625&-4.125&-11.375&12.375&18.875\end{array}\]

\begin{table}
\begin{tabular}{c c c c c c c} \hline Block & \multicolumn{6}{c}{Treatment combination} \\ \cline{2-7}  & 11 & 12 & 13 & 21 & 22 & 23 \\ \hline
1 & & 75 & 87 & 84 & 93 & 99 \\
2 & 93 & 84 & 96 & 90 & 108 & \\
3 & 99 & 93 & 96 & & 123 & 129 \\
4 & 99 & 108 & 99 & 99 & & 120 \\
5 & 99 & & 111 & 90 & 129 & 141 \\
6 & 129 & 135 & & 120 & 147 & 153 \\ \hline \end{tabular}
\end{table}
Table 11.15: Design and data for the step experiment For a balanced incomplete block design, the adjusted sums of squares for the main effects of \(C\) (step height) and \(D\) (step frequency) and their interaction can be obtained by hand by using the values of \(\hat{\tau}_{ij}\) in place of \(y_{ij,}\), and \(k/(\lambda v)\) in place of \(r\) in the formulae (6.4.20), (6.4.22), and (6.4.25), p. 157-159, or, equivalently, in Rule 4, p. 209, which leads to

\[\begin{array}{l}{\text{ss}C_{\text{adj}}=\frac{\lambda v}{k}\left[\frac{1}{d}\sum_{i=1}^{d}\hat{\tau}_{i.}^{2}-\frac{1}{cd}\hat{\tau}_{.}^{2}\right]\ =\ \left(\frac{\lambda v}{k}\right)\frac{1}{d}\sum_{i=1}^{d}\hat{\tau}_{i.}^{2}}\end{array}\]

\[\begin{array}{l}{\text{[3}\,pt]=\left(\frac{24}{5}\right)\frac{1}{3}(-19.875^{2}+19.875^{2})\ =\ 1264.05.}\end{array}\]

The adjusted treatment sums of squares, \(\text{ss}T_{\text{adj}}\), is calculated from (11.4.10), p. 359, and using (11.4.9) becomes

\[\begin{array}{l}{\text{ss}T_{\text{adj}}=\sum_{i=1}^{v}\left(\frac{k}{ \lambda v}\right)Q_{i}^{2}\ =\ \sum_{i=1}^{v}\left(\frac{\lambda v}{k}\right)\hat{\tau}_{i}^{2}\ =\ \left(\frac{4\times 6}{5}\right)\times 779.9688\ =\ 3743.85\,.}\end{array}\]

The adjusted sums of squares for the main effects of \(C\) and \(D\) and their interaction are shown in analysis of variance Table 11.16. It can be verified that

\[\begin{array}{l}{\text{ss}C_{\text{adj}}+\text{ss}D_{\text{adj}}+\text{ss} CD_{\text{adj}}=\text{ss}T_{\text{adj}}}\,.\end{array}\]

Using the \(p\)-values in the analysis of variance Table 11.16, the experimenters rejected the hypothesis of negligible interaction. A plot of the data (not shown) suggests that heart rate increases linearly as the step frequency is increased, but that the linear trend is not the same for the two step heights. The experimenters wanted to examine the average behavior of the two factors, so despite this interaction, they decided to examine the main effects. In Exercise 10, the reader is asked to examine the linear trends at each step height separately.

For simplicity of notation, we now drop the subscript "adj." However, all estimates and sums of squares are adjusted for block effects. The experimenters were interested in examining the linear and quadratic trend contrasts for step frequency, that is,

\[\begin{array}{l}{D_{\text{L}}=-\overline{\tau}_{.1}+\overline{\tau}_{.3}\ =\ -\frac{1}{2}(\tau_{11}+\tau_{21})+\frac{1}{2}(\tau_{13}+\tau_{23})\,,}\\ {D_{\text{Q}}=-\overline{\tau}_{.1}+2\overline{\tau}_{.2}-\overline{\tau}_{.3}\ =\ -\frac{1}{2}(\tau_{11}+\tau_{21})+\frac{2}{2}(\tau_{12}+\tau_{22})-\frac{1}{2}(\tau_{13}+\tau_{23})\,.}\end{array}\]

\begin{table}
\begin{tabular}{c c c c c c} \hline Source of variation & Degrees of freedom & Sum of squares & Mean square & Ratio & \(p\)-value \\ \hline Subject (Block) (adj) & 5 & 6685.05 & 1337.01 & \(-\) & \(-\) \\ \hline Subject (Block) (unadj) & 5 & 7400.40 & \(-\) & \(-\) & \(-\) \\ Height (\(C\)) (adj) & 1 & 1264.05 & 1264.05 & 28.63 & 0.0001 \\ Frequency (\(D\)) (adj) & 2 & 1488.90 & 744.45 & 16.86 & 0.0001 \\ Ht\(\times\)Freq (\(CD\)) (adj) & 2 & 990.90 & 495.45 & 11.22 & 0.0006 \\ Error & 19 & 838.95 & 44.16 & & \\ Total & 29 & 11983.20 & & & \\ \hline \end{tabular}
\end{table}
Table 11.16: Analysis of variance for the step experiment For the balanced incomplete block design, the least squares estimate for a contrast \(\sum c_{ij}\tau_{ij}\) and its associated variance are given by (11.4.11) and (11.4.12), p. 359-360; that is,

\[\frac{k}{\lambda v}\sum_{i}\sum_{j}c_{ij}\,Q_{ij}\quad\text{and}\quad\sum_{i} \sum_{j}c_{ij}^{2}\left(\frac{k}{\lambda v}\right)\sigma^{2}\,,\]

respectively. Using these formulae, we find that the least squares estimates of the linear and quadratic trend contrasts for step frequency (adjusted for subjects) are

\[\hat{D}_{\text{L}}=17.125\quad\text{and}\quad\hat{D}_{\text{Q}}=-7.125\,.\]

The linear trend is positive, suggesting that the average pulse rate increases as the step frequency increases, and the quadratic trend is negative, suggesting that the increase in pulse rate is greater from 14 to 21 steps per minute than it is from 21 to 28 steps per minute. The null hypotheses \(H_{0}^{L}:\{D_{\text{L}}=0\}\) and \(H_{0}^{Q}:\{D_{\text{Q}}=0\}\) should be tested to check whether the perceived trends are significantly different from zero. The variances of the contrast estimators are

\[\left(\frac{4}{4}\right)\left(\frac{5}{24}\right)\sigma^{2}\ =\ 0.2083\sigma^{2}\quad\text{and}\quad\left(\frac{12}{4}\right)\left(\frac{5}{24}\right)\sigma^{2}\ =\ 0.625\sigma^{2}\,,\]

respectively.

The contrast sum of squares for testing the null hypothesis \(H_{0}^{L}:\{D_{\text{L}}=0\}\) is obtained from (11.4.16), p. 360, as

\[ss(D_{\text{L}})\ =\ \frac{(\hat{D}_{\text{L}})^{2}}{\sum\sum c_{ij}^{2}\left(\frac{k}{\lambda v}\right)}\ =\ \frac{17.125^{2}}{0.2083}\ =\ 1407.675\,,\]

and the contrast sum of squares for testing \(H_{0}^{Q}:\{D_{\text{Q}}=0\}\) is

\[ss(D_{\text{Q}})\ =\ \frac{(\hat{D}_{\text{Q}})^{2}}{\sum\sum c_{ij}^{2}\left(\frac{k}{\lambda v}\right)}\ =\ \frac{(-7.125)^{2}}{0.625}\ =\ 81.225.\]

The linear and quadratic contrasts are orthogonal in a balanced incomplete block design even after adjusting for blocks, and we can now verify that indeed, \(ssD=ss(D_{\text{L}})+ss(D_{\text{Q}})\),

To test the null hypotheses \(H_{0}^{L}\) and \(H_{0}^{Q}\) against their respective alternative hypotheses that the null hypothesis is false, we compare each of \(ss(D_{\text{L}})/msE=31.88\) and \(ss(D_{\text{Q}})/msE=1.84\) with \(2F_{2,19,.01}=7.04\) for Scheffe's method and an overall level of \(\alpha=0.01\). We conclude that the quadratic trend is negligible, but there is a nonnegligible linear trend in the heart rate as the stepping frequency increases (averaged over step height).

* Using proc optex to search for an efficient block design with v = 7, b = 7, k = 3; DATA CANDIDATE; DO TREATMNT = 1 to 7; OUTPUT; END; PROC OPTEX DATA = CANDIDATE SEED = 72145; CLASS TREATMNT; MODEL TREATMNT;
* For 7 blocks of size 3; BLOCKS STRUCTURE = (7)3; EXAMINE DESIGN;

### 11.8 Using SAS Software

#### Generation of Efficient Block Designs

PROC OPTEX within the SAS software allows one to search for efficient incomplete block designs. Although one cannot specify the type of design to be generated, the software will search for the design that gives the smallest confidence region for all contrasts using the Scheffe method of multiple comparisons. If a balanced incomplete block design exists, it will usually be found by PROC OPTEX.

The first set of lines in the SAS program in Table 11.17 specify that there are 7 treatments and these are stored in a dataset called CANDIDATE. Then, in the second set of lines, PROC OPTEX is run for a block structure " (b) k". In Table 11.17, there are \(b=7\) blocks of size \(k=3\). Since the program is not guaranteed to find the optimal design, it makes 10 independent searches (-this number can be changed by the user). The use of a particular "SEED =" always starts the search at the same point, so that the same set of designs is obtained. This should be removed when starting a new experiment so that random starts of the search are made. The designs found using the seed given in Table 11.17 are listed in the first part of the output in Fig. 11.5. Among the designs found, the one which gives the smallest confidence region for all contrasts is the one with the largest value under the heading "Treatment D-efficiency". This will often coincide with the design with the largest "Treatment A-efficiency" which has the shortest average length of confidence intervals for pairwise comparisons. To search specifically for the best design under A-efficiency, we insert the statement GENERATE CRITERION = A; after the BLOCKS STRUCTURE statement, and the designs will then be rank ordered by the A-efficiency.

The designs found in the 10 searches may or may not be exactly the same, but those listed in Fig. 11.5 are equally good as measured by their efficiencies. The command EXAMINE DESIGN prints out the best design (the one at the top of the list). It can be seen in Fig. 11.5 that, for this design, Block I (listed as the first three "points") consists of treatments 1, 2, 4, while Block II consists of 2, 3, 7, and so on. It can be checked that this is a balanced incomplete block design, although not the same one as that in Table 11.2, p. 351. To examine a design which is not listed as the best, say the third design in the list, replace EXAMINE DESIGN; by EXAMINE NUMBER = 3 DESIGN;.

The quoted value of "A-efficiency" is the ratio of the average variance of the pairwise comparisons in the design being examined relative to the average variance in a randomized block design with the same

\begin{table}
\begin{tabular}{c c} * Using proc optex to search for an efficient block design with v = 7, b = 7, k = 3; DATA CANDIDATE; DO TREATMNT = 1 to 7; OUTPUT; END; PROC OPTEX DATA = CANDIDATE SEED = 72145; CLASS TREATMNT; MODEL TREATMNT; * For 7 blocks of size 3; BLOCKS STRUCTURE = (7)3; EXAMINE DESIGN; \\ \end{tabular}
\end{table}
Table 11.17: SAS program for generation of an efficient incomplete block design value of \(r\) and multiplied by 100%. Since, in this example, the design found is a balanced incomplete block design, the average variance is given by (11.4.12), p. 360, and the ratio is

\[\frac{2\sigma^{2}/r}{2k\sigma^{2}/\lambda v}100\%=\frac{\lambda v}{rk}100\%= \frac{v(k-1)}{k(v-1)}100\%=77.777\%\.\]

The quoted "average D-efficiency" is related to the volume of the confidence region for all contrasts in the design being examined as compared with that for a randomized block design with the same value of \(r\).

Figure 11.5: SAS output from PROC OPTEX from PROC OPTEX

For the requirements of Example 11.6.2, if PROC OPTEX is run with this same seed for \(v=5\) treatments and \(b=15\) blocks of size \(k=3\), the best design found has pairs of treatments appearing together in either \(\lambda_{1}=4\) or \(\lambda_{2}=5\) blocks. It consists of the 10-block balanced incomplete block design together with an additional 5 blocks comprising a cyclic incomplete block design. (A different seed, or no specified seed, may result in the additional 5 blocks being a non-cyclic incomplete block design but the best design listed will most likely still have \(\lambda_{2}=\lambda_{1}+1\)).

#### Analysis of Variance, Contrasts, and Multiple Comparisons

In this section, sample programs are given to illustrate the analysis of incomplete block designs using the SAS software. The programs shown are for the detergent experiment of Sect. 11.4.4 and the plasma experiment of Sect. 11.5, but similar programs can be used to analyze the data collected in any incomplete block design.

Table 11.18 contains the first sample program. The data are entered into a data set called ONE, using the variables BLOCK, TRTMT, and Y for the block, treatment, and response value, respectively. PROC SGPLOT is used to plot the observations against treatments, analogous to Fig. 11.2, p. 361, and the legend identifies the block labels by color (the plot is not shown here). The block labels are printed on the plot by inclusion of the command MARKERCHAR = BLOCK. In the next section of Table 11.18, PROC GLM is used to fit the block-treatment model (11.4.2), generate the analysis of

\begin{table}
\begin{tabular}{l} DATA ONE; \\  INPUT BLOCK TRTMT Y; \\  LINES; \\ 1 3 13 \\ : : \\  12 1 19 \\ ; \\ PROC SGPLOT; \\  SCATTER X = TRTMT Y = Y / GROUP = BLOCK MARKERCHAR = BLOCK; \\ PROC GLM; \\  CLASS BLOCK TRTMT; \\  MODEL Y = BLOCK TRTMT; \\  OUTPUT OUT = RESIDS PREDICTED = PREDY RESIDUALS = E; \\ * contrast sums of squares for 8 orthogonal contrasts; \\  CONTRAST ’I linear’  TRTMT -3 -1 1 3 0 0 0 0 0; \\  CONTRAST ’I quadratic’  TRTMT 1 -1 -1 1 0 0 0 0 0; \\  CONTRAST ’I cubic’  TRTMT -1 3 -3 1 0 0 0 0 0; \\  CONTRAST ’II linear’  TRTMT 0 0 0 0 -3 -1 1 3 0; \\  CONTRAST ’II quadratic’  TRTMT 0 0 0 0 1 -1 -1 1 0; \\  CONTRAST ’II cubic’  TRTMT 0 0 0 0 -1 3 -3 1 0; \\  CONTRAST ’I vs II’  TRTMT 1 1 1 1 -1 -1 -1 -1 0; \\  CONTRAST ’others vs control’ TRTMT 1 1 1 1 1 1 1 1 1 -8; \\ * estimation of treatment versus control contrasts via LSMEANS; \\  LSMEANS TRTMT / PDIFF = CONTROL(’9’) CL ADJUST = DUNNETT; \\ * estimation of treatment versus control contrast via ESTIMATE; \\  ESTIMATE ’Det 9-1’ TRTMT -1 0 0 0 0 0 0 0 1; \\ \end{tabular}
\end{table}
Table 11.18: SAS program for analysis of a balanced incomplete block design—detergent experiment variance table, and save the predicted values and residuals in the output data set RESIDS. Residuals can be standardized and plotted as in Chap. 6.

Output from PROC GLM is reproduced in Fig. 11.6. Since BLOCK has been entered before TRTMT in the model statement, the sum of squares for treatments adjusted for blocks is listed under Type I (or sequential) sums of squares as well as under the Type III sums of squares. The adjusted block sum of squares is listed under the Type III sums of squares. In order to use the sequential or Type I sums of squares to obtain the adjusted block sum of squares, one would need to rerun the program with TRTMT entered before BLOCK in the model statement. In Table 11.18, the sums of squares corresponding to \(v-1=8\) orthogonal treatment contrasts are requested via the CONTRAST statements, and it can be verified from Fig. 11.6 that the contrast sums of squares add to the treatment sum of squares.

Simultaneous confidence intervals for pairwise comparisons can be obtained via the ESTIMATE statements or via LSMEANS with options as discussed in Sect. 6.8.2, p. 180. Tukey, Scheffe and Dunnett methods can all be used for a balanced incomplete block design with code such as:

LSMEANS TRTMT / PDIFF=CONTROL('9') CL ADJUST=DUNNETT; Here, the PDIFF=CONTROL('9') option for Dunnett's method specifies that level 9 is the control, as was the case in the detergent experiment. If the designation "('9')" had been omitted, then the

Fig. 11.6: Partial output from PROC GLM for analysis of an incomplete block design—detergent experiment lowest level would have been taken to be the control treatment by default. Partial output is shown in Fig. 11.7. The first section of the table shows the output from the ESTIMATE statements. The second section of the output gives simultaneous 95% confidence intervals for the treatment-versus-control comparisons using Dunnett's method. A word of warning is in order here. If the treatments had been labeled anything other than 1, 2,..., 9, at this point SAS software would have relabeled them. For example, if the control treatment had been labeled as 0 and the test treatments as 1,..., 8, SAS software would have relabeled the control as treatment 1 and the test treatments as 2,..., 9.

Figure 11.8 shows partial output from PROC GLM in the first part of Table 11.19 for day one data from the plasma experiment (Sect. 11.5), which was a nonstandard incomplete block design. The Type I and Type III sums of squares are shown, together with partial output from the LSMEANS statement

LSMEANS TRTMT / PDIFF = ALL CL ADJUST=SCHEFFE;

Output from the above LSMEANS statement, combined with standard error estimates generated by an ESTIMATE statement for each pairwise treatment contrast like the following one for \(\tau_{1}-\tau_{2}\), were used to compile Table 11.14 (p. 370):

ESTIMATE 'T1-T2' TRTMT 1 -1 0 0 0 0;

Figure 11.7: Partial output from ESTIMATE and LSMEANS for an incomplete block design—detergent experiment with detergent 9 as the control treatment

#### Plots

Table 11.19 contains a sample SAS program illustrating how to plot the data adjusted for blocks against the treatment labels, using the day one data of the plasma experiment, (first three blocks of Table 11.11, p. 368). The program, as written, must be run in three passes. In successive passes, information generated by earlier passes must be added as input in later parts of the program. First, the data are entered into a data set called ONE. Since the block effect estimates are needed to adjust the observations, the option SOLUTION is included in the MODEL statement of PROC GLM. This causes a (nonunique) solution to the normal equations for \(\hat{\mu}\), \(\hat{\tau}_{i}\), and \(\hat{\theta}_{h}\) to be printed. The solutions will all be labeled "B" for "biased," meaning that the corresponding parameters are not individually estimable (see Fig. 10.8, p. 330, for example).

The least squares solutions \(\hat{\theta}_{h}\) are then entered (as "BHAT") into the data set TWO by the user in the second run of the program. PROC MEANS is used to compute and print the average value \(\hat{\overline{\theta}}_{i}\). Finally,

Figure 11.8: Partial output from PROC GLM and LSMEANS in a SAS program for analyzing an incomplete block design—plasma experiment, day onein the third run of the program, the block-effect estimates and their average value are used to adjust the data values. The adjusted values are then plotted against treatment. The SAS plot is not shown here, but it is similar to the plot in Fig. 11.4 (p. 370).

### Using R Software

#### Generating Efficient Incomplete Block Designs

The R function bibd from the package ibd can be used to construct balanced incomplete block designs when they exist. The first few lines of the program in Table 11.20 install and load the ibd package, then ask the program to search for a balanced incomplete block design with \(v=7\) treatments each appearing \(r=3\) times, \(b=7\) blocks of size \(k=3\), and pairs of treatments appearing together in \(\lambda=1\) block. In general, the bibd function checks that the necessary conditions for an existence of a

\begin{table}
\begin{tabular}{r r} * This program requires 3 runs, adding more information in each run; \\ DATA ONE; \\ \end{tabular} ;  INPUT BLOCK TRTMT Y;  LINES; \\  & 1 4 0.459 \\  & 1 5 0.467 \\  & : : \\  & 3 3 0.473 \\ ; \\ * Get block effect estimates; \\ PROC GLM; \\  CLASS BLOCK TRTMT; \\  MODEL Y = BLOCK TRTMT / SOLUTION; \\  LSMEANS TRTMT / PDIFF = ALL CL ADJUST=SCHEFFE; \\ PROC SORT; BY BLOCK; \\ * Add the following code for the second run; \\  * values BHAT are solutions for block parameters from first run; \\  DATA TWO; \\  INPUT BLOCK BHAT; \\  LINES; \\  & 1 -.0126666667 \\  & 2 -.00533333 \\  & 3 0.000000000 \\ ; \\ PROC MEANS MEAN; * print average of BHAT values; \\  VAR BHAT; \\ * Add the following code for the third run; \\ * The number -0.006 below is average BHAT calculated in second run; \\  DATA THREE; \\  MERGE ONE TWO; \\  BY BLOCK; \\  Y\_ADJ = Y - (BHAT - (-0.006)); \\ PROC SGPLT data = THREE; \\  SCATTER X = TRTMT Y = Y\_ADJ / GROUP = BLOCK; \\ \end{tabular}
\end{table}
Table 11.19: SAS program to plot data adjusted for block effects—plasma experiment, day one only bibd are satisfied. If so, it will either provide the design or respond with "design not found". For the design size in Table 11.20, the design does exist and is shown under the heading $design. The seven blocks of the design are given by the seven rows of three treatment labels. The quoted $Aeff is the ratio of the average variance of the pairwise comparisons in this incomplete block design relative to the average variance (11.4.12) in a balanced incomplete block design with the same values of \(v\) and \(k\). The quoted $Deff is related to the volume of the confidence region for all contrasts in the design being examined relative to a balanced incomplete block design with the same values of \(v\) and \(k\) (which may not actually exist in practice). Since the design found here is, itself, a balanced incomplete block design, A-eff and D-eff are given as 1 (approximately).

If no balanced incomplete block design exists, as for the requirements of Example 11.6.2, with \(v=5\) treatments and \(b=15\) blocks of size \(k=3\), then function ibd, whose inputs are \(v\), \(b\), and \(k\), can be used to construct an incomplete block design. For this example, the best design found is shown in Table 11.21 and has "A.Efficiency = 0.9975" and "D.Efficiency= 0.9987", where these efficiencies are calculated the same way as $Aeff and $Deff in the ibbd function. It consists of a balanced incomplete block design with 10 blocks, together with an additional 5 blocks comprising an incomplete block design with \(\lambda_{2}=\lambda_{1}+1\). The entire 15-block design has pairs of treatments appearing together in either \(\lambda_{1}=4\) or \(\lambda_{2}=5\) blocks. For a binary design, the values of \(\lambda_{i}\) are listed as the off-diagonal elements in the array called $conc.mat so, for example, the first row of this array shows that treatment 1 appears in 4 blocks with treatments 2 and 3, and in 5 blocks with treatments 4 and 5. The diagonal elements of the array are the values of \(r\).

The ibd function prints out the design with the highest D.Efficiency that it finds in 5 independent searches. If the design found has low efficiency, ibd may be able to obtain an improved design if the option ntrial=n is added into the ibd statement, where n is some integer larger than the default value of 5; for example,

\[\mathtt{ibd}(\mathtt{v}=5,\mathtt{b}=15,\mathtt{k}=3,\mathtt{ntrial}=20).\]

\begin{table}
\begin{tabular}{l r r} \multicolumn{3}{l}{ \(>\) \# install.packages(”ibd”)} \\ \multicolumn{3}{l}{ \(>\) library(ibd)} \\ \multicolumn{3}{l}{ \(>\) bibd(v = 7, r=3, b = 7, k = 3, lambda = l)} \\ \multicolumn{3}{l}{ \$design} \\ \multicolumn{3}{l}{ \([\mathtt{,}1]\) [\(\mathtt{,}2]\) [\(\mathtt{,}3]\)} \\ \([\mathtt{1,}]\) & 1 & 3 & 6 \\ \([\mathtt{2,}]\) & 1 & 4 & 5 \\ \([\mathtt{3,}]\) & 5 & 6 & 7 \\ \([\mathtt{4,}]\) & 1 & 2 & 7 \\ \([\mathtt{5,}]\) & 3 & 4 & 7 \\ \([\mathtt{6,}]\) & 2 & 4 & 6 \\ \([\mathtt{7,}]\) & 2 & 3 & 5 \\ \end{tabular}
\end{table}
Table 11.20: R code and output for ibbd with \(v=7\) treatments, \(b=7\) blocks of size \(k=3\)

#### Analysis of Variance, Contrasts, and Multiple Comparisons

In this section, sample programs are given to illustrate the analysis of incomplete block designs using the R software. The programs shown are for the detergent experiment of Sect. 11.4.4 and the plasma experiment of Sect. 11.5, but similar programs can be used to analyze the data collected in any incomplete block design.

Table 11.22, p. 385, contains the first sample program. The data are read into the data set detrgnt.data, using the variables Block, Trtmt, and y for the block, treatment, and response value, respectively. Corresponding factor variables fBlock ad fTrtmt are added to the data set. In the second block of code, the plot function is used to plot the observations against treatments, analogous to Fig. 11.2, p. 361, but using block labels as the plotting legend (the plot is not shown here).

In the third block of code, the linear models function lm is used to fit the block-treatment model (11.4.2), then corresponding anova and dropl functions generate the Type I (or sequential)

\begin{table}
\begin{tabular}{c c c} \textgreater{} library(ibd) \\ \textgreater{} ibd(v=5, b=15, k=3) \\ \end{tabular}
\end{table}
Table 11.21: R code and output for an incomplete block design with \(v=5\) treatments, \(b=15\) blocks of size \(k=3\)and Type III analysis of variance tables, respectively. Predicted values and residuals are available, and the residuals can be standardized and plotted as in Sect. 6.2.3.

The analysis of variance output from anova and drop1 is reproduced in Table 11.23, p. 386. Since fBlock has been entered before fTrtmt in the model statement, the sum of squares for treatments adjusted for blocks are obtained as both Type I and Type III sums of squares. The adjusted block sum of squares is listed under the Type III sums of squares whereas, to use the sequential or Type I sums of squares, one would need to rerun the program with fTrtmt entered before fBlock in the model statement. In the center of Table 11.22, the summary(contrast(lsmTrtmt... statement is used to list eight orthogonal treatment contrasts, producing corresponding least squares estimates, standard errors, two-sided \(t\)-tests, and individual 95% confidence intervals, as shown in the bottom part

\begin{table}
\begin{tabular}{l} detrgnt.data = read.table(‘data/detergent.txt’’, header=T) head(detrgnt.data) detrgnt.data = within(detrgnt.data, {fBlock = factor(Block); fTrtmt = factor(Trtmt) }) \\ \end{tabular}
\end{table}
Table 11.22: R program for analysis of a balanced incomplete block design—detergent experiment 

[MISSING_PAGE_FAIL:406]

[MISSING_PAGE_FAIL:407]

[MISSING_PAGE_FAIL:408]

#### Exercises

1. **Connectedness and estimability** 1. For each of the three block designs in Table 11.27, draw the connectivity graph for the design, and determine whether the design is connected. 2. If the design is connected, determine whether or not it is a balanced incomplete block design. 3. For designs II and III, determine graphically whether or not \(\tau_{1}-\tau_{5}\) and \(\tau_{1}-\tau_{6}\) are estimable. 4. For design III, use expected values to show that \(\tau_{1}-\tau_{8}\) is estimable.

\begin{table}
\begin{tabular}{c c c c c c} \hline  & Design I & & Design II & & Design III \\ \hline Block & Treatments & Block & Treatments & Block & Treatments \\ \hline
1 & 1 2 & 1 & 1 2 3 & 1 & 1 2 6 \\
2 & 1 3 & 2 & 4 5 6 & 2 & 3 4 5 \\
3 & 1 4 & 3 & 7 8 9 & 3 & 2 6 8 \\
4 & 2 3 & 4 & 1 4 7 & 4 & 4 5 7 \\
5 & 2 4 & 5 & 2 5 8 & 5 & 1 6 8 \\
6 & 3 4 & 6 & 3 6 9 & 6 & 3 5 7 \\  & & 7 & 1 5 9 & 7 & 1 2 8 \\  & & 8 & 2 6 7 & 8 & 3 4 7 \\  & & 9 & 3 4 8 & & \\ \hline \end{tabular}
\end{table}
Table 11.26: R program to plot data adjusted for block effects—plasma experiment, day one only

\begin{table}
\begin{tabular}{c c c c c} \hline  & Design I & & Design II & & Design III \\ \hline Block & Treatments & Block & Treatments & Block & Treatments \\ \hline
1 & 1 2 & 1 & 1 2 3 & 1 & 1 2 6 \\
2 & 1 3 & 2 & 4 5 6 & 2 & 3 4 5 \\
3 & 1 4 & 3 & 7 8 9 & 3 & 2 6 8 \\
4 & 2 3 & 4 & 1 4 7 & 4 & 4 5 7 \\
5 & 2 4 & 5 & 2 5 8 & 5 & 1 6 8 \\
6 & 3 4 & 6 & 3 6 9 & 6 & 3 5 7 \\  & & 7 & 1 5 9 & 7 & 1 2 8 \\  & & 8 & 2 6 7 & 8 & 3 4 7 \\  & & 9 & 3 4 8 & & \\ \hline \end{tabular}
\end{table}
Table 11.27: Three incomplete block designs2. **Connectedness** 1. Determine whether or not the cyclic design with initial block \((1,3,5)\) is a connected design if \(v=8\) or \(v=9\). 2. Determine whether or not the cyclic design with initial block \((1,4,7)\) is a connected design if \(v=8\) or \(v=9\).
3. **Randomization** Conduct a block design randomization for design II in Table 11.27.
4. **Cyclic designs** Determine whether or not the cyclic design obtained from each initial block below is a balanced incomplete block design or a group divisible design or neither. 1. Initial block: 1, 3, 4; \(v=7\). 2. Initial block: 1, 2, 4, 8; \(v=8\). 3. Initial block: 1, 2, 4; \(v=5\).
5. **Balanced incomplete block design** In the following questions, consider an experiment to compare \(v=7\) treatments in blocks of size \(k=5\). 1. Show that, for this experiment, a necessary condition for a balanced incomplete block design to exist is that \(r\) is a multiple of 5 and \(b\) is a multiple of 7. 2. Show that \(r\) must be at least 15. 3. Taking all possible combinations of five treatments from seven gives a balanced incomplete block design with \(r=15\). Calculate the number of blocks that must be in this design.
6. **Sample sizes** Consider an experiment to compare 7 treatments in blocks of size 5, with an anticipated error variance of at most 30 squared units. 1. Assuming that a balanced incomplete block design will be used, how many observations would be needed for the minimum significant difference to be about 50 units for a pairwise comparison using Tukey's method and a 95% simultaneous confidence level? 2. Repeat part (a) for a minimum significant difference of 25 units. 3. Repeat part (a) using Dunnett's method for treatment versus control comparisons.
7. **Least squares estimator, detergent experiment, continued** Consider the balanced incomplete block design in Table 11.8, p. 361, used for the detergent experiment in Sect. 11.4.4. 1. Show that the least squares estimator \(\hat{\tau}_{4}-\hat{\tau}_{6}\) is an unbiased estimator of \(\tau_{4}-\tau_{6}\) under the block-treatment model (11.4.2), p. 356 (that is, show that \(E[\hat{\tau}_{4}-\hat{\tau}_{6}]=\tau_{4}-\tau_{6}\)). 2. Calculate a confidence interval for \(\tau_{4}-\tau_{6}\) as part of a 95% set of simultaneous confidence intervals for pairwise comparisons, using Tukey's method.

8. **Rust experiment** The rust experiment investigated the effect of temperature on the percentage of surface area of a metal sheet exhibiting rust after a given length of time exposed to certain weathering conditions. Five temperatures were examined in the experiment, but only three could be examined at any one time under identical experimental conditions. A balanced incomplete block design was used, formed from two cyclic designs with initial blocks (1, 2, 3) and (1, 2, 4). The data and design are shown in Table 11.28. 1. Write down a model for this experiment and test the hypothesis of no difference in the effects of the temperature on the percentage of rust, against the alternative hypothesis that at least two temperatures differ. Use a significance level of 0.01. 2. What does "a significance level of 0.01" in part (a) mean? 3. Was blocking worthwhile in this experiment? 4. Give a formula for a 95% set of simultaneous confidence intervals for pairwise comparisons among the temperatures in this experiment. Calculate, by hand, the interval comparing temperatures 5 and 4 (that is, \(\tau_{5}-\tau_{4}\)) for illustration. Compare your answer with that obtained from your computer output. 5. Test the hypothesis that there is no linear trend in the percentage of rust as the temperature increases.
9. **Balanced incomplete block design** An experiment is to be run to compare the effects of four different formulations of a drug to relieve an allergy. In a pilot experiment, four subjects are to be used, and each is to be given a sequence of three of the four drugs. The measurements are the number of minutes that the subject appears to be free of allergy symptoms. Suppose the design shown in Table 11.29 is selected for the experiment. 1. Check that this design is a balanced incomplete block design. (Show what you are checking.) 2. Show a randomization of this design, explaining the steps of your randomization. 3. The experiment was run as described, and the block-treatment model (11.4.2), p. 356, was used to analyze it. Some information for the analysis is shown in Table 11.29. Using this information and (11.4.7), p. 358, show that \(Q_{1}\), \(Q_{2}\), \(Q_{3}\), \(Q_{4}\) are \(-79.333\), \(81.667\), \(-158.667\), \(156.333\), respectively. 4. Using the information in part (c), give a confidence interval for \(\tau_{3}-\tau_{2}\) assuming that it is part of a set of 95% Tukey confidence intervals. 5. Test the hypothesis that there is no difference between the effects of the drugs.

\begin{table}
\begin{tabular}{c c c c c c c c c c} \hline Temperature (\({}^{\circ}\)F) & & & & & Block & & & & \\  & I & II & III & IV & V & VI & VII & VIII & IX & X \\ \hline
50 & 12 & 19 & & & & 20 & 10 & 21 & 19 & \\
55 & 18 & & 33 & & 19 & & 18 & & 18 & 24 \\
60 & 24 & 36 & & 35 & 39 & 22 & & & & 28 \\
65 & & & 39 & 45 & & 43 & 34 & 42 & & 31 \\
70 & & 45 & 52 & 55 & 48 & & & 50 & 43 & \\ \hline \end{tabular}
\end{table}
Table 11.28: Percentage rust observed for the rust experiment * The typical model and analysis for a balanced incomplete block design is that of parts (c)-(e). Do you think this is a reasonable model and analysis for the experiment described? Why or why not? (Hint: think about the terms in, and assumptions on, the model.)

10. **Step experiment, continued** The step experiment was described in Example 11.7.1 and the data are shown in Table 11.15, p. 373. 1. Prepare a plot of the treatment averages and examine the linear trends in the heart rate due to step frequency at each level of step height. 2. Fit a block-treatment model to the data with \(v=6\) treatments representing the six treatment combinations. 3. Estimate the linear trends in the heart rate due to step frequency at each level of step height separately, and calculate confidence intervals for these. 4. Write down a contrast that compares the linear trends in part (c) and test the hypothesis that the linear trends are the same against the alternative hypothesis that they are different.

11. **Beef experiment** Cochran and Cox (1957) describe an experiment that was run to compare the effects of cold storage on the tenderness of beef coasts. Six periods of storage (0, 1, 2, 4, 9, and 18 days) were tested and coded 1-6. It was believed that roasts from similar positions on the two sides of the animal would be similar, and therefore the experiment was run in \(b=15\) blocks of size \(k=2\). The response \(y_{hi}\) from treatment \(i\) in block \(h\) is the tenderness score. The maximum score is 40, indicating very tender beef. The design and responses are shown in Table 11.30. 1. What is the value of \(\lambda\) for this balanced incomplete block design? 2. What benefit do you think the experimenters expected to gain by using a block design instead of a completely randomized design? 3. Calculate the least squares estimate of \(\tau_{6}-\tau_{1}\) and its corresponding variance. 4. Calculate a confidence interval for \(\tau_{6}-\tau_{1}\) as though it were part of a set of 95% confidence intervals using Tukey's method of multiple comparisons. 5. Calculate a confidence interval for the difference of averages contrast \[\frac{1}{3}(\tau_{4}+\tau_{5}+\tau_{6})-\frac{1}{3}(\tau_{1}+\tau_{2}+\tau_{ 3})\,,\] 
\begin{table}
\begin{tabular}{c c c c c} Block & Levels of treatment factor & Block totals & Treatment totals \\ I & 1 & 2 & 3 & \(B_{1}=417\) & \(T_{1}=385\) \\ II & 1 & 2 & 4 & \(B_{2}=507\) & \(T_{2}=582\) \\ III & 1 & 3 & 4 & \(B_{3}=469\) & \(T_{3}=329\) \\ IV & 2 & 3 & 4 & \(B_{4}=577\) & \(T_{4}=674\) \\  & & & \(\overline{y}_{-}=164.1667\) & \(msE=3.683\) \\ \end{tabular}
\end{table}
Table 11.29: Balanced incomplete block design of Exercise 9 and partial information for its analysis assuming that you want the overall level of this interval together with the intervals in part (d) to be at least 94%. What does your interval tell you about storage time and tenderness of beef?
12. **Balanced incomplete block design** 1. Explain under what circumstances you would choose to use a block design rather than a completely randomized design. 2. For a balanced incomplete block design, why is it incorrect to estimate the difference in the effects of treatments \(i\) and \(p\) as \(\overline{y}_{.i}-\overline{y}_{.p}\)? What is the formula for the correct least squares estimate and its corresponding variance if the design of Table 11.2, p. 351, is used? 3. Suppose that the design of Table 11.2 is used for an experiment with \(v=7\) treatments and \(b=3\) blocks of size \(k=3\), and suppose that \[\hat{\tau}_{1}=31.6,\ \hat{\tau}_{2}=22.4,\ \hat{\tau}_{3}=17.9,\ \hat{\tau}_{4}=21.5,\ \hat{\tau}_{5}=30.2,\ \hat{\tau}_{6}=18.6,\ \hat{\tau}_{7}=25.5\,.\] Calculate a set of 99% confidence intervals for comparing the effect of treatment 1 with the effects of the other treatments. State your conclusions.
13. **Lithium bioavailability experiment** An experiment described by W. J. Westlake (_Biometrics_, 1974) used a balanced incomplete block design to compare the amount of four formulations of lithium carbonate that were present in the blood serum of subjects several hours after administration. The four levels of the factor "formulation" consisted of 300 mg capsule (level 1), 250 mg capsule with different inert ingredients (level 2), 450mg delayed release capsule (level 3), 300 mg in solution (level 4). Level 4 is the standard (control) treatment. Table 11.31 shows the amounts of lithium carbonate in the blood serum after 3 hours, measured in mEq (milliequivalent which is a measure of the quantity of ions

\begin{table}
\begin{tabular}{c c c c c c c} \hline Block & \multicolumn{6}{c}{Treatment} \\ \cline{2-7}  & 1 & 2 & 3 & 4 & 5 & 6 \\ \hline I & 7 & 17 & & & & \\ II & & & 26 & 25 & & & \\ III & & & & & 33 & 29 \\ IV & 17 & & 27 & & & \\ V & & 23 & & & 27 & & \\ VI & & & & 29 & & 30 \\ VII & 10 & & & 25 & & & \\ VIII & & 26 & & & & 37 \\ IX & & & 24 & & 26 & & \\ X & 25 & & & & 40 & & \\ XI & & 25 & & 34 & & & \\ XII & & & 34 & & & 32 \\ XIII & 11 & & & & & 27 \\ XIV & & & 24 & 21 & & & \\ XV & & & & 26 & 32 & & \\ \hline \end{tabular}
\end{table}
Table 11.30: Design and data for the beef experiment 

[MISSING_PAGE_FAIL:414]

* Calculate the two possible lengths of 99% confidence intervals for treatment versus control contrasts using Scheffe's method, and verify your calculations using a computer program.
* What can you conclude about the control treatment in this experiment?
* Using (4.2.4), p. 73, find the linear trend coefficients for 12 equally spaced treatment levels. If the treatment code corresponds to milliliters of added sugar to a product, and the response is a taste score, test the hypothesis that the linear trend in score as the amount of sugar increases is negligible. Use a significance level of \(\alpha=0.01\) and a two-sided alternative hypothesis.

16. **Fabric stain experiment** The experiment was run by M. Nelson, T. Blake, D. Sullivan, A. Kemme and J. Jia in 2008 to examine how best to remove a stain caused by black waterproof drawing ink. There were three factors under consideration as follows. Factor A was type of cloth (1 = cotton, 2 = polyester), Factor B was type of pre-treatment (1 = gel stain remover, 2 = antibacterial dish soap, 3 = no pre-treatment), and Factor C was time between staining and washing (0, 1, 2 days, coded as levels 1, 2, 3). The experiment was run in several blocks; in some blocks the washing machine was set to the hot wash setting, and the others to the cold wash setting. Thirty six pieces of fabric of each type were prepared of approximately the same size. The amount of ink applied to each piece of cloth was held constant, as was the amount of detergent used in each wash. The stained fabric samples were evaluated by a single experimenter using a "Gray Scale" (cf. Chapter 10, Exercise 14) both before and after the wash. The differences between the pairs of evaluations formed the responses and are shown in Table 11.33. The order of the samples was randomized and unknown to the evaluator.

* Show that, for this design, pairs of treatments occur together in \(\lambda_{1}\) or \(\lambda_{2}\) or \(\lambda_{3}\) blocks, where these values are different. (This means that there are three different lengths of confidence intervals for treatment contrasts). Thus, argue that the design cannot be a balanced incomplete block design or a group divisible design.
* For the standard block-treatment model (11.4.2), p. 356, with \(b=6\) blocks and \(v=18\) treatments, write down the contrast coefficient lists for the following contrasts:
* the comparison of treating the stain immediately as compared with the average of the 1 and 2 day delays, *

\begin{table}
\begin{tabular}{c c c c c} \hline Block & \multicolumn{4}{c}{Treatments (Response)} \\ \hline
1 & 2 (4.5) & 4 (8.7) & 10 (19.1) & 11 (21.2) \\
2 & 5 (11.8) & 7 (13.6) & 9 (18.2) & 11 (22.2) \\
3 & 1 (4.8) & 8 (17.3) & 11 (24.0) & 12 (24.8) \\
4 & 4 (10.8) & 6 (14.5) & 7 (16.6) & 8 (18.1) \\
5 & 2 (7.9) & 3 (9.7) & 8 (19.1) & 9 (20.6) \\
6 & 2 (8.7) & 5 (14.4) & 6 (16.2) & 12 (27.7) \\
7 & 1 (7.5) & 6 (16.9) & 9 (20.7) & 10 (23.5) \\
8 & 3 (11.3) & 7 (19.8) & 10 (25.5) & 12 (29.0) \\
9 & 1 (9.1) & 3 (9.8) & 4 (12.9) & 5 (16.9) \\ \hline \end{tabular}
\end{table}
Table 11.32: Data for the group divisible design 2. the comparison of no pre-treatment versus the average of the two types of pre-treatment, 3. the comparison of a 1 or 2 day delay for each level of pre-treatment separately.
3. Prepare an analysis of variance table and test the hypothesis that each contrast in part (b) is negligible. Use an overall significance level of not more than 0.1. State your conclusions.
4. Using Scheffe's method of multiple comparisons at confidence level 95%, state which pairs of treatments are significantly different and give the confidence intervals for these.
5. From Scheffe's multiple comparisons calculated in part (d), verify that the confidence intervals for \(\tau_{1}-\tau_{p}\), for \(p=2,\ldots,18\), are of three different lengths, and that the shorter lengths correspond to larger values of \(\lambda_{i}\).
6. Using a factorial model for the treatment effects, prepare an analysis of variance table. State your conclusions and, repeat part (c) for the first two contrasts in (b). Use the mapping of treatment labels to levels of \(A\), \(B\), \(C\) as: \[\begin{array}{l}1=111\;\;\;2=112\;\;\;3=113\;\;\;4=121\;\;\;5=122\;\;\;6=123 \\ 7=131\;\;\;8=132\;\;\;9=133\;\;10=211\;\;11=212\;\;12=213\\ 13=221\;\;14=222\;\;15=223\;\;16=231\;\;17=232\;\;18=233\end{array}\]
6. Does this design have "factorial structure" as defined in Sect. 11.7.1?

17. **Air rifle experiment This is a dangerous experiment that should not be copied! It requires proper facilities and expert safety supervision**. An experiment was run in 1995 by C.-Y. Li, D. Ranson, T. Schneider, T. Walsh, and P.-J. Zhang to examine the accuracy of an air rifle shooting at a target. The two treatment factors of interest were the projectile type (factor \(A\) at levels 1 and 2) and the number of pumps of the rifle (factor \(B\), 2, 6, and 10 pumps, coded 1, 2, 3). The paper covering the target had to be changed after every four observations, and since there were \(v=6\) treatment combinations, coded 11, 12, 13, 21, 22, 23), an incomplete block design was selected. Two copies of the following incomplete block design (called a generalized cyclic design) were used:

\begin{table}
\begin{tabular}{c c c c c c} \hline Block & \multicolumn{5}{c}{Treatments (Response)} \\ \hline
1 & 1 (35) & 6 (35) & 8 (20) & 10 (80) & 15 (65) & 17 (10) \\
2 & 2 (30) & 4 (25) & 9 (10) & 11 (75) & 13 (60) & 18 (15) \\
3 & 3 (30) & 5 (30) & 7 (30) & 12 (75) & 14 (60) & 16 (15) \\
4 & 1 (20) & 5 (30) & 9 (15) & 10 (80) & 14 (65) & 18 (20) \\
5 & 2 (20) & 6 (15) & 7 (10) & 11 (80) & 15 (65) & 16 (15) \\
6 & 3 (20) & 4 (15) & 8 (20) & 12 (70) & 13 (50) & 17 (15) \\ \hline \end{tabular}
\end{table}
Table 133: Responses for the fabric stain experiment The total of 12 blocks were randomly ordered, as were the treatment combinations within each block. The data, shown in Table 11.34, are distances from the center of the target measured in millimeters.

1. Write down a suitable model for this experiment.
2. Check that the assumptions on your model are satisfied.
3. The experimenters expected to see a difference in accuracy of the two projectile types. Using a computer package, analyze the data and determine whether or not this was the case.
4. For each projectile type separately, examine the linear and quadratic trends in the effects of the number of pumps. State your conclusions.

\begin{table}
\begin{tabular}{c c c c} \hline Block & & Treatment combination (Response) & \\ \hline I & 22 (2.24) & 23 (6.02) & 12 (11.40) & 11 (26.91) \\ II & 13 (7.07) & 22 (8.49) & 21 (19.72) & 11 (24.21) \\ III & 12 (10.63) & 23 (6.32) & 21 (9.06) & 13 (29.15) \\ IV & 11 (11.05) & 22 (6.32) & 23 (7.21) & 13 (23.02) \\ V & 23 (6.71) & 22 (15.65) & 12 (11.40) & 11 (23.02) \\ VI & 21 (17.89) & 12 (8.60) & 22 (10.20) & 13 (10.05) \\ VII & 11 (18.38) & 13 (11.18) & 23 (11.31) & 22 (11.70) \\ VIII & 22 (1.00) & 11 (30.87) & 21 (20.10) & 13 (17.03) \\ IX & 11 (18.03) & 21 (8.25) & 23 (6.08) & 12 (19.24) \\ X & 21 (15.81) & 13 (2.24) & 12 (17.09) & 22 (7.28) \\ XI & 23 (8.60) & 21 (15.13) & 12 (14.42) & 11 (25.32) \\ XII & 13 (8.49) & 12 (14.32) & 23 (11.66) & 21 (17.72) \\ \hline \end{tabular}
\end{table}
Table 11.34: Data for the air rifle experiment 

### 12.1 Introduction

In Chaps. 10 and 11, we discussed designs for experiments involving a single system of blocks. However, as we saw in the randomized complete block design of Table 10.1, p. 308, a block label can represent a combination of levels of several factors. The design in Table 10.1 was presented as having six blocks--the six block labels being the six combinations of levels of the factors "run of the oven" and "shelf." When a block design is used in this way, the \(b-1\) degrees of freedom for the block effects include not only those degrees of freedom for the effects of the two factors, but also for their interaction.

In this chapter, we look at designs for experiments that involve two blocking factors that _do not_ interact. When the blocking factor interactions can be omitted from the model, fewer observations are needed, and the experiment can be designed with only one observation per combination of levels of the blocking factors. The plan of the design is then often written as an array (that is, a table) with the levels of one blocking factor providing the row headings and those of the other providing the column headings. These designs are called _row-column designs_, and the two sets of blocks are called row blocks and column blocks or, more simply, rows and columns. Such designs are described in Sect. 12.2, where we restrict discussion to the case of exactly one treatment label allocated to each cell of the table. The randomization procedure needed for row-column designs is given in Sect. 12.2.1.

In Sect. 12.2.2, Latin square designs are described. These are the two-dimensional counterparts of randomized complete block designs since the row blocks are complete blocks and the column blocks are also complete blocks. Latin square designs require that the numbers of levels of both blocking factors be the same as (or a multiple of) the number of treatments. Section 12.2.3 concerns Youden designs, in which the column blocks form a randomized block design and the row blocks form a balanced incomplete block design (or vice versa). Cyclic and other row-column designs are discussed in Sect. 12.2.4.

The standard row-column-treatment model for row-column designs is shown in Sect. 12.3, together with an overview of the analysis of variance and confidence intervals for general row-column designs. The analysis becomes greatly simplified for both Latin square designs and Youden designs, and this is shown in Sects. 12.4 and 12.5, respectively. Checks on the model assumptions are described briefly in Sect. 12.6, and an extension of the model to cover factorial experiments in row-column designs is given in Sect. 12.7. All row-column designs can be analyzed using statistical software (see Sects. 12.8 and 12.9 for analysis by SAS and R software).

Some experiments are designed with more than two blocking factors. Block designs with a single system of blocks can still be used where each block represents some combination of the levels of three or more blocking factors, but designs with more than two blocking factors and a single observation per combination of their levels are not discussed in this book.

### 12.2 Design Issues

#### Selection and Randomization of Row-Column Designs

In most row-column designs and, in particular, in all Latin square designs and Youden designs, all treatment contrasts are estimable. However, estimability is not as easy to verify for general row-column designs as it was for incomplete block designs (Sect. 11.2.3) since it cannot be deduced from the row blocks and column blocks separately. One way to check that a miscellaneous row-column design is suitable for a planned experiment is to enter a set of hypothetical data for the design into a computer package and see whether the required contrasts are estimable.

Once the numbers of rows, columns, and treatments have been selected, there are two stages to designing an experiment with two blocking factors and one observation at each combination of their levels. The first design stage is to choose an experimental plan. As an example, the plan in Table 12.1 has two sets of blocks corresponding to two blocking factors--one with 7 levels represented by the \(b=7\) rows, and the other with 4 levels represented by the \(c=4\) columns. There are \(v=7\) treatment labels, each appearing \(r=4\) times in the design, and at most once per row and per column. The second design stage is the random assignment of the labels in the design to the levels of the treatment factors and blocking factors in the experiment, as follows:

1. The row block labels in the design are randomly assigned to the levels of the first blocking factor.
2. The column block labels in the design are randomly assigned to the levels of the second blocking factor.
3. The treatment labels in the design are randomly assigned to the levels of the treatment factor.

Since there is only one experimental unit in each cell, there is no need for random assignment of experimental units to treatment labels within a cell.

\begin{table}
\begin{tabular}{c c c c c c} \hline  & & & \multicolumn{3}{c}{Column blocks} \\  & & I & II & III & IV \\ \hline Row blocks & I & 1 & 3 & 6 & 7 \\  & II & 2 & 4 & 7 & 1 \\  & III & 3 & 5 & 1 & 2 \\  & IV & 4 & 6 & 2 & 3 \\  & V & 5 & 7 & 3 & 4 \\  & VI & 6 & 1 & 4 & 5 \\  & VII & 7 & 2 & 5 & 6 \\ \hline \end{tabular}
\end{table}
Table 12.1: A row–column experimental plan with \(b=7\), \(c=4\), \(v=7\), \(r=4\)

#### Latin Square Designs

A \(v\) x _v Latin square_ is an arrangement of \(v\) Latin letters into a \(v\) x \(v\) array (a table with \(v\) rows and \(v\) columns) in such a way that each letter occurs once in each row and once in each column. For example, the following 3 x 3 array is a 3 x 3 Latin square:

\[\begin{array}{ccc}\text{A}&\text{B}&\text{C}\\ \text{B}&\text{C}&\text{A}\\ \text{C}&\text{A}&\text{B}\end{array}\]

A _Latin square design_ has \(v\) treatment labels, and \(v\)2 experimental units arranged in \(v\) row blocks and \(v\) column blocks, where experimental units within each row block are alike, units within each column block are alike, and units not in the same row block or column block are substantially different. The experimental plan of the design is a \(v\) x \(v\) Latin square. Randomization of row block, column block, and treatment labels in the plan is carried out as in Sect. 12.2.1.

If we look only at the row blocks of a Latin square design, ignoring the column blocks, we have a randomized complete block design, and if we look at the column blocks alone, ignoring the row blocks, we also have a randomized complete block design. Each level of the treatment factor is observed \(r\) = \(v\) times--once in each row block and once in each column block.

The 3 x 3 Latin square shown above is a "standard, cyclic Latin square." A Latin square is a _standard Latin square_ if the letters in the first row and in the first column are in alphabetical order, and it is _cyclic_ if the letters in each row can be obtained from those in the previous row by cycling the letters in alphabetical order (cycling back to letter \(A\) after the _v_th letter).

There is only one standard 3 x 3 Latin square, but there are four standard 4 x 4 Latin squares, and these are shown in Table 2.2. The first square is the cyclic standard Latin square. A standard cyclic Latin square exists for any number of treatments.

An example of a 6 x 6 Latin square design was shown in Table 2.5 (p. 19). It was a design that was considered for the cotton-spinning experiment. The row blocks represented the different machines with their attendant operators, and the column blocks represented the different days over which the experiment was to be run. The treatment labels were the combinations of degrees of twist and flyer used on the cotton-spinning machines. After careful consideration, the experimenters decided not to use this design, since it required the same six machines to be available over the same six days, and this could not be guaranteed in the factory setting.

Latin square designs are often used in experiments involving subjects, especially where the subjects are allocated a sequence of treatments over time and where the time effect is thought to have a major effect on the response. For example, in an experiment to compare the effects of \(v\) drugs, the rows of the Latin square might correspond to \(v\) subjects to whom the drugs are given, and the columns might correspond to \(v\) time periods, with each subject receiving one drug during each time period. An experiment of this type, in which each subject receives a sequence of treatments, is called a _crossover experiment_.

\begin{table}
\begin{tabular}{c c c c c} \hline Square 1 & Square 2 & Square 3 & Square 4 \\ \hline A B C D & A B C D & A B C D & A B C D \\ B C D A & B A D C & B A D C & B D A C \\ C D A B & C D A B & C D B A & C A D B \\ D A B C & D C B A & D C A B & D C B A \\ \hline \end{tabular}
\end{table}
Table 2.2: Latin squares with \(b\) = \(c\) = \(v\) = 4In a crossover experiment, it is possible that a treatment will continue to have some effect on the response when another treatment is administered to the same subject in a subsequent time period. Such an effect is called a _carryover effect_ or _residual effect_ and must be accounted for in the design and analysis of the experiment. This is outside the scope of this book, but for further information, see Ratkowsky et al. (1993) or Jones and Kenward (2003). We will consider experiments in which either there is no carryover effect or in which the gap between the administration of one treatment and the next is sufficient to allow the carryover effect to diminish (and, hopefully, to disappear). The "gap" is called a _washout period_.

To design the experiment, a square is selected from the list of standard squares and the randomization procedure of Sect. 12.2.1 is performed. Thus for an experiment with \(b=4\) levels of the row blocking factor, \(c=4\) levels of the column blocking factor, and \(v=4\) levels of the treatment factor, one of the four standard squares of Table 2 would be selected. For larger squares, we have not provided a list of standard squares, since there are so many. However, it is straightforward to write down the standard cyclic Latin square and perform the randomization procedure on this.

Although we have not given a procedure which selects a Latin square at random from the set of all possible Latin squares, the above procedure should be sufficient for the occasional experiment. Fisher and Yates (1973) give more information on this, as well as a complete list of standard squares for \(v=5\) and 6, and selected squares for \(v=7\)-12.

### Replication of Latin Squares

A design based on a single Latin square has \(r=v\) observations on each treatment, which may not be adequate for an analysis of the treatment effects. One way of increasing the number of observations is to piece together a number, \(s\) say, of \(v\times v\) Latin squares. We will call such a design an \(s\)_-replicate Latin square_. Use of an \(s\)-replicate Latin square requires the column (or row) blocks to be of size \(vs\). For example, stacking two 3 \(\times\) 3 Latin squares, one above the other, we can obtain two possible 2-replicate Latin squares as in Table 3. For either plan, the number of observations per treatment is now \(r=6=2v\) rather than only \(r=3=v\). Plan 2 is preferable to Plan 1 because the row blocks consist of each possible ordering of the three treatments (and this will remain true even after randomization).

Suppose we were to use Plan 2 for an experiment to compare the efficacy of \(v=3\) drugs, where there are two blocking factors, say "subjects"--the people to whom the drugs will be administered, and "time period"--the time during which each subject receives a single drug and a response is measured. If rows correspond to subjects, then \(b=6\) subjects would be required over \(c=3\) time periods, but if columns correspond to subjects, then each of \(c=3\) subjects would stay in the study for \(b=6\) periods. In practice, in drug studies, subjects are rarely used for more than 4 time periods, since the subject drop-out rate tends to be high after this length of time.

An \(s\)-replicate Latin square may allow some column-treatment interaction contrasts to be measured (after adjusting for row block effects as in Chap. 11). However, these will often not form a full set of

\begin{table}
\begin{tabular}{c c c c c c}  & Plan 1 & & Plan 2 & \\ A & B & C & A & B & C \\ B & C & A & B & C & A \\ C & A & B & C & A & B \\ A & B & C & A & C & B \\ B & C & A & B & A & C \\ C & A & B & C & B & A \\ \end{tabular}
\end{table}
Table 3: Two 2-replicate Latin squares for \(v=3\), \(b=6\), \(c=3\)\((v-1)^{2}\) orthogonal contrasts. For \(v=3\), Plan 2 does allow the adjusted column-treatment interaction to be measured based on the full set of \((v-1)^{2}=4\) degrees of freedom, but Plan 1 does not.

#### 12.2.3 Youden Designs

A \(v\times c\)_Youden square_ is an arrangement of \(v\) Latin letters into a \(v\times c\) array (with \(c<v\)) in such a way that each letter occurs once in each column and at most once in each row. In addition, every pair of treatments occurs in the same number of rows, so the columns form complete blocks and the rows form a balanced incomplete block design.

Notice that a Youden square, written in this way, is not, in fact, square! We have defined a Youden square to have more rows than columns, but the array could be turned so that there are more columns than rows. Plans 3 and 4 in Table 12.4 are examples of \(4\times 3\) Youden squares with \(v=4\) treatment labels, with Plan 3 being a standard Youden square.

In general, a _Youden design_ has \(v\) treatment labels and \(vc\) experimental units arranged in \(b=v\) row blocks and \(c<v\) column blocks, where experimental units within each row block are alike, experimental units within each column block are alike, and experimental units not in the same row block or column block are substantially different. The experimental plan is a \(v\times c\) Youden square, and randomization of row, column, and treatment labels is carried out as in Sect. 12.2.1. Each level of the treatment factor is observed \(r=c\) times--once in each column and at most once in each row.

The plans of Table 12.4 are both _cyclic Youden designs_ prior to randomization. In each case, the row blocks form a cyclic balanced incomplete block design with every pair of treatment labels occurring in \(\lambda=2\) rows. Any cyclic balanced incomplete block design (with the full set of \(v\) blocks) can be used as a cyclic Youden design. The design in Table 12.1 is also a cyclic Youden design, having \(b=v=7\) row blocks and \(c=4\) column blocks and every pair of treatments occurring in \(\lambda=2\) row blocks. Youden designs with \(c=v-1\) column blocks can be obtained by deleting any column from a \(v\times v\) Latin square design.

#### Replication of Youden Squares

We can obtain \(r=cs\) observations per treatment by stacking \(s\) Youden squares one above another (giving \(b=vs\) row blocks and \(c(<v)\) column blocks). This results in large column-block sizes but may allow for estimation of some column\(\times\)treatment interaction contrasts after adjusting for row block effects (although usually not the full set of \((c-1)(v-1)\) contrasts). The row blocks still form a balanced incomplete block design, and the column blocks still form a complete block design.

Suppose \(v=7\) drugs are to be compared and that a number of subjects are each to be given a sequence of 4 of the drugs over \(c=4\) time periods, with washout periods in between to avoid carryover effects. The experimental plan in Table 12.1, which uses 7 subjects, would be suitable for the experiment if \(r=4\) observations per drug is deemed adequate. Otherwise, several copies of this design could be stacked. Or column permutations could be made before stacking (cf. stacking the two plans in Table 12.4). If, for example, \(s=3\) copies of the Table 12.1 design are pieced together, the resulting 3-replicate Youden design would require 21 subjects, 4 time periods, and would have \(r=cs=12\)observations per treatment, with \(b=21\), \(c=4\), \(v=7\), and \(\lambda=6\). The design would be randomized before use as described in Sect. 12.2.1.

#### Cyclic and Other Row-Column Designs

Any arrangement of \(v\) treatment labels into \(b\) rows and \(c\) columns can be used as a row-column design for an experiment with two blocking factors. As with incomplete block designs, some row-column designs are better than others. The better designs (in terms of average length of confidence intervals for pairwise comparisons) have every pair of treatment labels occurring the same, or nearly the same, number of times in the row blocks and also in the column blocks. This is satisfied by Latin square designs, Youden designs, and also some cyclic designs.

A _cyclic row-column design with complete column blocks_ is a row-column design in which the row blocks form a cyclic block design and the column blocks are complete blocks. For example, the experimental plan in Table 1.1 is a cyclic row-column design. The class of cyclic row-column designs is very large, and a design with \(b=vs\) rows can always be found when a Youden design does not exist. For example, consider an experiment for comparing \(v=8\) treatments when there are two blocking factors having \(b=8\) and \(c=3\) levels, respectively (so \(r=c=3\)). There does not exist a Youden design for \(b=v=8\) and \(c=3\), because there does not exist a balanced incomplete block design for 8 treatments in 8 blocks of size \(c=3\). (Notice that (11.3.1) gives \(\lambda=r(c-1)/(v-1)=6/7\) which is not an integer.) A cyclic design that may be suitable for the experiment is given as Plan 5 in Table 1.5. The design is obtained by cycling the labels in the first row block. Treatment pairs (1, 5), (2, 6), (3, 7), and (4, 8) never occur together in a row block, but all other pairs of treatments occur in exactly one row block, so this should be a reasonably good design. The design should be randomized via the procedure in Sect. 12.2.1 before it is used.

Plan 6 of Table 1.5, which is neither a Youden design nor a cyclic design, could also be used, but we might guess that it is not quite as good for pairwise comparisons. Treatment 1, for example, appears in one block with each of treatments 3 and 4, in two blocks with 2 and 7, and not at all with treatments 5, 6, or 8. Thus, the treatments are not quite so evenly distributed in the row blocks of Plan 6 as they are of Plan 5. Nevertheless, Plan 6 was used for the exercise bike experiment described below, and will be analyzed using the SAS and R software in Sects. 12.8 and 12.9, respectively.

#### Exercise bicycle experiment

Yuedong Wang, Dong Xiang, and Yili Lu conducted an experiment in 1992 at the University of Wisconsin to investigate the effects of exercise on pulse rate. The exercise was performed on a stationary

\begin{table}
\begin{tabular}{c c c c c c c c} \hline  & \multicolumn{4}{c}{Plan 5} & \multicolumn{4}{c}{Plan 6} \\ \hline  & & I & II & III & & I & II & III \\ \cline{2-8}  & I & 1 & 2 & 4 & I & 1 & 2 & 7 \\ II & 2 & 3 & 5 & II & 2 & 4 & 1 \\ III & 3 & 4 & 6 & III & 3 & 7 & 6 \\ IV & 4 & 5 & 7 & IV & 4 & 8 & 2 \\ V & 5 & 6 & 8 & V & 5 & 6 & 8 \\ VI & 6 & 7 & 1 & VI & 6 & 3 & 5 \\ VII & 7 & 8 & 2 & VII & 7 & 1 & 3 \\ VIII & 8 & 1 & 3 & VIII & 8 & 5 & 4 \\ \hline \end{tabular}
\end{table}
Table 1.5: Incomplete-row complete-column designs with \(v=b=8\) and \(r=c=3\)

[MISSING_PAGE_FAIL:424]

where \(\theta_{h}\), \(\phi_{q}\), and \(\tau_{i}\) denote the effects on the response of row block \(h\), column block \(q\), and treatment \(i\), respectively. The term "(\(h\), \(q\), \(i\)) in the design" means that the model is valid for whichever treatment \(i\) is observed in the cell defined by the \(h\)th row block and \(q\)th column block. The model includes the usual assumptions that the error terms \(\epsilon_{hqi}\) are independent and normally distributed with constant variance. It also includes the assumptions of no interaction between the row and column blocking factors nor between these and the treatment factors.

#### Analysis of Variance for a Row-Column Design

We first give an overview of the analysis for connected row-column designs with no interactions. This is followed by the specific analyses for Latin square designs and Youden designs in Sects. 12.4 and 12.5, respectively. Analysis of general row-column designs can be done by computer, and this is illustrated via the SAS and R computer packages in Sects. 12.8 and 12.9.

For row-column designs with \(b\) row blocks, \(c\) column blocks, and \(r\) observations on each of \(v\) treatments with the row-column-treatment model (12.3.1), the top portion of Table 7 shows the form of the analysis of variance obtained when the row and column factors are entered into the model before the treatment factor. The (unadjusted) sum of squares \(\text{ss}\theta\) for row blocks, and the (unadjusted) sum of squares \(\text{ss}\phi\) for column blocks are calculated in a similar way to the block sum of squares in a complete block design; that is

\[\text{ss}\theta\ =\ \frac{1}{c}\sum_{h=1}^{b}B_{h}^{2}-\frac{1}{bc}G^{2}\quad\text{and}\quad\text{ss}\phi\ =\ \frac{1}{b}\sum_{q=1}^{c}C_{q}^{2}-\frac{1}{bc}G^{2}\]

where \(B_{h}\) is the total of the observations in the \(h\)th row block, \(C_{q}\) is the total of the observations in the \(q\)th column block, and \(G\) is the grand total of all the observations.

The sum of squares for treatments adjusted for rows and columns (i.e. adjusted for the fact that not all treatments may be in every row block and every column block, and some blocks are better than others) can be shown to be

\begin{table}
\begin{tabular}{c c c c c} \hline Source of variation & Degrees of freedom & Sum of squares & Mean square & Ratio \\ \hline Rows (unadj) & \(b-1\) & \(\text{ss}\theta\) & \(-\) & \(-\) \\ Columns (unadj) & \(c-1\) & \(\text{ss}\phi\) & \(-\) & \(-\) \\ Treatments(adj) & \(v-1\) & \(\text{ss}T_{\text{adj}}\) & \(\text{ms}T_{\text{adj}}\) & \(\text{ms}T_{\text{adj}}/\text{ms}E\) \\ Error & \(bc-b-c-v+2\) & \(\text{ss}E\) & \(\text{ms}E\) & \\ Total & \(bc-1\) & \(\text{sstot}\) & & \\ \hline \multicolumn{5}{c}{Formulae} \\ \hline \(Q_{i}=T_{i}-\frac{1}{c}\sum_{h=1}^{b}n_{h,i}B_{h}-\frac{1}{b}\sum_{q=1}^{c}n_{qi}C_{q}+\frac{r}{bc}G\) & \(\text{ss}T_{\text{adj}}=\Sigma_{i=1}^{v}Q_{i}\hat{\tau}_{i}\) \\ \(\text{sstot}=\Sigma_{h=1}^{b}\Sigma_{q=1}^{c}\Sigma_{i=1}^{v}n_{hqi}\gamma_{hqi}^{2}-\frac{1}{bc}G^{2}\) & \(\text{ss}\theta=\frac{1}{c}\sum_{h=1}^{b}B_{h}^{2}-\frac{1}{bc}G^{2}\) \\ \(\text{ss}\text{E}=\text{sstot}-\text{ss}\theta-\text{ss}\phi-\text{ss}T_{\text{adj}}\) & \(\text{ss}\phi=\frac{1}{b}\sum_{q=1}^{c}C_{q}^{2}-\frac{1}{bc}G^{2}\) \\ \(T_{i}=\Sigma_{h=1}^{b}\Sigma_{q=1}^{c}n_{hqi}\gamma_{hqi}\) & \(B_{h}=\Sigma_{q=1}^{c}\Sigma_{i=1}^{v}n_{hqi}\gamma_{hqi}\) \\ \(C_{q}=\Sigma_{h=1}^{b}\Sigma_{i=1}^{v}n_{hqi}\gamma_{hqi}\) & \(G=\Sigma_{h=1}^{b}\Sigma_{q=1}^{c}\Sigma_{i=1}^{v}n_{hqi}\gamma_{hqi}\) \\ \hline \end{tabular}
\end{table}
Table 7: Analysis of variance table for a connected row–column design with no interactions\[\text{s}\text{s}\text{T}_{\text{adj}}=\,\Sigma_{i=1}^{v}Q_{i}\hat{\tau}_{i}\,\,\, \text{with}\,\,\,\,Q_{i}=T_{i}-\frac{1}{c}\sum_{h=1}^{b}n_{h,i}B_{h}-\frac{1}{b }\sum_{q=1}^{c}n_{.qi}C_{q}+\frac{r}{bc}G\,, \tag{12.3.2}\]

where \(n_{h.i}\) is the number of times that treatment \(i\) appears in row block \(h\), and and \(n_{.qi}\) is the number of times that treatment \(i\) appears in column block \(q\). In general, it is not easy to obtain least squares solutions by hand for the treatment parameters \(\tau_{i}\) in row-column designs except for the cases of Latin square and Youden designs. Least squares solutions for these special cases are given in Sects. 12.4 and 12.5, respectively. The analysis of a more complicated row-column design is illustrated using the SAS and R computer packages in Sects. 12.8 and 12.9, respectively.

In general, the sum of squares for error for the row-column-treatment model (12.3.1) is obtained by subtraction as usual

\[\text{s}\text{s}\text{s}\text{E}=\text{s}\text{s}\text{t}\text{o}-\text{s} \text{s}\text{s}\text{\phi}-\text{s}\text{s}\text{T}_{\text{adj}}\,, \tag{12.3.3}\]

where

\[\text{s}\text{s}\text{t}\text{o}=\,\,\,\sum_{h}\sum_{q}\sum_{i}n_{hqi}y_{hqi}^ {2}-\frac{1}{bc}G^{2}\,,\]

and \(n_{hqi}=1\) if treatment label \(i\) is allocated to the combination of row block \(h\) and column block \(q\) and zero otherwise. As in any connected block design, the numbers of degrees of freedom for rows, columns and treatments are \(b-1\), \(c-1\) and \(v-1\), respectively. The number of degrees of freedom for error is obtained by subtraction:

\[\text{d}\text{f}=(bc-1)-(b-1)-(c-1)-(v-1)\,\,=\,\,bc-b-c-v+2\,, \tag{12.3.4}\]

where \(bc\) is the total number of observations.

A test of the null hypothesis \(H_{0}^{T}:\{\tau_{1}=\tau_{2}=\cdots\tau_{v}\}\) against the general alternative hypothesis \(H_{A}^{T}:\{\text{at least two of the $\tau_{i}$'s differ}\}\) is given by the decision rule

\[\text{reject}\,H_{0}^{T}\,\,\,\,\text{if}\,\,\,\,\text{m}\text{s}\text{T}_{ \text{adj}}/\text{m}\text{s}\text{E}>F_{v-1,bc-b-c-v+2,\alpha} \tag{12.3.5}\]

for some chosen significance level \(\alpha\). The test (12.3.5) is most conveniently set out in an analysis of variance table, as in the top portion of Table 12.7. The bottom portion of the table shows the specific formulae.

#### Confidence Intervals and Multiple Comparisons

The multiple-comparison methods of Bonferroni and Scheffe can be applied for any row-column design. Simultaneous \(100(1-\alpha)\)% confidence intervals for treatment contrasts \(\Sigma_{i}d_{i}\hat{\tau}_{i}\) are of the form

\[\left(\sum_{i}d_{i}\hat{\tau}_{i}\pm w\sqrt{\hat{\text{s}\text{r}}(\sum_{i}d_{ i}\hat{\tau}_{i})}\right)\,, \tag{12.3.6}\]

where the critical coefficient \(w\) is

\[w_{B}=t_{bc-b-c-v+2,\alpha/2m}\,\,\,\text{or}\,\,\,\,w_{S}=\sqrt{(v-1)F_{v-1, bc-b-c-v+2,\alpha}}\,,\]for the Bonferroni or Scheffe methods, respectively. Tukey and Dunnett methods of pairwise comparisons can be used in the special cases of Latin square designs and Youden designs (Sects. 12.4.2 and 12.5.2).

### Analysis of Latin Square Designs

#### Analysis of Variance for Latin Square Designs

Table 12.7, p. 406, shows the analysis of variance table for the row-column-treatment model (12.3.1) for any row-column design. In the table, \(T_{i},B_{h},C_{q}\), and \(G\) are, respectively, the sum of the observations on the \(i\)th level of the treatment factor, the \(h\)th level of the row blocking factor, the \(q\)th level of the column blocking factor, and the grand total of all the observations. The constant \(n_{hqi}\) is equal to 1 if treatment \(i\) is observed in the combination of row block \(h\) and column block \(q\), and \(n_{hqi}\) is equal to zero otherwise. For an \(s\)-replicate Latin square design, every treatment appears once in every row block and \(s\) times in every column block, so there are \(b=vs\) rows, \(c=v\) columns, and we have \(n_{h.i}=1\), \(n_{.qi}=s\). It can be shown that, for Latin square designs, least squares solutions for the treatment parameters \(\tau_{i}\) in model (12.3.1) are given by

\[\hat{\tau}_{i}=\frac{1}{vs}Q_{i}\,,\;\;\;\mbox{with}\;\;Q_{i}\;=\;T_{i}-\frac{ 1}{c}\sum_{h}n_{h.i}B_{h}\;=\;T_{i}-\frac{1}{v}G\,. \tag{12.4.7}\]

Thus, for an \(s\)-replicate Latin square design, the treatment sum of squares (12.3.2) become

\[ssT_{\rm adj}\;=\;\;\sum_{i=1}^{v}Q_{i}\hat{\tau}_{i}\;=\;\frac{1}{vs}\sum_{i= 1}^{v}\left(T_{i}-\frac{1}{v}G\right)^{2}\,,\]

and we see that the "adjusted" treatment sum of squares for a Latin square design is actually _not_ adjusted for row-block effects nor for column-block effects. This is because every treatment is observed the same number of times in every row block and in every column block (even though only \(bc\) of the \(bcv\) row-column-treatment combinations are actually observed). The computational formula for \(ssT_{\rm adj}\) is obtained by expanding the terms in parentheses to give

\[ssT_{\rm adj}\;=\;\frac{1}{vs}\sum_{i}T_{i}^{2}-\frac{1}{v^{2}s}G^{2}\,.\]

The error sum of squares and degrees of freedom are obtained by subtraction, as in (12.3.3). For an \(s\)-replicate Latin square design with \(b=vs\) rows and \(c=v\) columns, we have error degrees of freedom equal to

\[df=bc-b-c-v+2\;=\;v^{2}s-vs-2v+2\;=\;(vs-2)(v-1)\,. \tag{12.4.8}\]

The test for equality of treatment effects compares the ratio of the treatment and error mean squares with the corresponding value from the \(F\)-distribution, in the usual way (see Example 12.4.1). We will not utilize a test for the hypothesis of negligible row-block or of negligible column-block effects. However, we conclude that the current experiment has benefited from the use of the row (or column) blocking factor if the row (or column) mean square exceeds the mean square for error.

#### 12.4.1 _Dairy cow experiment_

Cochran and Cox (1957, p. 135) described an experiment that studied the effects of three diets on the milk production of dairy cows. The \(v=3\) diets (levels of a treatment factor) consisted of roughage (level 1), limited grain (level 2), and full grain (level 3). A crossover experiment was used, with each of the \(b=6\) cows being fed each diet in turn, each for a six-week period. The response variable was the milk yield for each cow during each of the \(c=3\) periods. Data were collected using a randomization of the 2-replicate Plan 2 Latin square in Table 12.3, p. 403, with \(v=3\) treatment labels, \(b=vs=6\) rows, \(c=3\) columns, and with \(v=3\) treatments each observed \(r=vs=6\) times. A possible randomization and the data collected are shown in Table 12.8.

Provided that each measurement on milk yield has been taken after a cow has been on a new diet for a sufficiently long period of time to allow the effect of the previous diet to "wash out" of the system, we need not be concerned with carryover effects. For this experiment, a model without carryover effects describes the data fairly well.

Table 12.9 shows the analysis of variance table. To test the null hypothesis \(H_{0}^{T}\) that all three diets have the same effect, the decision rule is

\[\text{reject }H_{0}^{T}\text{ if }\text{m}\text{s}\text{T}/\text{m}\text{s} \text{E}>F_{2,8,,01}=8.65\,,\]

with a probability of \(\alpha=0.01\) of making a Type I error. Since \(\text{m}\text{s}\text{T}/\text{m}\text{s}\text{E}=1138.39/103.06=11.05>8.65\), we reject the null hypothesis at the \(\alpha=0.01\) significance level and conclude that the diets do not all have the same effect.

To evaluate whether or not blocking was worthwhile, observe that the mean squares for periods and cows are both considerably larger than the error mean square. Thus, inclusion of both blocking factors in the experiment was beneficial in reducing the experimental error. (Since this is a Latin square design, no adjustment is needed to the row and column sums of squares to draw this conclusion.) 

#### 12.4.2 _Confidence Intervals for Latin Square Designs_

All treatment contrasts are estimable in Latin square designs. Using the row-column-treatment model (12.3.1), the least squares estimate of a treatment contrast \(\Sigma d_{i}\tau_{i}\), with \(\Sigma d_{i}=0\), is obtained from (12.4.7) as

\[\sum d_{i}\hat{\tau}_{i}=\frac{1}{vs}\sum_{i}d_{i}T_{i}\,, \tag{12.4.9}\]

\begin{table}
\begin{tabular}{c c c c c c c} \hline Row & Column & Cow & Period & \\  & 1 & 2 & 3 & 1 & 2 & 3 \\ \hline
1 & A & B & C & 6 & 2 (63) & 3 (101) & 1 (1) \\
2 & B & C & A & 4 & 3 (76) & 1 (86) & 2 (46) \\
3 & C & A & B & 2 & 3 (86) & 2 (109) & 1 (39) \\
4 & A & C & B & 5 & 1 (35) & 2 (75) & 3 (34) \\
5 & B & A & C & 1 & 2 (25) & 1 (38) & 3 (15) \\
6 & C & B & A & 3 & 1 (72) & 3 (124) & 2 (27) \\ \hline \end{tabular} _Source_ Data adapted from _Experimental Designs_, Second Edition, by Cochran and Cox (1957), Copyright © 1957, John Wiley & Sons, New York.

\end{table}
Table 12.8: Unrandomized 2-replicate Latin Square (Plan 2, Table 12.3), and possible randomization for the dairy cow experiment (with data in parentheses)and, since \(T_{i}\) is the sum of \(vs\) observations, the corresponding variance is

\[\text{Var}\left(\sum d_{i}\hat{\tau}_{i}\right)=\sum d_{i}^{2}\left(\frac{\sigma^ {2}}{vs}\right)\,, \tag{12.4.10}\]

The multiple-comparison methods of Bonferroni, Scheffe, Tukey, and Dunnett can be used for \(s\)-replicate Latin square designs. Formulae for confidence intervals for treatment contrasts \(\Sigma d_{i}\tau_{i}\) are of the form

\[\left(\frac{1}{vs}\,\Sigma_{i}d_{i}T_{i}\ \ \pm\ \ w\sqrt{msE\left(\frac{\Sigma d _{i}^{2}}{vs}\right)}\right)\,, \tag{12.4.11}\]

where the appropriate critical coefficients \(w\) for the four methods are,

\[w_{B}=t_{(vs-2)(v-1),\alpha/2m}\ \ ;\ \ w_{S}=\sqrt{(v-1)F_{v-1,(vs-2)(v-1),\alpha}}\ \ ;\] \[w_{T}=q_{v,(vs-2)(v-1),\alpha}/\sqrt{2}\ \ ;\ \ w_{D2}=|t|_{v-1,(vs-2)(v-1),\alpha}^{(0.5)}\ \.\]

#### _Example 12.4.2_Dairy cow experiment, continued

The dairy cow experiment was described in Example 12.4.1, p. 409. Tukey's method of all pairwise comparisons can be applied to determine which diets, if any, are significantly different from any of the others. The treatment sample means, which can be computed from the data in Table 12.8, are

\[\frac{1}{vs}T_{1}=45.167,\quad\frac{1}{vs}T_{2}=57.500,\quad\frac{1}{vs}T_{3}=72.667\,,\]

so that the least squares estimates of the pairwise differences are

\[\hat{\tau}_{2}-\hat{\tau}_{1}=57.500-45.167=12.333\,,\] \[\hat{\tau}_{3}-\hat{\tau}_{1}=72.667-45.167=27.500\,,\] \[\hat{\tau}_{3}-\hat{\tau}_{2}=72.667-57.500=15.167\,.\]

The value of the error mean square is \(msE=103.06\) from the analysis of variance table, Table 12.9. The error degrees of freedom are given by (12.4.8) as

\[df=(vs-2)(v-1)=(2\times 3-1)(3-1)=8\,.\]

Using a simultaneous confidence level of 95%, we obtain the critical coefficient for Tukey's method as \(w_{T}=q_{3,8,05}/\sqrt{2}=4.04/\sqrt{2}\). Hence, using (12.4.11), the minimum significant difference for

\begin{table}
\begin{tabular}{l c c c c c} \hline Source of variation & Degrees of freedom & Sum of squares & Mean square & Ratio & \(p\)-value \\ \hline Cow (row) & 5 & 5781.11 & 1156.22 & \(-\) & \(-\) \\ Period (column) & 2 & 11480.11 & 5740.06 & \(-\) & \(-\) \\ Diets (treatment) & 2 & 2276.78 & 1138.39 & 11.05 & 0.0050 \\ Error & 8 & 824.44 & 103.06 & & \\ Total & 17 & 20362.44 & & & \\ \hline \end{tabular}
\end{table}
Table 12.9: Analysis of variance table for the dairy cow experiment pairwise differences is

\[\text{msd}=(4.04/\sqrt{2})\sqrt{\text{msE}(2/6)}=16.743\,.\]

The simultaneous 95% confidence intervals are therefore

\[\tau_{3}-\tau_{1} \in (27.500\,\pm\,\,16.743)\,\,=\,\,(\,\,10.58,\,44.24)\,,\] \[\tau_{2}-\tau_{1} \in (12.333\,\pm\,\,16.743)\,\,=\,\,(-4.41,\,29.08)\,,\] \[\tau_{3}-\tau_{2} \in (15.167\,\pm\,\,16.743)\,\,=\,\,(-1.58,\,31.91)\,.\]

From these intervals, we can deduce that at overall significance level \(\alpha=0.05\), the full grain diet (level 3) results in a mean yield of 10.58-44.24 units higher than the roughage diet (level 1), but the limited grain diet (level 2) is not significantly different from either of the other two. 

#### How Many Observations?

The formula for determining the sample size needed to achieve a power \(\pi(\Delta)\) of detecting a difference \(\Delta\) in the treatment effects for given \(v\), \(\alpha\), and \(\sigma^{2}\), using a Latin square design, is the same as (10.6.13) for a randomized complete block design, but with \(b\) replaced by \(v\) (since \(r=vs\) rather than \(r=bs\)). Thus, after simplification of the formula, we need to find \(s\) to satisfy

\[s\,\geq\,\,\frac{2\sigma^{2}\phi^{2}}{\Delta^{2}}\,. \tag{12.4.12}\]

Alternatively, the confidence interval formula (12.4.11) can be used to calculate the sample sizes needed for achieving confidence intervals of a desired width (see Example 12.4.3).

##### Sample-size calculation for an \(s\)-replicate Latin square design

Consider an experiment to compare \(v=3\) computer keyboard designs with respect to the time taken to type an article of given length. Typists and time periods are the two blocking factors, with each of \(b=3s\) typists using each of the keyboards in a sequence of \(c=3\) time periods. An \(s\)-replicate Latin square design will be used, with \(r=3s\) observations per keyboard layout (treatment), and with sufficient time between observations to prevent a carryover effect.

With 3 treatments, there are 3 pairwise comparisons. Using Tukey's method of multiple comparisons and a simultaneous confidence level of 95%, suppose that the experimenters want confidence intervals with half-width (minimum significant difference) of 10 min or less. The error standard deviation is expected to be at most 15 min (a variance of at most 225 min\({}^{2}\)). The error degrees of freedom, as given in (12.4.8), are

\[\text{df}=(vs-2)(v-1)=2(3s-2)=6s-4\,.\]

Then, using the confidence interval formula (12.4.11) for Tukey's method of pairwise comparisons, the minimum significant difference is

\[\text{msd}\approx\frac{q_{3,6s-4,\,.05}}{\sqrt{2}}\sqrt{\frac{225\times 2}{vs}} =q_{3,6s-4,\,.05}\sqrt{\frac{225}{3s}}\,.\]To obtain msd 10, we require \(0.75q_{3,6s-4,.05}^{2}\leq s\). Sample size is then computed by trial and error as follows:

\[\begin{array}{ccc}s&6s-4&q_{3,6s-4,.05}&0.75q_{3,6s-4,.05}^{2}&\text{Required}\\ \hline\infty&3.31&8.22&s\geq 9\\ 9&50&3.42&8.77&s=9\end{array}\]

So, \(s=9\), and a 9-replicate Latin square would be needed, giving msd \(\approx 3.42\sqrt{\frac{225}{27}}=9.87\,\text{min}\) and requiring \(b=vs=27\) typists and \(r=vs=27\) observations per keyboard layout. 

### Analysis of Youden Designs

#### Analysis of Variance for Youden Designs

The \(s\)-replicate Youden design with \(v\) treatments has complete column blocks of size \(b=vs\) and row blocks forming a balanced incomplete block design with blocks of size \(c\). Each treatment is observed \(r=cs\) times. For the row-column-treatment model (12.3.1) with no interactions, a solution to the normal equations can be shown to be similar to the solution (11.4.9), p. 359, for a balanced incomplete block design; that is,

\[\hat{\tau}_{i}=\frac{c}{\lambda v}Q_{i}\,,\ \text{where}\ Q_{i}=T_{i}-\frac{1}{c}\sum_{h}n_{h,i}B_{h}\,, \tag{12.5.13}\]

for \(i=1\),..., \(v\), where \(\lambda=r(c-1)/(v-1)\).

As in the analysis of a balanced incomplete block design, the estimators of the treatment effects in a Youden design are not independent of the estimators of the row-block effects. As a result, the treatment-effect estimators must be adjusted for row blocks. However, since the column blocks form a randomized complete block design, no adjustment is needed for these. Table 12.7, p. 406, shows the analysis of variance table for a row-column design with no interactions. Using (12.5.13), the adjusted treatment sum of squares given in the table becomes

\[ssT_{\text{adj}}=\sum_{i=1}^{v}Q_{i}\hat{\tau}_{i}=\frac{c}{\lambda v}\sum_{i=1}^{v}Q_{i}^{2}\,,\]

and, because of the complete column blocks, this is exactly the same formula as for a balanced incomplete block design with blocks of size \(k=c\) (see Table 11.7, p. 358).

To test the null hypothesis \(H_{0}^{T}\) of no treatment differences, at significance level \(\alpha\), the decision rule is

\[\text{reject}\ H_{0}^{T}\ \ \ \text{if}\ \frac{msT_{\text{adj}}}{msE}>F_{v-1,d,\alpha}\,,\]

where, as given in Table 12.7, the number of error degrees of freedom for an \(s\)-replicate Youden square is

\[df = bc-b-c-v+2 \tag{12.5.14}\] \[= \ \ \ vsc-vs-c-v+2\] (12.5.15) \[= \ \ (vs-1)(c-1)-(v-1)\,.\]

#### Confidence Intervals for Youden Designs

All treatment contrasts \(\Sigma d_{i}\tau_{i}\) are estimable in all Youden designs. The least squares estimate of the contrast \(\Sigma d_{i}\tau_{i}\) is

\[\sum_{i}d_{i}\tau_{i}\ =\ \frac{c}{\lambda v}\sum_{i}d_{i}Q_{i}\ =\ \left(\frac{v-1}{vs(c-1)}\right)\sum_{i}d_{i}Q_{i}\,,\]

since \(\lambda=r(c-1)/(v-1)\) as for a balanced incomplete block design with \(k=c\). The variance of the corresponding estimator is

\[\text{Var}(\sum_{i}d_{i}\tau_{i})\ =\ \left(\frac{c}{\lambda v}\right)\sum_{i}d_{i}^{2}\sigma^{2}\ =\ \left(\frac{v-1}{vs(c-1)}\right)\sum_{i}d_{i}^{2}\sigma^{2}\,. \tag{12.5.15}\]

Confidence interval formulae for treatment contrasts \(\Sigma d_{i}\tau_{i}\) are the same as those for a balanced incomplete block design with block size \(k=c\); that is,

\[\left(\frac{v-1}{vs(c-1)}\right)\sum_{i}d_{i}Q_{i}\ \ \pm\ \ w\,\sqrt{m\text{s}E\,\left(\frac{v-1}{vs(c-1)}\right)\sum d_{i}^{2}}\,, \tag{12.5.16}\]

where \(w\), as usual, is the critical coefficient for the Bonferroni, Scheffe, Tukey, or Dunnett method, given by

\[w_{B}=t_{(vs-1)(c-1)-(v-1),\alpha/2m}\ \ ;\ \ w_{S}=\sqrt{(v-1)F_{v-1,(vs-1)(c-1)-(v-1),\alpha}}\ \ ;\] \[w_{T}=q_{v,(vs-1)(c-1)-(v-1),\alpha}/\sqrt{2}\ \ ;\ \ w_{D2}=|t|_{v-1,(vs-1)(c-1)-(v-1),\alpha}^{(0.5)}\ \.\]

#### How Many Observations?

The methods of sample-size calculation for an \(s\)-replicate Youden square are analogous to those for computing sample sizes for a balanced incomplete block design. To calculate the number of observations \(r=cs\) per treatment that are required to achieve a power \(\pi(\Delta)\) of detecting a difference \(\Delta\) in the treatment effects for given \(v\), \(\alpha\), and \(\sigma^{2}\), the power tables in Appendix A.7 can be used in the same way as for a balanced incomplete block design (Sect. 11.6). Thus, we need to find \(s\) satisfying

\[cs\geq\frac{2v\sigma^{2}\phi^{2}}{\Delta^{2}}\left[\frac{c(v-1)}{v(c-1)}\right]\,,\]

which reduces to

\[s\geq\frac{2\sigma^{2}\phi^{2}(v-1)}{\Delta^{2}(c-1)}\,.\]

Alternatively, the confidence interval formula (12.5.16) can be used to calculate the sample sizes needed for achieving confidence intervals of a desired width (see Example 12.5.1).

#### Example 12.5.1

Suppose an experiment is run to compare six paint additive formulations (levels 2-7 of the treatment factor) with a standard "control" formulation (level 1) with respect to the drying time (in minutes). Thepoint is sprayed through \(c=4\) different nozzles so that \(c=4\) paints can be sprayed simultaneously. A total of \(b=7s\) panels will each be painted with strips of 4 of the 7 paints (using a standard formulation between each test panel to clean the nozzles and create a washout period). The error variability is expected to be at most \(25\min^{2}\) (standard deviation at most \(5\min\)), and simultaneous \(90\%\) confidence intervals with half-width of at most \(3.5\min\) are required for the six treatment-versus-control contrasts.

A Youden square with 7 rows, 4 columns, and 7 treatments is shown in Table 12.1. Suppose that \(s\) copies (or column randomizations) of this basic square are to be stacked, giving an \(s\)-replicate Youden design with the same number of observations on the experimental and control treatments. The number of error degrees of freedom, given in (12.5.14), is then

\[df=(vs-1)(c-1)-(v-1)=(7s-1)(4-1)-(7-1)=21s-9\,.\]

Using Dunnett's method of multiple comparisons for treatment versus control, the minimum significant difference is

\[msd=w_{D2}\sqrt{msE\times\left(\frac{(v-1)}{vs(c-1)}\right)\times 2}\,,\]

so we require

\[msd\approx w_{D2}\sqrt{\frac{(25)(6)(2)}{(7)s(3)}}\leq 3.5\,,\]

that is,

\[w_{D2}^{2}\leq 0.8575s\,,\]

where \(w_{D2}=|t|_{6,21s-9,.1}^{(.5)}\). Using Table A.10 for the values of \(w_{D2}=|t|_{6,21s-9,.1}^{(.5)}\), we have

\[\begin{array}{ccccc}s&21s-9&w_{D2}=|t|_{6,21s-9,.1}^{(.5)}&w_{D2}^{2}&0.8575s& \mbox{Action}\\ \hline 20&411&2.30&5.29&17.15&\mbox{Decrease }s\\ 6&117&2.32&5.38&5.15&\mbox{Increase }s\\ 7&138&2.32&5.38&6.00&\mbox{Decrease }s\end{array}\]

So we see that \(s=7\) stacked Youden squares would be adequate, requiring \(b=vs=49\) panels and giving \(r=sc=28\) observations on each of the \(v=7\) paint formulations, both experimental and control. If 49 panels are not available for the experiment, then the experimenter would have to be satisfied with wider confidence intervals. 

### Checking the Assumptions on the Model

The error assumptions on the row-column-treatment model (12.3.1) can be checked by plotting the standardized residuals against the run order, the predicted values \(\hat{y}_{ijk}\), the levels of the row blocking factor, the levels of the column blocking factor, the levels of the treatment factor, and the normal scores.

The data collected from a row-column design can be examined by plotting the adjusted observations against the treatment labels. The observations are adjusted by subtracting the least squares estimates for row blocks and column blocks (which are adjusted for treatments):

\[y_{hqi}^{*}=y_{hqi}-(\hat{\theta}_{h}-\hat{\overline{\theta}}_{.})-(\hat{\phi} _{q}-\hat{\overline{\phi}}_{\overline{\phi}})\,. \tag{12.6.17}\]For the \(s\)-replicate Latin square design with \(b=vs\) row blocks and \(c=v\) column blocks, and the row-column-treatment model (12.3.1), the row-block and column-block effect estimators are independent of treatment effects, and (12.6.17) becomes

\[y_{hqi}^{*}=y_{hqi}-\left(\frac{1}{vs}B_{h}-\frac{1}{v^{2}s}G\right)-\left( \frac{1}{v}C_{q}-\frac{1}{v^{2}s}G\right)\,.\]

For other designs, the adjusted observations can be calculated by computer, as shown in Sects. 12.8 and 12.9. Since the variability due to the blocking factors has been extracted from the adjusted observations, the data plots will exhibit less variability than really exists.

#### 12.6.1 _Dairy cow experiment, continued_

For the dairy cow experiment, which was run as a Latin square design, the adjusted observations are plotted against treatment labels in Fig. 12.1. The plot shows how milk yield tended to increase as the quality of the diet improves from roughage (level 1) to limited grain (level 2) to full grain (level 3). The plot is consistent with the results of Example 12.4.1, where simultaneous confidence intervals (with an overall 95% confidence level) showed a significant difference in diets 1 and 3, but were unable to distinguish between diets 1 and 2 and between diets 2 and 3. 

The row-column-treatment model (12.3.1) assumes that the two blocking factors do not interact with each other nor with the treatment factor. If interactions are present, the error variance estimate will be inflated, decreasing the powers of hypothesis tests and widening confidence intervals for treatment contrasts. When the column blocks are complete blocks, the column-treatment interaction can be checked by plotting the row-adjusted observations (as in Chap. 11) against treatments, with plot labels being the column-block labels. Interaction is indicated by nonparallel lines. The row-column interaction can be investigated in the same way using the treatment-adjusted observations and plotting against row labels. The row-treatment interactions can only be investigated if the row blocks are also complete blocks as in Latin square designs.

Figure 12.1: Adjusted data for the dairy cow experiment

### Factorial Experiments in Row-Column Designs

The exercise bike experiment of Example 12.2.1, p. 404, was a factorial experiment with three treatment factors having two levels each. These were "time duration of exercise" (1 and 3 min, coded as 1 and 2), "exercise speed" (40 and 60 rpm, coded as 1 and 2), and "pedal type" (foot pedal and hand bars, coded as 1 and 2). The data were shown in Table 12.6.

If we use the row-column-treatment model with three-digit labels for the treatment combinations, then we can write the model as

\[Y_{hqijk}=\mu+\theta_{h}+\phi_{q}+\tau_{ijk}+\epsilon_{hqijk}\;,\]

where \(\theta_{h}\) is effect of day \(h\), \(\phi_{q}\) is the effect of subject \(q\), and \(\tau_{ijk}\) is the effect of treatment combination \(ijk\). If we now rewrite \(\tau_{ijk}\) in terms of its constituent main effects and interactions, we obtain the following form of the row-column-treatment model:

\[Y_{hqijk} =\mu+\theta_{h}+\phi_{q}+\alpha_{i}+\beta_{j}+\gamma_{k}\] \[\quad\quad\quad\quad\quad+(\alpha\beta)_{ij}+(\alpha\gamma)_{jk} +(\beta\gamma)_{jk}+(\alpha\beta\gamma)_{ijk}+\epsilon_{hqijk}\;,\] \[h=1,\ldots,8\;;\;q=1,2,3\;;\;\;i=1,2\;;\;\;j=1,2\;;\;\;k=1,2\;;\]

where \(\alpha_{i}\) is the effect of the \(i\)th duration, \(\beta_{j}\) is the effect of the \(j\)th speed, and \(\gamma_{k}\) is the effect of the \(k\)th pedal type, and the other terms represent interactions between the treatment factors. The analysis of this experiment by the programs SAS and R software is shown in Sects. 12.8 and 12.9, respectively, for both forms of the model. If some of the treatment interactions are thought to be negligible, they can be dropped from the latter model.

### Using SAS Software

In this section, a sample program is given to illustrate the analysis of row-column designs using the SAS software. The program uses the data of the exercise bicycle experiment, which was described in Example 12.2.1, p. 404. The design is a cyclic row-column design with \(v=8\) treatment labels representing the eight treatment combinations shown in Table 12.6, and with \(b=8\) row blocks representing days and \(c=3\) column blocks representing subject. The treatment combinations were combinations of the levels of the three treatment factors "time duration of exercise," "exercise speed," and "pedal type."

A SAS program for analyzing this experiment is shown in Table 12.10. The data are entered into a data set called BIKE, using DAY and SUBJECT as the two blocking factors, and using DURAT, SPEED, and PEDAL as the three treatment factors, and PULSE for the response variable "pulse rate." The combinations of the levels of the three treatment factors are recoded as levels of a factor TRTMT.

The MODEL statement in the first GLM procedure causes generation of the analysis of variance table shown in Fig. 12.2. The blocking factors are entered into the model before the treatment factor, so the treatment sum of squares is adjusted for block effects whether one looks at the Type I or Type III sums of squares. The row and column effects are independent of each other, since there is one observation at each combination of levels of the row and column blocking factors. Consequently, the Type I sums of squares reproduce the analysis of variance table, Table 12.7, with unadjusted block effects and adjusted treatment effects. In this particular experiment, the column blocks (subjects) are complete blocks, andso the treatment sum of squares is actually only adjusted for row-block (day) effects. The Type III sums of squares show the row-block (day) effects adjusted for the treatment effects.

The ESTIMATE statements request the SAS software to calculate the information needed to calculate three confidence intervals. The three selected contrasts are the main-effect contrasts comparing the effect on pulse rate of the two levels of each treatment factor (averaging over any interaction that might be present). The output, shown in Fig. 12.3, gives the least squares estimates of the contrasts and their associated standard errors. From this information, confidence intervals can be calculated in the usual way. The contrast estimates are adjusted for the incomplete row blocks.

#### Factorial Model

To write the row-column-treatment model in terms of factorial treatment combinations, the model statement in Table 12.10 is replaced by

MODEL PULSE = DAY SUBJECT DURAT SPEED PEDAL DURAT*SPEED  DURAT*PEDAL SPEED*PEDAL DURAT*SPEED*PEDAL; The Type III sums of squares are shown in Fig. 12.4, and we can see that the sums of squares for the main effects and interactions of the three treatment factors do not add to the Type III treatment sum of squares in Fig. 12.2 due to the individual adjustments for block effects and for the other treatment factor effects.

\begin{table}
\begin{tabular}{r r} DATA BIKE; & \\ INPUT DAY SUBJECT PULSE DURAT\$ SPEED\$ PEDAL\$; \\ TRTMT = trim(DURAT) \(||\)trim(SPEED) \(||\)trim(PEDAL); \\ LINES; & \\
1 1 45 1 1 2 \\
1 2 25 2 1 2 \\
1 3 18 2 2 1 \\
2 1 27 2 2 \\ : : & : : : \\
8 3 34 1 1 1 \\ ; \\ PROC PRINT; \\
* row-column-treatment model; \\ PROC GLM; \\ CLASS DAY SUBJECT TRTMT; \\ MODEL PULSE = DAY SUBJECT TRTMT / SOLUTION; \\ OUTPUT OUT=RESIDS PREDICTED=PRED RESIDUAL=2; \\ ESTIMATE ’DURATION DIFF’ TRTMT -1 -1 -1 -1 1 1 1 1 1 / DIVISOR=4; \\ ESTIMATE ’SPEED DIFF’ TRTMT -1 -1 1 1 -1 -1 1 1 / DIVISOR=4; \\ ESTIMATE ’PEDAL DIFF’ TRTMT -1 1 -1 1 -1 1 -1 1 -1 1 / DIVISOR=4; \\
* Standardize residuals and compute normal scores; \\ PROC STANDARD STD=1.0; VAR Z; \\ PROC RANK NORMAL=BLOM; VAR Z; RANKS NSCORE; \\
* Residual plots can now be generated using PROC SGPLOT; \\ \end{tabular}
\end{table}
Table 12.10: SAS program for analysis of a row–column design—Exercise bicycle experiment 

[MISSING_PAGE_EMPTY:8372]

The ESTIMATE statements for the factorial model become

ESTIMATE 'DURATION DIFF' DURAT -1 1;

ESTIMATE 'SPEED DIFF' SPEED -1 1;

ESTIMATE 'FOOT/HAND DIFF' PEDAL -1 1;

and give output identical to that of Fig. 12.3.

#### Plots

The statements needed for calculating the standardized residuals and normal scores are also shown in Table 12.10. Residual plots (not shown here) can then be generated as in Sects. 5.8.1 and 6.8.3.

The SOLUTION option in the MODEL statement causes a set of least squares solutions to the normal equations to be printed. These are subsequently used to calculate the adjusted data values needed for examining the data.

For obtaining the adjusted observations, the statements in Table 12.11 would be added to the program in Table 12.10 for a second and third run of the program. The data are adjusted using (12.6.17); that is,

\[y_{hqi}^{*} = y_{hqi} - (\hat{\theta}_{h} - \hat{\overline{\theta}}.) - (\hat{\phi}_{q} - \hat{\overline{\phi}}.)\;,\]

where \(\hat{\theta}_{h}\) and \(\hat{\phi}_{q}\) are obtained from the output of the SOLUTION option shown in Fig. 12.2. The second run of the program takes as input the values of \(\hat{\theta}_{h}\) and \(\hat{\phi}_{q}\) from the first run of the program and calculates \(\hat{\overline{\theta}}. = \Sigma\hat{\theta}_{h}/3 = 1.25\) and \(\hat{\overline{\phi}}. = \Sigma\hat{\phi}_{q}/8 = 1.66\), which are then copied by hand into the statements for the third run of the program. The symbols @@ allow the input to be entered with more than one record per line.

In the third run of the program, the data set BIKE5 is created as a copy of the data set BIKE. This is done to create the new variable YADJ, which contains the values of PULSE, adjusted for the row and column effects. The SGPLOT procedure is used to plot the adjusted observations by treatment. The SAS plot is analogous to that in Fig. 12.1 (p. 415) and is not shown here.

Figure 12.4: Analysis of variance for a row–column design—Exercise bicycle experiment

### Using R Software

In this section, a sample program is given to illustrate the analysis of row-column designs using the R software. The program uses the data of the exercise bicycle experiment, which was described in Example 12.2.1, p. 404. The design is a cyclic row-column design with \(v=8\) treatment labels representing the eight treatment combinations shown in Table 12.6, and with \(b=8\) row blocks representing days and \(c=3\) column blocks representing subject. The treatment combinations were combinations of the levels of the three treatment factors "time duration of exercise," "exercise speed," and "pedal type."

An R program for analyzing this experiment is shown in Table 12.12. The data are entered into a data set called bike.data, using fDay and fSubject as the two blocking factors, and using fDurat, fSpeed, and fPedal as the three treatment factors, and Pulse for the response variable "pulse rate." The combinations of the levels of the three treatment factors are recoded as levels of a factor fTrttm.

In the second block of code, the linear models function lm is used to fit the row-column-treatment model (12.3.1), then corresponding anova and dropl functions generate the type 1 and type 3

\begin{table}
\begin{tabular}{r} \hline \multicolumn{2}{r}{* Add the following code for the second run of the program;} \\ DATA BIKE3; * input subject effect estimates from first run; \\ INPUT SUBJECT SBJHAT; @@; \\ LINES; \\
1 5.25 2 -1.50 3 0.00 \\ PROC MEANS MEAN; * print average of the subject effect estimates; \\ VAR SBJHAT; \\ DATA BIKE4; * input day effect estimates from first run; \\ INPUT DAY DHAT @@; \\ LINES; \\
1 3.9911 2 1.5625 3 2.5714 4 0.8036 \\
5 2.5179 6 1.6334 7 0.2054 8 0.0000 \\ PROC MEANS MEAN; * print average of the day effect estimates; \\ VAR DHAT; \\
* Add the following code for the third run; \\
* Adjust data for subject and day effects, then plot adjusted data; \\ DATA BIKE5; SET BIKE; \\ IF SUBJECT = 1 THEN YADJ = PULSE-(5.25-1.25); \\ ELSE IF SUBJECT = 2 THEN YADJ = PULSE-(-1.50-1.25); \\ ELSE IF SUBJECT = 3 THEN YADJ = PULSE-(0.00-1.25); \\ IF DAY = 1 THEN YADJ = YADJ-(3.9911-1.660); \\ ELSE IF DAY = 2 THEN YADJ = YADJ-(1.5625-1.6607); \\ ELSE IF DAY = 3 THEN YADJ = YADJ-(2.5714-1.6607); \\ ELSE IF DAY = 4 THEN YADJ = YADJ-(0.8036-1.6607); \\ ELSE IF DAY = 5 THEN YADJ = YADJ-(2.5179-1.6607); \\ ELSE IF DAY = 6 THEN YADJ = YADJ-(1.6334-1.6607); \\ ELSE IF DAY = 7 THEN YADJ = YADJ-(0.2054-1.6607); \\ ELSE IF DAY = 8 THEN YADJ = YADJ-(0.0000-1.6607); \\ PROC SGPLOT; \\ SCATTER X = TRTMT Y = YADJ; \\ X AXIS LABEL = ’Treatment’; REFLINE 0/ AXIS = X; \\ Y AXIS LABEL = ’Adjusted Observations’; REFLINE 0/ AXIS = Y; \\ \hline \end{tabular}
\end{table}
Table 12.11: SAS code for calculating and plotting the adjusted observations—Exercise bicycle experimentanalysis of variance tables, respectively, shown at the top of Table 12.13. The blocking factors are entered into the model before the treatment factor, so the treatment sum of squares is adjusted for block effects whether one looks at the Type I or Type III sums of squares. The row and column effects are independent of each other, since there is one observation at each combination of levels of the row and column blocking factors. Consequently, the Type I sums of squares reproduce the analysis of variance table, Table 12.7, with unadjusted block effects and adjusted treatment effects. In this particular experiment, the column blocks (subjects) are complete blocks, and so the treatment sum of squares is actually only adjusted for row-block (day) effects. The Type I sums of squares show the row-block (day) effects adjusted for the treatment effects.

The summary and contrast functions of the lsmeans package are coupled to calculate estimates, standard errors, tests and confidence for the three main-effect contrasts comparing the effect

on pulse rate of the two levels of each treatment factor (averaging over any interaction that might be present). The corresponding output is shown in the bottom of Table 12.13.

Predicted values and residuals are available, and the residuals can be standardized and plotted as in Sects. 5.9.1 and 6.9.3. Sample code is provided at the bottom of Table 12.12.

\begin{table}
\begin{tabular}{r} \hline \hline \(>\) \# ANOVA: treatment combinations \\ \(>\) mode1TC = lm(Pulse \(\widetilde{\ }\) fDay + fSubject + fTrtmt, data=bike.data) \\ \(>\) anova(modelTC) \\ \end{tabular}
\end{table}
Table 12.13: Analysis of variance and contrast estimation for a row–column design—Exercise bicycle experiment 

#### Factorial Model

To write the row-column-treatment model in terms of factorial effects, the linear models statement in Table 12.12 is replaced by

 modelFE = lm(Pulse ~ fDay + fSubject + fDurat*fSpeed*fDedal,  data=bike.data)  The Type III sums of squares are shown in Table 12.14, and we can see that the sums of squares for the main effects and interactions of the three treatment factors do not add to the Type III treatment sum of squares in Table 12.13 due to the individual adjustments for block effects and for the other treatment factor effects.

The statements to estimate contrasts for the factorial model become

  lsmDurat = lsmeans(modelFE, ~ fDurat)  summary(contrast(lsmDurat, list(DurationDiff=c(-1, l))), infer=c(T,T))  lsmSpeed = lsmeans(modelFE, ~ fSpeed)  summary(contrast(lsmSpeed, list(SpeedDiff=c(-1, l))), infer=c(T,T))  lsmDedal = lsmeans(modelFE, ~ fDedal)  summary(contrast(lsmDedal, list(PedalDiff=c(-1, l))), infer=c(T,T)) and give output identical to that of Table 12.13.

\begin{table}
\begin{tabular}{l} \hline \hline \(>\) \# ANOVA: factorial effects \\ \(>\) modelFE = lm(Pulse ~ fDay + fSubject + fDurat*fSpeed*fDedal, \\ \(+\) data=bike.data) \\ \(>\) anova(modelFE) \\ \(>\) drop1(modelFE, ~\_, test = "F") \\ \end{tabular}
\end{table}
Table 12.14: Analysis of variance for a row–column design—Exercise bicycle experiment

#### Plots

The statements needed for calculating the standardized residuals and normal scores and for generating the residual plots are also shown in Table 12.12. These are as discussed in Sects. 5.9.1 and 6.9.3. The plot statement is used to generate the usual residual plots (not shown here).

The R program in Table 12.15 illustrates how to compute the adjusted observations--namely, the observations adjusted for row and column effect estimates--and how to plot the adjusted observations versus treatment. The data are adjusted using (12.6.17); that is,

\[y_{hqi}^{\ast} = y_{hqi} - (\hat{\theta}_{h} - \hat{\overline{\theta}}_{.}) - (\hat{\phi}_{q} - \hat{\overline{\phi}}_{.})\,.\]

\begin{table}
\begin{tabular}{r} \hline bike.data = read.table(*data/exercise.bicycle.txt*, header=T) \\ \# Create factor variables, plus numeric variable TLevel for plotting \\ bike.data = within(bike.data, \\ \{fDay\textasciitilde{}factor(Day);fSubject=factor(Subject);fDurat=factor(Durat);fSpeed=factor(Speed);fPedal=factor(Pedal);fTrtmt=factor(Trtmt); \\ \# Vb1 TLevel with treatment levels 1:8 for equispaced plotting; \\ TLevel = 4*(Durat-1) + 2*(Speed-1) + (Pedal-1) \}) \\
ANOVA: treatment combinations \\ modelTC = lm(Pulse \textasciitilde{}fDay + fSubject + fTrtmt, data=bike.data) \\
Plotting data adjusted for row and column effects \\ modelTC\$coefficients \# Display all model coefficient estimates \\ \((\)Intercept\()\) fDay2 fDay3 fDay4 fDay5 fDay6 \\ \(41.7500\) -2.4286 -1.4196 -3.1875 -1.4732 -2.3571 \\ fDay7 fDay8 fSubject2 fSubject3 fTrtmt112 fTrtmt121 \\ \(-3.7857\) -3.9911 -6.7500 -5.2500 -1.2143 -14.7054 \\ fTrtmt122 fTrtmt211 fTrtmt212 fTrtmt221 fTrtmt222 \\ \(-9.5714\) -10.1875 -4.1339 -19.9018 -12.6429 \\ thetahat = c(0, modelTC\$coefficients[2:8]) \# Row effect estimates \\ thetamean = mean(thetahat) \# Mean row effect estimate \\ phihat = c(0, modelTC\$coefficients[9:10]) \# Column effect estimates \\ phimean = mean(phihat) \# Mean column effect estimate \\ \# Compute adjusted y-values \\ bike.data\$yadj = ( bike.data\$Pulse \\ - (thetahat[bike.data\$Day] - thetamean) \\ - (phihat[bike.data\$Subject] - phimean) ) \\ \# Plot adjusted response versus treatment \\ plot(yadj \textasciitilde{}TLevel, data=bike.data, xaxt=*n, xlab="Treatment", \\ \(\)ylab="y Adjusted") \\ axis(1, at=bike.data\$TLevel, labels=bike.data\$fTrtmt) \\ \hline \end{tabular}
\end{table}
Table 12.15: R code for calculating and plotting the adjusted observations—Exercise bicycle experiment. Toward this end, having saved the fitted row-column design model as modelTC, the statement modelTCScoefficients displays a set of least squares solutions to the normal equations. These are shown for example in Table 12.15. The row and column effect estimates \(\hat{\theta}_{h}\) and \(\hat{\phi}_{q}\) are obtained from the column modelTC$coefficient of displayed least squares estimates by specifying the appropriate entries, and the mean of each collection of estimates is computed. Given this information, the adjusted observations are computed.

The plot function is used to plot the adjusted observations versus treatment. The adjusted observations are actually plotted against treatment levels 1-8, so the treatment combinations are equally spaced on the \(x\)-axis of the plot, but these equispaced levels are replaced by the treatment combination labels 111-222. The R plot is analogous to that in Fig. 12.1 (p. 415) and is not shown here.

## Exercises

1. **Randomization** 1. Randomize the plan in Table 12.1 (p. 400) so that it can be used for an experiment with seven subjects, each being assigned a sequence of four out of a possible seven antihistamines over four time periods. 2. Discuss whether or not one would need to include a carryover effect in the model, or whether this could be avoided through the design of the experiment.
2. **Latin squares** 1. Show that there is only one standard 3\(\times\)3 Latin square. (Hint: Given the letters in the first row and the first column, show that there is only one way to complete the Latin square.) 2. Show that there are exactly four standard 4\(\times\)4 Latin squares.
3. **Sample sizes** Consider an experiment to compare 4 degrees of twist in a cotton-spinning experiment with respect to the number of breaks per 100 pounds. A replicated Latin square design is to be used, with time periods and machines being the row and column blocking factors. 1. Determine the number \(s\) of Latin squares and the number \(r\) of observations per degree of twist to include in the experiment if each interval in a simultaneous set of 95% confidence intervals for all pairwise comparisons is to have a minimum significant difference (half-width) of 5 breaks per 100 pounds. The error standard deviation is thought to be at most 6 breaks per 100 pounds. Investigate both the Tukey and the Bonferroni methods. 2. Discuss how the resulting design would be randomized.
4. **Youden design randomization** 1. Find a Youden square (plan of treatment labels in rows and columns) for 5 treatments in 5 rows and 4 columns. 2. Randomize the design found in part (a), assigning the rows to 5 different drying temperatures, the columns to 4 different paint nozzles, and the treatment labels to 5 different paint formulations.

5. **Row-column design randomization** Consider an experiment to compare 5 protocols with respect to a resting metabolism rate measurement. A row-column design is to be used, blocking on subjects and time periods. Since subjects prefer to stay in a study for a short length of time, only 3 time periods will be used, with each subject assigned a different protocol in each of the 3 time periods. For 10 subjects, the following experimental plan with 10 rows and 3 columns could be used: 1. Does this experimental plan have treatments evenly distributed across rows and columns? Explain what you mean by "evenly distributed." 2. Determine the number of replicates \(s\) of this experimental plan, and the corresponding number of observations \(r\) per protocol to include in the experiment if each interval in a set of simultaneous 95% confidence intervals for all pairwise comparisons is to have a minimum significant difference (half-width) of 150 units. The error standard deviation is thought to be at most 250 units. Investigate both the Tukey and the Bonferroni methods. 3. Discuss how the resulting design would be randomized.
6. **Video game experiment** Professor Robert Wardrop, of the University of Wisconsin, conducted an experiment in 1991 to evaluate in which of five sound modes he best played a certain video game. The first three sound modes corresponded to three different types of background music, as well as game sounds expected to enhance play. The fourth mode had game sounds but no background music. The fifth mode had no music or game sounds. Denote these sound modes by the treatment factor levels 1-5, respectively. The experimenter observed that the game required no warm up, that boredom and fatigue would be a factor after 4-6 games, and that his performance varied considerably on a day-to-day basis. Hence, he used a Latin square design, with the two blocking factors being "day" and "time order of the game." The response measured was the game score, with higher scores being better. The design and resulting data are given in Table 12.16.

\begin{table}
\begin{tabular}{c c c c c c c c c c} \hline  & \multicolumn{4}{c}{Column} & \multicolumn{4}{c}{Column} \\ Row & I & II & III & Row & I & II & III \\ \hline I & 1 & 2 & 3 & VI & 1 & 2 & 4 \\ II & 2 & 3 & 4 & VII & 2 & 3 & 5 \\ III & 3 & 4 & 5 & VIII & 3 & 4 & 1 \\ IV & 4 & 5 & 1 & IX & 4 & 5 & 2 \\ V & 5 & 1 & 2 & X & 5 & 1 & 3 \\ \hline \end{tabular}
\end{table}
Table 12.16: Latin square design showing treatments and data for the video game experiment 1. Write down a possible model for these data and check the model assumptions. If the assumptions appear to be approximately satisfied, then answer parts (b)-(f). 2. Plot the adjusted data and discuss the plot. 3. Complete an analysis of variance table. 4. Evaluate whether blocking was effective. 5. Construct simultaneous 95% confidence intervals for all pairwise comparisons, as well as the "music versus no music" contrast \[\frac{1}{3}(\tau_{1}+\tau_{2}+\tau_{3})-\frac{1}{2}(\tau_{4}+\tau_{5})\] and the "game sound versus no game sound" contrast \[\frac{1}{4}(\tau_{1}+\tau_{2}+\tau_{3}+\tau_{4})-\tau_{5}\,.\] 6. What are your conclusions from this experiment? Which sound mode(s) should Professor Wardrop use?
7. **Video game experiment, continued** Suppose that in the video game experiment of Exercise 6, Professor Wardop had run out of time and that only the first four days of data had been collected. The design would then have been a Youden design. Repeat parts (c), (e), and (f) of Exercise 6. Do your conclusions remain the same? Is this what you expected? Why or why not?
8. **Air freshener experiment** A. Cunningham and N. O' Connor (1968, _European Journal of Marketing_ 2, 147-151) conducted a two-replicate Latin square design to compare the effects of four price-and-display treatments on the sales of a brand of air fresheners. Treatments 1-3 corresponded to high, middle, and low prices, respectively, and each had an extra display. Treatment 4 corresponded to the middle price and no extra display. The response variable was the unit sales for a one-week period. The experiment involved two blocking factors defined by stores (\(c=8\) levels) and one-week periods (\(b=4\) levels). The design and data are given in Table 12.17. 1. Factors such as product location and shelf stocking could affect sales. Discuss how these factors might be controlled in such an experiment. 2. Check the model assumptions. 3. Plot the adjusted data and comment on the results. 4. Complete an analysis of variance table. 12.17 Latin square design and data for the air freshener experiment \[\begin{array}{c} \begin{array}{c} \begin{array}{c} \begin{array}{c} \begin{array}{c} \begin{array}{c} \begin{array}{c} \begin{array}{c} \begin{array}{c} \begin{array}{c} \begin{array}{c} \begin{array}{c} \begin{array}{c} \begin{array}{c} \begin{array}{c} \begin{array}{c} \begin{array}{c} \begin{array}{c} \begin{array}{c} \begin{array}{c} \begin{array}{c} \begin{array}{c} \begin{array}{c} \end{array}\end{array}\end{array}\end{array}\end{array}\end{array}\end{array}\end{array}\end{array}\end\] \end{array}\end{array}\end{array}\end{array}\] \end{array} } \\ \end{array} \\ \end{array} \end{table}
Table 12.17: Latin square design and data for the air freshener experiment 

[MISSING_PAGE_FAIL:447]

[MISSING_PAGE_EMPTY:8383]

[MISSING_PAGE_FAIL:449]

* Suggest a model for this experiment. By looking at computer calculated interaction degrees of freedom and the adjusted and unadjusted sums of squares, verify that the golfer x driver interaction can be measured based on the full set of \((v-1)^{2}=9\) degrees of freedom, and without adjusting for order or round. Test whether the golfer x driver interaction is significantly different from zero using \(\alpha=0.01\).
* If there is no significant golfer x driver interaction, compare the driver effects (averaged over golfer, order and round) using simultaneous 99% confidence intervals. Which method of multiple comparisons did you use and why? What can you conclude?
* Compare the pairwise effects of the drivers for each golfer, using individual 99% confidence intervals. Which method of multiple comparisons did you use and why? State your overall confidence level and interpret your results.

### 13.1 Introduction

In Chaps. 6 and 7 we discussed factorial experiments arranged as completely randomized designs, and in Chaps. 10 and 11 we looked at factorial experiments arranged as block designs. Factorial experiments that involve several treatment factors tend to be large. Even a modest experiment with four factors having 2, 2, 3, and 3 levels has a total of 36 treatment combinations. Since experimenters generally are working to a restricted budget and since observations cost time and money, many factorial experiments are _single-replicate_ experiments (one observation per treatment combination). In this chapter we consider single-replicate experiments arranged in blocks where every treatment factor has two levels. This will be extended in Chap. 14 to cover treatment factors with more than two levels. Then, in Chap. 15, we will look at experiments in which only a fraction of the treatment combinations can be observed.

In Sect. 13.2, we discuss alternative codings of treatment combinations, and the general problem of confounding together with its implications for analysis. Methods of designing single-replicate experiments so that information is lost on as few lower-order treatment contrasts as possible are the main focus of Sects. 13.3 and 13.4, followed by an example in Sect. 13.5. Section 13.6 describes plans for the design of confounded experiments.

In Sects. 13.7-13.10 we return to the subject of multi-replicate factorial experiments in blocks and compare the traditional incomplete block designs with the multiple use of single-replicate confounded designs. Analysis of confounded factorial experiments by the computer packages SAS and R is considered briefly in Sects. 13.11 and 13.12.

### 13.2 Single Replicate Factorial Experiments

#### 13.2.1 Coding and Notation

A factorial experiment that involves two treatment factors each having two levels is known as a 2 x 2, or 22, experiment. Similarly, an experiment with two factors each having 3 levels is known as a 3 x 3, or 32, experiment. A 24 x 32 experiment has six treatment factors, the first four having two levels each, and the last two having three levels each. Other factorial experiments are described in a similar manner. A factorial experiment is called _symmetric_ if all factors have the same number of levels. Otherwise, it is called _asymmetric_. In this chapter we will deal only with symmetric 2\(p\) experiments. Other situations will be discussed in Chap. 14.

The levels of a two-level treatment factor are often referred to as the "low" and "high" levels, and in Chaps. 6 and 7 we coded these as 1 and 2. The codings 0 and 1, or -1 and +1, are also commonly used. A 22 experiment then has four treatment combinations coded as (11, 12, 21, 22) or as (00, 01, 10, 11) or as (-1 - 1, -1 + 1, +1 - 1, +1 + 1). A fourth standard coding for the treatment combinations is ((1), \(b\), \(a\), _ab_), where the letter \(a\) or \(b\) appears if the corresponding factor \(A\) or \(B\) is at its high level, and is absent if the corresponding factor is at its low level. The symbol (1) means that both factors are at their low level.

Coding is a matter of personal choice. Although we have coded the levels as 1 and 2 until now, the other three codings are more usual when talking about single-replicate factorial experiments. We will code the levels as 0 and 1 throughout this and the next two chapters.

#### Confounding

A factorial experiment with \(v\) treatment combinations uses \(v\) -1 degrees of freedom to measure all of the main effects and interactions. In a single-replicate experiment, there are only \(v\) observations and \(v\) -1 total degrees of freedom. Thus, the experiment is not large enough to allow measurement of all of the factorial effects and also estimation of the error variance. Three ways around this problem for statistical inference in completely randomized designs were discussed in Sects. 6.7 and 7.5.

The problem is worse when the experiment is to be run as a block design. If there are \(b\) blocks in the design, \(b\) -1 of the total degrees of freedom are used to measure the block differences, leaving only \((v - 1) - (b - 1) = \(v\) - \(b\) degrees of freedom available for measuring the treatment contrasts and the error variance. The result of this is that \(b\) -1 of the treatment contrasts can no longer be measured. They cannot be distinguished from block contrasts and are said to be _confounded_ with blocks. Such a design is useful only when at most \(v\) - \(b\) treatment contrasts are to be measured.

Care is required in designing this type of experiment. If \(v\) treatment combinations are arbitrarily divided into \(b\) blocks of size _v_/_b_, the important treatment contrasts will not necessarily be estimable. The estimable contrasts are those that are orthogonal to the confounded contrasts. This means that the experiment should be designed in such a way that the confounded contrasts belong only to interactions that are expected to be negligible. Fortunately, in some cases this is not difficult to achieve, and we will examine these cases in this chapter. For a 2\(p\) experiment, we will restrict attention to designs with \(b\) = 2\(s\) blocks of size \(k\) = 2_p_-_s_.

#### Analysis

The standard block-treatment model for a single-replicate factorial experiment arranged as an incomplete block design has the same form as model (11.4.2), p. 356, used for incomplete block designs in Chap. 11; that is,

\[\begin{array}{l} {Y_{hi} = \mu + \theta_{h} + \tau_{i} + \epsilon_{hi}} \\ {\epsilon_{hi} \sim N(0,\sigma^{2})} \\ {\epsilon_{hi}}^{\prime}\text{s are mutually independent} \\ h = 1, \ldots, {b};\quad i = 1, \ldots, {v};\quad(h,i)\text{ is in the design}. \end{array}\]

As usual, _Yhi_ is the random variable representing the observation on treatment combination \(i\) in block \(h\) (if it appears in the design), _eh__hi_ is the corresponding error random variable, \(m\) is a constant, \(t_{i}\) is the effect of the _i_th treatment combination, and _th__h_ is the effect of the _h_th block. The block x treatment interaction is assumed to be negligible.

Analysis of all single-replicate designs described in this chapter is straightforward. Because of the way in which the designs will be constructed, contrasts in the important main effects and interactions will be completely orthogonal to block contrasts. As a consequence, these contrasts will have no adjustment for blocks, and their estimates and sums of squares can be calculated in exactly the same way as for completely randomized designs (see Chaps. 6 and 7). An outline of an analysis of variance table is shown in Table 13.1. The maximum number of degrees of freedom available for estimating main effects and interactions is \(v-b\) if no estimate of the error variance is required; otherwise, it is \(v-b-1\). The unadjusted sum of squares for blocks ss\(\theta\) can be calculated either as the total of all the confounded contrast sums of squares or by the usual formula, which was given in Table 11.7, p. 358, as

\[\text{ss}\theta=\frac{1}{k}\,\Sigma_{h}\,B_{h}^{2}-\frac{1}{v}\,G^{2}\,, \tag{13.2.2}\]

where \(B_{h}\) is the total of the observations in the \(h\)th block and \(G\) is the grand total of all the observations.

### 13.3 Confounding Using Contrasts

#### Contracts

Treatment contrasts for factorial experiments were discussed in Sects. 6.3, 7.2.4, and 7.3. When there are two factors, \(A\) and \(B\), each having two levels, there are \(v=4\) treatment combinations in total, and it is possible to find a set of three orthogonal contrasts, one for the main effects of each of \(A\) and \(B\) and one for their interaction. The coefficient lists [\(c_{00}\), \(c_{01}\), \(c_{10}\), \(c_{11}\)] for these contrasts are

\[\text{For }A: \quad[\,-1,\,-1,\quad 1,\,\,1\,],\] \[\text{For }B: \quad[\,-1,\,\,1,\,-1,\,\,1\,],\] \[\text{For }AB: \quad[\,\,\,1,\,-1,\,\,-1,\,\,\,1\,].\]

Each coefficient for the \(AB\) interaction is the product of the corresponding coefficients for the main effects of \(A\) and \(B\). Similarly, for three factors, the coefficient lists for the seven contrasts are shown in Table 13.2 written as columns. The interaction coefficients are, again, the product of corresponding main-effect coefficients. The row labels in Table 13.2 are the treatment combinations (in lexicographical order) whose observations are to be multiplied by the contrast coefficients when estimating the contrast. The seven contrasts are orthogonal. This can be verified by multiplying together corresponding digits

\begin{table}
\begin{tabular}{c c c c} \hline Source of variation & Degrees of freedom & Sum of squares \\ \hline Blocks & \(b-1\) & ss\(\theta=\frac{1}{k}\,\Sigma\,B_{h}^{2}-\frac{1}{v}\,G^{2}\) \\  & & \(\vdots\) & \(\vdots\) \\ constructed by the methods of this chapter & \(\Sigma\,c_{i}\tau_{i}\) & 1 & ss\(c=\frac{(\Sigma\,\Sigma\,c_{ij}\tau_{ij})^{2}}{\Sigma\,c_{i}^{2}}\) \\ (at most \(v-b\) of these) & & & \\  & & \(\vdots\) & \(\vdots\) \\ Error & \(df\) (by subtraction) & ss\(E\) (by subtraction) \\ Total & \(v-1\) & ss\(\text{tot}=\Sigma\,\Sigma y_{hi}^{2}-\frac{1}{v}\,G^{2}\) \\ \hline \end{tabular}
\end{table}
Table 13.1: Outline analysis of variance table for single-replicate factorial experiments constructed by the methods of this chapter in any two columns and showing that the sum of the products is zero. A table of orthogonal contrasts, such as Table 13.2, is sometimes called an _orthogonal array_.

Such contrasts in a \(2^{p}\) experiment all have the same variance, since \(\Sigma c_{i}^{2}=v=2^{p}\) for all contrasts and \(\text{Var}(\Sigma c_{i}\,\hat{\tau}_{i})=\Sigma c_{i}^{2}\sigma^{2}=v\sigma^{2}\). The main effect of \(A\) is often measured by the \(A\) contrast divided by \(v/2\), so that it compares the average of all treatment combinations at the high level of \(A\) with the average of the treatment combinations at the low level. If the interaction contrast coefficients are also divided by \(v/2\), the contrast estimators all have variance \(\sum c_{i}^{2}\sigma^{2}=4\sigma^{2}/v\), and the \(AB\) interaction, for example, then compares the average response when factors \(A\) and \(B\) are at the same level with the average response when they are at different levels. We shall use either \(v/2\) or \(1\) for the divisor for all contrasts in \(2^{p}\) experiments both here and in Chap. 15.

#### Experiments in Two Blocks

We start with an example. Suppose that a single-replicate \(2^{3}\) experiment is to be run in two blocks of size four. Suppose also that the experimenter knows that one of the factors, say factor \(A\), does not interact with either of the other two factors. This means that the interactions \(AB\), \(AC\), and \(ABC\) may be assumed to be negligible and that the contrasts labeled \(A\), \(B\), \(C\), and \(BC\) in Table 13.2 are the only contrasts to be measured.

Since there will be \(b=2\) blocks, it follows that \(b-1=1\) degree of freedom will be used to measure block differences and one treatment contrast will be confounded with blocks. Without too much difficulty, we can ensure that the confounded contrast is one of the negligible contrasts. For example, we can confound the negligible \(ABC\) contrast by placing in one block those treatment combinations corresponding to \(-1\) in the \(ABC\) contrast, and placing in the second block those treatment combinations corresponding to \(+1\) in the same contrast. Referring to Table 13.2, we can see that the design in Table 13.3 results. The \(ABC\) contrast is now identical to a block contrast that compares Block I with Block II, and consequently, the \(ABC\) contrast is confounded with blocks. The other two negligible contrasts, \(AB\) and \(AC\), provide two degrees of freedom to estimate \(\sigma^{2}\). Since all the nonnegligible factorial contrasts are orthogonal to \(AB\), \(AC\), and \(ABC\), they can be measured as though there were no blocks present. Block design randomization (see Sect. 11.2.2) needs to be carried out before the design in Table 13.3 can be used in practice.

\begin{table}
\begin{tabular}{c c c c c c} \hline Block I & 000 & 011 & 101 & 110 \\ Block II & 001 & 010 & 100 & 111 \\ \hline \end{tabular}
\end{table}
Table 13.3: \(2^{3}\) experiment in 2 blocks of 4, confounding \(ABC\)A similar method of confounding can be used for any \(2^{p}\) experiment in \(b=2\) blocks of size \(k=2^{p-1}\). All factorial contrasts except for the one confounded contrast can be estimated.

#### 13.3.1 Field experiment

The data shown in Table 13.4 form part of the results of a field experiment on the yield of beans using various types of fertilization. The experiment was conducted at Rothamsted Experimental Station in 1936 and was reported by W.G. Cochran and G.M. Cox in their book _Experimental Designs_. There were four treatment factors each at two levels. Factor \(A\) was the amount of dung (0 or 10 tons) spread per acre, factors \(B\), \(C\), and \(D\) were the amounts of nitrochalk (0 and 45 lb), superphosphate (0 and 67 lb), and muriate of potash (0 and 112 lb), respectively, per acre. The experimental area was divided into two possibly dissimilar blocks of land, each of which was subdivided into eight plots (experimental units). Since this was a single-replicate experiment with \(2^{4}=16\) treatment combinations (TC) divided into \(b=2\) blocks of size \(k=8\), one treatment contrast had to be confounded. The experimenters chose to confound the _ABCD_ contrast, since the four-factor interaction was of least interest.

The _ABCD_ contrast is shown below, and it can be verified that the treatment combinations corresponding to contrast coefficient \(+1\) appear in Block I of Table 13.4, while those corresponding to coefficient \(-1\) appear in Block II. All the other factorial contrasts are orthogonal to the _ABCD_ contrast, so they can all be estimated without adjusting for the block effects. We take as examples the \(B\) and \(BC\) contrasts shown below.

Using rule 10 of Sect. 7.3, the least squares estimate of the \(B\) contrast is \(\overline{y}_{\ldots 1}\ldots\overline{y}_{\ldots 0\ldots}=\frac{1}{8}\Sigma c_{ijkl} y_{hijkl}\), where the sum is to be taken over the four subscripts, and the contrast coefficients \(c_{ijkl}\) are given in

\begin{table}
\begin{tabular}{c c c c} \hline \hline  & Block I & \multicolumn{2}{c}{Block II} \\ TC & Yield & TC & Yield \\ \hline
0000 & 58 & 0001 & 55 \\
0011 & 51 & 0010 & 45 \\
0101 & 44 & 0100 & 42 \\
0110 & 50 & 0111 & 36 \\
1001 & 43 & 1000 & 53 \\
1010 & 50 & 1011 & 55 \\
1100 & 41 & 1101 & 41 \\
1111 & 44 & 1110 & 48 \\ \hline \hline \end{tabular}
\end{table}
Table 13.4: Data for the field experiment (_ABCD_ is confounded)standard order above. Multiplying the contrast coefficients by the data values, we obtain

\[\text{For }B:\tfrac{1}{8}\sum c_{ijkl}y_{hijkl} = -8.00.\]

Similarly, if we divide the \(BC\) contrast shown above by the same divisor \(v/2\), we obtain the contrast estimate

\[\text{For }BC:\tfrac{1}{8}\sum c_{ijkl}y_{hijkl} =\tfrac{1}{8}(y_{\ldots 00}-y_{\ldots 01}-y_{\ldots 10}+y_{\ldots 11}) = 2.25.\]

Using (6.7.53), the sum of squares for testing the hypothesis that the main effect of \(B\) is negligible is

\[\text{ss}B=\frac{\left(\tfrac{1}{8}\sum c_{ijkl}y_{hijkl}\right)^{2}}{\sum\left( \tfrac{1}{8}c_{ijkl}\right)^{2}}=\frac{(-8.00)^{2}}{\tfrac{16}{64}}=256.0.\]

Similarly, the sum of squares for testing the hypothesis that the interaction between \(B\) and \(C\) is negligible is

\[\text{ss}(BC)=\frac{(2.25)^{2}}{\tfrac{16}{64}}=20.25.\]

An alternative way to calculate the sums of squares is to use the method of Sect. 7.3. Following the rules in that section, we obtain

\[\text{ss}B =acd\sum_{j}\overline{y}_{\ldots j\ldots}^{2}-abcd\overline{y}_ {\ldots\ldots}^{2}\] \[=8\left[(51.25)^{2}+(43.25)^{2}\right]-16(47.25)^{2} = 256.0\,,\]

and

\begin{table}
\begin{tabular}{c c c c} \hline Source of variation & Degrees of freedom & Sum of squares & Contrast estimate (divisor \(v/2\)) \\ \hline Block (\(ABCD\)) & 1 & 2.25 & \\ \(A\) & 1 & 2.25 & \(-0.75\) \\ \(B\) & 1 & 256.00 & \(-8.00\) \\ \(C\) & 1 & 0.25 & 0.25 \\ \(D\) & 1 & 20.25 & \(-2.25\) \\ \(AB\) & 1 & 6.25 & 1.25 \\ \(AC\) & 1 & 81.00 & 4.50 \\ \(AD\) & 1 & 0.00 & 0.00 \\ \(BC\) & 1 & 20.25 & 2.25 \\ \(BD\) & 1 & 12.25 & \(-1.75\) \\ \(CD\) & 1 & 1.00 & 0.50 \\ \(ABC\) & 1 & 16.00 & \(-2.00\) \\ \(ABD\) & 1 & 16.00 & 2.00 \\ \(ACD\) & 1 & 20.25 & 2.25 \\ \(BCD\) & 1 & 121.00 & \(-5.50\) \\ Total & 15 & 575.00 & \\ \hline \end{tabular}
\end{table}
Table 13.5: Analysis of variance for the field experiment \[ss(BC) = ad\sum_{j}\sum_{k}\overline{y}_{..jk.}^{2}-acd\sum_{j}\overline{y}_{.. j..}^{2}-abd\sum_{k}\overline{y}_{..k.}^{2}+abcd\overline{y}_{.....}^{2}\] \[= 4\left[(52.25)^{2}+(50.25)^{2}+(42.00)^{2}+(44.50)^{2}\right]\] \[-8\left[(51.25)^{2}+(43.25)^{2}\right]-8\left[(47.125)^{2}+(47.375 )^{2}\right]\] \[+16(47.25)^{2}\ \ =\ \ 20.25.\]

The complete analysis of variance table is shown in Table 13.5. The important contrasts can be identified using one of the methods of Sect. 7.5. A half-normal probability plot of the 14 contrast estimates is shown in Fig. 13.1. Note that we have not included the confounded _ABCD_ contrast in the half-normal probability plot. Although it is not the case here, the block effect is usually expected to be large and may draw attention away from the important treatment contrasts.

The contrasts \(B\), _BCD_, and _AC_ may or may not be important, since their plotted points roughly line up with those of the seven smallest absolute estimates, but not with those of the 11 smallest absolute estimates. Suppose they are considered important. We notice that the contrast estimate for \(B\) is negative, suggesting that the addition of nitrochalk decreased the yield of beans when averaged over the levels of \(A\), \(C\), and \(D\). The interaction plot for _BCD_ is shown in Fig. 13.2 and that for _AC_ in Fig. 13.3. We see from Fig. 13.2 that the _BCD_ interaction can be characterized by the fact that the _CD_ interaction changes as \(B\) changes from its low level to its high level. If the objective of the experiment is to increase yield, then comparison of the two plots in Fig. 13.2 suggests that \(B\) should be set at its low level, unless

Figure 13.2: _BCD_ interaction plot for the field experiment

Figure 13.3: _BCD_ interaction plot for the field experiment

the high level of \(C\) and the low level of \(D\) are used. This tends to agree with the earlier observation that the contrast estimate for \(B\) is negative, suggesting that the low level is better. If \(B\) is set at its low level, the left-hand graph of Fig. 13.2 suggests that both \(C\) and \(D\) should be at their low levels. The \(AC\) interaction plot in Fig. 13.3 shows that either both \(C\) and \(A\) should be at their low levels or both \(C\) and \(A\) should be at their high levels. The contrast estimators for \(A\) and \(D\) are both negative, suggesting that on average the low level is better, although the difference in yield is minor. More importantly, the low levels in this experiment are cheaper. Therefore, all the evidence points towards not adding any fertilizer ingredients in the quantities studied in the experiment. A followup experiment could be run with the same four factors but with an increased "high" level of \(C\) and lower "high" levels of \(A\), \(B\), and \(D\). Since it is possible that the response is quadratic for each of the factors, a \(3^{4}\) experiment could be run.

Suppose the experimenters had known ahead of time that factors \(A\) and \(D\) do not interact, so that interactions \(AD\), \(ABD\) and \(ACD\) could have been assumed negligible; then the corresponding terms would have been omitted from the model. There would then have been 3 degrees of freedom for estimating the error variance. The error sum of squares would have been the total of the sums of squares for \(AD\), \(ABD\), and \(ACD\) listed in Table 13.5, so that

\[\hat{\sigma}^{2}=\text{ms}E=\frac{1}{3}(\text{ss}(AD)+\text{ss}(ABD)+\text{ss} (ACD))=\frac{1}{3}(36.25)=12.0833.\]

The analysis of variance table would then have been as shown in Table 13.6, and we see that at an overall significance level of at most \(\alpha=11(0.005)=0.055\), none of the contrasts would have been judged as significantly different from zero, since \(F_{1,3,0.005}=55.55\).

Confidence intervals could be calculated for each contrast at an overall confidence level of at least 94.5%, using the Bonferroni method (formula (4.4.21)) with each interval at individual level 99.5%, with error degrees of freedom df = 3 and with \(r_{i}=8\) being the number of observations averaged over to obtain the estimate. For example, a confidence interval for the difference in the high and low levels of \(B\) is

\[\beta_{1}^{*}-\beta_{0}^{*} \in \left(\frac{1}{8}\Sigma c_{ijkl}y_{hijkl}\pm t_{3,0.0025}\sqrt{ \text{ms}E\left(16/64\right)}\ \right)\] \[= \left(-8\pm 7.4532\times 1.7381\right)\ \ =\ \ \left(-20.954,4.954\right).\]

Figure 13.3: \(AC\) interaction plot for the field experiment

We remind the reader that if both of the above analyses are done, that is, if the interactions \(AD\), \(ABD\), and \(ACD\) are dropped from the model after examining the half-normal probability plot, then it is no longer meaningful to talk about the significance levels of the tests or the confidence interval levels (see Sect. 6.5.6, p. 170). 

#### Experiments in Four Blocks

We can extend the method of confounding that we used for two blocks to obtain \(b=4=2^{2}\) blocks. We then need to use two contrasts to divide up the treatment combinations. For example, suppose that in a \(2^{4}\) experiment, all interactions except for the two-factor interactions are thought to be negligible. We can select one of the negligible interactions to produce two blocks of size 8 and then select a second interaction to subdivide each of these two blocks into two smaller blocks, giving a total of 4 blocks of size 4. Since \(b-1=3\) degrees of freedom are needed to measure blocks, a third treatment contrast must also be confounded. We require this third contrast to be among the negligible contrasts, so care must be taken as to which pair of contrasts is initially selected for confounding. The choice of \(ABCD\) and \(ABC\), for example, is a very poor choice even if these high-order interactions may be thought to be negligible. We can see this by examining the design and the third confounded contrast as follows.

The two contrasts and the corresponding treatment combinations (TC) are shown in Table 13.7. The treatment combinations are divided into 2 blocks of size 8 according to the coefficients in the \(ABCD\) contrast. Each of these blocks is then subdivided into 2 blocks of size 4 according to the coefficients in the \(ABC\) contrast. The \(b=4\) blocks of size \(k=4\) are therefore determined by the pairs of coefficients \((ABCD,\,ABC)=(-1,\,-1)\) or \((-1,\,1)\) or \((1,\,-1)\) or \((1,\,1)\) in the two contrasts. The resulting design is shown in Table 13.7 (prior to randomization).

Examination of the blocks in the design shows that all of the treatment combinations in Block I and Block IV have the fourth digit equal to 1, and all of those in Blocks II and III have the fourth digit equal to 0. This means that the high and low levels of factor \(D\) cannot be compared within the same block, and therefore the contrast for the main effect of \(D\) must be the third contrast confounded with blocks.

\begin{table}
\begin{tabular}{c c c c c c} \hline Source of variation & Degrees of freedom & Sum of squares & Mean square & Ratio & \(p\)-value \\ \hline Block & 1 & 2.25 & 2.25 & \(-\) & \(-\) \\ \(A\) & 1 & 2.25 & 2.25 & 0.186 & 0.6952 \\ \(B\) & 1 & 256.00 & 256.00 & 21.186 & 0.0193 \\ \(C\) & 1 & 0.25 & 0.25 & 0.021 & 0.8947 \\ \(D\) & 1 & 20.25 & 20.25 & 1.676 & 0.2861 \\ \(AB\) & 1 & 6.25 & 6.25 & 0.517 & 0.5240 \\ \(AC\) & 1 & 81.00 & 81.00 & 6.703 & 0.0811 \\ \(BC\) & 1 & 20.25 & 20.25 & 1.676 & 0.2861 \\ \(BD\) & 1 & 12.25 & 12.25 & 1.014 & 0.3882 \\ \(CD\) & 1 & 1.00 & 1.00 & 0.083 & 0.7923 \\ \(ABC\) & 1 & 16.00 & 16.00 & 1.324 & 0.3332 \\ \(BCD\) & 1 & 121.00 & 121.00 & 10.014 & 0.0507 \\ Error & 3 & 36.25 & 12.0833 & & \\ Total & 15 & 575.00 & & & \\ \hline \end{tabular}
\end{table}
Table 13.6: Analysis of variance for the field experiment We could have predicted this outcome, since if corresponding coefficients of the two contrasts _ABCD_ and _ABC_ shown in Table 13.7 are multiplied together, the coefficients of the \(D\) contrast results. Notice that in symbols, we can write

\[(ABCD)(ABC) = A^{2}B^{2}C^{2}D = D,\]

where any letter with exponent 2 is ignored. The squared coefficients of any 2\(p\) factorial contrast are all +1, so multiplying the \(D\) contrast by \(C\)2, say, is the same as multiplying the contrast coefficients by +1 and \(C\)2_D_. Multiplication of the contrast names in this way gives a quick, easy method of checking which third contrast is confounded without writing out the contrasts and without writing out the design.

The above design is not suitable for the stated experiment. Suppose that the contrasts _ABD_ and _BCD_ were selected for confounding instead. The third confounded contrast would then be \((ABD)(BCD) = AB^2CD^{2} = AC.\) This, too, is not suitable since all two-factor interactions were to have been measured. Unfortunately, there is no choice that will meet the specifications of this particular experiment. The number of blocks and the block sizes are too small to measure everything that is required. At least one two-factor interaction would have to be sacrificed, or a larger experiment must be run.

##### 25 experiment in 4 blocks of 8

In Sect. 13.5 we will describe a 25 experiment that was run in \(b = 4\) blocks of size \(k = 8\). In designing such an experiment, one needs to select two contrasts for confounding and to check that the third confounded contrast is acceptable. As in the discussion above, selecting the 5-factor interaction for confounding will generally be a poor choice, since no matter which other interaction is selected for the second confounded interaction, a 2-factor interaction or main effect will be among the confounded contrasts. For example,

\[(ABCD)(ABCDE) = E\;\;\text{and}\;\;(ABC)(ABCDE) = DE.\]

If an experimenter knew ahead of time that factors \(D\) and \(E\) do not interact, then the second choice might be acceptable. In general, though, most experimenters would prefer not to confound low-order interactions. So, a selection of a 3-factor interaction and a 4-factor interaction with as few letters in common as possible will generally be the best choice. For example,

\begin{table}
\begin{tabular}{c c c c c c c c} TC & 0000 & 0001 & 0010 & 0011 & 0100 & 0101 & 0110 & 0111 \\ _ABCD_ & 1 & −1 & −1 & 1 & −1 & 1 & 1 & −1 \\ _ABC_ & −1 & −1 & 1 & 1 & 1 & 1 & −1 & −1 \\ TC & 1000 & 1001 & 1010 & 1011 & 1100 & 1101 & 1110 & 1111 \\ _ABCD_ & −1 & 1 & 1 & −1 & 1 & −1 & −1 & 1 \\ _ABC_ & 1 & 1 & −1 & −1 & −1 & −1 & 1 & 1 \\ \end{tabular}
\end{table}
Table 13.7: 24 experiment in 4 blocks of 4, confounding _ABCD_, _ABC_, _D_\[(ABCD)(CDE)=ABE.\]

There are many selections of this type, and the experimenter would wish to avoid confounding any 3-factor interaction that might be of some interest. The selection made in Sect. 13.5 is \(ABD\), \(BCE\), and their product \(ACDE\). If the treatment combinations are written out in standard order together with the contrast coefficients for \(ABD\) and \(BCE\), it can be verified that the pairs of contrast coefficients give the four blocks shown in Table 13.11 (p. 448). 

#### Experiments in Eight Blocks

If an experiment is required in \(b=2^{3}\) blocks, then three contrasts must be selected for confounding. A single-replicate design in eight blocks confounds \(b-1=7\) treatment contrasts in total, including the three contrasts initially selected and all products of these. For example, suppose that a \(2^{6}\) experiment is required in \(b=2^{3}=8\) blocks of 8, and that the two-factor interactions are of interest together with the four three-factor interactions \(ACE\), \(ACD\), \(ADE\), and \(CDE\) (these are the four 3-factor interactions that do not contain \(B\) or \(F\)). A suitable choice might be to confound the interactions \(BCD\), \(ABE\), and \(ADF\). The other four confounded contrasts would be

\[(BCD)(ABE) = \ ACDE,\] \[(BCD)(ADF) = \ ABCF,\] \[(ABE)(ADF) = \ BDEF,\] \[(BCD)(ABE)(ADF) = \ CEF.\]

The list of seven confounded contrasts is called the _confounding scheme_ for the design. The reader is invited to write out the three selected contrasts and verify that the design in Table 13.10 (p. 446) results. The fact that \(ACDE\), \(ABCF\), \(BDEF\), and \(ABE\) are also confounded can be verified by showing that the coefficients of each of these four contrasts are constant for all treatment combinations within each block.

Note that the same design will be obtained for any initial selection of three of the above seven confounded contrasts, _provided that no selected contrast is a product of the other two_. For example, suppose that \(ABCF\), \(ABE\), and \(CEF\) are initially selected. The selected contrasts \(ABCF\) and \(ABE\) divide the treatment combinations into four blocks, but \(CEF\) does not subdivide these blocks further, since it is the third contrast automatically confounded in the four blocks, i.e., \((ABCF)(ABE)=CEF\). A different third contrast needs to be chosen, and any of the remaining four contrasts will do. Three selected contrasts satisfying the requirement that no selected contrast be a product of the other two is called a set of three _independent_ contrasts.

#### Experiments in More Than Eight Blocks

The same ideas can be used for \(2^{p}\) experiments in \(2^{s}\) blocks of size \(k=2^{p-s}\) by selecting \(s\) independent contrasts to subdivide the treatment combinations into blocks; \(s\) contrasts are independent if none can be obtained as the product of two or more of the other \(s-1\) contrasts. Although the multiplication of contrast names is a convenient method to determine the list of confounded contrasts, it becomes harder to use the contrasts themselves for constructing the design as the number of factors increases.

In the next section, we present a method of constructing block designs for single-replicate factorial experiments that avoids writing out the contrasts.

### Confounding Using Equations

#### Experiments in Two Blocks

The design in Table 13.8 (given previously in Table 13.3) was constructed by allocating the treatment combinations to blocks in such a way that the contrast that compares Block I with Block II is identical to the _ABC_ contrast. The _ABC_ contrast is confounded with blocks and cannot be estimated, but all of the other factorial contrasts are estimable because they are orthogonal to the confounded contrast.

If the treatment combinations in the two blocks of the design are examined closely, an interesting property becomes apparent. All the treatment combinations in the first block have an even number of 1's, and all those in the second block have an odd number of 1's. We could, in fact, have predicted this property. The _ABC_ contrast is the product of the \(A\), \(B\), and \(C\) contrasts (see Sect. 13.3.1), and so the only way to achieve a coefficient -1 in the _ABC_ contrast is for there to be an odd number of -1's among the corresponding coefficients in the \(A\), \(B\), and \(C\) contrasts. This means that there must be an odd number of 0's and an even number of 1's in the corresponding treatment combination. Thus, if we want to confound _ABC_ without writing out the contrasts, we can simply allocate a treatment combination \(a\)1_a_2\(a\)3 to Block I if it has an even number of 1's among its digits, and to Block II if it has an odd number of 1's. Equivalently, we allocate \(a\)1_a_2\(a\)3 to Block I if \(a\)1_ + \(a\)2_ + \(a\)3 is an even number and to Block II if \(a\)1_ + \(a\)2_ + \(a\)3 is an odd number. Instead of writing "_a_1_ + \(a\)2_ + \(a\)3 is an even number," we write "_a_1_ + \(a\)2_ + \(a\)3 = 0 (mod 2)" and instead of writing "_a_1_ + \(a\)2_ + \(a\)3 is an odd number," we write "_a_1_ + \(a\)2_ + \(a\)3 = 1 (mod 2)". Working mod 2, or modulo 2, means that we subtract 2 repeatedly from the number until we reach either 0 or 1, or equivalently, we divide by 2 and take the remainder which is either 0 or 1. For example, 5 = 1 (mod 2), but 8 = 0 (mod 2). We call the pair of equations "_a_1_ + \(a\)2_ + \(a\)3 = 0 (mod 2)" and "_a_1_ + \(a\)2_ + \(a\)3 = 1 (mod 2)" the _confounding equations_. The design of Tables 13.3 and 13.8 is constructed using the following rule:

\[\begin{array}{l} {\text{Block I: Treatment combinations with}\,a_{1}+a_{2}+a_{3}=0\,({\text{mod 2}})\,,}\\ {\text{Block II: Treatment combinations with}\,a_{1}+a_{2}+a_{3}=1\,({\text{mod 2}})\,.}\end{array}\]

If the _AC_ contrast were to be confounded in the 23 experiment instead of the _ABC_ contrast, only the first and third digits of each treatment combination would be used to allocate it to a block. This is because only the first and third digits of the treatment combination govern the coefficients in the _AC_ contrast. We would use the pair of confounding equations \(a\)1_ + \(a\)3 = 0 (mod 2) and \(a\)1_ + \(a\)3 = 1 (mod 2), and the design would be constructed using the rule

\[\begin{array}{l} {\text{Block I: Treatment combinations with}\,a_{1}+a_{3}=0\,({\text{mod 2}})\,,}\\ {\text{Block II: Treatment combinations with}\,a_{1}+a_{3}=1\,({\text{mod 2}})\,,}\end{array}\]

giving the design of Table 13.9. It can be verified that _AC_ is indeed confounded with blocks in this design, since the coefficients of the _AC_ contrast (shown in Table 13.2) are all equal to +1 for the

\begin{table}
\begin{tabular}{c c c c c} Block I: & Treatment combinations with \(a\)1_ + \(a\)3 = 0 (mod 2) & & & \\ Block II: Treatment combinations with \(a\)1_ + \(a\)3 = 0 (mod 2) & & & \\ Block II: Treatment combinations with \(a\)1_ + \(a\)2_ + \(a\)3 = 1 (mod 2) & & & \\ \end{tabular}
\end{table}
Table 13.8: 23 experiment treatment combinations in Block I and -1 for those in Block II. All other contrasts are estimable because they are orthogonal to the confounded _AC_ contrast.

We may now generalize to 2\(P\) experiments in 2 blocks of size 2_P_-1. If the interaction \(A^{z_{1}}B^{z_{2}}C^{z_{3}}\cdots P^{z_{P}}\) is to be confounded with blocks, where \(z_{i}=1\) if the factor is present in the interaction and \(z_{i}=0\) if it is not, the blocks of the design are

\[\begin{array}{ll}\text{Block I:}&\text{Treatment combinations with}\\ &z_{1}a_{1}+z_{2}a_{2}+z_{3}a_{3}+\cdots+z_{P}a_{P}=0\;(\text{mod}\;2)\,,\\ \text{Block II:}&\text{Treatment combinations with}\\ &z_{1}a_{1}+z_{2}a_{2}+z_{3}a_{3}+\cdots+z_{P}a_{P}=1\;(\text{mod}\;2)\,.\end{array}\]

#### Experiments in More Than Two Blocks

We obtain designs with 4, 8, 16, \(\ldots\) blocks by using more than one pair of confounding equations. We label the pairs of confounding equations as \(L_{1}\), \(L_{2}\), etc. For example, the (unsatisfactory) design

\[\begin{array}{ll}&\text{Block Treatment Combinations}\\ \text{I}&0000\;0110\;1010\;1100\\ \text{II}&0011\;0101\;1001\;1111\\ \text{III}&0001\;0111\;1011\;1101\\ \text{IV}&0010\;0100\;1000\;1110\end{array}\]

from Table 13.7 for a 24 experiment in 4 blocks of size 4 was produced by confounding the _ABCD_ and _ABC_ contrasts. Using the _ABCD_ contrast to produce two blocks is equivalent to using the pair of confounding equations \(L_{1}=a_{1}+a_{2}+a_{3}+a_{4}=0\;(\text{mod}\;2)\) and \(L_{1}=1\;(\text{mod}\;2)\), and using the _ABC_ contrast is equivalent to using the pair of confounding equations \(L_{2}=a_{1}+a_{2}+a_{3}=0\;(\text{mod}\;2)\) and \(L_{2}=1\;(\text{mod}\;2)\). Thus there are four possible values for the pair (\(L_{1}\), \(L_{2}\)), and it can be verified that the blocks of the design satisfy

\[\begin{array}{ll}\text{Block I:}&L_{1}=a_{1}+a_{2}+a_{3}+a_{4}=0;\;L_{2}=a_{1}+a_{2}+a_{3}=0\;(\text{mod}\;2)\,;\\ \text{Block II:}&L_{1}=a_{1}+a_{2}+a_{3}+a_{4}=0;\;L_{2}=a_{1}+a_{2}+a_{3}=1\;(\text{mod}\;2)\,;\\ \text{Block III:}&L_{1}=a_{1}+a_{2}+a_{3}+a_{4}=1;\;L_{2}=a_{1}+a_{2}+a_{3}=0\;(\text{mod}\;2)\,;\\ \text{Block IV:}&L_{1}=a_{1}+a_{2}+a_{3}+a_{4}=1;\;L_{2}=a_{1}+a_{2}+a_{3}=1\;(\text{mod}\;2)\,.\end{array}\]

We already know from Sect. 13.3.3 that a third contrast, namely contrast \(D\), is confounded in this design. If we add the two confounding equations used to create each block, we have, for Block I,

\[\begin{array}{ll}L_{1}=&a_{1}+\;\;a_{2}+\;\;a_{3}+a_{4}=0\;(\text{mod}\;2)\\ +\;L_{2}=&a_{1}+\;\;a_{2}+\;\;a_{3}=0\;(\text{mod}\;2)\\ \hline L_{1}+L_{2}=&2a_{1}+2a_{2}+2a_{3}+a_{4}=0\;(\text{mod}\;2)\end{array}\]

If all coefficients are reduced modulo 2, the sum gives \(a_{4}=0\;(\text{mod}\;2)\), which indicates that the \(D\) contrast is also confounded.

\begin{table}
\begin{tabular}{c c c c c} Block I: & Treatment combinations with \\ & \(z_{1}a_{1}+z_{2}a_{2}+z_{3}a_{3}+\cdots+z_{P}a_{P}=0\;(\text{mod}\;2)\,,\) \\ Block II: & Treatment combinations with \\ & \(z_{1}a_{1}+z_{2}a_{2}+z_{3}a_{3}+\cdots+z_{P}a_{P}=1\;(\text{mod}\;2)\,.\) \\ \end{tabular}
\end{table}
Table 13.9: 23 experiments in 2 blocks of 4, confounding _AC_As has been demonstrated, there is a correspondence between the contrasts, the contrast names, and the confounding equations. The contrast names are the most convenient for checking the total list of confounded contrasts, and the equations are the most convenient for constructing the design.

Design construction can be done in several ways. One way is to examine each of the \(2^{p}\) treatment combinations and allocate them to blocks according to their values obtained in the left sides of the confounding equations. Another way is to identify the treatment combinations that make the confounding equations equal to zero. These will form Block I of the design. The other blocks of the design are obtained by adding (modulo 2) to the treatment combinations in Block I any treatment combination that has not yet appeared in a block. This is illustrated in the following example.

#### 26 experiment in 8 blocks of 8

A confounding scheme was found in Sect. 13.3.4 for a \(2^{6}\) experiment in 8 blocks of 8 by selecting contrasts _BCD_, _ABE_, and _ADF_ for confounding. It was shown that contrasts _ACDE_, _ABCF_, _BDEF_, and _CEF_ were also confounded. Writing out the equations for the three selected contrasts, we have

\[\begin{array}{l} L_{1}=a_{2}+a_{3}+a_{4}=0\text{ or }1\left(\text{mod }2\right),\\ L_{2}=a_{1}+a_{2}+a_{5}=0\text{ or }1\left(\text{mod }2\right),\\ L_{3}=a_{1}+a_{4}+a_{6}=0\text{ or }1\left(\text{mod }2\right).\end{array}\]

The equations corresponding to the other four confounded contrasts are obtained by setting \(L_{1}+L_{2}\), \(L_{1}+L_{3}\), \(L_{2}+L_{3}\), and \(L_{1}+L_{2}+L_{3}\) equal to 0 or 1 (mod 2).

The design is shown in Table 10. It can be constructed systematically as follows. The first treatment combination 000000 gives 0 for each of \(L_{1}\), \(L_{2}\), \(L_{3}\) and is allocated to Block I. The second treatment combination 000001 gives values 0, 0, 1 for the three \(L_{i}\) and is allocated to Block II, and so on.

Alternatively, one can look for the eight treatment combinations that give zero for each of \(L_{1}\), \(L_{2}\), and \(L_{3}\) and construct Block I first. Solving \(L_{1}=0\), \(L_{2}=0\), and \(L_{3}=0\) each for the last \(a_{i}\) gives \(a_{4}=a_{2}+a_{3}\) (mod 2), \(a_{5}=a_{1}+a_{2}\) (mod 2) and \(a_{6}=a_{1}+a_{4}\) (mod 2), respectively. For each one

\begin{table}
\begin{tabular}{c c c c c c} \hline Block & \(L_{1}\), \(L_{2}\), \(L_{3}\) & Treatment Combinations \\ \hline I & 0, 0, 0 & 000000 & 001101 & 010111 & 011010 \\  & & 100011 & 101110 & 110100 & 111001 \\ II & 0, 0, 1 & 000001 & 001100 & 010110 & 011011 \\  & & 100010 & 101111 & 110101 & 111000 \\ III & 0, 1, 0 & 000010 & 001111 & 010101 & 011000 \\  & & 100001 & 101100 & 110110 & 111011 \\ IV & 0, 1, 1 & 000011 & 001110 & 010100 & 011001 \\  & & 100000 & 101101 & 11011 & 111010 \\ V & 1, 0, 0 & 000101 & 001000 & 010010 & 011111 \\  & & 100110 & 101011 & 110001 & 111100 \\ VI & 1, 0, 1 & 000100 & 001001 & 010011 & 011110 \\  & & 100111 & 101010 & 110000 & 111101 \\ VII & 1, 1, 0 & 000111 & 001010 & 010000 & 011101 \\  & & 100100 & 101001 & 110011 & 111110 \\ VIII & 1, 1, 1 & 000110 & 001011 & 010001 & 011100 \\  & & 100101 & 101000 & 110010 & 111111 \\ \hline \end{tabular}
\end{table}
Table 10: \(2^{6}\) experiment in 8 blocks of 8, confounding _ABE_, _ADF_, _BCD_, _CEF_, _ABCF_, _ACDE_, _BDEF_of of the eight combinations \(a_{1}\), \(a_{2}\), \(a_{3}\) of factors \(A\), \(B\), and \(C\), the corresponding values of \(a_{4}\), \(a_{5}\), and \(a_{6}\) can thus be computed to obtain one of the eight treatment combinations of Block I. For example, if \(a_{1}=a_{2}=a_{3}=1\), then \(a_{4}=a_{2}+a_{3}=1+1=0\) (mod 2), \(a_{5}=a_{1}+a_{2}=1+1=0\) (mod 2), and \(a_{6}=a_{1}+a_{4}=1+0=1\) (mod 2), so the treatment combination 111001 is in Block I.

Each of the other blocks is obtained by adding a new treatment combination to those in Block I--"new" meaning not yet in a block. For example, the treatment combination 000001 is not in Block I and if 000001 is added modulo 2 to the eight treatment combinations in Block I, then Block II results. For example, 000001 is added to 111001 of Block I by adding corresponding digits and reducing modulo 2; that is,

\[000001+111001=111002=111000\;({\rm mod}\;2),\]

so 111000 is also in Block II.

A third block can be obtained by taking any treatment combination not in the first two blocks, and adding it to each treatment combination in Block I. Proceeding in this fashion, blocks are constructed until each treatment combination has been allocated to some block. 

### A Real Experiment--Mangold Experiment

O. Kempthorne in his book _Design and Analysis of Experiments_ describes an experiment run at Rothamsted Agricultural Station to investigate the effects of five different fertilizers on the growth of mangold roots. The five factors were Sulphate of ammonia (factor \(A\) at levels 0 or 0.6 cwt per acre), Superphosphate (factor \(B\) at levels 0 or 0.5 cwt per acre), Muriate of potash (factor \(C\) at levels 0 or 1.0 cwt per acre), Agricultural salt (factor \(D\) at levels 0 or 5 cwt per acre), and Dung (factor \(E\) at levels 0 or 10 tons per acre). The experimental area was divided into \(b=4\) blocks of size \(k=8\). All 3-, 4-, and 5-factor interactions were expected to be negligible. The two three-factor interactions \(ABD\), \(BCE\), and their product \(ACDE\) were selected for confounding.

The division of the 32 treatment combinations into the four blocks was then determined from the confounding equations corresponding to \(ABD\) and \(BCE\); that is,

\[\begin{array}{llll}L_{1}=a_{1}+a_{2}&+a_{4}&=0\;{\rm or}\;1\;({\rm mod}\;2) \,,\\ L_{2}=&a_{2}+a_{3}&+a_{5}=0\;{\rm or}\;1\;({\rm mod}\;2)\,.\end{array}\]

The blocks can be formed by systematically working through all 32 treatment combinations and assigning them to the blocks according to the values of \(L_{1}\) and \(L_{2}\) and the rule

\[\begin{array}{llll}{\rm Block\;I:}&L_{1}=0({\rm mod}\;2)&{\rm and}&L_{2}=0({ \rm mod}\;2)\,,\\ {\rm Block\;II:}&L_{1}=0({\rm mod}\;2)&{\rm and}&L_{2}=1({\rm mod}\;2)\,,\\ {\rm Block\;III:}&L_{1}=1({\rm mod}\;2)&{\rm and}&L_{2}=0({\rm mod}\;2)\,,\\ {\rm Block\;IV:}&L_{1}=1({\rm mod}\;2)&{\rm and}&L_{2}=1({\rm mod}\;2)\,.\end{array}\]

Alternatively, we can notice that \(L_{1}=0\) gives \(a_{4}=a_{1}+a_{2}\) (mod 2) and \(L_{2}=0\) gives \(a_{5}=a_{2}+a_{3}\) (mod 2). Computing these for each combination of levels \(a_{1}a_{2}a_{3}\) of the first three factors gives Block I as

\[\begin{array}{llll}{\rm Block\;I:}&00000\;10010\;00101\;10111\\ &11100\;01110\;11001\;01011\end{array}\]Any treatment combination that is not in Block I can be added to the treatment combinations in Block I to obtain a second block. So, if we add 00001, for example, we obtain

\[\begin{array}{l} {\text{Block II: }00001\ 10011\ 00100\ 10110} \\ {11101\ 0111\ 11000\ 01010} \\ \end{array}\]

Any treatment combination not in Blocks I and II can now be added to the treatment combinations in Block I to obtain a third block. Since 00010, for example, has not appeared in Blocks I or II, we can add it to the treatment combinations in Block I to obtain Block III. Block IV can then be obtained by adding a treatment combination, say 00011, that has not appeared in the previous three blocks.

\[\begin{array}{l} {\text{Block III: }00010\ 10000\ 00111\ 10101} \\ {11110\ 01100\ 11011\ 01001} \\ {\text{Block IV: }00011\ 10001\ 00110\ 10100} \\ {11111\ 01101\ 11010\ 01000} \\ \end{array}\]

The order of the treatment combinations was randomized within each block, and the order of the blocks was randomized. The final design, together with the resulting yields (in pounds) of mangold roots, is shown in Table 13.11.

The contrasts for the main effects and interactions are obtained as usual. The contrast for comparing the high and low levels of superphosphate (_B_), for example, is \(\sum_{i}c_{i}\tau_{i}\), where \(\tau_{i}\) is the effect of the \(i\)th treatment combination, and the coefficient \(c_{i}\) is the \(i\)th element of

\[\begin{array}{l} {\frac{1}{16}[-1,\ -1,\ -1,\ -1,\ -1,\ -1,\ -1,\ -1,\ 1,\ 1,\ 1,\ 1,\ 1,\ 1,\ 1,\ 1,\ 1,\ 1,\ 1,\ 1,\ 1,\ -1,\ -1,\ -1,\ -1,\ 1,\ 1,\ 1,\ 1,\ 1,\ 1,\ 1,\ 1,\ 1,\ 1,\ 1,\ 1\ ]}. \\ \end{array}\]

\begin{table}
\begin{tabular}{c c c c} \hline Block & Treatment Combinations & & \\  & & (Yield) & & \\ \hline I & 01101 & 00011 & 10100 & 11111 \\  & (844) & (1104) & (1156) & (1508) \\  & 11010 & 00110 & 10001 & 01000 \\  & (1312) & (1000) & (1176) & (888) \\ II & 00001 & 01111 & 00100 & 10011 \\  & (1248) & (1100) & (784) & (1376) \\  & 11101 & 10110 & 11000 & 01010 \\  & (1356) & (1376) & (1008) & (964) \\ III & 00101 & 11001 & 01011 & 01110 \\  & (896) & (1284) & (996) & (860) \\  & 10010 & 11100 & 00000 & 10111 \\  & (1184) & (984) & (740) & (1468) \\ IV & 10101 & 11110 & 00111 & 11011 \\  & (1328) & (1292) & (1008) & (1324) \\  & 01001 & 01100 & 00010 & 10000 \\  & (1008) & (692) & (780) & (1108) \\ \hline \end{tabular}
\end{table}
Table 13.11: Yields (in pounds) of mangold roots for the mangold experiment 

[MISSING_PAGE_FAIL:467]

so we fail to reject the null hypothesis \(H_{0}^{B}\) and conclude that there is no evidence to suggest a difference in yield due to the high and low levels of superphosphate. The ratio for each of the other hypothesis tests is given in Table 13.12, and we see that the only hypotheses that would be rejected at overall significance level 0.075 are the hypotheses of no effect of \(A\) or \(D\) or \(E\).

The block sum of squares is the sum of the _ABD_, _BCE_, and _ACDE_ contrast sums of squares, or alternatively, it can be calculated as

\[{\rm ss}\theta=\frac{1}{8}\sum_{h}B_{h}^{2}-\frac{1}{32}G^{2}=52832.0\]

as in (13.2.2), where \(B_{h}=y_{h.....}\) and \(G=y......\). The block mean square is more than twice the size of the error mean square, indicating that the creation of blocks in this experiment was useful for reducing the error variability, assuming that the effects confounded with blocks are negligible.

Since none of the interactions appear to be significantly different from zero, the main effects can be investigated. The contrast estimates of the significant main effects are all positive, suggesting that the high levels of \(A\), \(D\), and \(E\) increase the yield of mangold roots significantly. Confidence intervals for all the main-effect contrasts can be obtained via Bonferroni's method using formula (4.4.21), but with error degrees of freedom \({\rm df}=13\). If we select the confidence level to match the \(\alpha\) level of the hypothesis tests, we obtain a set of simultaneous confidence intervals with overall confidence level of at least 92.5% as follows:

\[{\rm For}\ A:\ \left(\overline{y}_{.1.....}-\overline{y}_{.0.....}\pm t_{13,0.0025}\sqrt{32\hat{\sigma}^{2}/16^{2}}\right) = \left(333.0\pm 3.372\sqrt{6791.23/8}\right) = \left(333.0\pm 98.25\right)=\left(234.75,\ 431.25\right);\] \[{\rm For}\ B:\ (-19.5\pm 98.25)=\left(-117.75,\ 78.75\right);\] \[{\rm For}\ C:\ \ \ \ \ (9.5\pm 98.25)=\left(-88.75,\ 107.75\right);\] \[{\rm For}\ D:\ (134.5\pm 98.25)=\left(36.25,\ 232.75\right);\] \[{\rm For}\ E:\ (181.0\pm 98.25)=\left(82.75,\ 279.25\right).\]

At a somewhat higher overall significance level, the hypothesis of no interaction between \(A\) and \(C\) would have been rejected. The _AC_ interaction plot is shown in Fig. 13.4. This plot agrees with the earlier observation that \(A\) should be set at its high level. Unless the cost is high, the plot suggests that \(C\) should also be set at its high level. Factor \(B\) does not seem to affect the yield much and can be set at its low (zero) level. As stated earlier, \(D\) and \(E\) should be at their high levels.

Figure 13.4: _AC_ interaction plot for the mangold experiment

After an experiment of this type, it is good policy to run a _confirmatory experiment_ verifying that the selected levels are, indeed, a good combination. Here the recommendation is to use treatment combination 10111. Certainly, in the main experiment, this treatment combination gave the highest yield in Block III, but it cannot easily be compared with the other observations because of the large block differences. A few more observations on this particular treatment combination would help to verify that it is consistently a good choice.

### Plans for Confounded 2\({}^{p}\) Experiments

Suggestions for confounding schemes useful for constructing designs for 2\({}^{p}\) experiments in \(b=2^{s}\) blocks of size \(k=2^{p-s}\) are given in Table 13.29 at the end of this chapter. These have been chosen to allow all main effects to be estimable and as many two-factor interactions as possible. The first block of each design can be obtained from the given relations on the factor levels, and the other blocks can be obtained by adding (modulo 2) new treatment combinations to those in Block I. This process was illustrated in Example 13.4.1, p. 446.

If one or more of the listed confounded contrasts is an important contrast in the experiment being designed, the factors should be relabeled. For example, suppose that a design is required for a 2\({}^{6}\) experiment in 8 blocks of 8. The design listed in Table 13.29 confounds _BCD_, _ABE_, _ACDE_, _ADF_, _ABCF_, _BDEF_, and _CEF_ (this is also the design of Table 13.10). Suppose that the experimenter wished to estimate the contrasts _ABC_ and _BCD_. The design, as listed, confounds _BCD_. However, if the experimenter were to switch the labels \(B\) and \(E\) of the actual treatment factors, then the important contrasts would be called _ACE_ and _CDE_, both of which can be estimated in the listed design. Equivalently, the experimenter could switch the labels \(B\) and \(E\) of the listed design, so as to confound _CDE_, _ABE_, _ABCD_, _ADF_, _ACEF_, _BDEF_, and _BCF_, leaving _ABC_ and _BCD_ unconfounded.

### Multireplicate Designs

When the experiment is large enough that each treatment combination can be observed \(r>1\) times, we have a choice of several different ways to design the experiment. If the block size can be chosen to be as large as the number of treatment combinations, then a randomized block design (Chap. 10) can be used.

If an incomplete block design is required, we could choose to use one of the standard incomplete block designs described in Chap. 11, such as a balanced incomplete block design. Alternatively, we could take a single-replicate design, confounding one or more interaction contrasts, and repeat the design \(r\) times. Alternatively, again, we could piece together \(r\) different single-replicate designs, confounding different contrasts in each. The confounding of a contrast in some but not all replicates is called _partial confounding_.

The choice between these three types of incomplete block designs involves tradeoffs concerning what is to be estimated and how accurately. The analysis of a standard incomplete block design of Chap. 11 requires that _every_ contrast estimate be adjusted for blocks. Thus, while all contrasts are estimable, their least squares estimators have higher variances than they would if they were unadjusted for blocks--there is some _loss of information_ on each contrast. If a balanced incomplete block design is used, then there is the same loss of information on every treatment contrast.

A repeated single-replicate design, on the other hand, loses information completely on the confounded contrasts--they are not estimable and are said to be _completely confounded_--but all contrasts orthogonal to these are unconfounded and can be estimated with no block adjustment and so with no loss of information. The estimator of any unconfounded contrast is the same as it would be in a complete block design, and with the same variance formula. The use of smaller blocks should, however, result in a smaller error variance \(\sigma^{2}\).

The designs with partial confounding fall between these two extremes, allowing all contrasts to be estimable but with different levels of adjustment and loss of information. Complete and partial confounding are illustrated in Sects. 13.8-13.9 and are compared via an example in Sect. 13.10.

### Complete Confounding: Repeated Single-Replicate Designs

If the number of treatment combinations \(v\) is divisible by the block size \(k\), the \(v/k\) blocks of a single-replicate design can be repeated \(r\) times to give an incomplete block design with \(b=rv/k\) blocks. The contrasts that are confounded in the single-replicate design are also confounded in the \(r\)-replicate design--they cannot be estimated and are said to be _completely confounded_. For all other contrasts, the estimators and corresponding variance formulae are as in a complete block design--no block adjustments are needed.

#### A Real Experiment--Decontamination Experiment

An experiment was described by M.K. Barnett and F.C. Mead, Jr. in the journal _Applied Statistics_ in 1956 to explore the effect of four factors on the efficiency of a decontamination process for the removal of radioactive isotopes from liquid waste. The four treatment factors were:

* The amount of aluminum sulphate added to the liquid waste (two levels, 0.4 g and 2.5 g per liter, coded 0, 1).
* The amount of barium chloride added to the liquid waste (two levels, 0.4 g and 2.5 g per liter, coded 0, 1).
* The amount of carbon added to the liquid waste (two levels, 0.08 g and 0.4 g per liter, coded 0, 1).
* Final pH of liquid waste (two levels, 6 and 10, coded 0, 1) achieved by adding sodium hydroxide or hydrochloric acid.

The experimental units were portions of a typical laboratory waste of pH 8.3 and in which the principal radioactivity was attributable to salts of radium, thorium, and actinium. The measurements

\begin{table}
\begin{tabular}{c c c c c c c c c} \hline Block & \multicolumn{6}{c}{Treatment combinations (response)} \\ \hline I & 1010 & 1111 & 0110 & 0000 & 1100 & 0101 & 0011 & 1001 \\  & (183) & (350) & (188) & (881) & (225) & (298) & (1039) & (466) \\ II & 0010 & 0001 & 0111 & 1000 & 1101 & 0100 & 1110 & 1011 \\  & (650) & (1180) & (238) & (191) & (420) & (289) & (135) & (781) \\ III & 0101 & 1001 & 1100 & 0000 & 1010 & 1111 & 0110 & 0011 \\  & (273) & (890) & (370) & (834) & (193) & (389) & (163) & (1146) \\ IV & 0001 & 1110 & 1000 & 0100 & 0111 & 1011 & 0010 & 1101 \\  & (1193) & (156) & (257) & (178) & (254) & (775) & (494) & (429) \\ \hline \end{tabular}
\end{table}
Table 13.13: Repeated single-replicate design for a \(2^{4}\) experiment in \(2\times 2\) blocks of size 8, confounding \(ABCD\). Data for the decontamination experiment are shown in parentheses taken after the experimental decontamination process were the counts per minute per milliliter of alpha and beta particles. Here, we will only reproduce the data for the alpha particles (see Table 13.13).

Only 8 of the 16 treatment combinations could be examined per day. Four days were available for the experiment, allowing each treatment combination to be measured twice during the course of the experiment. The experimenters anticipated day-to-day variations in the observations and decided to run a block design with \(b=4\) blocks of size \(k=8\). In fact, an unforeseen change of operators became necessary at the end of the first day. Since a block design had been used, any shift in the observations due to the operator change was absorbed into the block differences and did not affect the comparisons of the treatment combinations.

The experimenters first selected a single-replicate design in \(b^{*}=2\) blocks of size \(k=8\) that confounded the 4-factor interaction contrast _ABCD_ (which they thought unlikely to exist in this experiment). By using this single-replicate design twice, they obtained a design with \(r=2\) observations per treatment combination and with \(b=2b^{*}=4\) blocks in which all contrasts except for _ABCD_ could be measured without adjustments for blocks. (The single-replicate design selected is that listed in Table 13.29.) The treatment combinations were randomly ordered within each block, and the final design is shown in Table 13.13.

The chosen model included all main effects and all 2-factor and 3-factor interactions. The block\(\times\)treatment interaction was assumed to be negligible. Thus, the model was

\[Y_{hijkl} = \mu + \theta_{h} + \alpha_{i} + \beta_{j} + \gamma_{k} + \delta_{l} + (\alpha\beta)_{ij} + (\alpha\gamma)_{ik} + (\alpha\delta)_{il} + (\beta\gamma)_{jk} + (\beta\delta)_{jl} + (\gamma\delta)_{kl} + (\alpha\beta\gamma)_{ijk} + (\alpha\beta\delta)_{ijl} + (\alpha\gamma\delta)_{ikl} + (\beta\gamma\delta)_{jkl} + \epsilon_{hijkl},\]

\[\epsilon_{hijkl} \sim N(0,\sigma^{2})\text{ and mutually independent},\]

\[h = 1,2,3,4;\ \ i = 0,1;\ \ j = 0,1;\ \ k = 0,1;\ \ l = 0,1;\]

\[(h,i,j,k,l)\text{ in the design}.\]

The analysis of variance table is shown in Table 13.14. There are \(b=4\) blocks in the design, but _ABCD_ is the only treatment contrast confounded. The sum of squares for _ABCD_ is included in the block sum of squares. The sums of squares for the other interactions and main effects can be obtained from rules 4 or 12 in Sect. 7.3. For example, the sum of squares for testing the hypothesis of negligible _AC_ interaction is

\[\begin{split}\text{ss}(AC)&=\sum_{i}\sum_{k}\frac{y _{j,k,}^{2}}{8}-\sum_{i}\frac{y_{j,...}^{2}}{16}-\sum_{k}\frac{y_{...k,}^{2}} {16}+\frac{y_{....}^{2}}{32}\\ &=\frac{1}{8}(5126^{2}+4172^{2}+3248^{2}+2962^{2})-\frac{1}{16}( 9298^{2}+6210^{2})\\ &\quad-\frac{1}{16}(8374^{2}+7134^{2})+\frac{1}{32}(15508^{2}) \\ &=13,944.5.\end{split}\]

Alternatively, we can calculate the sum of squares for the _AC_ contrast as follows. The contrast coefficients, which are 1 if the levels of factors \(A\) and \(C\) are both high or both low, and -1 otherwise, are Then,

\[\text{ss}(\textit{AC})=\frac{\left(\sum_{i}\sum_{j}\sum_{k}\sum_{l}\ c_{ijkl} \overline{y}_{.ijkl}\right)^{2}}{\left(\sum_{i}\sum_{j}\sum_{k}\sum_{l}\ c_{ijkl }^{2}/r\right)}=\frac{(334)^{2}}{16/2}=13,\!944.5.\]

The error sum of squares is obtained by subtracting the sums of squares for the main effects and interactions from the total sum of squares, where the latter is

\[\text{sstot}\ =\ \sum_{h}\sum_{i}\sum_{j}\sum_{k}\sum_{l}y_{hijkl}^{2}-\frac{G^{2}}{32}\,.\]

Similarly, the error degrees of freedom are obtained by subtraction.

There are fourteen hypothesis tests to be done. If each is done at a significance level 0.01, the overall level is at most \(\alpha=0.14\). At this level \(F_{1,14.,01}=8.86\), and the significant effects are the _AB_ and _BD_ interactions (and the main effects of \(A\), \(B\), and \(D\) averaged over the levels of the other factors). The hypotheses of negligible \(C\) main effect and _ABC_ interaction would be rejected at a slightly higher significance level.

Interaction plots of the two most important interactions (_AB_ and _BD_) are shown in Fig. 13.5. Figure 13.5(a) suggests that \(B\) should be set at its high level to achieve a lower radioactivity. The interaction is caused by the fact that the benefit of setting \(B\) at its high level is more marked when \(A\) is at its low level than at its high level. If \(B\) is at its high level, there is a slight preference for \(A\) to be at its low level to achieve a lower radioactivity. On the other hand, the system is more stable when \(A\) is at its high level, meaning that the radioactivity is not so sensitive to the level of \(B\). So the choice for the setting of \(A\) is not completely obvious. Figure 13.5(b) shows a similar picture. Again \(B\) should be at its high level with a preference for \(D\) at its low level (which also produces the more stable system).

\begin{table}
\begin{tabular}{c c c c c} \hline Source of variation & Degrees of freedom & Sum of squares & Ratio & _p_-value \\ Blocks & 3 & 28262.500 & – & – \\ \(A\) & 1 & 297992.000 & 40.25 & 0.0001 \\ \(B\) & 1 & 1444150.125 & 195.07 & 0.0001 \\ \(C\) & 1 & 48050.000 & 6.49 & 0.0232 \\ \(D\) & 1 & 700336.125 & 94.60 & 0.0001 \\ _AB_ & 1 & 570846.125 & 77.11 & 0.0001 \\ _AC_ & 1 & 13944.500 & 1.88 & 0.1915 \\ _AD_ & 1 & 22366.125 & 3.02 & 0.1041 \\ _BC_ & 1 & 15.125 & 0.00 & 0.9646 \\ _BD_ & 1 & 252050.000 & 34.05 & 0.0001 \\ _CD_ & 1 & 24531.125 & 3.31 & 0.0902 \\ _ABC_ & 1 & 38226.125 & 5.16 & 0.0394 \\ _ABD_ & 1 & 144.500 & 0.02 & 0.8909 \\ _ACD_ & 1 & 66.125 & 0.01 & 0.9260 \\ _BCD_ & 1 & 5618.000 & 0.76 & 0.3984 \\ Error & 14 & 103645.000 & & & \\ Total & 31 & 3550243.500 & & & \\ \hline \end{tabular}
\end{table}
Table 13.14: Analysis of variance for the decontamination alpha-particle experiment The main effect of \(C\) is not significant, but the data suggest that it should be set at its high level unless this increases the cost substantially.

Thus, the results of the analysis of variance table suggest that suitable treatment combinations for the decontamination process are 0110 or 1110. These are the same two treatment combinations that would be selected from a perusal of the data in Table 13. The benefit of the investigation of main effects and interactions is that it suggests directions for future experiments (raising the level of \(B\) further while keeping \(D\) fairly low and perhaps raising \(A\) a little). It also allows the chemical analysts to better understand the nature of the chemical system (see the original article of Barnett and Mead). Finally, it helps to ensure that the treatment combination that appears to be the best from the data is not just the result of error variability or a spurious observation (outlier).

### Partial Confounding

_Partial confounding_ is the term applied to a design that is formed from the combination of the blocks from different single-replicate designs with different confounding schemes. A contrast that is confounded in some replicates but not in others is said to be _partially confounded_ with blocks. A partially confounded contrast can be estimated using only the data of those replicates in which it is unconfounded. Thus, the variance of the contrast estimator is inversely proportional to the number of replicates in which it is estimable.

For example, the design in Table 13.15 for a \(2^{3}\) experiment in 8 blocks of size 4 has four observations on each treatment combination. It is made up of four single-replicate designs; the first confounds the contrast from the \(ABC\) interaction, while the second confounds the \(AB\) contrast, the third confounds \(AC\), and the fourth \(BC\). This means that the \(ABC\) contrast is estimable from the second, third, and fourth single-replicate designs, but not the first, and the \(AB\) contrast is estimable from the first, third, and fourth single-replicate designs, but not the second. Similarly, the \(AC\) and \(BC\) contrasts are estimable from three of the four replicates. The main-effect contrasts \(A\), \(B\), and \(C\) are estimable from all four replicates. Consequently, all factorial treatment contrasts can be estimated, but the variance associated with each partially confounded contrast will be larger than that associated with each of the unconfounded contrasts by a factor of four-thirds. The benefit of using a partially confounded design instead of a repeated single-replicate design is that each treatment contrast is estimable, yet all totally unconfounded contrasts are still estimated with the maximum possible precision.

Figure 13.5: Interaction plots for the decontamination alpha-particle experiment

#### **Example 13.9.1** Coil experiment

C. R. Hicks, in his textbook _Fundamental Concepts in the Design of Experiments_, describes an experiment to examine the variability of outside diameters of coils of wire. There were three treatment factors of interest, as follows:

\(A\): Two winding machines, coded 0, 1.

\(B\): Two wire stocks, coded 0, 1.

\(C\): Two positions on the coil, coded 0, 1.

Only four of the \(v=8\) treatment combinations could be measured at any one time. Consequently, the experiment was divided into blocks of size \(k=4\). A total of \(n=32\) observations could be taken, and a block design of \(b=8\) blocks of size \(k=4\) was needed.

It is easily verified that no balanced incomplete block design of this size exists (since \(r=4\) and \(\lambda=12/7\)). A cyclic design could have been used, but cyclic designs do not have orthogonal factorial structure in general. A partially confounded design was selected, consisting of four single-replicate designs, each confounding a different interaction (\(ABC\), \(AB\), \(AC\), and \(BC\)). The design and responses are shown in Table 13.15.

We use the standard model for 3 treatment factors and one block factor with no block\(\times\)treatment interaction.

\[Y_{hijk} = \mu + \theta_{h} + \tau_{ijk} + \epsilon_{hijk}\] \[= \mu + \theta_{h} + \alpha_{i} + \beta_{j} + \gamma_{k} + (\alpha\beta)_{ij} + (\alpha\gamma)_{ik}\] \[+ (\beta\gamma)_{jk} + (\alpha\beta\gamma)_{ijk} + \epsilon_{hijk}\,,\] \[\epsilon_{hijk} \sim N(0,\,\sigma^{2})\text{ and mutually independent}\,,\] \[h = 1,\ldots,8;\,\,\,i = 0,1;\,\,\,\,j = 0,1;\,\,\,\,k = 0,\,1;\] \[(h,\,i,\,j,\,k)\text{ in the design}.\]

Since the main effect contrasts are not confounded in any part of the design, these can be estimated using all of the data. In addition, these contrasts are orthogonal to block contrasts, so no block adjustments are needed. The contrast for comparing the first two levels of factor \(B\) (averaged over the levels of \(A\) and \(C\)), for example, is then

\[\beta_{1}^{*} - \beta_{0}^{*}\,,\,\,\,\,\,\text{where}\,\,\beta_{j}^{*} = \beta_{j} + (\overline{\alpha\beta})_{.j} + (\overline{\beta\gamma})_{.j} + (\overline{\alpha\beta\gamma})_{.j.}\,,\]

\begin{table}
\begin{tabular}{c c c c c} \hline Confounded & Block & Treatment combination (response) & \\ \hline _ABC_ & I & 000 (2208) & 110 (2133) & 101 (2459) & 011 (3096) \\  & II & 100 (2196) & 010 (2086) & 001 (3356) & 111 (2776) \\ _AB_ & III & 000 (2004) & 110 (2112) & 001 (3073) & 111 (2631) \\  & IV & 100 (2179) & 010 (2073) & 101 (3474) & 011 (3360) \\ _AC_ & V & 001 (2839) & 100 (2189) & 011 (3522) & 110 (2095) \\  & VI & 000 (1916) & 101 (2979) & 010 (2151) & 111 (2500) \\ _BC_ & VII & 100 (2056) & 000 (2010) & 011 (3209) & 111 (3066) \\  & VIII & 010 (1878) & 110 (2156) & 001 (3423) & 101 (2524) \\ \hline \end{tabular}
\end{table}
Table 13.15: Design and data (in parentheses) for the coil experimentand has least squares estimate

\[\hat{\beta}_{1}^{*}-\hat{\beta}_{0}^{*}\ =\ \overline{y}_{..1}-\overline{y}_{..0}\ =\ \frac{y_{..1}}{16}-\frac{y_{..0}}{16}\ =\ 2552.75-2555.31\ =\ -\ 2.56.\]

To four decimal places, this estimate is \(-2.5625\). Equivalently, in terms of the treatment combinations the contrast is \(\sum_{i}\sum_{j}\sum_{k}c_{ijk}\tau_{ijk}\), where the coefficients \(c_{ijk}\) in standard order and divisor \(v/2\) are given by

\[\frac{1}{4}[-1,\ -1,\ \ 1,\ \ 1,\ -1,\ -1,\ \ 1,\ \ 1\ ]\,.\]

with least squares estimate \(\sum_{j}\sum_{k}c_{ijk}\overline{y}_{.ijk}=-2.5625\). The variance associated with this contrast is

\[\frac{\sum_{i}\sum_{j}\sum_{k}c_{ijk}^{2}\sigma^{2}}{4}\ =\ \frac{8\sigma^{2}}{16\times 4}\ =\ \frac{\sigma^{2}}{8}\,.\]

The test of the hypothesis \(H_{0}:\{\beta_{1}^{*}-\beta_{0}^{*}=0\}\) against the alternative hypothesis \(H_{A}:\{\beta_{1}^{*}-\beta_{0}^{*}\neq 0\}\) is similar to (4.3.15) (p. 77); that is,

\[\text{reject }H_{0}\ \text{if}\ \frac{\text{ssc}_{B}}{\text{msE}}\ =\ \frac{(\overline{y}_{..1}-\overline{y}_{..0})^{2}}{\text{msE}/8}\ >\ F_{1,df,\alpha/m}\,,\]

where _df_ is the error degrees of freedom obtained from the analysis of variance table, which is shown in Table 13.16, \(m\) is the number of hypotheses to be tested, and \(\text{ssc}_{B}=8(-2.5625)^{2}=52.53\). To test the equivalent hypothesis \(H_{0}^{B}:\{\beta_{0}^{*}=\beta_{1}^{*}\}\) using the rules of Sect. 7.3, we obtain the same value of ssB; that is,

\[\text{ssB}\ =\ acr\sum_{j}\overline{y}_{..j.}^{2}-abcr\overline{y}_{....}^{2}=52.53\,.\]

The sum of squares for each of the other main effects can be calculated in a similar fashion. The sum of squares for the interactions can be calculated similarly, except that only three of the four replicates are used. For example, the _BC_ interaction contrast can be estimated only from the first three replicates (that is, from 24 observations, not 32). Thus, the contrast \(\frac{1}{2}[(\beta\gamma)_{00}^{*}-(\beta\gamma)_{01}^{*}-(\beta\gamma)_{10}^{*}+(\beta\gamma)_{11}^{*}]\)

\begin{table}
\begin{tabular}{l r r r r} \hline Source of variation & Degrees of freedom & Sum of squares & Mean square & Ratio & _p_-value \\ \hline Blocks (adj) & 7 & 303,414.14 & 43,344.88 & - & \\ Blocks (unadj) & 7 & 439,777.72 & - & - & \\ \(A\) & 1 & 224,282.53 & 224,282.53 & 3.97 & 0.0627 \\ \(B\) & 1 & 52.53 & 52.53 & 0.00 & 0.9760 \\ \(C\) & 1 & 6,886,688.28 & 6,886,688.28 & 121.79 & 0.0001 \\ _AB_ (adj) & 1 & 737.04 & 737.04 & 0.01 & 0.9104 \\ _AC_ (adj) & 1 & 416,066.67 & 416,066.67 & 7.36 & 0.0148 \\ _BC_ (adj) & 1 & 2,667.04 & 2,667.04 & 0.05 & 0.8307 \\ _ABC_ (adj) & 1 & 70,742.04 & 70,742.04 & 1.25 & 0.2789 \\ Error & 17 & 961,283.11 & 56,546.07 & & \\ Total & 31 & 9,002,296.97 & & & \\ \hline \end{tabular}
\end{table}
Table 13.16: Analysis of variance for the coil experiment 

[MISSING_PAGE_FAIL:476]

If we let the effect of treatment combination \(\mathit{j\!k}\) be denoted by \(\tau_{ijk}\), then following Sect. 11.4.3, the least squares estimator of a contrast \(\Sigma\,\Sigma\,\Sigma c_{ijk}\tau_{ijk}\) is \(\Sigma\,\Sigma\,\Sigma c_{ijk}\widehat{\tau}_{ijk}=\frac{k}{\lambda v}\,\Sigma \,\Sigma\,\Sigma c_{ijk}\,Q_{ijk}\), where \(Q_{ijk}=T_{ijk}-\frac{1}{k}\sum_{h}n_{hijk}\,B_{h}\), and \(T_{ijk}\) is the total of the observations on treatment combination \(\mathit{j\!k}\), \(B_{h}\) is the total of the observations in the \(h\)th block, and \(n_{hijk}\) is 1 if treatment combination \(\mathit{j\!k}\) is in block \(h\), and otherwise \(n_{hijk}\) is 0. Taking all contrast coefficients \(c_{ijk}\) equal to \(+1\) or \(-1\), the variance of the least squares estimator, \(\Sigma\,\Sigma\,\Sigma c_{ijk}\widehat{\tau}_{ijk}\), is

\[\text{Var}\left(\sum_{i}\sum_{j}\sum_{k}c_{ijk}\,\hat{\tau}_{ijk}\right)=\frac {k}{\lambda v}\ \sum_{i}\sum_{j}\sum_{k}c_{ijk}^{2}\ \sigma^{2}=\frac{8\sigma^{2}}{6}\, \tag{13.10.3}\]

and this is the same for all main-effect and interaction contrasts for a \(2^{3}\) experiment.

##### Design Possibility 2

For the same experiment, suppose that the 3-factor interaction \(\mathit{ABC}\) is expected to be negligible and is of no interest. Then the balanced incomplete block design discussed above is not ideal, because \(\mathit{ABC}\) contrast is measured with the same precision as the main-effect and 2-factor interaction contrasts. Suppose, instead, we decide to confound the \(\mathit{ABC}\) contrast in each of seven replicates. Using the equations

\[a_{1}+a_{2}+a_{3}=0\text{ or }1\ (\text{mod}\ 2),\]

the following single-replicate design in two blocks would be obtained:

\[\begin{array}{l}\text{Block I: }\ 000\ 011\ 101\ 110\\ \text{Block II: }\ 001\ 010\ 100\ 111\end{array}\]

The design in \(b=14\) blocks is obtained by repeating these two blocks \(r=7\) times. Since \(\mathit{ABC}\) is confounded in every replicate, it is not estimable--it cannot be measured. \(\mathit{ABC}\) is said to be _completely confounded_. All other orthogonal contrasts (including the main-effect and 2-factor interaction contrasts) are unconfounded, so can be estimated without adjusting for blocks.

Let \(\Sigma\,\Sigma\,\Sigma c_{ijk}\tau_{ijk}\) be a contrast (with all coefficients \(\pm 1\)) measuring a 2-factor interaction or a main effect. Then its least squares estimator is \(\Sigma\,\Sigma\,\Sigma c_{ijk}\overline{Y}_{.ijk}\), where the average is taken over the 7 replicates or repeated pairs of blocks. The corresponding variance is

\[\text{Var}\left(\Sigma\,\Sigma\,\Sigma c_{ijk}\,\widehat{\tau}_{ijk}\right)= \text{Var}\left(\Sigma\,\Sigma\,\Sigma c_{ijk}\overline{Y}_{.ijk}\right)=\frac {8\sigma^{2}}{7}. \tag{13.10.4}\]

\begin{table}
\begin{tabular}{c c c c c c c c c c c c c} \hline  & & & & & & Blocks & & & & & & & \\ I & II & III & IV & V & VI & VII & VIII & IX & X & XI & XIII & XIV \\ \hline
1 & 5 & 1 & 3 & 1 & 2 & 1 & 2 & 1 & 3 & 1 & 2 & 1 & 2 \\
2 & 6 & 2 & 4 & 3 & 4 & 4 & 3 & 2 & 4 & 3 & 4 & 4 & 3 \\
3 & 7 & 7 & 5 & 6 & 5 & 6 & 5 & 5 & 7 & 5 & 6 & 5 & 6 \\
4 & 8 & 8 & 6 & 8 & 7 & 7 & 8 & 6 & 8 & 7 & 8 & 8 & 7 \\ \hline \end{tabular}
\end{table}
Table 17: A balanced incomplete block design with 8 treatment labels and 14 blocks of size 4Comparing (13.10.4) with (13.10.3), we see that the effect of losing all of the information on the _ABC_ contrast is to reduce the variance of all other factorial contrasts from \(8\sigma^{2}/6\) to \(8\sigma^{2}/7\).

#### Design Possibility 3

Instead of repeating the same design seven times as was done above, we could try to spread the loss of information due to confounding across several of the interaction contrasts by using partial confounding. Suppose that we take four copies of the two blocks that confound _ABC_, together with one pair of blocks that confounds _AB_, one pair that confounds _AC_, and one pair that confounds _BC_. This seven-replicate design is shown in Table 13.18.

The _ABC_ contrast is confounded in replicates I-IV, but can be estimated (without block adjustments) from replicates V-VII (that is, from Blocks IX-XIV, or three pairs of blocks). The variance of the _ABC_ contrast estimator is then \(8\sigma^{2}/3\), compared with \(8\sigma^{2}/6\) in the balanced incomplete block design--it is completely confounded in the second design.

Each 2-factor interaction contrast can be estimated without block adjustments from the six replicates, or pairs of blocks, in which it is not confounded. The variances of their least squares estimators are then \(8\sigma^{2}/6\), the same as in the balanced incomplete block design, but worse than the value \(8\sigma^{2}/7\) for the design with _ABC_ completely confounded.

The main effects can be estimated from all seven replicates. The variances of their contrast estimators are all \(8\sigma^{2}/7\), the same as for the second design, but better than the value of \(8\sigma^{2}/6\) for the balanced incomplete block design.

#### Summary

A summary of the variances of the least squares estimators of the factorial contrasts is given in Table 13.19. No one design is the best for all seven factorial effects. The choice of design would depend upon the importance of estimating the _ABC_ contrast relative to the 2-factor and main-effect contrasts.

\begin{table}
\begin{tabular}{c c c c c} \hline Contrast & Design 1 & Design 2 & Design 3 \\ \cline{2-5}  & BIBD & Complete Confounding of _ABC_ & Partial Confounding of _ABC_, _AB_, _AC_, _BC_ \\ \hline _ABC_ & \(\frac{8\sigma^{2}}{6}\) & not estimable & \(\frac{8\sigma^{2}}{3}\) \\ _AB_, _AC_, _BC_ & \(\frac{8\sigma^{2}}{6}\) & \(\frac{8\sigma^{2}}{7}\) & \(\frac{8\sigma^{2}}{6}\) \\ \(A\), \(B\), \(C\) & \(\frac{8\sigma^{2}}{6}\) & \(\frac{8\sigma^{2}}{7}\) & \(\frac{8\sigma^{2}}{7}\) \\ \hline \end{tabular}
\end{table}
Table 13.19: Variances of contrast estimators \(\Sigma\,\Sigma\,\Sigma c_{ijk}\tau_{ijk}\) (with all coefficients \(\pm 1\)) measuring a 2-factor interaction or a main effect for three design possibilities for \(v=8,r=7\), \(b=14\), \(k=4\)We have not exhausted all the possible designs that can be obtained by partial confounding. For example, one could confound the two-factor interactions in two pairs of blocks and the three-factor interaction in one pair of blocks, or alternatively, one could confound each of the seven factorial contrasts in turn in one pair of blocks. (This latter option gives design possibility 1.) In every case, the smaller contrast variances will coincide with the contrasts that are confounded less often, the contrast variance being \(8\sigma^{2}/r\) if the contrast is unconfounded in \(r\) replicates.

#### Using SAS Software

Analyzing factorial experiments with confounding using the SAS software is straightforward for the types of designs discussed in this chapter. The SAS statements required for the analysis are the same as those outlined in Chaps. 6, 7, and 10. Using the GLM procedure, the blocking factor is listed in the MODEL statement first, so that the Type I sums of squares for factorial effects are appropriately adjusted for blocks.

Any effect that is completely confounded--including effects confounded in a single replicate design--should _not_ be included in the MODEL statement. If included after the blocking factor, a completely confounded effect would show zero degrees of freedom under the Type I and Type III sums of squares. The corresponding degree of freedom would already be accounted for under block effects. Partially confounded effects, however, should be included in the model statement as illustrated in the following example.

\begin{table}
\begin{tabular}{r r} DATA COIL; \\ INPUT BLOCK A B C Y; \\ LINES; \\
1 0 0 0 2208 \\
1 1 1 0 2133 \\
1 1 0 1 2459 \\
1 0 1 1 3096 \\
2 1 0 0 2196 \\ : : : : : \\
8 1 1 0 2156 \\
8 0 0 1 3423 \\
8 1 0 1 2524 \\ ; \\ PROC GLM; \\ CLASS BLOCK A B C; \\ MODEL Y = BLOCK A B C A*B A*C B*C A*B*C; \\ ESTIMATE ’A’ A -1 1; \\ ESTIMATE ’B’ B -1 1; \\ ESTIMATE ’C’ C -1 1; \\ ESTIMATE ’AB’ A*B 1 -1 -1 1 / DIVISOR=2; \\ ESTIMATE ’AC’ A*C 1 -1 -1 1 / DIVISOR=2; \\ ESTIMATE ’BC’ B*C 1 -1 -1 1 / DIVISOR=2; \\ ESTIMATE ’ABC’ A*B*C -1 1 1 -1 1 -1 -1 1 / DIVISOR=4; \\ \end{tabular}
\end{table}
Table 20: SAS program for analysis of an experiment with partial confounding—the coil experiment 

#### Example 13.11.1 Partial confounding-Coil experiment, continued

Table 13.20 contains a SAS program for analysis of the coil experiment data. Corresponding output is given in Fig. 13.6. The coil experiment was a four-replicate \(2^{3}\) experiment with partial confounding--each of the four interaction effects was confounded in one of the four replicates. In the GLM procedure, the blocking factor is entered into the MODEL statement first. As a result, the Type I sum of squares for blocks is unadjusted for treatment effects, whereas the Type I sums of squares for each treatment interaction effect is adjusted for block effects. The Type III sum of squares for blocks is adjusted for treatment effects, so can be used to assess the usefulness of blocking in this experiment.

The divisors used in the ESTIMATE statements of the GLM procedure cause use of divisor \(v/2=4\) for the contrast coefficients \(c_{ijk}\) for each contrast. Thus, all contrasts would have been estimated with the same variance had there been no partial confounding. Because each interaction contrast is confounded in one of the four replicates, the variance of each interaction contrast estimator is larger than each main effect contrast estimator by a factor of four-thirds (i.e. \(97.079^{2}/84.073^{2}\) = 1.333).

Figure 13.6: SAS program partial output illustrating partial confounding—the coil experiment

[MISSING_PAGE_EMPTY:8416]

[MISSING_PAGE_FAIL:482]

treatment interaction effect is adjusted for block effects. The Type III sum of squares for blocks (not shown) is adjusted for treatment effects, so can be used to assess the usefulness of blocking in this experiment.

In the third block of code, for each factorial effect contrast, the summary and contrast functions of lsmeans are coupled to compute the contrast estimate, standard error, _t_-test, and 95% confidence interval. Since each main effect contrast is averaged over the four combinations of two other factors, specifying a pair of coefficients \(\pm 1\) yields contrast coefficients \(c_{ijk}\) with divisor \(v/2=4\). Likewise, each two-factor interaction contrast is averaged over the two levels of the third factor, so specifying four coefficients \(\pm 1/2\) again yields contrast coefficients \(c_{ijk}\) with divisor \(v/2=4\). The three factor interaction contrast coefficients \(c_{ijk}\) have divisor \(v/2=4\) as directly specified. Output for the main effect of \(B\), the \(BC\) interaction, and the \(ABC\) interaction contrasts are shown in the bottom of Table 13.22.

Since all contrasts considered here have contrast coefficients \(c_{ijk}=\pm 1/4\), all contrasts would have been estimated with the same variance had there been no partial confounding. Because each interaction contrast is confounded in one of the four replicates, the variance of each interaction contrast estimator is larger than that of each main effect contrast estimator by a factor of four-thirds. Correspondingly, the squares of the standard errors are in this ratio. 

## Exercises

1. Construct a single-replicate \(2^{3}\) design confounding \(AB\) with blocks. In other words, list the treatment combinations block by block.
2. Construct a single replicate \(2^{5}\) design confounding \(ABC\) and \(CDE\). Determine the other effect that is confounded.
3. **Projectile experiment** N.L. Johnson and F.C. Leone, in their 1977 book _Statistics and Experimental Design in Engineering and the Physical Sciences_, described a single-replicate \(2^{4}\) experiment concerning the performance of a new rifle under test. Under study were the effects on projectile velocity of the factors charge weight (\(A\)), projectile weight (\(B\)), propellant web (\(C\)), and weapon (\(D\)), where two rifles were used. The design included two blocks each of size eight, corresponding to the two days on which data were collected, confounding \(ABCD\). The coded velocity data are given in Table 13.23.

\begin{table}
\begin{tabular}{c c c c c c} \hline  & Day 1 & & & Day 2 & \\ Run & TC & \(y_{1ijkl}\) & Run & TC & \(y_{2ijkl}\) & \\ \hline
1 & 0000 & 97 & 13 & 0001 & 75 \\
7 & 0011 & 26 & 11 & 0010 & 39 \\
5 & 0101 & 53 & 9 & 0100 & 68 \\
3 & 0110 & 15 & 15 & 0111 & \(-\)16 \\
6 & 1001 & 145 & 10 & 1000 & 151 \\
4 & 1010 & 100 & 16 & 1011 & 97 \\
2 & 1100 & 150 & 14 & 1101 & 141 \\
8 & 1111 & 54 & 12 & 1110 & 66 \\ \hline \end{tabular}
\end{table}
Table 13.23: Projectile experiment data, confounding \(ABCD\)1. Fit a model including block effects, treatment main effects, and 2-factor interactions. Use residual plots to check the standard model assumptions. 2. Conduct the analysis of variance, and discuss the results. 3. Construct simultaneous confidence intervals for any interesting treatment contrasts using an appropriate method of multiple comparisons. 4. Reanalyze the data using the Voss-Wang method, including all estimable treatment effects in the analysis.
4. **Field experiment, continued** 1. For the field experiment of Example 13.3.1, p. 437, verify that the sum of squares and the contrast estimate for _BD_ are as shown in Table 13.5, p. 438. 2. Draw the _BD_ interaction plot. Does this plot also suggest that \(B\) and \(D\) should be at their low levels? 3. Suppose that the experimenters had expected all of the 3-factor interactions to be negligible and had omitted the corresponding terms from the model (instead of those involving _AD_). Reanalyze the experiment accordingly. What would have been concluded? 4. Apply the Voss-Wang method to analyze the data of the field experiment. Relevant information is given in Table 13.5, p. 438.
5. Suggest a confounding scheme for a 26 experiment in 8 blocks of 8, assuming that all 2-factor interactions are to be estimated, as are the 3-factor interactions involving both \(A\) and \(F\). List all effects confounded. List the treatment combinations in the design block by block.
6. Suggest a confounding scheme for a 28 experiment in 16 blocks of 16, assuming that all 2-factor and 3-factor interactions are to be estimated. List all effects confounded. List the treatment combinations in Block I and in two other blocks.
7. **Mangold experiment, continued** 1. For the mangold experiment of Sect. 13.5, verify that the sum of squares and the contrast estimate for _CD_ are as shown in Table 13.12, p. 449. 2. Draw the _CD_ interaction plot. Does this plot agree with the factor levels suggested in Sect. 13.5 for increasing the yield? 3. Check that the assumption of normality of the error variables is satisfied. Also check that the variances of the errors appear to be equal for each level of the four factors. 4. Draw a half-normal probability plot of all of the contrast estimates (including the higher-order interactions). Does it appear that the experimenters made the correct assumptions of negligible higher-order interactions?
8. **Decontamination experiment--Beta particles** An experiment was described by M. K. Barnett and F. C. Mead, Jr. in the journal _Applied Statistics_ in 1956 to explore the effect of four factors on the efficiency of a decontamination process for the removal of radioactive isotopes from liquid waste. The measurements taken after the decontamination process were the counts per minute per milliliter of alpha and beta particles. Data for the alpha particles and further description of the experiment were given in Sect. 13.8.1, p. 452. We consider here part of the data for the beta particles, shown in Table 13.24. The four treatment factors were:

[MISSING_PAGE_FAIL:485]

* The experimenters decided to use logarithms of the data. Does your assumption check in part (a) confirm that this should be done? If so, reanalyze the data and state your conclusions.
* Using the logarithms of the data, draw a half-normal probability plot of the contrast estimates without using any knowledge that the higher-order interactions are likely to be negligible. Do your conclusions remain the same? Which analysis do you prefer? Why?
10. **Peas experiment** The following experiment was run at Biggelswade, in England, and reported by F. Yates in his 1935 paper _Complex Experiments_. The three treatment factors were the standard fertilizers, nitrogen, phosphate, and potassium (factors \(N\), \(P\), and \(K\)) each at two levels. The experimental area was divided into \(b=6\) blocks of 1/70 of an acre. Each block was large enough for four plots on which a certain variety of pea was sown, and the fertilizer combinations shown in Table 13.26 were added. The design consists of three identical single-replicate designs each of which confounds the 3-factor interaction \(NPK\). Each block has been separately randomized. 1. Estimate the treatment contrasts for all main effects and interactions. 2. Calculate the analysis of variance table for this experiment and test all relevant hypotheses. State the overall significance level. 3. Draw interaction plots for any important interactions. Give a set of 95% confidence intervals for the main-effect contrasts, if appropriate. 4. State your overall recommendations about the fertilizers in this experiment. Would you recommend a followup experiment? If so, what would you investigate?
11. **Field experiment, continued** The field experiment was described in Example 13.3.1, p. 437. There were four treatment factors

\begin{table}
\begin{tabular}{c c c c} \hline \hline  & Block I & & Block II \\ Treatment combination & Yield & Treatment combination & Yield \\ \hline
00000 & 142 & 00001 & 106 \\
00011 & 101 & 00010 & 148 \\
00101 & 113 & 00100 & 185 \\
00110 & 200 & 00111 & 130 \\
01001 & 88 & 01000 & 129 \\
01010 & 146 & 01011 & 140 \\
01100 & 200 & 01101 & 166 \\
01111 & 145 & 01110 & 215 \\
10001 & 106 & 10000 & 114 \\
10010 & 108 & 10011 & 114 \\
10100 & 162 & 10101 & 88 \\
10111 & 83 & 10110 & 164 \\
11000 & 109 & 11001 & 98 \\
11011 & 72 & 11010 & 195 \\
11101 & 79 & 11100 & 172 \\
11110 & 118 & 11111 & 110 \\ \hline \hline \end{tabular} _Source Data adapted from _The Design and Analysis of Industrial Experiments_ Second edition, 1979. Editor O. L. Davies. Published by Longman Group Ltd

\end{table}
Table 13.25: Data for the penicillin experiment (\(A\), \(B\), \(C\), and \(D\)) at two levels each, and the \(v=16\) treatment combinations were observed twice. Each of the \(r=2\) sets of treatment combinations were divided into blocks of size 8. The first two blocks, which confounded the \(ABCD\) interaction, were shown in Table 13.4, p. 437. The complete design, which is shown in Table 27, consisted of two such single-replicate designs. 1. Calculate the analysis of variance table for this experiment. Now that \(r=2\), there is an estimate for error variability. Test any hypotheses of interest. Are the results similar to those obtained from the first two blocks only? 2. Draw any interaction plots of interest. If the yield is to be increased, what recommendations would you make about the levels of the factors?
12. Construct a four-replicate \(2^{3}\) design in eight blocks of size four, partially confounding each interaction effect. Compare the variance of each interaction contrast with that of each main effect, using divisor \(v/2=4\) for each contrast.
13. **Catalytic reaction experiment** J.R. Bainbridge, in his 1951 article in the journal _Industrial and Engineering Chemistry_, described a factorial experiment conducted at a small plant carrying out a catalytic gaseous synthesis reaction to remove the product as a liquid solution. A 2-replicate \(2^{3}\) experiment was conducted to study the effects of converter reaction temperature (factor \(A\)), throughput rate through the converter (factor \(B\)), and the concentration of the active ingredient in the makeup gas (factor \(C\)) on each of several response variables, including the strength of the product solution (\(y_{hijk}\)). The design was composed of four blocks of size four, with the \(ABC\) interaction completely confounded. The design

\begin{table}
\begin{tabular}{c c c c c c c} \hline Block & \multicolumn{2}{c}{Block I} & \multicolumn{2}{c}{Block II} & \multicolumn{2}{c}{Block III} & \multicolumn{2}{c}{Block IV} \\ TC & \(y_{1ijkl}\) & TC & \(y_{2ijkl}\) & TC & \(y_{3ijkl}\) & TC & \(y_{4ijkl}\) \\ \hline
0000 & 58 & 0001 & 55 & 0000 & 57 & 0001 & 50 \\
0011 & 51 & 0010 & 45 & 0011 & 56 & 0010 & 39 \\
0101 & 44 & 0100 & 42 & 0101 & 43 & 0100 & 47 \\
0110 & 50 & 0111 & 36 & 0110 & 39 & 0111 & 43 \\
1001 & 43 & 1000 & 53 & 1001 & 52 & 1000 & 42 \\
1010 & 50 & 1011 & 55 & 1010 & 52 & 1011 & 44 \\
1100 & 41 & 1101 & 41 & 1100 & 42 & 1101 & 34 \\
1111 & 44 & 1110 & 48 & 1111 & 54 & 1110 & 52 \\ \hline \end{tabular}
\end{table}
Table 27: Data for the field experiment, by block and treatment combination (TC)

\begin{table}
\begin{tabular}{c c c c c} \hline Block & \multicolumn{2}{c}{Treatment combinations (Yield)} & Block & \multicolumn{2}{c}{Treatment combinations (Yield)} \\ \hline I & 011 (49.5) & 000 (46.8) & II & 100 (62.0) & 001 (45.5) \\  & 110 (62.8) & 101 (57.0) & & 111 (48.8) & 010 (44.2) \\ III & 100 (59.8) & 001 (55.5) & IV & 110 (52.0) & 101 (49.8) \\  & 111 (58.5) & 010 (56.0) & & 000and data are provided in Table 13.28, including the run order. (The observations in Table 13.28 are "uncoded," each value being 80 plus one-tenth the coded value given by Bainbridge.)
1. Based on the run order, discuss how the design was probably randomized.
2. Fit an appropriate model, and use residual plots to check the standard model assumptions.
3. Conduct the analysis of variance, and discuss the results.
4. Using a simultaneous confidence level of 95% for all six factorial effects, construct confidence intervals for those effects found to be significant in the analysis of variance.

14. **Catalytic reaction experiment, continued** In the experiment described in Exercise 13, the covariate "makeup gas purity" was measured. The covariate values were 17, 12, 10, 10, 13, 14, 10, 16, 12, 13, 13, 11, 16, 11, 12, and 11, corresponding to runs 1-16, respectively. Repeat Exercise 13, but for an analysis of covariance.
15. **Design of a follow-up experiment** An experiment was run in 2007 by Joanne Sklodowski, Josh Svenson, Adam Dallas, Tim Degenero and Paul Cotellesso to examine the compressive strength of various mortar mixes. They examined the effects of four factors: Amount of water (Factor \(A,0.75\)lb and \(0.85\)lb), Sand type (Factor \(B\), play sand and medium grain sand), Temperature of water (Factor \(C\), \(58\) and \(96\,^{\circ}\)C), Cure time (Factor \(D\), \(4\) and \(6\) days). The type and age of cement and the mixing time were held fixed throughout the experiment. The ingredients were mixed and poured into a cylindrical mold. After the allotted curing time, the cylinder was crushed on a compression machine. The maximum pressure exerted before the cylinder failed was recorded in pounds per square inch (psi). 1. The analysis of the experiment showed large effects of \(BCD\), \(B\), \(C\), \(AB\). Design a follow-up experiment to examine the interactions \(AB\), \(BC\), \(BD\), \(CD\) and \(BCD\), as well as all main effects. You can only take \(r=1\) observation on each treatment combination and you need to run the experiment in \(4\) blocks of \(4\). Write out two of the four blocks of your design and state how to find the other two. 2. Write down a model for this experiment. Write out the "Degrees of Freedom" columns of the analysis of variance table. 2. Write down a model for this experiment. Write out the "Degrees of Freedom" columns of the analysis of variance table. 3. Write down a model for this experiment. Write out the "Degrees of Freedom" columns of the analysis of variance table. 4. Write down a model for this experiment. Write out the "Degrees of Freedom" columns of the analysis of variance table. 5. Write down a model for this experiment. Write out the "Degrees of Freedom" columns of the analysis of variance table. 6. Write down a model for this experiment. Write out the "Degrees of Freedom" columns of the analysis of variance table. 7. Write down a model for this experiment. Write out the "Degrees of Freedom" columns of the analysis of variance table. 8. Write down a model for this experiment. Write out the "Degrees of Freedom" columns of the analysis of variance table. 9. Write down a model for this experiment. Write out the "Degrees of Freedom" columns of the analysis of variance table. 10. Write down a model for this experiment. Write out the "Degrees of Freedom" columns of the analysis of variance table. 11.

16. **Design of an experiment** 1. Design an experiment with five factors \(A\), \(B\), \(C\), \(D\), \(E\), each having two levels, in 4 blocks of 8 and \(r=1\) observation per treatment combination. Make sure that you can estimate all main effects, all two-factor interactions, as well as all three-factor interactions that involve _both_\(D\) and \(E\). 2. Write out the 8 treatment combinations in Block I, and indicate how to find the treatment combinations in the other blocks. Illustrate this with two treatment combinations in the second block. 3. Write out the degrees of freedom column for the analysis of variance table corresponding to the model that you would fit.

[MISSING_PAGE_EMPTY:8425]

#### 14.1 Introduction

In Chap. 13, incomplete block designs for \(2^{p}\) factorial experiments were obtained by confounding one or more interaction contrasts with block contrasts. In this chapter, we extend the idea of confounding to encompass experiments in which some or all factors have more than two levels. We will code the levels of an \(m\)-level factor as \(0\), \(1\), \(\ldots\), \(m-1\).

In Sect. 14.2, we consider single-replicate \(3^{p}\) experiments arranged in \(b=3^{s}\) blocks of size \(k=3^{p-s}\). The techniques used in designing these types of experiment can be adapted for \(m^{p}\) experiments in \(m^{s}\) blocks of size \(m^{p-s}\) where \(m\) is a prime number.

Pseudofactors are introduced in Sect. 14.3 to facilitate confounding in symmetric \(4^{p}\) experiments and asymmetric \(2^{p}4^{q}\) experiments. Then, in Sect. 14.4, we consider asymmetric experiments involving factors or pseudofactors at both two and three levels, allowing us to look at more complicated situations where the treatment factors have a mixture of \(2\), \(3\), \(4\), and \(6\) levels.

Analysis of a two-replicate \(3^{3}\) experiment with partial confounding is illustrated using the SAS and R software packages in Sects. 14.5 and 14.6, respectively.

### 14.2 Confounding with Factors at Three Levels

#### 14.2.1 Contrasts

In a factorial experiment where all treatment factors have \(3\) levels, each main effect has \(2\) degrees of freedom associated with it, each two-factor interaction has \(2\times 2=4\) degrees of freedom, etc. (see rule 3 of Sect. 7.3). Therefore, we can find \(2\) orthogonal contrasts to measure each main effect, \(4\) orthogonal contrasts to measure each two-factor interaction, and so on.

In a \(3^{2}\) experiment, for example, two orthogonal contrasts measuring the main effect of each of factors \(A\) and \(B\) are the linear and quadratic trend contrasts. Similarly, four orthogonal trend contrasts \(A_{\rm L}B_{\rm L}\), \(A_{\rm L}B_{\rm Q}\), \(A_{\rm Q}B_{\rm L}\), and \(A_{\rm Q}B_{\rm Q}\) (see Sect. 6.3) measuring the interaction are reproduced in Table 14.1. A different set of four orthogonal contrasts, labeled in pairs as (\(AB\); \(A^{2}B^{2}\)) and (\(AB^{2}\); \(A^{2}B\)), is also shown in Table 14.1. Although this second set of contrasts is less useful than the set of trend contrasts in measuring details of the interaction for quantitative factors, it will prove extremely useful for confounding purposes. The reader is asked to verify that _any_ contrasts that measure the main effects of \(A\) and \(B\) are orthogonal to all the contrasts in Table 14.1 measuring the interaction.

Notice that the pair of contrasts labeled (\(AB\); \(A^{2}B^{2}\)) are two orthogonal contrasts that compare the three groups of treatment combinations (00, 12, 21) and (01, 10, 22) and (02, 11, 20). Any linear combination of this pair of contrasts is also a contrast between these three groups of treatment combinations. We have illustrated these groups of treatment combinations in the left-hand side of Table 14.2, where treatment combinations with the same superscript are in the same group. Notice that each group contains one treatment combination from each row and each column, making sure that each level of each factor is represented once in each group.

Similarly, the pair of contrasts labeled (\(AB^{2}\); \(A^{2}B\)) comprise two orthogonal contrasts that compare the three groups of treatment combinations (00, 11, 22) and (01, 12, 20) and (02, 10, 21). Any linear combination of this pair of contrasts is also a contrast between these three groups of treatment combinations. The groups are illustrated in the right-hand side of Table 14.2 and also have the property that each group contains one treatment combination from each row and each column.

The reason for the labeling (\(AB\); \(A^{2}B^{2}\)) and (\(AB^{2}\); \(A^{2}B\)) is to match the contrasts with the equation method of confounding in Sect. 14.2.3. The contrast names themselves have little meaning, except to acknowledge that each contrast belongs to the \(AB\) interaction and, as will be seen, each pair corresponds to a set of equations that partitions the treatment combinations into the three groups represented in Table 14.2.

Many texts list only one of the two labels in each pair, since each is the square of the other. For example, when the exponents are reduced modulo 3, then \(A^{2}B=(AB^{2})^{2}\). The convention is then to list \(AB^{2}\) rather than \(A^{2}B\), for example, since the leading exponent is one. However, we will list both labels to aid in identifying a complete set of confounded contrasts in designs with more than three blocks.

#### Confounding Using Contrasts

In this section we consider the division of treatment combinations into blocks by deliberately confounding negligible contrasts, as in Sect. 13.3.2 for \(2^{p}\) experiments. For \(3^{p}\) experiments, we look at designs with \(3^{s}\) blocks of size \(3^{p-s}\), starting with 3 blocks of size \(3^{p-1}\). For a design with \(b=3\) blocks,

\begin{table}
\begin{tabular}{c c c c c c c c} \hline TC & \(A_{\mathrm{L}}B_{\mathrm{L}}\) & \(A_{\mathrm{L}}B_{\mathrm{Q}}\) & \(A_{\mathrm{Q}}B_{\mathrm{L}}\) & \(A_{\mathrm{Q}}B_{\mathrm{Q}}\) & (\(AB\); \(A^{2}B^{2}\)) & (\(AB^{2}\); \(A^{2}B\)) \\ \hline
00 & 1 & -1 & -1 & 1 & -1 & 1 & -1 & 1 \\
01 & 0 & 2 & 0 & -2 & 0 & -2 & 1 & 1 \\
02 & -1 & -1 & 1 & 1 & 1 & 1 & 0 & -2 \\
10 & 0 & 0 & 2 & -2 & 0 & -2 & 0 & -2 \\
11 & 0 & 0 & 0 & 4 & 1 & 1 & -1 & 1 \\
12 & 0 & 0 & -2 & -2 & -1 & 1 & 1 & 1 \\
20 & -1 & 1 & -1 & 1 & 1 & 1 & 1 & 1 \\
21 & 0 & -2 & 0 & -2 & -1 & 1 & 0 & -2 \\
22 & 1 & 1 & 1 & 1 & 0 & -2 & -1 & 1 \\ \hline \end{tabular}
\end{table}
Table 14.1: Sets of orthogonal contrasts measuring the interaction in a \(3^{2}\) experiment two degrees of freedom are used to measure the block differences. Therefore, in a single-replicate design, we must confound a pair of treatment contrasts.

As a simple example, we start with an experiment with two factors \(A\) and \(B\) in which the interaction is known to be negligible. We will attempt to use two of the interaction contrasts shown in Table 14.1 to divide the treatment combinations into 3 blocks. A pair of trend contrasts, such as \(A_{\text{L}}B_{\text{Q}}\) and \(A_{\text{Q}}B_{\text{Q}}\) cannot be used to give blocks of equal size, since the values of the coefficients do not fall into 3 groups of 3. However, the pair of contrasts labeled (\(AB\); \(A^{2}B^{2}\)) have three pairs of coefficients (\(-1,\ 1\)), (\(0,\,-2\)), and (\(1,\ 1\)) each of which appear three times. If we use these as a guide to dividing the treatment combinations into blocks, we obtain the design in Table 14.3.

Any contrast that is orthogonal to the two confounded contrasts can be estimated without requiring block adjustments. Estimable contrasts include all contrasts measuring the main effects of \(A\) and \(B\) and the remaining two interaction contrasts labeled (\(A^{2}B\); \(AB^{2}\)) and linear combinations of these. The trend contrasts in Table 14.1 are not orthogonal to any of the \(AB\), \(A^{2}B^{2}\), \(AB^{2}\), \(A^{2}B\) contrasts, so they do not fall into either the confounded or the estimable category. They are _partly confounded_. In general, interaction trend contrasts can be estimated completely only when no contrasts from the interaction are confounded.

In the present example, the interaction has four degrees of freedom. Two are used to measure blocks. The other two correspond to two estimable contrasts, which are negligible and provide two degrees of freedom to measure \(\sigma^{2}\).

If the contrasts labeled (\(A^{2}B\); \(AB^{2}\)) in Table 14.1 were used instead of the contrasts labeled (\(AB\); \(A^{2}B^{2}\)) to provide three blocks, the design of Table 14.4 would result. This has the same properties as the design in Table 14.3 in that all main-effect contrasts are estimable and there are two estimable contrasts (\(AB\); \(A^{2}B^{2}\)) remaining in the interaction. Neither design is better than the other, and a choice can be made at random. Block design randomization should be carried out before the design is used.

As we saw in \(2^{p}\) experiments, there is a correspondence between the contrasts used for confounding, the contrast names, and the equation method of confounding. In the next section we show how to obtain the design of Table 14.3 by the equation method.

#### Confounding Using Equations

##### \(3^{p}\) Experiments in Three Blocks

The design in Table 14.3, which was obtained by confounding the two interaction contrasts labeled (\(AB\); \(A^{2}B^{2}\)) in Table 14.1, can be obtained by an equation method similar to that of Sect. 13.4. Notice that in Block I the digits of the three treatment combinations add to 0 or 3. In Block II they add to 1 or 4, and in Block III they add to 2. Now that both factors have three levels, we work modulo 3, which means that we subtract 3 from the sum of the digits until we obtain one of 0, 1, or 2, or equivalently, we take the remainder on division by 3. Writing the treatment combinations as \(a_{1}a_{2}\), the blocks can be defined by the confounding equations

\[\begin{array}{ll}\text{Block I:}&\text{Treatment combinations with}\,L=a_{1}+a_{2}=0\,\,(\text{mod}\,3)\,,\\ \text{Block II:}&\text{Treatment combinations with}\,L=a_{1}+a_{2}=1\,\,(\text{mod}\,3)\,,\\ \text{Block III:}&\text{Treatment combinations with}\,L=a_{1}+a_{2}=2\,\,(\text{mod}\,3)\,.\end{array}\]

Equivalently, the same three blocks can be obtained if the equations are multiplied by 2; that is,

\[\begin{array}{ll}\text{Block I:}&\text{Treatment combinations with}\,2L=2a_{1}+2a_{2}=0\,\,(\text{mod}\,3)\,,\\ \text{Block II:}&\text{Treatment combinations with}\,2L=2a_{1}+2a_{2}=2\,\,(\text{mod}\,3)\,,\\ \text{Block III:}&\text{Treatment combinations with}\,2L=2a_{1}+2a_{2}=1\,\,(\text{mod}\,3)\,.\end{array}\]

Thus, if the contrasts labeled (\(AB\); \(A^{2}\!B^{2}\)) in Table 14.1 are confounded with blocks, the treatment combinations in the three blocks satisfy both

\[L=a_{1}+a_{2}=0,\,\,1,\,\,\text{or}\,\,2\,\,(\text{mod}\,3),\]

and

\[2L=2a_{1}+2a_{2}=0,\,\,2,\,\,\text{or}\,\,1\,\,(\text{mod}\,3).\]

Alternatively, if the contrasts labeled (\(AB^{2}\); \(A^{2}\!B\)) are to be confounded, the equations

\[L=a_{1}+2a_{2}=0,\,\,1,\,\,\text{or}\,\,2\,\,(\text{mod}\,3)\]

and, multiplying by 2,

\[2L=2a_{1}+a_{2}=0,\,\,2,\,\,\text{or}\,\,1\,\,(\text{mod}\,3)\]

will produce the design in Table 14.4. Notice that the coefficients in the confounding equations correspond to the exponents in the contrast names. A set of equations defines the same set of blocks when it is multiplied by 2. Therefore, the confounded contrast names always come in pairs--one name being the square of the other--(\(AB^{2}\))\({}^{2}=A^{2}\!B^{4}=A^{2}\!B\), reducing exponents (mod 3).

In general, in a \(3^{p}\) experiment, if the equations

\[L=z_{1}a_{1}+z_{2}a_{2}+\cdots+z_{p}a_{p}=0,\,\,1,\,\text{or}\,\,2\,\,(\text{ mod}\,3)\]

are used to produce three blocks, two contrasts will be confounded that can be labeled (\(A^{z_{1}}\!B^{z_{2}}\cdots P^{z_{p}}\); \(A^{2z_{1}}\!B^{2z_{2}}\cdots P^{2z_{p}}\)), where \(z_{i}\) is 1 or 2 if the factor is present in the interaction, and 0 if it is not, and where the exponent is reduced modulo 3. For example, in a \(3^{5}\) experiment, the equations

\[L=a_{1}+2a_{2}+a_{4}=0,\,\,1,\,\,\text{or}\,\,2\,\,(\text{mod}\,3)\]

will give 3 blocks of size \(3^{4}\) confounding \(AB^{2}\!D\) and \(A^{2}\!B^{4}\!D^{2}=A^{2}\!B\!D^{2}\), which represent two contrasts from the three-factor interaction \(ABD\). It is rarely of importance to identify exactly what the contrasts look like (they are any pair of orthogonal contrasts between the groups of treatment combinations in the three blocks). What is important is the knowledge that the confounded contrasts belong to a particular interaction and, therefore, that all other main-effect and interaction contrasts are estimable.

### 3\({}^{p}\) Experiments in Nine Blocks

The equation method of confounding can be used to produce \(b=9=3^{2}\) blocks of size \(3^{p-2}\) in a \(3^{p}\) experiment by selecting two pairs of contrasts to be confounded. If the pair (\(A^{2_{1}}\!B^{2_{2}}\cdots P^{2_{p}}\); \(A^{2_{2}}\!iB^{2_{2}}\cdots P^{2_{2p}}\)) is chosen for confounding together with the pair (\(A^{y_{1}}\!B^{y_{2}}\cdots P^{y_{p}}\); \(A^{2y_{1}}\!B^{2y_{2}}\cdots P^{2y_{p}}\)), the \(b=9\) blocks are produced from the nine possible pairs of values of the two equations

\[L_{1}=z_{1}a_{1}+z_{2}a_{2}+\cdots+z_{p}a_{p}=0,\ 1,\ \text{or}\ 2\ (\text{mod}\ 3),\]

\[L_{2}=y_{1}a_{1}+y_{2}a_{2}+\cdots+y_{p}a_{p}=0,\ 1,\ \text{or}\ 2\ (\text{mod}\ 3).\]

The \(b-1=8\) confounded contrasts are the two pairs originally chosen, together with all possible products. This is most conveniently set out as a table. The selected pairs of contrasts are written in the first row and first column. The table is then filled out by multiplication, and the exponents are reduced modulo 3, as follows:

\[A^{y_{1}}\!B^{y_{2}}\cdots P^{y_{p}} A^{2y_{1}}\!B^{2y_{2}}\cdots P^{2y_{p}}\] \[A^{z_{1}}\!B^{z_{2}}\cdots P^{z_{p}} A^{z_{1}+y_{1}}\!B^{z_{2}+y_{2}}\cdots P^{z_{p}+y_{p}} A^{z_{1}+2y_{1}}\!B^{z_{2}+2y_{2}}\cdots P^{z_{p}+2y_{p}}\] \[A^{2z_{1}}\!B^{2z_{2}}\cdots P^{2z_{p}} A^{2z_{1}+y_{1}}\!B^{2z_{2}+y_{2}}\cdots P^{2z_{p}+y_{p}} A^{2z_{1}+2y_{1}}\!B^{2z_{2}+2y_{2}}\cdots P^{2z_{p}+2y_{p}}\]

If \(b=3^{s}\) blocks of size \(3^{p-s}\) are required, then \(s\) independent pairs of contrast names need to be chosen for confounding. All possible products determine the entire set of \(b-1=3^{s}-1\) confounded contrasts.

#### 3\({}^{4}\) experiment in 9 blocks of size 9

Suppose that a \(3^{4}\) experiment, with factors \(A\), \(B\), \(C\), \(D\), is to be run in \(b=9\) blocks of size 9. Further, suppose that the only interactions thought to be important are the 2-factor interactions and, therefore, these should not be confounded. Now \(b=3^{2}\) blocks are required, so 2 pairs of contrasts should be chosen for confounding. The \(ABCD\) interaction has 16 degrees of freedom, so we can find 16 orthogonal contrasts and label them in pairs as

\[\begin{array}{ll}(ABCD;A^{2}\!B^{2}\!C^{2}\!D^{2}),&(AB^{2}\!CD;A^{2}\!BC^{2 }\!D^{2}),\\ (ABCD^{2};A^{2}\!B^{2}\!C^{2}\!D),&(AB^{2}\!CD^{2};A^{2}\!BC^{2}\!D),\\ (ABC^{2}\!D;A^{2}\!B^{2}\!CD^{2}),&(AB^{2}\!C^{2}\!D;A^{2}\!BCD^{2}),\\ (ABC^{2}\!D^{2};A^{2}\!B^{2}\!CD),&(AB^{2}\!C^{2}\!D^{2};A^{2}\!BCD).\end{array}\]

Selecting two pairs of contrasts from the 4-factor interaction for confounding contrasts is not a good choice. For example, if (\(ABCD^{2}\); \(A^{2}\!B^{2}\!C^{2}\!D\)) and (\(ABCD\); \(A^{2}\!B^{2}\!C^{2}\!D^{2}\)) were chosen, the set of eight confounded degrees of freedom would be

\[\begin{array}{ll}ABCD^{2}&A^{2}\!B^{2}\!C^{2}\!D\\ ABCD&A^{2}\!B^{2}\!C^{2}\!D^{2}\\ A^{2}\!B^{2}\!C^{2}\!D^{2}&D&ABC\end{array}\]and we can see that two orthogonal contrasts in the main-effect \(D\) would also be confounded. All possible selections of two pairs of contrasts from the \(ABCD\) interaction will confound either a main effect or a two-factor interaction. However, in this example, the three-factor interactions are also thought to be negligible, so one possible choice is to confound (\(ABD\); \(A^{2}B^{2}D^{2}\)) together with (\(BCD^{2}\); \(B^{2}C^{2}D\)). This gives the following set of eight confounded degrees of freedom.

\[\begin{array}{l}BCD^{2}B^{2}C^{2}D\\ ABD\quad AB^{2}C\quad AC^{2}D^{2}\\ A^{2}B^{2}D^{2}\quad A^{2}CD\quad A^{2}BC\end{array}\]

Thus, each 3-factor interaction (which has 8 degrees of freedom) has two orthogonal contrasts confounded with blocks and six estimable contrasts, which are assumed to be negligible. This means that there are 24 degrees of freedom from the 3-factor interactions and a further 16 degrees of freedom from the \(ABCD\) interaction available for estimating \(\sigma^{2}\). The design is obtained by using the linear functions \(L_{1}\) and \(L_{2}\), corresponding to the selected confounded contrasts \(ABD\) and \(BCD^{2}\) as follows. For each treatment combination, compute the values of \(L_{1}\) and \(L_{2}\) modulo 3:

\[\begin{array}{l}L_{1}=a_{1}+a_{2}\qquad+\ \ a_{4}=0,\ 1,\ \text{or}\ 2\ (\text{mod}\ 3).\\ L_{2}=\qquad a_{2}+a_{3}+2a_{4}=0,\ 1,\ \text{or}\ 2\ (\text{mod}\ 3).\end{array}\]

The design is given in Table 14.5, and it can be verified that the nine blocks are obtained from the nine possible pairs of values of \(L_{1}\) and \(L_{2}\). 

#### A Real Experiment--Dye Experiment

An experiment is described in the book _Design and Analysis of Industrial Experiments_, edited by O. L. Davies, that investigates three reactants (the base material and two inorganic materials, called here \(M\) and \(N\)) in the manufacture of a cotton dyestuff. The three factors of interest in the experiment were the concentration of \(M\) in the free water in the reaction mixture (factor \(A\) at three equally spaced levels), the volume of free water in the reaction mixture (factor \(B\) at three equally spaced levels), and the concentration of \(N\) in the free water in the reaction mixture (factor \(C\) at three equally spaced levels).

Although it was possible to control the conditions in the laboratory fairly accurately, the experimenters divided the treatment combinations into blocks of size 9. This was done as a safeguard against time trends, because the time required to complete the investigation was reasonably long. The experiment involved \(r=2\) replications of each treatment combination, but here we will analyze only the first replicate.

The observations were the volumes of dyestuff resulting from the chemical reactions and are shown in Table 14.6. Looking at the treatment combinations (TC) listed in Block I, we can see that they all satisfy the confounding equation \(a_{1}+2a_{2}+2a_{3}=0\) (mod 3). Consequently, the experimenters have confounded two contrasts from the 3-factor interaction, which we can label as (\(AB^{2}C^{2}\); \(A^{2}BC\)). Since there are only three blocks, these are the only two contrasts confounded. If the 3-factor interaction can be assumed to be negligible, the remaining six degrees of freedom can be used to measure the error variability. The analysis of variance table is shown in Table 14.7. The sum of squares for testing that the main effect of \(A\) (averaged over the levels of the other factors) can be calculated either by using the formulae of Chap. 7 or by adding together the sums of squares for two orthogonal contrasts. For example, rule 4 of Sect. 7.3 gives

\[\begin{split} ssA&=9\;\sum_{i=1}^{3}\overline{y}_{i..}^{2}-27\;\overline{y}_{....}^{2}\\ &=9(5980.44+38,590.42+16,698.38)-27(18,045.44)\\ &=64,196.222.\end{split}\]

Two orthogonal contrasts for \(A\) are the linear and quadratic contrasts. From Table A.2, the coefficients for the (nonnormalized) linear contrast are \((-1,\;0,\;1)\), and those for the quadratic contrast are \((1,\;-2,\;1)\). The least squares estimates for these two contrasts are

\[\hat{A}_{\text{L}}=(-\overline{y}_{.0..}+\overline{y}_{.2..})=51.889\]

and

\[\hat{A}_{\text{Q}}=(\overline{y}_{.0..}-2\overline{y}_{.1..}+\overline{y}_{.2..})=-186.333.\]

\begin{table}
\begin{tabular}{c c c c c c} \hline \multicolumn{2}{c}{Block I} & \multicolumn{2}{c}{Block II} & \multicolumn{2}{c}{Block III} \\ TC & Volume & TC & Volume & TC & Volume \\ \hline
000 & 74 & 020 & 69 & 010 & 13 \\
021 & 130 & 011 & 46 & 001 & 112 \\
012 & 56 & 002 & 71 & 022 & 125 \\
110 & 110 & 100 & 211 & 120 & 199 \\
101 & 166 & 121 & 220 & 111 & 218 \\
122 & 227 & 112 & 216 & 102 & 201 \\
220 & 195 & 210 & 147 & 200 & 74 \\
211 & 146 & 201 & 47 & 221 & 198 \\
202 & 90 & 222 & 164 & 212 & 102 \\ \hline \end{tabular} _Source_ Data adapted from _The Design and Analysis of Industrial Experiments_, Second edition, 1979. Editor O. L. Davies. Published by Longman Group Limited.

\end{table}
Table 14.6: Data for dye experiment To normalize the contrasts, one would divide \(\hat{A}_{\rm L}\) by \(\sqrt{\Sigma c_{i}^{2}/(rbc)}=\sqrt{2/9}\) and divide \(\hat{A}_{\rm Q}\) by \(\sqrt{\Sigma c_{i}^{2}/(rbc)}=\sqrt{6/9}\).

The sum of squares for testing the hypothesis that the linear contrast for \(A\) is negligible is the square of the normalized contrast estimate,

\[ss(A_{\rm L})=\frac{(-\overline{y}_{0..}+\overline{y}_{2..})^{2}}{2/9}=\frac{(5 1.889)^{2}}{2/9}=12,116.06;\]

the sum of squares for testing the hypothesis that the quadratic contrast for \(A\) is negligible is

\[ss(A_{\rm Q})=\frac{(\overline{y}_{0..}-2\overline{y}_{1..}+\overline{y}_{2..} )^{2}}{6/9}=\frac{(-186.333)^{2}}{6/9}=52,080.17;\]

and we see that

\[ss(A_{\rm L})+ss(A_{\rm Q})=12,116.06+52,080.17=64,196.23=ssA.\]

The other sums of squares in Table 4.7 can be obtained in a similar way.

For testing the hypotheses that the three main effects and the three 2-factor interactions are negligible at individual significance levels \(\alpha^{*}=0.01\) (an overall level significance level of \(\alpha\leq 0.06\)), we would compare the ratios in the analysis of variance table (Table 4.7) with the critical values from the \(F\)-distribution (\(F_{2,6,0.01}=10.9\) for the main effects and \(F_{4,6,0.01}=9.15\) for the 2-factor interactions), and we would reject only the hypothesis that the main effect of \(A\) is negligible. Plots for the average response due to \(A\) and \(B\) are shown in Fig. 14.1. We can see from the plot of the \(A\) average responses that, as the levels of the concentration of inorganic material M in the free water increase, the volumes of dyestuff first increase and then begin to decrease. We might expect to see both a significant linear trend and a significant quadratic trend. Testing the two hypotheses that the linear trend in \(A\) is negligible

\begin{table}
\begin{tabular}{c c c c c c} \hline Source of variation & Degrees of freedom & Sum of squares & Mean square & Ratio & \(p\)-values \\ \hline Block & 2 & 182.00 & & & \\ \(A\) & 2 & 64,196.22 & 32,098.11 & 26.60 & 0.0010 \\ \(A_{\rm L}\) & 1 & 12,116.06 & 12,116.06 & 10.04 & 0.0194 \\ \(A_{\rm Q}\) & 1 & 52,080.17 & 52,080.17 & 43.16 & 0.0006 \\ \(B\) & 2 & 16,857.56 & 8,428.78 & 6.98 & 0.0271 \\ \(B_{\rm L}\) & 1 & 12,853.39 & 12,853.39 & 10.65 & 0.0172 \\ \(B_{\rm Q}\) & 1 & 4,004.17 & 4,004.17 & 3.32 & 0.1184 \\ \(C\) & 2 & 2,334.89 & 1,167.44 & 0.97 & 0.4324 \\ \(C_{\rm L}\) & 1 & 1,422.22 & 1,422.22 & 1.18 & 0.3193 \\ \(C_{\rm Q}\) & 1 & 912.67 & 912.67 & 0.76 & 0.4179 \\ \(AB\) & 4 & 12,512.89 & 3,128.22 & 2.59 & 0.1428 \\ \(AC\) & 4 & 4,044.89 & 1,011.22 & 0.84 & 0.5481 \\ \(BC\) & 4 & 2,698.89 & 674.72 & 0.56 & 0.7015 \\ Error & 6 & 7,240.67 & 1,206.78 & & \\ \hline Total & 26 & 110, 068.00 & & & \\ \hline \end{tabular}
\end{table}
Table 4.7: Analysis of variance for the dye experiment and the quadratic trend in \(A\) is negligible, each at level 0.005 (to give an overall significance level of \(\alpha^{*}\leq 0.01\)), we have

\[ss(A_{\rm L})/msE=10.04<F_{1,6,0.005}=18.6\]

and

\[ss(A_{\rm Q})/msE=43.16>F_{1,6,0.005}=18.6,\]

and we conclude that there is a quadratic trend in the levels of \(A\), and that the turning point is towards the center of the range of levels investigated (otherwise, the linear trend would also have been significantly different from zero). Since the objective of the experiment was to boost the volume of dyestuff produced, the results of the experiment suggest that further investigation around the second concentration of inorganic material M might be wise. Although the hypothesis of no effect of \(B\) was not rejected, Fig. 14.1 suggests that further experimentation with higher volumes of free water in the reaction mixture is worth consideration.

The above method of testing these two hypotheses uses Bonferroni's method of combining significance levels. An alternative method is to use Scheffe's method of multiple comparisons and test the two hypotheses simultaneously at level 0.01. Since

\[ss(A_{\rm L})/msE=10.04<2F_{2,6,0.01}=21.8\]

and

\[ss(A_{\rm Q})/msE=43.16>2F_{2,6,0.01}=21.8,\]

we arrive at the same conclusion. The more powerful method here is the first since

\[F_{1,6,0.005}<2F_{2,6,0.01}\.\]

#### Plans for Confounded 3\({}^{p}\) Experiments

At the end of the chapter, Table 14.20 gives suggested confounding schemes for 3\({}^{p}\) experiments in blocks of size 3, 9, or 27. As illustrated in Sect. 13.6, if the design in the table confounds important contrasts in the experiment, then a relabeling of treatment factors should be attempted.

Figure 14.1: Main-effect plots for the dye experiment

### Designing Using Pseudofactors

#### Confounding in \(\mathcal{A}^{p}\) Experiments

A treatment factor \(F\) with four levels coded 0, 1, 2, 3 can be represented by two factors \(F_{1}\) and \(F_{2}\) each having two levels coded 0, 1. The levels of \(F_{1}\) and \(F_{2}\) taken together correspond to the levels of the original factor \(F\). One possible correspondence is given below:

\[\begin{array}{ccc}F&F_{1}&F_{2}\\ \hline 0&0&0\\ 1&0&1\\ 2&1&0\\ 3&1&1\end{array}\]

The factors \(F_{1}\) and \(F_{2}\) are called _pseudofactors_. All factors in a \(\mathcal{A}^{p}\) experiment can be represented by pseudofactors. Thus, a \(\mathcal{A}^{p}\) experiment in \(4^{s}\) blocks of size \(\mathcal{A}^{p-s}\) can be represented as a \(2^{2p}\) experiment in \(2^{2s}\) blocks of size \(2^{2(p-s)}\). The techniques of confounding in a \(2^{2p}\) experiment as discussed in Chap. 13 can therefore be used. The only difference is that an interaction of pseudofactors of the form \(F_{1}G_{1}G_{2}\), say, does not represent a 3-factor interaction. It represents one of nine orthogonal contrasts measuring the two-factor interaction, \(FG\). Similarly, \(F_{1}F_{2}\) does not represent a contrast in a two-factor interaction. It represents one of three orthogonal contrasts measuring the main effect of factor \(F\).

#### 4\({}^{2}\) experiment in 4 blocks of size 4

Consider a \(4^{2}\) experiment with two factors \(F\) and \(G\) to be run in 4 blocks of size 4. The main effects are to be estimated, but the interaction is thought to be negligible. If \(F\) and \(G\) are represented by pseudofactors \(F_{1}\), \(F_{2}\), \(G_{1}\), \(G_{2}\) having two levels each, we can consult Table 13.29 hoping to find a suitable \(2^{4}\) experiment in 4 blocks of size 4.

In Table 13.29, we find a design that confounds \(AC\), \(ABD\), and \(BCD\). If we make the correspondence \(F_{1}=A\), \(F_{2}=B\), \(G_{1}=C\), \(G_{2}=D\), then the design confounds \(F_{1}G_{1}\), \(F_{1}F_{2}G_{2}\), \(F_{2}G_{1}G_{2}\), all three of which belong to the interaction of \(F\) and \(G\). All main-effect contrasts of \(F\) and \(G\) are orthogonal to all interaction contrasts and can therefore be estimated without adjustment for blocks. The design is shown in Table 14.8, with blocks corresponding to combinations of values of \(L_{1}=a_{1}+a_{3}\) (mod 2) and \(L_{2}=a_{1}+a_{2}+a_{4}\) (mod 2).

If we make a different correspondence, say \(F_{1}=A\), \(F_{2}=D\), \(G_{1}=B\), \(G_{2}=C\), then a slightly different design is obtained, this time confounding \(F_{1}G_{2}\), \(F_{1}F_{2}G_{1}\), and \(F_{2}G_{1}G_{2}\), which again belong to the interaction of \(F\) and \(G\). There is no particular reason to prefer one design over the other. However, a third correspondence, \(F_{1}=A\), \(F_{2}=C\), \(G_{1}=B\), \(G_{2}=D\), would not be good, since it confounds \(F_{1}F_{2}\), \(F_{1}G_{1}G_{2}\), \(F_{2}G_{1}G_{2}\), and this includes one degree of freedom \(F_{1}F_{2}\) from the main effect of \(F\). 

\begin{table}
\begin{tabular}{c c c c} \hline Block & \(L_{1}\), \(L_{2}\) & Pseudofactors \(F_{1}\), \(F_{2}\), \(G_{1}\), \(G_{2}\) & Factors \(F\), \(G\) \\ \hline I & 0,0 & 0000 0101 1011 1110 & 00 11 23 32 \\ II & 0,1 & 0001 0100 1010 1111 & 01 10 22 33 \\ III & 1,0 & 0010 0111 100 1100 & 02 13 21 30 \\ IV & 1,1 & 0011 0110 1000 1101 & 03 12 20 31 \\ \hline \end{tabular}
\end{table}
Table 14.8: \(4^{2}\) experiment in 4 blocks of 4, confounding three degrees of freedom (\(F_{1}G_{1}\), \(F_{1}F_{2}G_{2}\), \(F_{2}G_{1}G_{2}\)) from \(FG\)Since two-level pseudofactors are being used, block sizes need only be a power of two, not necessarily a power of four.

#### Confounding in 2\({}^{p}\times 4^{q}\) Experiments

Since factors with 4 levels can be written in terms of pseudofactors having 2 levels each, a 2\({}^{p}\times 4^{q}\) experiment can be written in terms of pseudofactors as a 2\({}^{(p+2q)}\) experiment, and no new techniques are needed.

##### 2\({}^{3}\times 4\) experiment in 4 blocks of size 8

Suppose that a 2\({}^{3}\times 4\) experiment with factors \(F\), \(G\), \(H\), and \(J\) is to be run in 4 blocks of size 8. This could be designed using pseudofactors by selecting a design for a 2\({}^{5}\) experiment in 4 blocks from Table 3.29. A design is shown that confounds \(ABE\), \(CDE\), and \(ABCD\). If we let the combination of levels of \(A\) and \(C\) represent the levels of the 4-level factor \(JJ_{2}=J\) with the representation \(00=0\), \(01=1\), \(10=2\), \(11=3\), and let the levels of \(B\), \(D\), and \(E\) respectively represent the levels of \(F\), \(G\), and \(H\), we obtain the design of Table 3.9, that confounds one contrast from each of the 3-factor interactions \(FHJ\), \(GHJ\), and \(FGJ\). All main effects and 2-factor interactions can be estimated. There are 10 degrees of freedom available for estimating \(\sigma^{2}\). These come from the two unconfounded degrees of freedom from each of \(FHJ\), \(GHJ\), and \(FGJ\) and the one degree of freedom from \(FGH\) and the three from \(FGHJ\). 

### Designing Confounded Asymmetric Experiments

A factorial experiment is called an asymmetric experiment when the treatment factors do not all have the same number of levels. For example, \(2^{2}\times 4^{2},\ 2^{5}\times 3,\ 2^{2}\times 3^{2}\times 4^{2}\), and \(3\times 6\) experiments are all asymmetric experiments. We have already discussed the design of asymmetric \(2^{p}\times 4^{q}\) experiments in Sect. 14.3.2. We used pseudofactors for the factors with four levels, thus allowing the symmetric designs for \(2^{p+2q}\) experiments to be used. We can use this idea only when the numbers of levels of all factors are powers of the same prime number. For all of the other examples mentioned above, the use of pseudofactors would transform the experiment into a \(2^{p}\times 3^{q}\) experiment. Consequently, we concentrate on this type of situation in this section.

Since 2 and 3 are relatively prime, the only type of design that can be constructed using the equation method will confound contrasts within the two symmetric parts of the experiment. Consequently, to obtain a design for a \(2^{p}\times 3^{q}\) experiment in \(2^{s}\times 3^{t}\) blocks of size \(2^{p-s}\times 3^{q-t}\), we combine a design for a \(2^{p}\) experiment in \(2^{s}\) blocks with a design for a \(3^{q}\) experiment in \(3^{t}\) blocks, using the idea of

\begin{table}
\begin{tabular}{c c c c c c c c c} \hline Blocks & \multicolumn{6}{c}{Treatment combinations (Factors \(F\), \(G\), \(H\), \(J\))} \\ \hline I & 0000 & 1002 & 0101 & 1103 & 0013 & 1011 & 0112 & 1110 \\ II & 0010 & 1012 & 0111 & 1113 & 0003 & 1001 & 0102 & 1100 \\ III & 0100 & 1102 & 0001 & 1003 & 0113 & 1110 & 0012 & 1010 \\ IV & 0110 & 1112 & 0011 & 1013 & 0103 & 1101 & 0002 & 1000 \\ \hline \end{tabular}
\end{table}
Table 3.9: \(2^{3}\times 4\) experiment in 4 blocks of 8, using pseudofactors and confounding one degree of freedom from interactions \(FGJ\), \(GHJ\), and \(FHJ\)a _crossed array_ as illustrated in the following example. The total number of blocks created in the combined design is always the product of the numbers of blocks in the original two designs. Likewise, the block sizes in the combined design are products of the block sizes in the original two designs. The confounded contrasts in the combined design are those confounded in the separate designs together with those indicated by all possible products of contrast names.

#### Example 14.4.1 \(2^{2}\times 3^{2}\) experiment in 6 blocks of size 6

Suppose that a \(2^{2}\times 3^{2}\) experiment is to be run in 6 blocks of size 6. We label the two 2-level factors as \(A\) and \(B\) and the two 3-level factors as \(C\) and \(D\). Since the design must confound within the two symmetric parts of the experiment, one contrast from \(A\), \(B\), or \(AB\) must be confounded to divide the \(2^{2}\) treatment combinations into two blocks, and one pair of contrasts from \(C\), \(D\), or \(CD\) must be confounded to divide the \(3^{2}\) treatment combinations into three blocks. The confounded contrasts in the combined design are those confounded in the separate designs together with their products.

For example, we could combine the two designs in Table 14.10. The design labeled \(d_{1}\) is for a \(2^{2}\) experiment in two blocks of size 2 confounding \(AB\), with treatment combinations (TC) grouped into blocks determined by the two values of \(L_{1}=a_{1}+a_{2}\pmod{2}\). The design labeled \(d_{2}\) is for a \(3^{2}\) experiment in three blocks of size 3 confounding the pair of contrasts (\(CD^{2}\); \(C^{2}D\)), with blocks determined by the three values of \(L_{2}=a_{3}+2a_{4}\pmod{3}\). The combined array in Table 14.11 divides the treatment combinations into blocks according to the six combinations of values of \(L_{1}\) and \(L_{2}\).

A quick way to obtain the design with six blocks is to combine each of the 2 blocks of \(d_{1}\) with each of the 3 blocks of \(d_{2}\). For example, to combine the first blocks of \(d_{1}\) and \(d_{2}\), each of the combinations 00 and 11 in block I\({}_{1}\) of \(d_{1}\) is combined with each of the combinations 00, 11, and 22 in block I\({}_{2}\) of \(d_{2}\) to give the treatment combinations 0000, 1100, 0011, 1111, 0022, 1122 in the first block of the combined design. The other blocks of the combined design are obtained in a similar way.

The \(b-1=5\) confounded contrasts are those corresponding to the original confounding schemes, namely the contrast \(AB\) and the pair of contrasts represented by (\(CD^{2}\); \(C^{2}D\)), together with the pair of contrasts represented by the products of these labels--namely (\(ABCD^{2}\); \(ABC^{2}D\)). 

\begin{table}
\begin{tabular}{c c c c c c c c} \hline Design & \(L_{1}\) & Block & TC & Design & \(L_{2}\) & Block & TC \\ \hline \(d_{1}\) & 0 & I\({}_{1}\) & 00 11 & \(d_{2}\) & 0 & I\({}_{2}\) & 00 11 22 \\  & 1 & II\({}_{1}\) & 01 10 & & 1 & II\({}_{2}\) & 02 10 21 \\  & & & & & 2 & III\({}_{2}\) & 01 12 20 \\ \hline \end{tabular}
\end{table}
Table 14.10: Design \(d_{1}\) for a \(2^{2}\) experiment confounding \(AB\) and design \(d_{2}\) for a \(3^{2}\) experiment confounding (\(CD^{2}\); \(C^{2}D\))

\begin{table}
\begin{tabular}{c c c c} \hline \(L_{1},L_{2}\) & Block combinations & Treatment combinations \\ \hline
0,0 & I\({}_{1}\), I\({}_{2}\) & \(\rightarrow\) I & 0000 0011 0022 1100 1111 1122 \\
0,1 & I\({}_{1}\), II\({}_{2}\) & \(\rightarrow\) II & 0002 0010 0021 1102 1110 1121 \\
0,2 & I\({}_{1}\), III\({}_{2}\) & \(\rightarrow\) III & 0001 0012 0020 1101 1112 1120 \\
1,0 & II\({}_{1}\), I\({}_{2}\) & \(\rightarrow\) IV & 0100 0111 0122 1000 1011 1022 \\
1,1 & II\({}_{1}\), II\({}_{2}\) & \(\rightarrow\) V & 0102 0110 0121 1002 1010 1021 \\
1,2 & II\({}_{1}\), III\({}_{2}\) & \(\rightarrow\) VI & 0101 0112 0120 1001 1012 1020 \\ \hline \end{tabular}
\end{table}
Table 14.11: \(2^{2}\times 3^{2}\) experiment in 6 blocks of 6, confounding \(AB\), (\(CD^{2}\); \(C^{2}D\)), (\(ABCD^{2}\); \(ABC^{2}D\))

#### Example 14.4.2 \(4\times 6\times 3\) experiment in 6 blocks of size 12

Suppose that a \(4\times 6\times 3\) experiment with factors \(F\), \(G\), \(H\) is to be run in 6 blocks of size 12. If we use the pseudofactor labels \(F_{1}\), \(F_{2}\), \(G_{1}\), \(G_{2}\), and \(H\), then the factors \(F_{1}\), \(F_{2}\), and \(G_{1}\) are in the \(2^{3}\) pseudofactor experiment and \(G_{2}\) and \(H\) are in the \(3^{2}\) pseudofactor experiment. In the \(2^{3}\) experiment, we confound \(F_{1}\!F_{2}G_{1}\) to give the two blocks of the design \(d_{1}\) of Table 14.12, and in the \(3^{2}\) experiment, we confound the pair of contrasts (\(G_{2}H\); \(G_{2}^{2}H^{2}\)) to give the three blocks of the design \(d_{2}\). Combining each treatment combination in design \(d_{1}\) with those in \(d_{2}\) gives the design in Table 14.13, which has \(b=6\) blocks of size 12. The \(b-1=5\) confounded degrees of freedom correspond to the original three confounded contrasts together with their products, that is, \(F_{1}\!F_{2}G_{1}\), (\(G_{2}H\); \(G_{2}^{2}H^{2}\)), and (\(F_{1}\!F_{2}G_{1}G_{2}H\); \(F_{1}\!F_{2}G_{1}G_{2}^{2}H^{2}\)).

Translating back to the original factors, we can see that one degree of freedom from the interaction \(FG\) is confounded, together with two degrees of freedom from each of \(GH\) and \(FGH\). This means that all contrasts from the three main effects and also from the interaction \(FH\) can be estimated.

If we take the mapping of pseudofactor levels to factor levels as follows, then the design of Table 14.13 is as shown in Table 14.14:

\begin{table}
\begin{tabular}{c c c c c c c c c c} \hline \multicolumn{2}{c}{Block combinations} & \multicolumn{6}{c}{Pseudofactor combinations} \\ \hline \(\mathrm{I}_{1},\mathrm{I}_{2}\) & \(\rightarrow\) & \(\mathrm{I}\) & 00000 & 00012 & 00021 & 01100 & 01112 & 01121 \\  & & & 10100 & 10112 & 10121 & 11000 & 11012 & 11021 \\ \(\mathrm{I}_{1},\mathrm{II}_{2}\) & \(\rightarrow\) & \(\mathrm{II}\) & 00001 & 00010 & 00022 & 01101 & 01110 & 01122 \\  & & & 10101 & 10110 & 10122 & 11001 & 11010 & 11022 \\ \(\mathrm{I}_{1},\mathrm{III}_{2}\) & \(\rightarrow\) & \(\mathrm{III}\) & 00002 & 00011 & 00020 & 01102 & 01111 & 01123 \\  & & & 10102 & 10111 & 10120 & 11002 & 11011 & 11020 \\ \(\mathrm{II}_{1},\mathrm{I}_{2}\) & \(\rightarrow\) & \(\mathrm{IV}\) & 00100 & 00112 & 00121 & 01000 & 01012 & 01021 \\  & & & 10000 & 10012 & 10021 & 11100 & 11112 & 11121 \\ \(\mathrm{II}_{1},\mathrm{II}_{2}\) & \(\rightarrow\) & \(\mathrm{V}\) & 00101 & 00110 & 00122 & 01001 & 01010 & 01022 \\  & & & 10001 & 10010 & 10022 & 11101 & 11110 & 11122 \\ \(\mathrm{II}_{1},\mathrm{III}_{2}\) & \(\rightarrow\) & \(\mathrm{VI}\) & 00102 & 00111 & 00120 & 01002 & 01011 & 01023 \\  & & & 10002 & 10011 & 10020 & 11102 & 11111 & 11120 \\ \hline \end{tabular}
\end{table}
Table 14.12: Design \(d_{1}\) for a \(2^{3}\) experiment confounding \(F_{1}\!F_{2}G_{1}\) and design \(d_{2}\) for a \(3^{2}\) experiment confounding \((G_{2}H\); \(G_{2}^{2}H^{2})\)

[MISSING_PAGE_FAIL:504]

\begin{table}
\begin{tabular}{c c c c c c} \hline  & Block I & & Block II & & Block III \\ TC & Volume & TC & Volume & TC & Volume \\ \hline

[MISSING_PAGE_POST]

 \hline \end{tabular} _Source Data adapted from The Design and Analysis of Industrial Experiments. Second edition, 1979. Editor O. L. Davies published by Longman Group Ltd._

\end{table}
Table 14.15: Data for the dye experiment

\begin{table}
\begin{tabular}{c c c c c c} \hline  & Block I & & Block II & & Block III \\ TC & Volume & TC & Volume & TC & Volume \\ \hline

[MISSING_PAGE_POST]

 \hline \end{tabular} _Source Data adapted from The Design and Analysis of Industrial Experiments. Second edition, 1979. Editor O. L. Davies published by Longman Group Ltd._

\end{table}
Table 14.16: SAS program for the dye experimentAll contrasts from the main-effects and 2-factor interactions are orthogonal to the block contrasts and can be estimated without adjustment for blocks. Consequently, the sums of squares for these terms are the same whether or not the block parameter is in the model. This can be verified by comparing the Type III sums of squares for the two runs of PROC GLM shown in Figs. 14.2 and 14.3. Comparing these two analysis of variance tables, we can see that inclusion of the block parameter in the model changes the sum of squares for the three-factor interaction, since the three-factor interaction is partially confounded with blocks. The degrees of freedom for the three-factor interaction remain at 8, as all 8 orthogonal contrasts can be estimated from some portion of the data.

Figure 14.3: Incorrect analysis of variance, omitting the blocking factor to show the effect of partial confounding

The analysis of variance table (Fig. 14.2) provides _no_ evidence that certain contrasts are partially confounded. However, partially confounded contrasts are estimated with larger variance due to the adjustment for blocks. As a result, for the corresponding effects, confidence intervals are wider and tests are less powerful. 

#### Using R Software

In this section we illustrate the use of the R software in analyzing a two-replicate factorial experiment with partial confounding. This we do via an example. The analysis is straightforward, as was illustrated in the previous chapter. Along with the correct analysis, we also fit an incorrect model--one without block effects--to illustrate the effect of partial confounding on the analysis.

##### _Example 14.6.1_ Dye experiment, continued

The dye experiment was described in Sect. 14.2.4, where part of the data was analyzed as though it came from a single-replicate confounded experiment. In fact, in the original experiment, the design was a partially confounded design made up of two single-replicate \(3^{3}\) designs with different confounding schemes. The three factors of interest in the experiment were the concentration of inorganic material \(M\) in the free water in the reaction mixture (factor \(A\) at three equally spaced levels), the volume of free water in the reaction mixture (factor \(B\) at three equally spaced levels), and the concentration of inorganic material \(N\) in the free water in the reaction mixture (factor \(C\) at three equally spaced levels). The observations were the volumes of dyestuff resulting from the chemical reactions and are shown in Table 14.15 (p. 487) together with the design (prior to randomization). The contrasts (\(AB^{2}C^{2}\); \(A^{2}BC\)) are confounded in the first set of three blocks and estimable in the second set, whereas the contrasts (\(ABC^{2}\); \(A^{2}B^{2}C\)) are confounded in the second set of three blocks and estimable in the first set.

Since no contrast is completely confounded, no terms need be omitted from the model. Table 14.17 shows the R commands and output for analyzing this experiment with partial confounding. The statements are exactly as they would be for a replicated experiment with three factors and no confounding. A second call of the linear models function lm with no blocking factor in the model is included for illustration purposes to show the effect of the partial confounding.

All contrasts from the main-effects and 2-factor interactions are orthogonal to the block contrasts and can be estimated without adjustment for blocks. Consequently, the sums of squares for these terms are the same whether or not the block parameter is in the model. This can be verified by comparing the Type I sums of squares for the two models fit in Table 14.17--the first model with block effects entered first, so for which factorial effects are adjusted for block effects, and the second model without block effects. Inclusion of the block parameter in the model changes the sum of squares for the three-factor interaction, since the three-factor interaction is partially confounded with blocks. The degrees of freedom for the three-factor interaction remain at 8, as all 8 orthogonal contrasts can be estimated from some portion of the data.

The analysis of variance table (the first in Table 14.17) provides no evidence that certain contrasts are partially confounded. However, partially confounded contrasts are estimated with larger variance due to the adjustment for blocks. As a result, for the corresponding effects, confidence intervals (not shown) are wider and tests are less powerful.

* > dye.data = read.table("data/dye.txt", header=T) > head(dye.data, 3)

Blk A B C Y
1 1 1 0 0 0 74
2 1 0 2 1 130
3 1 0 1 2 56

> # Create factor variables > dye.data = within(dye.data, + {fBlk = factor(Blk); fA = factor(A); + fB = factor(B); fC = factor(C) )) > # Analysis of variance > modell = lm(y ~ fBlk + fA*fB*fC, data=dye.data) > anova(modell)

Analysis of Variance Table  Response: y  Df Sum Sq Mean Sq F value Pr(>F)  fBlk 5 979 196 0.23 0.94703  fA 2 141000 70500 81.58 6.7e-11  fB 2 19448 9724 11.25 0.00043  fcC 2 4934 2467 2.86 0.07899  fA:fB 4 27923 6981 8.08 0.00036  fA:fC 4 13044 3261 3.77 0.01749  fB:fC 4 2913 728 0.84 0.51300  fA:fB:fC 8 10795 1349 1.56 0.19353  Residuals 22 19011 864

> # ANOVA without block effects for comparison > modell = lm(y ~ fA*fB*fC, data=dye.data) > anova(modell)

Analysis of Variance Table  Response: y  Df Sum Sq Mean Sq F value Pr(>F)  fA 2 141000 70500 90.48 1.1e-12  fB 2 19448 9724 12.48 0.00015  fC 2 4934 2467 3.17 0.05816  fA:fB 4 27923 6981 8.96 9.7e-05  fA:fC 4 13044 3261 4.18 0.00915  fB:fC 4 2913 728 0.93 0.45877  fA:fB:fC 8 9746 1218 1.56 0.18257  Residuals 27 21039 779

\begin{table}
\begin{tabular}{l r r r r} \multicolumn{5}{l}{ \(>\) dye.data = read.table("data/dye.txt", header=T)} \\ \multicolumn{5}{l}{ \(>\) head(dye.data, 3)} \\ \multicolumn{5}{l}{ Blk A B C Y} \\
1 & 1 0 0 0 & 74 \\
2 & 1 0 2 & 1 130 \\
3 & 1 0 1 & 2 & 56 \\ \end{tabular}
\end{table}
Table 14.17: R program and output for the dye experiment 

## Exercises

1. Suggest a confounding scheme for a \(3^{5}\) experiment in 9 blocks of size 27 if all 2-factor interactions and the 3-factor interaction \(ABE\) are to estimated.
2. Suggest a confounding scheme for a \(3^{5}\) experiment in 27 blocks of size 9 if all 2-factor interactions and the 3-factor interaction \(ABE\) are to be estimated.
3. **Dye experiment, continued** 1. For the dye experiment of Sect. 14.2.4, check that the variances of the errors appear to be equal for the different levels of the three factors. Check also that the assumption of normality of the error variables is reasonable. 2. Calculate the normalized contrast estimate for Linear \(A\)\(\times\) Linear \(B\), using the method outlined in Sect. 14.2.4. 3. Compute the sum of squares for testing the hypothesis that the Linear \(A\)\(\times\) Linear \(B\) contrast is negligible, using the method outlined in Sect. 14.2.4. 4. Test the hypothesis that the Linear \(A\)\(\times\) Linear \(B\) contrast is negligible, using an individual significance level of 0.01. 5. Draw an interaction plot for \(AC\) and verify that the interaction appears to be negligible. 6. Assuming that the contrasts were preplanned, calculate confidence intervals for the pairwise differences in yields due to the three different levels of each of \(A\), \(B\) and \(C\). State your overall confidence level.
4. **Dye experiment, continued** The experimenters who ran the dye experiment were interested in the linear and quadratic components of the main effects and interactions. Analyze the experiment accordingly. What information have you gathered about the levels of the factors if high yield is of importance?
5. A set of hypothetical data is given in Table 18 for a partially confounded \(3^{2}\) experiment in 6 blocks of 3. The design is made up of two single-replicate designs: The first confounds the contrasts (\(AB\); \(A^{2}\!B^{2}\)) from the interaction, while the second confounds the contrasts (\(AB^{2}\); \(A^{2}\!B\)). 1. By hand, write out the estimates of the linear and quadratic contrasts for the main effects and their associated variances. 2. Using the contrast estimates in part (a), calculate the sums of squares for \(A\) and \(B\).

\begin{table}
\begin{tabular}{l l c c c} \hline \multicolumn{1}{c}{Replicate} & \multicolumn{2}{c}{Block} & \multicolumn{2}{c}{Treatment combinations (Response)} \\ \hline
1 & I & 00 (53) & 12 (59) & 21 (80) \\ Confounds (\(AB\); \(A^{2}\!B^{2}\)) & II & 01 (66) & 10 (71) & 22 (78) \\  & III & 02 (69) & 11 (91) & 20 (92) \\
2 & IV & 00 (46) & 11 (62) & 22 (58) \\ Confounds (\(AB^{2}\); \(A^{2}\!B\)) & V & 01 (65) & 12 (61) & 20 (76) \\  & VI & 02 (34) & 10 (50) & 21 (66) \\ \hline \end{tabular}
\end{table}
Table 18: Partially confounded \(3^{2}\) experiment in \(b=6\) blocks of \(k=3\). Hypothetical data are shown in parentheses with corresponding treatment combinations3. Calculate the least squares estimates of a pair of orthogonal contrasts for \((AB^{2};A^{2}\!B)\) from the first replicate and the estimates of a pair of orthogonal contrasts for \((AB;A^{2}\!B^{2})\) from the second replicate. Using these contrast estimates, calculate the sum of squares for the \(AB\) interaction (adjusted for blocks). 4. Prepare an analysis of variance table. Test any hypotheses that you think are of interest and state your conclusions about the two factors and their interaction. 5. Check your analysis in part (d) using a computer program.
6. **Sugar beet experiment** F. Yates, in a 1935 paper published in a supplement to the _Journal of the Royal Statistical Society_, describes an agricultural experiment on the yield of sugar beet. The three factors of interest were three standard fertilizers, nitrogen, phosphate, and potassium (factors \(N\), \(P\), and \(K\)) each at three equally spaced levels. The experimental field was divided into \(b=3\) blocks and each block subdivided into \(k=9\) 0.1 acre plots. The experiment was designed so that the contrasts (\(NP^{2}\!K\); \(N^{2}\!PK^{2}\)) were confounded with blocks. The randomized design and yields of sugar beet are shown in Table 14.19. 1. Prepare an analysis of variance table for the data, assuming that the three-factor interaction is negligible. 2. Investigate the linear and quadratic trends of the main effects and the two-factor interactions. Yates assumed in his analysis that the only important contrast for each two factor interaction was the linear\(\times\)linear contrast. Is this assumption supported by your analysis? 3. Draw any plots that help to illustrate the important features of the analysis.
7. **Example 14.3.2, continued** In Example 14.3.2, p. 483, we showed one way of associating design factors \(F\), \(G\), \(H\), and \(J\) of a \(2^{3}\times 4\) factorial experiment to the 2-level pseudofactors \(A\!-\!E\) of a specific design from Table 13.29. _Source_ Yates (1935). Copyright (c) 1935 Blackwell Publishers. Reprinted with permission. (Reprinted in _Experimental Design_ (1970), Charles Griffin and Company, Ltd., London. Copyright 1970 Edward Arnold/Hodder & Stoughton Educational. Reprinted with permission.) _Source_ Yates (1935).

There are 10 different ways to make this association (since there are 10 ways of selecting two of \(A\)-\(E\) to represent \(J_{1}\) and \(J_{2}\)). 1. Investigate the confounding schemes for each of the ten possible associations. Specifically, for each association, determine the number of contrasts confounded for each effect, and compare the results. 2. State under which circumstances you would recommend each design.
8. Consider a \(2^{2}\times 3^{2}\) design confounding \(AB\), (\(CD^{2}\); \(C^{2}\!D\)), and (\(ABCD^{2}\); \(ABC^{2}\!D\)). 1. Give the design--namely, list the treatment combinations block by block. 2. Describe how to randomize the design. 3. Give a set of five orthogonal treatment contrasts that are confounded with blocks.
9. Suggest a confounding scheme for a \(2^{3}\times 3^{3}\) experiment in 12 blocks of size 18. Under what circumstances would the design be useful? Write out two blocks of the design.
10. Suggest a confounding scheme for a \(2^{2}\times 3^{2}\times 4\) experiment in 12 blocks of size 12. Under what circumstances would the design be useful? Write out two blocks of the design.
11. Suggest a confounding scheme for a \(2^{2}\times 3^{2}\times 6\) experiment in 9 blocks of size 24. Under what circumstances would the design be useful? Explain how to find the blocks of the design.
12. Suggest a confounding scheme for a \(2^{2}\times 3^{2}\times 6\) experiment in 12 blocks of size 18. Under what circumstances would the design be useful? Write out two blocks of the design.

\begin{table}
\begin{tabular}{c c c c c} \hline \(3^{p}\) & \(b\) & \(k\) & Confounded contrasts & Block I \\ \hline \(3^{2}\) & 3 & 3 & (\(\underline{AB}\); \(A^{2}B^{2}\)) & \(a_{1}\) \\  & & & & \(a_{2}=2a_{1}\) \\ \(3^{3}\) & 3 & 9 & (\(\underline{ABC}^{2}\); \(A^{2}B^{2}\!C\)) & \(a_{1},a_{2}\) \\  & & & & \(a_{3}=a_{1}+a_{2}\) \\ \(3^{3}\) & 9 & 3 & (\(\underline{AB}^{2}\); \(A^{2}B\)), (\(\underline{AC}\); \(A^{2}\!C^{2}\)), & \(a_{1}\) \\  & & & (\(BC\); \(B^{2}\!C^{2}\)), (\(\underline{ABC}^{2}\); \(A^{2}\!B^{2}\!C\)) & \(a_{2}=a_{1}\) \\  & & & & \(a_{3}=2a_{1}\) \\ \(3^{4}\) & 3 & 27 & (\(\underline{ABCD}^{2}\); \(A^{2}B^{2}\!C^{2}\!D\)) & \(a_{1},a_{2},a_{3}\) \\  & & & & \(a_{4}=a_{1}+a_{2}+a_{3}\) \\ \(3^{4}\) & 9 & 9 & (\(\underline{AB}^{2}\!C\); \(A^{2}\!B\!C^{2}\)), (\(\underline{AB}\); \(A^{2}\!B^{2}\!D^{2}\)), & \(a_{1},a_{2}\) \\  & & & (\(AC^{2}\!D^{2}\); \(A^{2}\!CD\)), (\(\underline{BCD}^{2}\); \(B^{2}\!C^{2}\!D\)) & \(a_{3}=2a_{1}+a_{2}\) \\  & & & & \(a_{4}=2a_{1}+2a_{2}\) \\ \(3^{5}\) & 9 & 27 & (\(\underline{ABCD}^{2}\); \(A^{2}\!B^{2}\!C^{2}\!D\)), (\(\underline{AB}^{2}\!E^{2}\); \(A^{2}\!BE\)) & \(a_{1},a_{2},a_{3}\) \\  & & & (\(AC^{2}\!DE\); \(A^{2}\!CD\!E^{2}\)), & \(a_{4}=a_{1}+a_{2}+a_{3}\) \\  & & & (\(BC^{2}\!DE^{2}\); \(B^{2}\!C^{2}\!E\)) & \(a_{5}=a_{1}+2a_{2}\) \\ \hline \end{tabular}
\end{table}
Table 14.20: Confounding schemes for \(3^{p}\) experiments in \(b=3^{s}\) blocks of size \(k=3^{p-s}\). For each design, \(s\) independent generators are underlined, and \(s\) corresponding equations are given. To obtain Block I of a design, list all \(k\) combinations of the first \(a_{i}\)’s shown, then use the equations modulo 3 to complete each treatment combination 

### 15.1 Introduction

Fractional factorial experiments are used frequently in industry, especially in various stages of product development and in process and quality improvement. In a _fractional factorial experiment_ only a fraction of the treatment combinations are observed. This has the advantage of saving time and money in running the experiment, but has the disadvantage that each main-effect and interaction contrast will be confounded with one or more other main-effect or interaction contrasts and cannot be estimated separately. Two factorial contrasts that are confounded are referred to as being _aliased_. The term "confounded" is generally reserved for the indistinguishability of a treatment contrast and a block contrast (as described in Chaps. 13 and 14).

We look at two methods of obtaining fractional factorial designs that can be analyzed in a straightforward manner. The first method, described in Sects. 15.2-15.5, is to select one block from one of the single-replicate designs in Chap. 13 as the fraction to be used. The second method of choosing a fraction, described in Sect. 15.6, is popular in industry and uses the concept of an _orthogonal array_. In Sect. 15.7, we aim to identify the treatment factor levels whose effects are least affected by noise variable fluctuations; the intention being to reduce the sensitivity of a product or manufacturing process to uncontrolled variation.

In Sect. 15.8, very small screening designs are introduced. These designs allow one to search among many factors for the few factors which have substantially large main effects. The use of SAS and R software in analyzing fractional factorial experiments is explored in Sects. 15.9 and 15.10, respectively.

### 15.2 Fractions from Block Designs; Factors with 2 Levels

#### Half-Fractions of 2\({}^{p}\) Experiments; 2\({}^{p-1}\) Experiments

We start with a very small example to illustrate the ideas of fractional factorial experiments. Suppose that an experiment is to be run with three treatment factors \(A\), \(B\), and \(C\), each having two levels. There are no blocking factors, so the experiment will be run as a completely randomized design. However, only four observations can be taken.

We can obtain a fractional factorial design with just 4 of the 8 total treatment combinations by selecting at random one of the blocks of a single-replicate design with two blocks of size 4. For illustration, consider the block design that confounds the \(ABC\) contrast, given in Table 15.1. Supposewe select the second block, which is (001, 010, 100, 111) and is defined by the equation

\[a_{1}+a_{2}+a_{3}=1\bmod 2.\]

The four treatment combinations constitute a \(\frac{1}{2}\)_-fraction_ or \(\frac{1}{2}\)_-replicate_ of a \(2^{3}\) experiment, called a \(2^{3-1}\) design, and the \(ABC\) contrast is called the _defining contrast_ for the fraction. We write

\[I=ABC,\]

which is called the _defining relation_ for the fraction.

With only \(n=4\) observations, there are only \(n-1=3\) total degrees of freedom. This means that it is not possible to estimate each of the six remaining contrasts (\(A,B,C,AB,AC,BC\)) even if no estimate of \(\sigma^{2}\) is required. If we look at the contrasts for a \(2^{3}\) experiment (shown in Table 13.2, p. 436) and cross out the rows corresponding to the unobserved treatment combinations, just the contrast coefficients shown in the left part of Table 15.2 remain.

Table 15.2 shows several interesting features. First, the column corresponding to \(ABC\) is not a contrast. The coefficients are the coefficients that one would use in obtaining the sum of the four observations, which is a multiple of the mean. So, \(ABC\) is confounded with the mean, and the \(ABC\) contrast cannot be measured. The notation \(I=ABC\) of the defining relation indicates the equivalence of \(ABC\) and the sum of the observations, since \(I\) corresponds to a list of coefficients all equal to \(+1\).

Secondly, we see from Table 15.2 that the contrast coefficients for \(A\) and \(BC\) are identical, the contrasts for \(B\) and \(AC\) are identical, and the contrasts for \(C\) and \(AB\) are identical. The main effect of \(A\) and the interaction \(BC\) are said to be _aliased_, as are \(B\) and \(AC\), and \(C\) and \(AB\). We write

\[A=BC,\ \ \ B=AC,\ \ \ C=AB.\]

Thus, there are three estimable contrasts in the fraction, but each measures more than one factorial effect. For example, using the cell-means model

\[Y_{ijk}=\mu+\tau_{ijk}+\epsilon_{ijk}\,\]

the "\(A=BC\)" contrast with divisor \(v/2\) (where \(v\) is the number of treatment combinations in the fraction) is obtained by multiplying the \(\tau_{ijk}\)'s by the coefficients in the column labeled \(A\) in Table 15.2, that is,

\[\frac{1}{2}[-\tau_{001}-\tau_{010}+\tau_{100}+\tau_{111}].\]This is an estimable contrast with least squares estimate

\[\frac{1}{2}[-y_{001}-y_{010}+y_{100}+y_{111}].\]

It can be verified that this "\(A=BC\)" contrast in (15.2.1) can be written as

\[\begin{array}{l}\frac{1}{4}[-\tau_{000}-\tau_{001}-\tau_{010}-\tau_{011}+\tau _{100}+\tau_{101}+\tau_{110}+\tau_{111}]\\ \qquad\qquad+\frac{1}{4}[+\tau_{000}-\tau_{001}-\tau_{010}+\tau_{011}+\tau_{10 0}-\tau_{101}-\tau_{110}+\tau_{111}]\\ \qquad=[-\overline{\tau}_{0..}+\overline{\tau}_{1..}]+\frac{1}{2}[\overline{ \tau}_{.00}-\overline{\tau}_{.01}-\overline{\tau}_{.10}+\overline{\tau}_{.11}] \,.\end{array}\]

Thus, what is being estimated is the sum of the \(A\) contrast and the \(BC\) contrast, and we could refer to the "\(A=BC\)" contrast as the \(A+BC\) contrast. However, for simplicity, we often refer to it as the \(A\) contrast, remembering the role of \(BC\) from the list of aliased contrasts.

If in a hypothesis test or half-normal probability plot the main effect of factor \(A\) is nonsignificant, then there are two possibilities. One is that neither \(A\) nor its alias, \(BC\), is significantly different from zero. The alternative is that the two contrasts have equal and opposite effects and cancel each other out. Since the former is much more likely, this is the assumption that is usually made. If the main effect of \(A\) appears to be significant, then it is not clear whether the observed effect is due to the main effect of \(A\) or to the \(BC\) interaction or the combination of both effects. Because of the aliasing problem, fractional factorial experiments are most often run as _screening experiments_. The word "screening" means that the experimenter is trying to determine which of a large number of factors affect the response (see Sect. 15.8).

The list of aliased contrasts is called the _aliasing scheme_ for the design. We generally write this as in the right hand side of Table 15.2, with the first row showing the defining relation and the following rows listing the aliased contrasts. The number of rows in the aliasing scheme is the same as the number of observations in the design.

It can be verified that, if Block I of the single replicate design in Table 15.1 were to be used as the \(\frac{1}{2}\)-fraction instead of Block II, exactly the same aliasing scheme would result except that, in each pair of aliased contrasts, the coefficients would differ from each other in sign. The fraction would then consist of the four treatment combinations 000, 011, 101, 110, and the \(A\) contrast would be

\[\begin{array}{l}\frac{1}{2}[-\tau_{000}-\tau_{011}+\tau_{101}+\tau_{110}]\\ \qquad=\frac{1}{4}[-\tau_{000}-\tau_{001}-\tau_{010}-\tau_{011}+\tau_{100}+ \tau_{101}+\tau_{110}+\tau_{111}]\\ \qquad\qquad-\frac{1}{4}[+\tau_{000}-\tau_{001}-\tau_{010}+\tau_{011}+\tau_{10 0}-\tau_{101}-\tau_{110}+\tau_{111}]\\ \qquad=[-\overline{\tau}_{0..}+\overline{\tau}_{1..}]-\frac{1}{2}[\overline{ \tau}_{.00}-\overline{\tau}_{.01}-\overline{\tau}_{.10}+\overline{\tau}_{.11}] \,,\end{array}\]

which we could refer to as the \(A-BC\) contrast. This difference in signs can be highlighted by including this information in the aliasing scheme, that is, \(I=-ABC\), \(A=-BC\), \(B=-AC\), and \(C=-AB\).

The entire aliasing scheme in the right hand side of Table 15.2 can be deduced from the defining relation without writing out the contrasts. Using the contrast names, we can multiply the defining relation by \(A\) to obtain

\[A\times I=A\times ABC\,.\]

Treating \(I\) as a multiplicative identity so that \(A\times I=A\), and reducing superscripts modulo 2 so that \(A^{2}BC=BC\), we obtain \(A=BC\). The other two rows of the scheme can be obtained in a similar fashion. From now on, we will avoid writing out the contrasts and use the contrast names and the defining relation to obtain the aliasing scheme.

Half-fractions of \(2^{p}\) experiments have \(\frac{1}{2}2^{p}\) treatment combinations and are called \(2^{p-1}\) experiments. They are almost always obtained by selecting one block from a block design that confounds the highest-order interaction. Thus for \(p=4\), for example, the fraction satisfies either

\[a_{1}+a_{2}+a_{3}+a_{4}=0\;(\text{mod}\;2)\]

and has defining relation \(I=ABCD\), or it satisfies

\[a_{1}+a_{2}+a_{3}+a_{4}=1\;(\text{mod}\;2)\]

and has defining relation \(I=-ABCD\). For \(p=5\), the fraction satisfies either

\[a_{1}+a_{2}+a_{3}+a_{4}+a_{5}=0\;(\text{mod}\;2)\]

and has defining relation \(I=-ABCDE\), or it satisfies

\[a_{1}+a_{2}+a_{3}+a_{4}+a_{5}=1\;(\text{mod}\;2)\]

and has defining relation \(I=ABCDE\). Notice that the sign of the contrast in the defining relation is positive if the equation contains an even number of \(a_{i}\)'s and is set equal to 0 (mod 2). It is also positive if the equation contains an odd number of \(a_{i}\)'s and also is set equal to 1 (mod 2). Otherwise, the sign is negative. This always holds, even for the more complicated fractions of \(2^{p}\) experiments discussed in the following sections.

For most purposes, we do not need to know whether the contrasts listed in the defining relation differ in sign. Consequently, unless they are needed, we shall usually ignore the signs in the aliasing scheme.

#### Resolution and Notation

The defining relation contains a set of contrasts such as \(AB\), \(ABC\), etc. that are aliased with the mean; these contrasts are often called _words_. The number of letters in the shortest word in the defining relation is called the _resolution_ of the design.

The design in Table 15.2 is a Resolution III design, since the only word in the defining relation is \(ABC\), which has three letters. In all Resolution III designs, main-effect contrasts are aliased with 2-factor interaction contrasts. In a Resolution IV design, the defining relation contains only words with 4 or more letters. Some main effects are then aliased with 3-factor interactions and 2-factor interactions aliased with other 2-factor interactions. In a Resolution V design, such as that in Table 15.4, some main effects are aliased with 4-factor interactions, and 2-factor interactions are aliased with 3-factor interactions. This is summarized in Table 15.3.

Since the main-effects and low-order interactions are usually the most important factorial effects to be measured, it is generally beneficial to select a design with as high resolution as can be found. The designs in Table 15.60 (at the end of the chapter) all satisfy this requirement.

A \(1/2^{q}\) fraction of a \(2^{p}\) experiment is usually referred to as a \(2^{p-q}\)_fractional factorial experiment_. The resolution number is sometimes added as a subscript. A resolution III design, for example, can be written as a \(2^{p-q}_{\text{III}}\) design.

#### A Real Experiment--Soup Experiment

L.B. Hare, in the (1988) issue of the _Journal of Quality Technology_, described an experiment on a dry soup mix filling process that was run at Thomas J. Lipton, Inc. The company was concerned about keeping the weight of the mix as uniform as possible. They found that most of the variability was due to the uneven flow of the "intermix," which is a mixture of vegetable oil, salt, and other ingredients, during the mixing process. The researchers prepared a list of five treatment factors that they thought might be influential in controlling the mixing process. The factors and their levels (subsequently coded 0, 1) were:

A: number of mixer ports through which vegetable oil was added (two levels, 1 and 3);

B: temperature of mixer jacket (two levels; ambient temperature, presence of cooling water);

C: mixing time (two levels; 60 and 80 sec);

D: batch weight (two levels; 1500 and 2000 lb);

E: delay between mixing and packaging (two levels; 1 day and 7 days).

This was a screening experiment, since the researchers had little idea of which factors were going to turn out to be important in affecting the variability of the soup mix weight. They decided to run a \(\frac{1}{2}\)-fraction to investigate the five factors, and follow up the experiment with a more detailed study of the important factors later. They chose a Resolution V design with defining relation \(I=ABCDE\), which allowed them to include all main effects and two-factor interactions in the model. The corresponding block design, which confounds \(ABCDE\), is listed in Table 13.29. The experimenters chose the second block, as it contained the treatment combination that represented the normal operating conditions prior to the experiment. These were 00010, that is, one port, presence of cooling water, 60 s mix, 2000 lb batch weight, and a one day delay before packaging.

The experiment was designed so that it could be run with very little disruption to the daily production routine. Sets of 5 samples were taken every 15 min during the production run for each treatment combination and weighed. The response variable was a measure of variation based on these weights. The randomized design and the responses obtained are shown in Table 14. Also shown in the table are the contrasts for the main effects. As in Chap. 13, the contrast has coefficient \(-1\) when the corresponding factor is at its low level and coefficient \(+1\) when it is at its high level. The contrast coefficients for the interactions are the products of the corresponding main-effect contrast coefficients.

The experimenters included all the main effects and 2-factor interactions in the model. Since there were \(16-1=15\) degrees of freedom in total and 15 contrasts to estimate (5 main effects and 10 two-factor interactions), there were no degrees of freedom available to estimate the error variability. The experimenters calculated all the contrast estimates and prepared a normal probability plot to find the important contrasts. For example, the contrast estimate for the main effect of \(E\) is

\[\hat{E}= (0.78+1.10-1.70-1.28+0.97+1.47-1.85-2.10+0.76\] \[+0.62-1.09-1.13+1.25+0.98-1.36-1.18)/8 = -0.47.\]

\begin{table}
\begin{tabular}{c c c} \hline Resolution & Main effects aliased with & 2-factor interactions aliased with \\ \hline III & 2-factor interactions and/or higher & Main effects and/or interactions \\ IV & 3-factor interactions and/or higher & 2-factor interactions and/or higher \\ V & 4-factor interactions and/or higher & 3-factor interactions and/or higher \\ \hline \end{tabular}
\end{table}
Table 15.3: Resolution numbers of fractional factorial experimentsThe main effect and two-factor interaction contrast estimates are shown in Table 15.5. In Fig. 15.1, we present a half-normal probability plot (Sect. 7.5.2) which shows the absolute values of the contrast estimates plotted against their half-normal scores. It can be seen that the most important contrasts appear to be \(E\), \(BE\), and \(DE\).

\begin{table}
\begin{tabular}{c c c c c c c c c} \hline Contrasts & \(A\) & \(B\) & \(C\) & \(D\) & \(E\) & \(AB\) & \(AC\) & & \\ Estimates & \(0.145\) & \(-0.088\) & \(0.038\) & \(-0.038\) & \(-0.470\) & \(-0.015\) & \(0.095\) & & \\ Contrasts & \(AD\) & \(AE\) & \(BC\) & \(BD\) & \(BE\) & \(CD\) & \(CE\) & \(DE\) \\ Estimates & \(0.030\) & \(-0.153\) & \(0.068\) & \(-0.163\) & \(0.405\) & \(0.073\) & \(0.135\) & \(-0.315\) \\ \hline \end{tabular}
\end{table}
Table 15.5: Contrast estimates (with divisor \(v/2=8\)) for the soup experiment

\begin{table}
\begin{tabular}{c c c c c c c} \hline Levels of \(A\), \(B\), \(C\), \(D\), \(E\) & \(y_{ijklm}\) & & Contrasts & & & \\  & & \(A\) & \(B\) & \(C\) & \(D\) & \(E\) \\ \hline
01011 & 0.78 & \(-1\) & 1 & \(-1\) & 1 & 1 \\
1111 & 1.10 & 1 & 1 & 1 & 1 & 1 \\
10000 & 1.70 & 1 & \(-1\) & \(-1\) & \(-1\) & \(-1\) \\
11100 & 1.28 & 1 & 1 & 1 & \(-1\) & \(-1\) \\
00001 & 0.97 & \(-1\) & \(-1\) & \(-1\) & \(-1\) & 1 \\
01101 & 1.47 & \(-1\) & 1 & 1 & \(-1\) & 1 \\
00010 & 1.85 & \(-1\) & \(-1\) & \(-1\) & 1 & \(-1\) \\
10110 & 2.10 & 1 & \(-1\) & 1 & 1 & \(-1\) \\
00111 & 0.76 & \(-1\) & \(-1\) & 1 & 1 & 1 \\
10011 & 0.62 & 1 & \(-1\) & \(-1\) & 1 & 1 \\
01110 & 1.09 & \(-1\) & 1 & 1 & 1 & \(-1\) \\
01000 & 1.13 & \(-1\) & 1 & \(-1\) & \(-1\) & \(-1\) \\
11001 & 1.25 & 1 & 1 & \(-1\) & \(-1\) & 1 \\
10101 & 0.98 & 1 & \(-1\) & 1 & \(-1\) & 1 \\
11010 & 1.36 & 1 & 1 & \(-1\) & 1 & \(-1\) \\
00100 & 1.18 & \(-1\) & \(-1\) & 1 & \(-1\) & \(-1\) \\ \hline \end{tabular}
\end{table}
Table 15.4: Design, data (measure of weight variability), and main-effect contrasts for the soup experiment. Defining relation \(I=ABCDE\)Interaction plots of the two interactions \(BE\) and \(DE\) are shown in Fig. 15.2. The response is a measure of weight variability, and the experimenters wanted to reduce this as much as possible. The estimate of the \(E\) contrast is negative, indicating that the low level of \(E\) (one-day delay before packaging) is more variable that the high level (seven-day delay). The two interaction plots also indicate that a seven-day delay before packaging would be beneficial using the ambient temperature (low level of \(B\)) and the large batch size (2000 lb, high level of \(D\)). The interaction plots also indicate that if a seven-day delay is not feasible, then it is better to use cooling water and a small batch size (high \(B\), low \(D\)). The production management of the company agreed to a seven-day delay, and the researchers decided to investigate these three factors (\(B,D\), and \(E\)) in more detail in a followup experiment, together with factor \(C\), whose interaction with \(E\) was the next largest effect.

#### Quarter-Fractions of \(2^{p}\) Experiments; \(2^{p-2}\) Experiments

We can obtain a \(\frac{1}{4}\)-fraction of a \(2^{p}\) experiment by selecting at random one of the blocks from a single-replicate confounded design with 4 blocks of size \(2^{p-2}\). The defining relation is then the set of three contrasts that were confounded to obtain the block design.

For example, suppose a \(2^{5}\) experiment was to be run as a completely randomized design, but only eight observations could be taken, and the main effects and interaction \(AE\) were of particular interest. Table 13.29 (p. 471) lists a design in 4 blocks of 8. Suppose we switch \(E\) and \(D\) in the listed design, then we obtain a design in 4 blocks of 8 which confounds the three interactions \(ABD\), \(CDE\), and \(ABCE\). We can then select one block for the \(\frac{1}{4}\)-fraction; for example, if we select the block that satisfies

\[a_{1}+a_{2}+a_{4}=1\;(\text{mod}\;2)\;\;\;\text{and}\;\;\;a_{3}+a_{4}+a_{5}=0 \;(\text{mod}\;2),\]

the treatment combinations in the resulting fraction are

\[00011\;\;00110\;\;01000\;\;01101\;\;10000\;\;10101\;\;11011\;\;11110\,.\]

Figure 15.2: Interaction plots for the soup experiment

The defining relation for the fraction is

\[I=ABD=CDE=ABCE\.\]

(If we work out the contrast coefficients for this fraction, we find that the coefficients for \(ABD\) are all \(+1\), while those for \(CDE\) and \(ABCE\) are all \(-1\). Thus, if the signs of the contrasts were taken into account, the defining relation would be \(I=ABD=-CDE=-ABCE\).) The other seven rows of the aliasing scheme are obtained by multiplying the defining relation by each of the contrast names in turn. The resulting aliasing scheme (ignoring signs) is shown in Table 15.6.

Only one factorial effect from each row of the aliasing scheme (and none from the defining relation) can be entered into the model for analyzing the experiment. So, for example, we could include all main effects and the two 2-factor interactions \(AC\) and \(AE\) in the model. (Notice that, if we had not made the switch of labels \(E\) and \(D\), then \(AE\) would have been aliased with \(B\).)

If the \(D\) effect, for example, is insignificant, the interactions \(AB\), \(CE\), and \(ABCDE\) are also regarded as insignificant. But if the analysis shows that \(D\) has a significant effect on the response, it is unknown whether the effect is due to the main effect of \(D\), or to \(AB\), or to \(CE\), or to \(ABCDE\) (although this latter effect is the least likely), or to some combination of all four. The design is useful for screening when it is believed that most main effects and interactions will be negligible but one or two factors will possibly have an important effect on the response.

This design is clearly ideal if all of the interactions are negligible, or if all interactions except exactly one of \(AC\), \(BE\), \(AE\), and \(BC\) are thought to be negligible. In the first case, two degrees of freedom are available to estimate \(\sigma^{2}\). In the second case, all of the main effects and the one interaction can be measured, and one degree of freedom remains to estimate \(\sigma^{2}\). If all main effects and, say, the \(CD\) interaction were required to be estimated, then a different block design should be chosen since, in this design \(CD=E\). For example, a suitable design could be obtained by interchanging \(A\) and \(D\) in the list of confounded contrasts. In other words, the design obtained by confounding \(ABD\), \(ACE\), and \(BCDE\) will give a \(\frac{1}{4}\)-fraction in which \(CD\) is not aliased with main effects.

A list of useful \(\frac{1}{4}\)-fractions is given in Table 15.60 at the end of the chapter.

#### 15.2.1 Sludge experiment

S.R. Schmidt and R.G. Launsby, in their textbook _Understanding Industrial Designed Experiments_, include an article by J. Brickell and K. Knox on the operation of a biological treatment system (known as an activated sludge system) used in wastewater treatment plants. The details of the system are given in the article. The response, Y, is the removal of "biochemical oxygen demand," which is related to the quality of water. The water quality increases as more biochemical oxygen demand is removed, so the

\begin{table}
\begin{tabular}{c c c c c c} \hline \hline \multirow{2}{*}{\(I=ABD=CDE=ABCE\)} & \(I\) & \(=\) & \(ABD\) & \(=\) & \(CDE\) & \(=\) & \(ABCE\) \\  & \(A\) & \(=\) & \(BD\) & \(=\) & \(ACDE\) & \(=\) & \(BCE\) \\  & \(B\) & \(=\) & \(AD\) & \(=\) & \(BCDE\) & \(=\) & \(ACE\) \\  & \(C\) & \(=\) & \(ABCD\) & \(=\) & \(DE\) & \(=\) & \(ABE\) \\  & \(D\) & \(=\) & \(AB\) & \(=\) & \(CE\) & \(=\) & \(ABCDE\) \\  & \(E\) & \(=\) & \(ABDE\) & \(=\) & \(CD\) & \(=\) & \(ABC\) \\  & \(AC\) & \(=\) & \(BCD\) & \(=\) & \(ADE\) & \(=\) & \(BE\) \\  & \(AE\) & \(=\) & \(BDE\) & \(=\) & \(ACD\) & \(=\) & \(BC\) \\ \hline \hline \end{tabular}
\end{table}
Table 15.6: Aliasing scheme (ignoring signs) for a \(\frac{1}{4}\)-fraction of a \(2^{5}\) experiment with the defining relation \(I=ABD=CDE=ABCE\)response Y is to be maximized. The experiment described in the article investigates the effect of five factors on Y:

* Reactor biomass concentration (3000 and 6000 mg/l),
* Clarifier biomass concentration (8000 and 12000 mg/l),
* Waste sludge flow rate (78.5 and 940 m3/d),
* Biological growth rate constant (0.040 and 0.075 d-1)
* Fraction of food to biomass (0.4 and 0.8 kg/kg).

Since this experiment was to be run in a water treatment plant, it was necessary to keep the number of observations small, and a \(\frac{1}{4}\)-fraction was selected with defining relation \(I=ABD=CDE=ABCE\). This gives the aliasing scheme of Table 15.6.

The experimenters selected the fraction whose treatment combinations, written as \(a_{1}a_{2}a_{3}a_{4}a_{5}\), satisfied

\[\begin{array}{rll}a_{1}+a_{2}&+a_{4}&=1\;(\text{mod}\;2)\\ a_{3}+a_{4}+a_{5}&=1\;(\text{mod}\;2)\end{array}\]

The design, prior to randomization, is shown in Table 15.7 together with the responses obtained.

The experimenters included all main effects and the 2-factor interactions \(AC\) and \(BC\) in their model. The contrast estimates (with divisors \(v/2=4\)) are listed in Table 15.8, and a half-normal probability plot of the seven contrast estimates is shown in Fig. 15.3. There are too few contrast estimates in total to be able to draw good conclusions from the half-normal probability plot. Nevertheless, the most important effect appears to be the main effect of \(C\) and, perhaps to a lesser extent, \(E\). Now, \(C\) is aliased with \(DE\), and \(E\) is aliased with \(CD\). A followup experiment investigating the effects of \(C\), \(D\), and \(E\) would certainly be advisable.

If we try to draw conclusions from the results of the present experiment, and if we are willing to assume that the main effects are the dominant effects in any alias sets, it would seem advisable to set \(C\) and possibly \(B\) at their high levels in order to maximize the response, and to set \(E\) and possibly \(D\) at their low levels. On the other hand, if we assume that the interactions in the alias sets might be

\begin{table}
\begin{tabular}{c c c c c c c c} \hline Levels of \(A\), \(B\), \(C\), \(D\), \(E\) & \(\mathit{yijklm}\) & & & Contrasts & & & \\  & & \(A\) & \(B\) & \(C\) & \(D\) & \(E\) & \(AC\) & \(BC\) \\ \hline
00010 & 195 & \(-1\) & \(-1\) & \(-1\) & \(1\) & \(-1\) & \(1\) & \(1\) \\
00111 & 496 & \(-1\) & \(-1\) & \(1\) & \(1\) & \(1\) & \(-1\) & \(-1\) \\
01001 & 87 & \(-1\) & \(1\) & \(-1\) & \(-1\) & \(1\) & \(1\) & \(-1\) \\
01100 & 1371 & \(-1\) & \(1\) & \(1\) & \(-1\) & \(-1\) & \(-1\) & \(1\) \\
10001 & 102 & 1 & \(-1\) & \(-1\) & \(-1\) & \(1\) & \(-1\) & \(1\) \\
10100 & 1001 & 1 & \(-1\) & \(1\) & \(-1\) & \(-1\) & \(1\) & \(-1\) \\
11010 & 354 & 1 & 1 & \(-1\) & \(1\) & \(-1\) & \(-1\) & \(-1\) \\
1111 & 775 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\ \hline \end{tabular}
\end{table}
Table 15.7: \(\frac{1}{4}\)-fraction of a \(2^{5}\) experiment and data from the sludge experiment

\begin{table}
\begin{tabular}{c c c c c c c c} \hline Contrast & \(A\) & \(B\) & \(C\) & \(D\) & \(E\) & \(AC\) & \(BC\) \\ Estimate & 20.75 & 198.25 & 726.25 & \(-185.25\) & \(-365.25\) & \(-66.25\) & \(126.25\) \\ \hline \end{tabular}
\end{table}
Table 15.8: Contrast estimates (with divisor \(v/2=4\)) for the sludge experiment important, we would examine the _DE_ and _CD_ interaction plots (see Fig. 15.4). The _DE_ plot suggests that \(D\) and \(E\) should both be at their low levels, and the _CD_ plot suggests that \(C\) should be at its high level and \(D\) at its low level. Since the recommendations from the interaction plots agree with those from the main effect comparisons, we would feel comfortable in recommending that the process be set at the cheaper of 01100 or 11100. Notice that the first of these was included among the experimental runs (and happened to give rise to the largest observed yield), whereas the second was not included. In either case, the experiment should be re-run at the chosen setting to confirm the results.

The authors of the article point out that other considerations, such as cost, come into play before any system can be changed. In an actual water treatment plant, it would be expensive to change the levels of \(D\) (biological growth rate constant) and \(E\) (fraction of food to biomass) from their current settings. Also, increasing the waste sludge flow rate (_C_) increases cost. A followup experiment could verify that the above recommendations were correct, and also could examine intermediate values of \(C\).

Figure 15.4: Interaction plots for the sludge experiment

Figure 15.3: Half-normal probability plot of contrast absolute estimates for the sludge experiment

#### 15.2.5 Smaller Fractions of 2\({}^{p}\) Experiments

Smaller fractions of a 2\({}^{p}\) experiment can be obtained in exactly the same way as the \(\frac{1}{2}\)-fractions and \(\frac{1}{4}\)-fractions of the preceding subsections. For a \(1/2^{s}\) fraction, the first step is to find a design with \(2^{s}\) blocks of size \(2^{p-s}\) that confounds negligible interactions. One block is selected at random. The aliasing scheme is then checked to ensure that as few important contrasts as possible are aliased with each other. If the aliasing scheme is not suitable, then an attempt is made to obtain a better design by interchanging letters in the confounding scheme, or by investigating different confounding schemes. A list of useful \(\frac{1}{4}\)-, \(\frac{1}{8}\)- and \(\frac{1}{16}\)-fractions of \(2^{p}\) experiments is given in Table 15.60 at the end of the chapter.

_Example 15.2.2_ Welding experiment

An experiment was discussed by A.K. Shahani in _The Statistician_ in 1970 which involved a (1/1024) fraction of a \(2^{21}\) experiment (that is, a \(2^{21-16}\) experiment). The experiment, which required only \(v=2^{5}=32\) observations, was designed by Dr. Shahani for Bristol Aerojet Ltd and concerned the "pull strength" of welds resulting from a certain welding process. The company wished to discover which settings of the 21 factors would give welds with pull strength exceeding a given size. Of the 21 factors, only a few were expected to have important effects on the pull strength, and this allowed the use of such a highly fractionated design.

All 21 factors were easy to manipulate, and the engineers selected two reasonable settings for each factor (coded 0 and 1). For some of the factors, the two levels chosen were at equal distances on each side of the current operating conditions. For others, such as factors \(A\), \(D\), and \(W\), the low levels were at the current operating conditions and could not be lowered further. If we label the factors \(A\), \(B\), \(\ldots\), \(W\) omitting \(I\) and \(O\), the contrasts selected for confounding were as follows:

\[\begin{array}{ccccc}ABV&ACW&ADT&AES\\ BCU&ABEN&ACDQ&ACEP\\ ADEM&BCER&BDEL&CDEK\\ \par ABCEH&ABDEJ&ACDEG&BCDEF\end{array}\]

The defining relation consists of these 16 contrasts together with all their possible products. Since the shortest word in the defining relation is of length 3, the design is Resolution III. Although each main effect is aliased with several two-factor interactions, the main effects are not aliased with each other.

The 32 treatment combinations and their responses are shown in Table 15.9. (We have corrected typing errors that occurred in the original paper in the two treatment combinations in the second row of our table). The responses are in coded units, details of which were not given in the original paper.

This experiment has too many factors to be able to analyze it easily by hand. The main-effect contrast estimates (with divisors \(v/2=16\)), obtained from a computer package, are shown in Table 15.10. Under the current operating conditions, it was known that the error standard deviation \(\sigma\) was about 60 units. The experimenters were willing to assume that this would not change appreciably under different operating conditions and therefore calculated the standard error of a main effect contrast \(\Sigma_{i}c_{i}\tau_{i}\) to be

\[\sqrt{\mathrm{Var}(\Sigma_{i}c_{i}\hat{\tau}_{i})}=\sigma\sqrt{\Sigma c_{i}^{2 }}=60\sqrt{32/16^{2}}=21.21.\]

Without assuming that the coded responses follow a normal distribution, the experimenters then deemed any contrast whose estimated absolute value turned out to be several times larger than 21.21 to be important.

The contrast estimates whose absolute values exceed 63.63 are those for the main effects of \(A\), \(D\), \(H\), \(J\), \(N\), \(V\), and \(W\). The estimates for main effects of \(M\), \(K\), and \(S\) are all around 2 standard errors, with those for \(C\) and \(F\) a little smaller.

Since there are 32 observations, a total of 31 orthogonal contrasts can be measured. Thus there are 10 sets of confounded interaction contrasts that can be measured in addition to the 21 main-effect contrasts. The identification of these contrast sets requires writing out the entire aliasing scheme--a daunting task! A proper analysis of the main effects also requires knowledge about which interactions are aliased with which main effects. A followup experiment to separate out the most likely aliased effects would be needed.

Assuming, temporarily, that the process can be improved by considering the main effects only, the contrast estimates (high level minus low level) suggest that factors \(A\), \(D\), and \(W\) (whose contrast estimates are negative) should be set at their low levels and factors \(H\), \(J\), \(K\), \(N\), \(V\), \(M\), and \(S\) (whose contrast estimates are positive) should be set at their high levels. As mentioned above, \(A\), \(D\), and \(W\) were already set at the lowest possible values in the original process, and therefore further experimentation with these factors is unnecessary. The other seven factors were discussed by the engineers and new (higher) settings selected for these, resulting in an improved process that met the pull strength requirements. The author of the article commented that the research and development department should give consideration to a further experiment involving these seven factors in which main effects and two-factor

\begin{table}
\begin{tabular}{c c c c c c c c} \hline Contrast & \(A\) & \(B\) & \(C\) & \(D\) & \(E\) & \(F\) & \(G\) \\ Estimate & \(-104.8\) & \(-34.6\) & \(-39.4\) & \(-152.5\) & \(12.3\) & \(37.4\) & \(5.3\) \\ \hline Contrast & \(H\) & \(J\) & \(K\) & \(L\) & \(M\) & \(N\) & \(P\) \\ Estimate & \(101.9\) & \(70.5\) & \(48.4\) & \(-23.4\) & \(43.5\) & \(100.1\) & \(32.9\) \\ \hline Contrast & \(Q\) & \(R\) & \(S\) & \(T\) & \(U\) & \(V\) & \(W\) \\ Estimate & \(16.6\) & \(3.0\) & \(42.1\) & \(-8.1\) & \(7.1\) & \(72.8\) & \(-69.0\) \\ \hline \end{tabular}
\end{table}
Table 15.9: Treatment combinations and responses for the \(2^{21-16}\) welding experiment

\begin{table}
\begin{tabular}{c c c c} \hline Treatment combination & Response & Treatment combination & Response \\ \hline
0000011110000001111 & 430 & 10000100001111000 & 422 \\
0100001000100111001 & 336 & 110000011011100010 & 380 \\
00100000110001111010 & 438 & 1010001101010010001 & 96 \\
0110010101101101100 & 394 & 11100110111000000111 & 319 \\
0001001011100101010111 & 334 & 1001001011011000100 & 202 \\
0101010101101110001 & 322 & 1101011101000101010 & 238 \\
001101100011010110010 & 184 & 1011010110101101001 & 188 \\
011100111001110010100 & 348 & 111100000000001001111 & \(-234\) \\
0000100001111110101111 & 384 & 100010111110001110100 & 338 \\
010011011101010001001 & 404 & 1100111001010101010010010 & 370 \\
001011110011100101010 & 542 & 101010101010010010001 & 114 \\
011010101001001101100 & 316 & 1110100100001101111 & 432 \\
0001111010001111001111 & 256 & 10011101001000100111100 & 206 \\
0101101101001001000001 & 82 & 1101100010111000110 & 106 \\
001110011100100000010 & 528 & 10111010010101011001 & 110 \\
011110001110000000100 & 528 & 101111111111111111111111 & 370 \\ \hline \end{tabular} _Source_ Shahani (1970). Copyright © 1970 Blackwell Publishers. Reprinted with permission

\end{table}
Table 15.10: Contrast estimates for the welding experiment (with divisor 16)interactions could all be measured. He suggested the use of a \(2^{7-1}\) experiment, which would require 64 observations. Fewer observations would require aliasing some of the 2-factor interactions (see Table 15.60). 

### Fractions from Block Designs; Factors with 3 Levels

#### One-Third Fractions of 3\({}^{p}\) Experiments; 3\({}^{p-1}\) Experiments

To obtain a fraction of a 3\({}^{p}\) experiment, we use the same idea that we used for 2\({}^{p}\) experiments. We select one block at random from a confounded single-replicate design with 3\({}^{s}\) blocks of size 3\({}^{p-s}\) with a suitable confounding scheme. For example, suppose a \(\frac{1}{3}\)-fraction of a 3\({}^{4}\) experiment is required (that is, a total of 3\({}^{4-1}=27\) observations). The highest-order interaction in a 3\({}^{4}\) experiment that can be confounded is the 4-factor interaction. Therefore, the maximum number of letters in a word in the defining relation of the fraction is also four. For a Resolution IV design, when 3- and 4-factor interactions are negligible, the main-effect contrasts can be estimated, but the 2-factor interactions will be aliased. This is the best design available and, unless a larger budget can be obtained to allow more observations, some aliasing among the low-order interactions will have to be tolerated.

Suppose the selected single-replicate confounded design is that which confounds the pair of contrasts (\(ABCD\); \(A^{2}\!B^{2}\!C^{2}\!D^{2}\)) from the 4-factor interaction. The block design is constructed using the equations

\[a_{1}+a_{2}+a_{3}+a_{4}=0,\ 1,\text{ or }2\ (\text{mod }3)\]

as in Sect. 14.2.3, and one block is selected at random for the \(\frac{1}{3}\)-fraction. Since there are 27 treatment combinations to be observed, the aliasing scheme has 27 rows. Seven rows from the aliasing scheme are given in Table 15.11. The remaining rows contain main effects or 2-factor interaction contrasts (such as \(AB^{2}\) or \(A^{2}\!B\)) that are aliased only with higher-order interactions. The 27 rows of the aliasing scheme include one for effects aliased with the mean, together with 13 additional pairs of rows, such as the pair of rows involving \(AB\) and \(A^{2}\!B^{2}\) which represent contrasts from the same two-factor interaction. The two rows containing \(AB\) and \(A^{2}\!B^{2}\) indicate, for example, that the pair of contrasts (\(AB\); \(A^{2}\!B^{2}\)) is aliased with the pairs of contrasts (\(CD\); \(C^{2}\!D^{2}\)) and (\(ABC^{2}\!D^{2};A^{2}\!B^{2}\!CD\)). Use of this design is illustrated in Example 15.3.1.

#### Refinery experiment

John (1971) describes an experiment of Vance (1962) to find a set of operating conditions to optimize the quality of lube oil treated at a refinery. There were four factors of interest, called here \(A\), \(B\), \(C\), and \(D\), and three equally spaced levels were selected for each of these so that quadratic trends could be measured.

\begin{table}
\begin{tabular}{c c c c c c c c c c} \(I\) & \(=\) & \(ABCD\) & \(=\) & \(A^{2}\!B^{2}\!C^{2}\!D^{2}\) & & & & & \\ \(AB\) & \(=\) & \(A^{2}\!B^{2}\!C\!D^{2}\) & \(=\) & \(C^{2}\!D^{2}\) & \(A^{2}\!B^{2}\) & \(=\) & \(CD\) & \(=\) & \(ABC^{2}\!D^{2}\) \\ \(AC\) & \(=\) & \(A^{2}\!BC^{2}\!D\) & \(=\) & \(B^{2}\!D^{2}\) & \(A^{2}\!C^{2}\) & \(=\) & \(BD\) & \(=\) & \(AB^{2}\!CD^{2}\) \\ \(AD\) & \(=\) & \(A^{2}\!BCD^{2}\) & \(=\) & \(B^{2}\!C^{2}\) & \(A^{2}\!D^{2}\) & \(=\) & \(BC\) & \(=\) & \(AB^{2}\!C^{2}\!D\) \\ \end{tabular}
\end{table}
Table 15.11: Seven rows from the aliasing scheme for a \(\frac{1}{3}\)-fraction of a 3\({}^{4}\) experiment with the defining relation \(I=ABCD=A^{2}\!B^{2}\!C^{2}\!D^{2}\)Since this was a preliminary experiment, a \(\frac{1}{3}\)-fraction of Resolution IV was thought to be adequate. The experimenters used a design with defining relation \(I=ABCD=A^{2}B^{2}C^{2}\!D^{2}\). Part of the aliasing scheme is shown in Table 11. We see from row 2 that two degrees of freedom from the \(AB\) interaction are aliased with two degrees of freedom from each of the \(CD\) and \(ABCD\) interactions. The other two degrees of freedom from each of these interactions are aliased with 3-factor interactions. (For example, the pair \((AB^{2};A^{2}\!B)\) is aliased with the pairs \((A^{2}CD;AC^{2}\!D^{2})\) and \((BC^{2}\!D^{2};B^{2}\!CD)\)). A similar confounding pattern occurs with \(AC\) and \(BD\) and also with \(AD\) and \(BC\).

The treatment combinations can be obtained from the equation

\[a_{1}+a_{2}+a_{3}+a_{4}=0\;({\rm mod}\;3)\]

and are shown in Table 12, prior to randomization, together with the data collected. Also shown are the linear and quadratic contrast coefficients for the main effects. The objective of the experiment was to select factor levels that would increase the response (a measure of quality).

The analysis of variance is complicated by the aliasing of pairs of degrees of freedom for two-factor interactions. We have not tried to separate these but have listed the contributions of the pairs of

\begin{table}
\begin{tabular}{c r r r r r r r r} \hline Treatment combination & \(y_{ijkl}\) & \(A_{\rm L}\) & \(A_{\rm Q}\) & \(B_{\rm L}\) & \(B_{\rm Q}\) & \(C_{\rm L}\) & \(C_{Q}\) & \(D_{\rm L}\) & \(D_{\rm Q}\) \\ \hline
0000 & 4.2 & \(-1\) & 1 & \(-1\) & 1 & \(-1\) & 1 & \(-1\) & 1 \\
0012 & 5.9 & \(-1\) & 1 & \(-1\) & 1 & 0 & \(-2\) & 1 & 1 \\
0021 & 8.2 & \(-1\) & 1 & \(-1\) & 1 & 1 & 1 & 0 & \(-2\) \\
0102 & 13.1 & \(-1\) & 1 & 0 & \(-2\) & \(-1\) & 1 & 1 & 1 \\
0111 & 16.4 & \(-1\) & 1 & 0 & \(-2\) & 0 & \(-2\) & 0 & \(-2\) \\
0120 & 30.7 & \(-1\) & 1 & 0 & \(-2\) & 1 & 1 & \(-1\) & 1 \\
0201 & 9.5 & \(-1\) & 1 & 1 & 1 & \(-1\) & 1 & 0 & \(-2\) \\
0210 & 22.2 & \(-1\) & 1 & 1 & 1 & 0 & \(-2\) & \(-1\) & 1 \\
0222 & 31.0 & \(-1\) & 1 & 1 & 1 & 1 & 1 & 1 \\
1002 & 7.7 & 0 & \(-2\) & \(-1\) & 1 & \(-1\) & 1 & 1 & 1 \\
1011 & 16.5 & 0 & \(-2\) & \(-1\) & 1 & 0 & \(-2\) & 0 & \(-2\) \\
1020 & 14.3 & 0 & \(-2\) & \(-1\) & 1 & 1 & 1 & \(-1\) & 1 \\
1101 & 11.0 & 0 & \(-2\) & 0 & \(-2\) & \(-1\) & 1 & 0 & \(-2\) \\
1110 & 29.0 & 0 & \(-2\) & 0 & \(-2\) & 0 & \(-2\) & \(-1\) & 1 \\
1122 & 55.0 & 0 & \(-2\) & 0 & \(-2\) & 1 & 1 & 1 & 1 \\
1200 & 8.5 & 0 & \(-2\) & 1 & 1 & \(-1\) & 1 & \(-1\) & 1 \\
1212 & 37.4 & 0 & \(-2\) & 1 & 1 & 0 & \(-2\) & 1 & 1 \\
1221 & 66.3 & 0 & \(-2\) & 1 & 1 & 1 & 1 & 0 & \(-2\) \\
2001 & 11.4 & 1 & 1 & \(-1\) & 1 & \(-1\) & 1 & 0 & \(-2\) \\
2010 & 21.1 & 1 & 1 & \(-1\) & 1 & 0 & \(-2\) & \(-1\) & 1 \\
2022 & 57.9 & 1 & 1 & \(-1\) & 1 & 1 & 1 & 1 \\
2100 & 13.5 & 1 & 1 & 0 & \(-2\) & \(-1\) & 1 & \(-1\) & 1 \\
2112 & 51.6 & 1 & 1 & 0 & \(-2\) & 0 & \(-2\) & 1 & 1 \\
2121 & 76.5 & 1 & 1 & 0 & \(-2\) & 1 & 1 & 0 & \(-2\) \\
2202 & 31.0 & 1 & 1 & 1 & 1 & \(-1\) & 1 & 1 & 1 \\
2211 & 74.5 & 1 & 1 & 1 & 1 & 0 & \(-2\) & 0 & \(-2\) \\
2220 & 85.1 & 1 & 1 & 1 & 1 & 1 & 1 & \(-1\) & 1 \\ \hline \end{tabular} _Sources_ John (1971). Copyright © 1971 P.W.M. John. Reprinted with permission

\end{table}
Table 12: \(\frac{1}{3}\)-fraction of a \(3^{4}\) experiment and data from the refinery experiment interactions on the same line of the analysis of variance table shown in Table 13. Without information concerning negligible interactions, we are unable to obtain an estimate for the error variance. The most important interactions appear to be the \(AC\) or \(BD\) interactions, and the \(BC\) or \(AD\) interactions; the corresponding interaction plots are shown in Fig. 15. In each case, the plots indicate that in order to increase the response, factors \(A\), \(B\), and \(C\) should all be set at their high levels, cost permitting, and factor \(D\) should be set at its middle level. They also indicate that since the lines are not too far from parallel, it would be reasonable to examine the main-effect contrasts.

Normalized linear and quadratic main-effect contrast estimates are obtained as

\[\frac{1}{d}\sum_{i}\sum_{j}\sum_{k}\sum_{l}c_{ijkl}\hat{\tau}_{ijkl}=\frac{1}{d }\sum_{i}\sum_{j}\sum_{k}\sum_{l}c_{ijkl}y_{ijkl}\,\]

where the \(c_{ijkl}\)'s are the contrast coefficients in Table 13 and the divisor \(d\) is the square root of the sum of squares of the coefficients (that is, \(\sqrt{18}\) for the linear contrasts and \(\sqrt{54}\) for the quadratic contrasts). These estimates are listed in Table 13, and a half-normal probability plot of the estimates is shown in Fig. 15. Eight estimates are too few to make a good judgment, but the most important effects appear to be the linear trends in \(C\), \(A\), and \(B\) (in that order). All of these contrast estimates are positive, suggesting that the high levels should be selected in order to increase the response. This agrees with the conclusions from the interaction plots as well as the observed data in Table 13. Note that we could have examined interactions more closely by including individual interaction contrast estimates in the half-normal probability plot. We have not done this because of the complicated confounding of the interactions.

Since we have no estimate for error, we are unable to test any hypotheses. However, had the experimenters believed, prior to the experiment, that some or all of the interactions were negligible, then tests would have been done for the remaining interactions and the main effects. The sums of squares for testing the linear and quadratic main-effect contrasts are the squares of the corresponding normalized contrast estimates in Table 13. For example, the sums of squares for testing the

\begin{table}
\begin{tabular}{c c c c} \hline Source of variation & Degrees of freedom & Sum of squares & Mean square \\ \hline \(A\) & 2 & 4496.29 & 2248.14 \\ \(A_{\rm L}\) & 1 & 4399.22 & 4399.22 \\ \(A_{\rm Q}\) & 1 & 97.07 & 97.07 \\ \(B\) & 2 & 2768.69 & 1384.35 \\ \(B_{\rm L}\) & 1 & 2647.49 & 2647.49 \\ \(B_{\rm Q}\) & 1 & 121.20 & 121.20 \\ \(C\) & 2 & 5519.79 & 2759.89 \\ \(C_{\rm L}\) & 1 & 5516.00 & 5516.00 \\ \(C_{\rm Q}\) & 1 & 3.79 & 3.79 \\ \(D\) & 2 & 283.37 & 141.68 \\ \(D_{\rm L}\) & 1 & 213.56 & 213.56 \\ \(D_{\rm Q}\) & 1 & 69.81 & 69.81 \\ \(AB\), \(CD\) & 6 & 339.00 & 56.50 \\ \(AC\), \(BD\) & 6 & 1384.24 & 230.71 \\ \(AD\), \(BC\) & 6 & 753.38 & 125.56 \\ Total & 26 & 15,544.66 & \\ \hline \end{tabular}
\end{table}
Table 13: Analysis of variance for the refinery experiment hypothesis that the linear trend of factor \(A\) is negligible, against the alternative hypothesis that it is not negligible, is

\[ss(A_{\rm L})=66.327^{2}=4399.22\.\]

The sums of squares for the main effects of factors \(A\), \(B\), \(C\), and \(D\) can be obtained either by adding their respective linear and quadratic contrast sums of squares, or by using the rules of Chap. 7 with \(r=1/3\) (since this is a one-third fraction). For example,

\[ssA=ss(A_{\rm L})+ss(A_{\rm Q})=66.327^{2}+9.852^{2}=4399.22+97.07=4496.29\,\]

or

\[ssA=9\Sigma\bar{y}_{i_{L}}^{2}-27\bar{y}_{i_{L}}^{2}=28766.30-24270.01=4496.29\.\qquad\qquad\square\]

Figure 5: Interaction plots for the refinery experiment

#### One-Ninth Fractions of 3\({}^{p}\) Experiments; 3\({}^{p-2}\) Experiments

As an example of a \(\frac{1}{9}\)-fraction, we take the sixth block of the 3\({}^{4}\) single-replicate confounded design shown in Table 5. The list of confounded interactions in the block design provides the list of interactions in the defining relation for the 3\({}^{4-2}\) fractional factorial design. In the block design of Table 5, the confounded contrasts are (\(AB^{2}C\); \(A^{2}BC^{2}\)), (\(ABD\); \(A^{2}B^{2}D^{2}\)), (\(AC^{2}D^{2}\); \(A^{2}CD\)), and (\(BCD^{2}\); \(B^{2}C^{2}D\)) so, in the fraction, which consists of 9 treatment combinations, the defining relation is

\[\begin{array}{ccc}I&=&AB^{2}C&=&A^{2}BC^{2}\\ =&ABD&=&A^{2}CD&=&B^{2}C^{2}D\\ =&A^{2}B^{2}D^{2}&=&BCD^{2}&=&AC^{2}D^{2}\,.\end{array}\]

This design has Resolution III (since the shortest word has 3 letters), and main-effect contrasts will be aliased with 2-factor interaction contrasts. The nine observations provide 8 degrees of freedom, which is sufficient to estimate the four main effects (with two degrees of freedom each). Therefore, the design would be useful if all two-factor interactions were believed to be negligible. Since there are no degrees of freedom available for estimating \(\sigma^{2}\), a half-normal probability plot of normalized contrast estimates would be drawn as was done in Fig. 6.

### 5.4 Fractions from Block Designs; Other Experiments

#### 5.4.1 2\({}^{p}\)\(\times\) 4\({}^{q}\) Experiments

The simplest way to design a fractional factorial experiment when all factors have four levels, or when some factors have two levels and the others have four levels, is to use pseudofactors. For example, suppose we require a design for a 2\({}^{3}\)\(\times\) 4 experiment with eight observations. A design in four blocks of size 8 is shown in Table 7. The confounded contrasts are \(FGJ_{1}J_{2}\), \(GHJ_{2}\), and \(FHJ_{1}\), where \(J_{1}\) and \(J_{2}\) are the two 2-level pseudofactors making up the 4-level factor \(J\). Suppose Block I is

\begin{table}
\begin{tabular}{c c c c c c c c}  & \(\hat{A}_{\rm L}\) & \(\hat{A}_{\rm Q}\) & \(\hat{B}_{\rm L}\) & \(\hat{B}_{\rm Q}\) & \(\hat{C}_{\rm L}\) & \(\hat{C}_{\rm Q}\) & \(\hat{D}_{\rm L}\) & \(\hat{D}_{\rm Q}\) \\ \hline Estimate & 66.33 & 9.85 & 51.45 & −11.01 & 74.27 & −1.95 & 14.61 & −8.36 \\ \hline \end{tabular}
\end{table}
Table 5.4: Normalized contrast estimates for the refinery experiment

Figure 6: Half-normal probability plot for the refinery experiment contrast absolute estimatesselected from the design to give a \(\frac{1}{4}\)-fraction of a \(2^{3}\times 4\) experiment, then the defining relation is

\[I=FGJJ_{2}=GHJ_{2}=FHJ_{1}\]

and the design is Resolution III. The aliasing scheme, shown in Table 15.15, indicates that the \(F\) contrast, for example, is aliased with one contrast from each of the \(GJ\), \(FGHJ\) and \(HJ\) interactions. There are 3 contrasts (\(J_{1},J_{2}\) and \(Jy_{2}\)) for the 4-level factor \(J\). The aliasing scheme shows that \(J\) is aliased with contrasts from the \(FGJ\), \(GHJ\), \(FH\), \(GH\), \(FHJ\), \(FG\) interactions.

An experiment involving pseudofactors will be illustrated in Example 15.5.1 in Sect. 15.5.

#### 15.4.2 \(2^{p}\times 3^{q}\) Experiments

Suppose that a \(\frac{1}{6}\)-fraction of a \(2^{3}\times 3^{3}\) experiment is required, which has a total of 36 observations. Again, we follow the idea of selecting one block from a block design. So we first need a block design in \(b=6\) blocks, each of size 36. Following the procedure of Example 14.4.1, p. 484, we select, for example, (i) a block design in two blocks of size 4 from the \(2^{3}\) experiment with factors \(A\), \(B\), \(C\), confounding the \(ABC\) interaction, and (ii) a block design in three blocks of size 9 from the \(3^{3}\) experiment with factors \(E\), \(F\), \(G\), confounding the pair of contrasts (\(DE^{2}\!F\); \(D^{2}\!EF^{2}\)). Combining the treatment combinations in the blocks of these designs as in Example 14.4.1 leads to a design with six blocks in which the five contrasts \(ABC\), (\(DE^{2}\!F\); \(D^{2}\!EF^{2}\)), and (\(ABCDE^{2}\!F\); \(ABCD^{2}\!EF^{2}\)) are confounded. Then, if one of the six blocks is selected for the \(\frac{1}{6}\)-fraction, we have a Resolution III design with defining relation

\[I\ \ =\ ABC\ =\ DE^{2}\!F\ =\ D^{2}\!EF^{2}\ =\ ABCDE^{2}\!F\ =\ ABCD^{2}\!EF^{2}\,\]

and the contrasts \(ABC\), (\(DE^{2}\!F\); \(D^{2}\!EF^{2}\)), and (\(ABCDE^{2}\!F\); \(ABCD^{2}\!EF^{2}\)) are aliased with the mean.

The aliasing scheme for the fraction has 36 rows and includes the following three rows:

\[\begin{array}{l}A\ =\ BC\ =\ ADE^{2}\!F\ =\ AD^{2}\!EF^{2}\ =\ BCDE^{2}\!F\ =\ BCD^{2}\!EF^{2}\,\\ B\ =\ AC\ =\ BDE^{2}\!F\ =\ BD^{2}\!EF^{2}\ =\ ACDE^{2}\!F\ =\ ACD^{2}\!EF^{2}\,\\ C\ =\ AB\ =\ CDE^{2}\!F\ =\ CD^{2}\!EF^{2}\ =\ ABDE^{2}\!F\ =\ ABD^{2}\!EF^{2}. \end{array}\]

Thus, the 2-level factors \(A\), \(B\), and \(C\) are aliased with 2-factor interactions between the 2-level factors plus some higher-order interactions. For example, the \(A\) contrast is aliased with the contrasts \(BC\), (\(ADE^{2}\!F\); \(AD^{2}\!EF^{2}\)), and (\(BCDE^{2}\!F\); \(BCD^{2}\!EF^{2}\)).

A similar aliasing happens for the 3-level factors. For example,\[\begin{array}{l}D\ =\ ABCD\ =\ D^{2}\!E^{2}\!F\ =\ EF^{2}\ \ =\ ABCD^{2}\!E^{2}\!F\ =\ ABCEF^{2}\,,\\ D^{2}\ =\ ABCD^{2}\ =\ E^{2}\!F\ \ \ =\ DEF^{2}\ =\ ABCE^{2}\!F\ \ =\ ABCDEF^{2}\,,\end{array}\]

so the pairs of contrasts (\(D\); \(D^{2}\)), (\(ABCD\); \(ABCD^{2}\)), (\(DEF^{2}\);\(D^{2}\!E^{2}\!F\)), (\(EF^{2}\); \(E^{2}\!F\)), and (\(ABCEF^{2}\); \(ABCE^{2}\!F\)) are aliased with one another.

Finally, there is aliasing of interactions involving both 2- and 3-level factors, for example

\[\begin{array}{l}AD\ =\ BCD\ =\ AB^{2}\!E^{2}\!F\ =\ AEF^{2}\ \ =\ BCD^{2}\!E^{2}\!F\ =\ BCEF^{2}\,,\\ AD^{2}\ =\ BCD^{2}\ =\ AE^{2}\!F\ \ \ =\ ADEF^{2}\ =\ BCE^{2}\!F\ \ \ =\ BCDEF^{2}\,,\end{array}\]

so the pairs of contrasts (\(AD\); \(AD^{2}\)), (\(BCD\); \(BCD^{2}\)), (\(ADEF^{2}\); \(AD^{2}\!E^{2}\!F\)), (\(AEF^{2}\); \(AE^{2}\!F\)), and (\(BCEF^{2}\); \(BCE^{2}\!F\)) are aliased with one another.

The design would be useful mainly when most of the interactions were expected to be negligible.

### Blocked Fractional Factorial Experiments

If experimental conditions are not constant over the entire experiment, it may be necessary to arrange a fractional factorial experiment in blocks. For example, consider the soup experiment in Sect. 15.2.3 (p. 499), for which the experimenters used the resolution V \(2^{5-1}\) fraction with defining relation \(I=ABCDE\). Suppose the experimenters had decided that the experimental conditions could be kept fairly stable over the course of 8 observations but not 16. The treatment combinations would then have been divided into two blocks of size 8. If the fraction is divided into \(b=2\) blocks, then \(b-1=1\) contrast _and its alias_ must be confounded. If \(CDE\), for example, is selected for confounding, then the aliased pair of contrasts \(CDE=AB\) is confounded with blocks, and neither of these contrasts can be measured. Rather than confound a 2-factor interaction, an alternative might be to select the Resolution IV design with defining relation \(I=ABDE\) and to confound the aliased pair of contrasts \(BCE=ACD\). Then, all two-factor interactions can be estimated, although six of them will be in aliased pairs. The choice between these two designs is the choice of losing information on one 2-factor interaction completely while aliasing the others with high-order interactions, or aliasing three pairs of 2-factor interactions.

For each fractional factorial design listed Table 15.60, at the end of the chapter, a suggestion (shown in parentheses) is given for selecting an interaction to be confounded when running the corresponding fraction in two blocks. (The aliases of this interaction can be obtained by multiplication with the interaction names in the defining relation, as usual).

#### Flour experiment

M.G. Tuck, S.M. Lewis, and J.I.L. Cottrell describe a series of four experiments in the 1993 issue of _Applied Statistics_ that were carried out at Spillers Milling Ltd. in order to identify a flour that would give a "high loaf volume and be tolerant to fluctuations in the bread making process". In the the third experiment in the series, four flour formulations were investigated (four levels of factor \(A\), coded 0, 1, 2, 3), together with four noise factors each at two levels. The noise factors were amount of yeast (factor \(N\), low or high), proof time (factor \(S\), short or long), degree of mixing and moulding (factor \(Q\), "undermixing, little water, heavy pressure" or "overmixing, much water, little pressure"), and dough time delay (factor \(T\), short or long). Thus, this was a \(4\times 2^{4}\) experiment. A \(\frac{1}{2}\) fraction with \(v=32\) treatment combinations was selected and divided into two blocks of size 16, representing the number of observations that could be taken per day.

The 4-level factor \(A\) can be written in terms of two pseudofactors \(A_{1}\) and \(A_{2}\), with the level correspondence \(0=00\), \(1=01\), \(2=10\), \(3=11\). The researchers selected the first block of the 

[MISSING_PAGE_EMPTY:8466]

[MISSING_PAGE_FAIL:532]

\(F_{1,11,0.01}=9.65\) or \(F_{3,11,0.01}=6.22\) as appropriate. The interactions of the flour formulations with the noise variables are not significantly different from zero, but the noise variables \(N\), \(S\), \(Q\) themselves do have a large effect on the specific volume. Although the flours are not significantly different in terms of average specific volume, the contrast \(A\)\(A_{2}\) appears to be the most important of the three flour contrasts investigated. This contrast compares the average of flours 0 and 3 with the average of flours 1 and 2. The first pair give the higher average specific volume. Before the experiment took place, the experimenters had expected flour 3 (coded 11) to be the best. The difference of averages contrast, which compares flour 3 with the average of the other three flours, has least squares estimate

\[\begin{array}{l}\bar{y}_{11\ldots}-\frac{1}{3}(\bar{y}_{00\ldots}+\bar{y}_{0 1\ldots}+\bar{y}_{10\ldots})\\ =491.000-\frac{1}{3}(476.250+455.875+463.250)\\ =25.875\,.\end{array}\]

A preplanned 95% confidence interval for this contrast is given by

\[\begin{array}{l}\bar{y}_{11\ldots}-\frac{1}{3}(\bar{y}_{00\ldots}+\bar{y}_{0 1\ldots}+\bar{y}_{10\ldots})\pm t_{11,0.025}\sqrt{mse\left(\frac{1}{8}+3\left( \frac{1}{9}\right)\left(\frac{1}{8}\right)\right)}\\ =25.875\pm 2.201\sqrt{(623.849)(0.1667)}\\ =25.875\pm 22.443\\ =(3.432,48.318).\end{array}\]

At the 95% confidence level, it does appear that flour 3 (coded 11) has specific volume between 3.4 and 48.3 units larger than the average of the other three flours. (We can draw this conclusion only because the contrast was preplanned. Otherwise, we would need to use Scheffe's method of multiple comparisons with \(t_{11,0.025}\) replaced by \(\sqrt{3F_{3,11,0.05}}=3.24\), and the interval would include zero). 

### Fractions from Orthogonal Arrays

#### 15.6.1 \(2^{p}\) Orthogonal Arrays

The simplest type of orthogonal array is that shown in Table 15.19, consisting of a set of \(2^{p}-1\) orthogonal contrasts. The first column has the first half of its 8 entries equal to \(-1\) and the second half equal to \(+1\). The second column has the first quarter of its entries equal to \(-1\), the second quarter equal to \(+1\), the third quarter equal to \(-1\) again and the fourth quarter equal to \(+1\) again. The third column is divided into eighths with alternating \(-1\)'s and \(+1\)'s. If the columns had been longer, the next column would have been divided into sixteenths, and so on. These are the "independent" columns. The fourth, fifth and sixth columns of Table 15.19 are the products of corresponding coefficients in the first three columns taken in pairs, and the last column is the triple product of the first three columns. The result is a table with \(2^{p}=8\) rows and \(2^{p}-1=7\) columns in which any pair of columns are orthogonal.

The \(p\) independent columns of an orthogonal array define the treatment combinations for a \(2^{p}\) design. As usual, a contrast coefficient of \(-1\) in a column corresponds to level 0 in the corresponding factor, and a contrast coefficient of \(+1\) in a column corresponds to level 1. If all eight treatment combinations of Table 15.19 are used for a \(2^{3}\) experiment, then the orthogonal array defines a full factorial experiment, and no aliasing of contrasts occurs.

Now suppose that only 4 observations can be taken in a \(2^{3}\) experiment. Instead of proceeding as in Sect. 15.2.1 and choosing a defining relation, we could first construct an orthogonal array with \(n=4\)rows and \(n-1=3\) columns. One is shown in Table 15.20, where the first column has the first half of its entries \(-1\), and the second half \(+1\), the second column is divided into quarters, and the third column is the product of the first two. Since we have 3 factors, suppose we label the columns in order as \(A\), \(B\), \(C\). The three columns then show the parts of the \(A\), \(B\), and \(C\) contrasts corresponding to a \(\frac{1}{2}\)-fraction. However, the third column is also the product of the first two columns, so it not only represents the \(C\) contrast but also the interaction between \(A\) and \(B\). Consequently, \(C\) is aliased with \(AB\). Similarly, the first column is the product of the last two columns, so \(A\) is aliased with \(BC\). Similarly, again, \(B\) is aliased with \(AC\). The defining relation must be \(I=ABC\) in order to produce this aliasing scheme.

The coefficients in the contrasts tell us which treatment combinations are represented, and the design is "Design \(d_{1}\)" shown in Table 15.21. Notice that this is the same design that would have been produced from the equation \(a_{1}+a_{2}+a_{3}=1\) (mod 2). We could obtain the \(\frac{1}{2}\)-fraction corresponding to \(a_{1}+a_{2}+a_{3}=0\) (mod 2), by multiplying any one of the columns by \(-1\) (see Design \(d_{2}\) in Table 15.21, where the second column has been multiplied by \(-1\)).

Thus, we have arrived back at the same type of design that we studied in Sect. 15.2, and this will often (but not always) be the case. The main difference in procedure is that when we start with an orthogonal array, we are starting with an unlabeled list of contrasts which can be labeled in any way we please. The labeling then determines the defining relation and the design.

Any columns in an orthogonal array can be multiplied by \(-1\) and we still obtain an orthogonal array, although the treatment combinations may not be identical, or they may be identical but in a different order (try multiplying the \(B\) and \(C\) columns for the designs in Table 15.21 by \(-1\) and see whether the same design results).

Now we return to the orthogonal array of Table 15.19, which is reproduced in Table 15.22 with column headings indicating which columns are products of which other columns. For example, column 7 is the product of columns 1, 2, and 3. We consider using this array for a \(2^{5}\) experiment instead of a \(2^{3}\) experiment. Since there are only 8 rows, we will be looking for a \(\frac{1}{4}\)-replicate (that is, a \(2^{5-2}\) fractional factorial experiment).

Suppose that we label the first 5 columns as \(A,B,C,D,E\). Since the product of the first two columns gives column 4 and the product of the first and third columns gives column 5, aliasing would occur between \(D\) and \(AB\), and between \(E\) and \(AC\). Consequently, \(ABD\) and \(ACE\) must be in the defining relation, together with their product, so we have

\[I=ABD=ACE=BCDE\,.\]

The rest of the aliasing scheme can be written out also, and we would see that \(A\) is aliased with \(BD\) and \(CE\), that \(B\) is aliased with \(AD\), and that \(C\) is aliased with \(AE\). The sixth column, which is the product of columns 2 and 3, and also of columns 4 and 5, can be labeled \(BC\) or \(DE\), and these two interactions are aliased. The seventh column is \(ABC=CD=BE=ADE\). The eight treatment combinations are deduced from the \(-1\)'s and \(+1\)'s in the first five columns; that is,

\[00011,\ 00110,\ 01001,\ 01100,\ 10000,\ 10101,\ 11010,\ 11111\,.\]

Different sets of treatment combinations corresponding to the same defining relation (but with different signs in the aliasing scheme) can be obtained by multiplying one or more columns of Table 15.22 by \(-1\).

There is nothing special about labeling the first five columns of Table 15.22 as \(A\), \(B\), \(C\), \(D\), \(E\). Any five columns could have been chosen. Different choices may lead to different aliasing schemes, and sometimes these aliasing schemes may not be equally good. Table 15.62 at the end of the chapter lists orthogonal arrays for various-sized experiments. Some useful column labelings for various fractional factorial experiments are suggested in the table.

The standard notation, used by industrial statisticians and engineers, for an orthogonal array is the letter \(L\) with subscript equal to the number of runs. Sometimes, the largest Resolution III design that can be used with the array is added in brackets. The orthogonal array in Table 15.20 provides a Resolution III design with 4 observations for 3 or fewer two-level factors and would be written as \(L_{4}(2^{3})\). Similarly, the design of Table 15.22 would be written as \(L_{8}(2^{7})\). Occasionally, an orthogonal array for \(2^{p}\) experiments will be written using factor levels rather than contrast coefficients. The orthogonality could then be checked by ensuring that in every pair of columns, all possible pairs of factor levels (00, 01, 10, and 11) appear the same number of times (see, for example, the factor levels shown together with designs \(d_{1}\) and \(d_{2}\) of Table 15.21).

\begin{table}
\begin{tabular}{c c c c c c c}  & \multicolumn{6}{c}{Columns} \\  & 1 & 2 & 3 & 12 & 13 & 23 & 123 \\ \hline \(-1\) & \(-1\) & \(-1\) & 1 & 1 & 1 & \(-1\) \\ \(-1\) & \(-1\) & 1 & 1 & \(-1\) & \(-1\) & 1 \\ \(-1\) & 1 & \(-1\) & \(-1\) & 1 & \(-1\) & 1 \\ \(-1\) & 1 & 1 & \(-1\) & \(-1\) & 1 & \(-1\) \\ \(1\) & \(-1\) & \(-1\) & \(-1\) & \(-1\) & 1 & 1 \\ \(1\) & \(-1\) & \(-1\) & \(-1\) & \(-1\) & 1 & 1 \\ \(1\) & \(-1\) & \(1\) & \(-1\) & 1 & \(-1\) & \(-1\) \\ \(1\) & \(1\) & \(-1\) & 1 & \(-1\) & \(-1\) & \(-1\) \\ \(1\) & \(1\) & \(1\) & 1 & 1 & 1 & 1 \\ \hline \end{tabular}
\end{table}
Table 15.22: An orthogonal array for 8 observations

#### Example 15.6.1 Wafer experiment

R. Kackar and A. Shoemaker (_AT&T Technical Journal_, 1986) describe an experiment that they helped to run at AT&T to try to reduce the variability of the thickness of an "epitaxial layer" deposited onto silicon wafers during the manufacture of integrated circuit devices.

The wafers were mounted on a seven-sided "susceptor" with two wafers (one above the other) on each side. The susceptor rotated inside a heated bell jar as chemical vapors were introduced via a nozzle near the top of the jar. The chemicals were deposited on the wafers, and the bell jar was cooled when the thickness of the deposited layer was close to the target of 14.5 \(\upmu\)m.

The engineers identified eight factors that might affect the variability of the thickness of the epitaxial layer. These are shown in Table 15.23 together with the operating factor levels prior to the experiment and the levels selected for the experiment.

The experimenters decided to take 16 observations. The 16 treatment combinations were selected via the orthogonal array \(L_{16}(2^{15})\) shown in Table 15.24. The orthogonal array is constructed as described earlier in this section. The labels in the row headings of the table identify which columns are products of which other columns. The assignment of factors to columns chosen by the experimenters is indicated in the foot of the table. The experiment is a \(2^{8-4}\) experiment, and the defining relation is generated by 4 confounded interactions. Notice, from the heading and the foot of Table 15.24, that \(D\) must be aliased with \(ABC\), \(F\) must be aliased with \(ABE\), \(G\) with \(ACE\), and \(H\) with \(BCE\). Thus, the defining relation includes \(ABCD\), \(ABEF\), \(ACEG\), \(BCEH\), and all their possible products (a total of \(2^{4}=16\) terms in the defining relation):

\[\begin{array}{ccccc}I&=&ABCD&=&ABEF&=&CDEF\\ =&ACEG&=&BDEG&=&BCFG&=&ADFG\\ =&BCEH&=&ADEH&=&ACFH&=&BDFH\\ =&ABGH&=&CDGH&=&EFGH&=&ABCDEFGH\end{array}\]

This is a Resolution IV design, and there is considerable aliasing between 2-factor interactions. For example, the contrast listed in column labelled 12 in Table 15.24 not only measures the 2-factor interaction \(AB\), but also measures its aliased 2-factor interactions \(CD\), \(EF\), \(GH\) (and some higher-order interactions).

There were 70 measurements taken for each treatment combination (5 measurements on each of the 2 wafers on the 7 sides of the receptor). From these, two different response variables were calculated--the average of the 70 measurements (which we denote by \(x\)) and the log sample variance of the 70

\begin{table}
\begin{tabular}{c c c c} \hline Factors & Prior level & \multicolumn{2}{c}{Experimental levels} \\ \cline{3-4}  & & Low (0) & High (1) \\ \hline \(A\) (rotation method) & Oscillating & Continuous & Oscillating \\ \(B\) (wafer batch) & & 668G4 & 678D4 \\ \(C\) (deposition temperature) & 1215 °C & 1210 °C & 1220 °C \\ \(D\) (deposition time) & Low & High & Low \\ \(E\) (arsenic flow rate) & 57\% & 55\% & 59\% \\ \(F\) (acid etch temp.) & 1200 °C & 1180 °C & 1215 °C \\ \(G\) (acid flow rate) & 12\% & 10\% & 14\% \\ \(H\) (nozzle position) & 4 & 2 & 6 \\ \hline \end{tabular}
\end{table}
Table 15.23: Treatment factors and their levels for the wafer experimentmeasurements (which we denote by _v_). The treatment combinations, corresponding to the orthogonal array in Table 15.24, together with the two response variables, are shown in Table 15.25.

The experimenters first analyzed the log variance response. The contrast estimates (high level minus low level) for this response variable are shown in Table 15.26. The contrast estimates for factors \(A\) and \(H\) are considerably larger in absolute value than those for the other factors. Consequently, \(A\) and \(H\) are more sensitive to the response variables than those for the other factors.

\begin{table}
\begin{tabular}{c c c c} Treatment combination & Average response \(x_{ijklmnpq}\) & Log variance response \(v_{ijklmnpq}\) \\
0 0 0 0 0 0 0 0 & 14.821 & \(-\)0.4425 \\
0 0 0 1 1 1 1 & 14.888 & \(-\)1.1989 \\
0 0 1 1 0 0 1 1 & 14.037 & \(-\)1.4307 \\
0 0 1 1 1 1 0 0 & 13.880 & \(-\)0.6505 \\
0 1 0 1 0 1 0 1 & 14.165 & \(-\)1.4230 \\
0 1 0 1 1 0 1 0 & 13.860 & \(-\)0.4969 \\
0 1 1 0 0 1 1 0 & 14.757 & \(-\)0.3267 \\
0 1 1 0 1 0 0 1 & 14.921 & \(-\)0.6270 \\
1 0 0 1 0 1 1 0 & 13.972 & \(-\)0.3467 \\
1 0 0 1 1 0 0 1 & 14.032 & \(-\)0.8563 \\
1 0 1 0 0 1 0 1 & 14.843 & \(-\)0.4369 \\
1 0 1 0 1 0 1 0 & 14.415 & \(-\)0.3131 \\
1 1 0 0 0 0 1 1 & 14.878 & \(-\)0.6154 \\
1 1 0 0 1 1 0 0 & 14.932 & \(-\)0.2292 \\
1 1 1 0 0 0 0 & 13.907 & \(-\)0.1190 \\
1 1 1 1 1 1 1 1 & 13.914 & \(-\)0.8625 \\ \end{tabular}
\end{table}
Table 15.25: Treatment combinations and response variables for the wafer experiment should be investigated for reducing variability in the response. Since the log variance response is to be reduced, and the contrast estimate for \(A\) is positive while that for \(H\) is negative, we would want to set \(A\) at its low level (continuous rotation) and \(H\) at its high level (position 6). All other factors can be set at their current operating conditions.

The second requirement of the experimenters was to achieve an average thickness of 14.5 \(\mu\)m. Contrast estimates for the average response are shown in Table 15.27. Not surprisingly, factor \(D\), deposition time, has by far the largest effect on the mean response, and the experimenters were able to adjust this factor in order to meet the target.

As with any good experiment, the experimenters wished to confirm their results. Their confirmation experiment investigated two treatment combinations. The first treatment combination consisted of the prior operating levels of factors \(A\) and \(C\)-\(H\), with factor \(B\) at level 1, and the second treatment combination was the same except that the levels of \(A\) and \(H\) were changed as discussed above. The confirmation experiment showed that the variance of the thickness had been reduced by a factor 2.5--quite a remarkable result! 

#### 15.6.2 \(2^{p}\times 4^{q}\) Orthogonal Arrays

The orthogonal arrays of Sect. 15.6.1 can be used when one or more factors have 4 levels. Each 4-level factor requires 3 independent columns to represent 3 orthogonal contrasts. For example, the orthogonal array in Table 15.22 could be used for a \(2^{3}\times 4\) experiment as follows. The first three columns (which are independent) could be labeled \(A\), \(B\), and \(C\). If the 4th column is labeled \(D_{1}\), then \(D_{1}\) is aliased with \(AB\). If the 7th column is labeled \(D_{2}\), then \(D_{2}\) is aliased with \(ABC\). The product of the coefficients in the 4th and 7th columns gives the coefficients in the 3rd column, so \(D_{1}D_{2}\), the remaining contrast for the 4-level factor, is aliased with \(C\), and the defining relation is

\[I=ABD_{1}=ABCD_{2}=CD_{1}D_{2}\;.\]

This is a Resolution II design, which should be avoided if possible, since it confounds two main effects (\(C\) and \(D\)). A better design is to assign \(D_{2}\) to the 5th column, where it is aliased with \(AC\). The product of the 4th and 5th columns gives the 6th column, so that \(D_{1}D_{2}\) is aliased with \(BC\). The defining relation is

\[I=ABD_{1}=ACD_{2}=BCD_{1}D_{2}\;,\]

which is Resolution III. The 7th column of Table 15.22 corresponds to the \(ABC\) contrast, which is aliased with \(AD_{1}D_{2}\), \(CD_{1}\), and \(BD_{2}\) contrasts. The complete aliasing scheme is

\begin{table}
\begin{tabular}{c c c c c c c c c} \hline Contrast & \(A\) & \(B\) & \(C\) & \(D\) & \(E\) & \(F\) & \(G\) & \(H\) \\ Estimate & \(-\)0.055 & 0.056 & \(-\)0.109 & \(-\)0.836 & \(-\)0.067 & 0.060 & \(-\)0.098 & 0.142 \\ \hline \end{tabular}
\end{table}
Table 15.27: Contrast estimates for the mean response variable

\begin{table}
\begin{tabular}{c c c c c c c c c} \hline Contrast & \(A\) & \(B\) & \(C\) & \(D\) & \(E\) & \(F\) & \(G\) & \(H\) \\ Estimate & 0.352 & 0.122 & 0.105 & \(-\)0.249 & \(-\)0.012 & \(-\)0.072 & \(-\)0.101 & \(-\)0.566 \\ \hline \end{tabular}
\end{table}
Table 15.26: Contrast estimates for log sample variance response variable \[\begin{array}{lcl}I=ABD_{1}&=ACD_{2}&=BCD_{1}\!D_{2}\\ A=BD_{1}&=CD_{2}&=ABCD_{1}\!D_{2}\\ B=AD_{1}&=ABCD_{2}&=CD_{1}\!D_{2}\\ C=ABCD_{1}&=AD_{2}&=BD_{1}\!D_{2}\\ D_{1}=AB&=ACD_{1}\!D_{2}&=BCD_{2}\\ D_{2}=ABD_{1}\!D_{2}&=AC&=BCD_{1}\\ D_{1}\!D_{2}=ABD_{2}&=ACD_{1}&=BC\\ ABC=CD_{1}&=BD_{2}&=AD_{1}\!D_{2}\end{array}\]

The design would be useful for an experiment where all interactions were expected to be negligible, in which case one degree of freedom would be available to estimate \(\sigma^{2}\).

#### 3\({}^{p}\) Orthogonal Arrays

The orthogonal arrays for \(2^{p}\) experiments introduced in Sect. 15.6.1 have the property that any pair of columns in the array are orthogonal (that is, the sum of the products of corresponding coefficients is zero). An examination of the arrays in Tables 15.21, 15.22 and 15.24 reveals that this orthogonality arises because every pair of coefficients (\(-1\), \(-1\)), (\(-1\), \(1\)), (\(-1\)) and (\(1\), \(1\)) occurs equally often in every pair of columns. We could rewrite the array to contain the factor labels 0, 1 instead of the contrast coefficients \(-1\), 1, and every pair of labels would occur the same number of times in every pair of columns. This is the way that orthogonal arrays are defined for \(3^{p}\) experiments.

An orthogonal array with 9 treatment combinations is shown as columns 1-4 in Table 15.28 for four factors, each having 3 levels. If any pair of columns is selected, it can be verified that each of the nine pairs of levels (0, 0), (0, 1), (0, 2), (1, 0), (1, 1), (1, 2), (2, 0), (2, 1), (2, 2) occurs once. The first column consists of three copies of each of 0, 1, and 2. The second column consists of 0, 1, and 2, in order, repeated three times. The third column is obtained from the sum of the coefficients in the first two columns reduced modulo 3 (thereby ensuring that any factor assigned to the 3rd column will be aliased with the interaction between the first two factors). The fourth column is obtained from twice the sum of columns 2 and 3 (ensuring that any factor assigned to the fourth column will be aliased with the interaction of factors assigned to columns 2 and 3 and with the interaction of the first two factors). It is not possible to find more than four orthogonal columns with only 9 observations.

\begin{table}
\begin{tabular}{c c c c c c c c c c c c} \hline  & \multicolumn{3}{c}{Columns} & \multicolumn{6}{c}{Contrasts} \\
1 & 2 & 3 & 4 & & & & & & & & & \\
0 & 0 & 0 & 0 & \(-1\) & 1 & \(-1\) & 1 & \(-1\) & 1 & \(-1\) & 1 \\
0 & 1 & 1 & 1 & \(-1\) & 1 & 0 & \(-2\) & 0 & \(-2\) & 0 & \(-2\) \\
0 & 2 & 2 & 2 & \(-1\) & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\
1 & 0 & 1 & 2 & 0 & \(-2\) & \(-1\) & 1 & 0 & \(-2\) & 1 & 1 \\
1 & 1 & 2 & 0 & 0 & \(-2\) & 0 & \(-2\) & 1 & 1 & \(-1\) & 1 \\
1 & 2 & 0 & 1 & 0 & \(-2\) & 1 & 1 & \(-1\) & 1 & 0 & \(-2\) \\
2 & 0 & 2 & 1 & 1 & 1 & \(-1\) & 1 & 1 & 1 & 0 & \(-2\) \\
2 & 1 & 0 & 2 & 1 & 1 & 0 & \(-2\) & \(-1\) & 1 & 1 & 1 \\
2 & 2 & 1 & 0 & 1 & 1 & 1 & 0 & \(-2\) & \(-1\) & 1 & 1 \\ \hline \(A\) & \(B\) & \(C\) & \(D\) & \(A_{\rm L}\) & \(A_{\rm Q}\) & \(B_{\rm L}\) & \(B_{\rm Q}\) & \(C_{\rm L}\) & \(C_{\rm Q}\) & \(D_{\rm L}\) & \(D_{\rm Q}\) \\ \hline \end{tabular}
\end{table}
Table 15.28: A \(3^{p}\) orthogonal array for 9 observationsIn Table 15.28, a pair of orthogonal contrasts is given corresponding to each of the four columns in the orthogonal array. It can be verified that this set of 8 contrasts is orthogonal. As for \(2^{p}\) experiments, a \(3^{p}\) orthogonal array with \(n\) rows can have at most \(n-1\) orthogonal columns of contrast coefficients, and therefore can accommodate at most \((n-1)/2\) three-level factors. An experiment is discussed in Sect. 15.7.1 that uses part of the orthogonal array for three-level factors and 27 observations listed in Table 15.65.

### Design for the Control of Noise Variability

Design for the control of noise variability is sometimes known as _robust design_ or _parameter design_ and refers to the procedure of developing or designing a product in such a way that it performs consistently, and as intended, under the variety of conditions of its use throughout its life. The ideas apply equally well to the design of high quality manufacturing systems and other organizational processes. Experimentation involves _design factors_ (also known as _control factors_) which are possible inexpensive to control in the design of the product, and _noise factors_ which may affect the performance of a product but which are difficult or impossible to control when the product is in use.

Experiments that involve both design and noise factors are often known colloquially as _Taguchi experiments_. Dr. Taguchi was a Japanese quality consultant who advocated the use of quality improvement techniques, including the design of experiments, to the Japanese engineering and industrial communities from the 1950s. One of his fundamental contributions is the principle that reduction of variation is generally the most difficult task from an engineering perspective and so should be the focus of attention during the design of a product.

There are two different types of designs for such experiments--"mixed arrays" and "product arrays". _Mixed arrays_ are ordinary fractional factorial designs in which the difference between the design and noise factors is ignored at the design stage except to ensure that the design-by-noise interactions are estimable and not confounded with blocks or part of the defining relation of a fraction. For a mixed array, all of the treatment combinations (composed of both design and noise factors) are observed in a random order. This complete randomization allows the design\(\times\)noise interactions to be studied and to try to identify the particular levels of the design factors that are least affected by changing the levels of the noise factors. An example of a mixed array is the design used for the flour experiment of Example 15.5.1 which had a single design factor at 4 levels and four two-level noise factors. Analysis of the design\(\times\)noise interactions for this experiment is illustrated in Example 15.7.1 assuming a complete randomization of the order of treatment combinations.

_Product arrays_, on the other hand, are designed and analyzed differently from the usual factorial experiments. They are composed of two fractional factorial or full factorial experiments, one for the design factors and one for the noise factors. Then every combination of design factors is observed in conjunction with every combination of noise factors. In product arrays, first the order of the design factor combinations is randomized. Then, for each design factor combination in turn, observations are taken across all of the noise factor combinations in a random or non-random order. (Occasionally, the order of randomization is reversed). This restricted randomization means that the usual analysis of design\(\times\)noise interactions is not valid. Instead, for each design factor combination, the average and log sample variance of the responses are calculated across the different noise factor combinations. The average response and the log variance response are then taken as two totally separate sets of data values and analyzed separately. The objective of the experiment is to find out which factors affect the log sample variance response the most, and which factors most affect the average response. Design factor combinations are then sought that give a low variance across the noise factor combinations and also that give an average response close to the target value. Finally, confirmatory observations are taken.

The reason for taking the log of the sample variance before analysis is that the assumptions of the linear model with \(\ln(s^{2})\) as the response are more closely satisfied than taking \(s^{2}\) itself as the response. (See Sect. 5.6.2 for a discussion of transformations).

The design of the wafer experiment of Example 15.6.1 was a product array, where the levels of the single noise factor "position" were the 14 locations on the susceptor and the two responses, log sample variance response and average response, were analyzed separately. An example of a product array with factors at three levels will be illustrated in Sect. 15.7.1 and the computer analysis discussed in Sects. 15.9.2 and 15.10.2 using SAS and R software, respectively.

##### 15.7.1 Flour experiment, continued

One purpose of the flour experiment in Example 15.5.1, p. 513, was to find which of the four flours (factor \(A\), coded 0, 1, 2, 3) was least variable under the different levels of the four noise variables: amount of yeast (factor \(N\)), proof time (factor \(S\)), degree of mixing and moulding (factor \(Q\)), and dough time delay (factor \(T\)), each at 2 levels. If the treatment combinations in Table 15.16 were observed in a completely random order within each block, this experiment can be analyzed as a mixed array. The analysis of variance is shown in Table 15.18. The interactions of \(A\) with the noise variables can provide information on which flours are least sensitive to noise fluctuations.

Although none of the design\(\times\)noise factor interactions were significantly different from zero, we illustrate the search for robust design factor levels by looking at the two largest such interactions (\(AQ\) and \(AT\)). If we plot the average response (specific volume) for each level of \(A\) versus the levels of \(Q\) or \(T\) on the horizontal axis, we obtain the interaction plots in Fig. 15.7. From the \(AT\) interaction plot, we can see that flours 1, 2, and 3 are much more stable than flour 0 in terms of the resulting average specific volume of loaves. This is also apparent, to a lesser extent, in the \(AQ\) interaction plot. Thus, flour 0 is not as robust as the other three flours and should probably be ruled out of consideration for general use.

If we now examine the average specific volume of loaves baked over the two levels of \(T\), we see that flour 3 seems to be the best. a similar result is obtained by averaging over the levels of \(Q\). In this experiment, the \(AQ\) and \(AT\) interactions were not significantly different from zero, but if they had been larger, this analysis would have pointed to flour 3 being preferable both in terms of robustness to fluctuating noise factors and of leading to loaves with high specific volume.

Figure 15.7: Design\(\times\)noise interaction plots for the flour experiment

#### A Real Experiment--Inclinometer Experiment

A collaborative study involving statisticians and mechanical engineers was described by S. Lewis, B. Hodgson, R. New, and C. Sexton in the 1989 _Proceedings of the Institute of Mechanical Engineers International Conference on Engineering Design_. The experiment sought to improve the performance of an inclinometer, which is an instrument that records the angle of tilt of an object such as a crane jib. The design of the inclinometer is described in the article as follows:

"The basic design of the product is composed in four parts: a bob-weight and flexure, a flanged flywheel and a copper-plated disc (PCB). All are attached to a shaft supported in low-friction bearings. When the object to which the flywheel is attached is tilted, the bob-weight assembly moves to stay perpendicular to the earth, causing the PCB to rotate relative to the casing. The main performance difficulty of the inclinometer is that it does not immediately register the true angle of tilt. Spurious swing of the disc is produced by movement of the object."

The purpose of the experiment was to vary the relative sizes of the parts of the inclinometer to find a combination of factors that would reduce the swing. The engineers identified 7 design factors (_A_-_G_) that could be altered and that might affect the swing. Three levels were selected for each factor so that linear and quadratic trends could be investigated. The levels of factors _A_-_F_ were equally spaced. The factors were:

\(A\): Flexure length (30.00, 31.25, 32.5) _B_: Flexure thickness (0.05, 0.275, 0.5)

\(C\): Flexure width (4.0, 5.0, 6.0)

\(E\): Flange width (6.0, 10.5, 15.0)

\(G\): Copper plating thickness (0.0175, 0.035, 0.07)

All measurements are in millimeters, and the levels of all factors are coded 0, 1, and 2. For the experiment, it was possible to produce the factor levels exactly as specified, but in mass production variability naturally creeps in. The experimenters decided to build the production variability into the experiment as noise factors as follows (measured in mm, except where stated):

\(H\): Flexure length (\(-\)0.25, +0.25) \(P\): Flexure thickness (\(-\)0.005, +0.005)

\(J\): Flange thickness (\(-\)0.025, +0.025) \(K\): Flange width (\(-\)0.025, +0.025)

\(L\): Copper plating thickness (\(-\)0.005, +0.005)

\(M\): Tolerance on bob weight mass (\(-\)9.0, +9.0 x (1/100)\(g\))

\(N\): Maximum horizontal amplitude of vibration (5, 25)

The two levels of each noise factor were coded as 0 and 1. Thus, the entire experiment was a \(3^{7}\times 2^{7}\) factorial experiment, where the 3-level factors were the design factors and the 2-level factors were the noise factors. The treatment combination 0000000 of the design factors in conjunction with the combination 0000000 of the noise factors would have flexure length (\(A\)) of (30.00 \(-\) 0.25) mm = 29.75 mm, flexure thickness of (0.050 \(-\) 0.005) mm = 0.045 mm, and so on.

The objective of the experiment was to select the combinations of the design factors that gave the least amount of swing. In terms of producing a product of consistently high quality, it was also important that the variability of the amount of swing also remain low across the different noise combinations.

The experimenters selected a product array formed from a \(\frac{1}{81}\) fraction of the \(3^{7}\) design-treatment combinations and a \(\frac{1}{16}\) fraction of the \(2^{7}\) noise combinations. This gave a total of 27 x 8 = 216 observations. For the \(3^{7-4}\) fractional factorial experiment, seven columns of the orthogonal array \(L_{27}(3^{13})\) were selected. These are indicated in Table 15.65 (p. 562). For the \(2^{7-4}\) fractional factorial experiment, the orthogonal array \(L_{8}(2^{7})\) shown in Table 15.22 (p. 518) was used with the noise factors

[MISSING_PAGE_EMPTY:8478]

assigned to the columns in the order \(H\), \(P\), \(K\), \(-J\), \(-L\), \(-M\), \(N\), where the minus signs indicate that the column was multiplied by \(-1\) (thus reversing the high and low levels).

The maximum absolute angle of swing was ascertained for each of the selected combinations of design- and noise- factor levels, and these are shown in Table 15.29. The noise-factor combinations label the columns, and the design-factor combinations label the rows. The last two columns of the table show the average and log sample variance of the observations for the design combinations calculated across the noise combinations.

Consider first using the log sample variance \(\ln(s^{2})\) of the observations as the response variable. The analysis of variance table is shown in Table 15.30. We have included the information needed for testing the hypotheses of negligible linear and quadratic trends in each of the factors except for \(G\). The levels of \(G\) are not equally spaced, and therefore the correct trend contrast coefficients are not those shown in Table A.2.

If we test the hypotheses of negligible contrasts for each trend contrast shown in Table 15.30 at individual significance levels \(\alpha^{*}=0.01\) and test the hypothesis of no effect of factor \(G\) at level \(\alpha^{*}=0.01\) (for an overall level of at most \(\alpha=0.13\)), we reject the hypotheses of negligible linear trends in factors \(A\), \(C\), \(D\), \(E\), \(F\) and of a negligible quadratic trend in factor \(D\). Factors \(B\) and \(G\) show very little effect on log variance response, so these factors (flexure thickness and copper plating thickness) cannot be employed to achieve less variability in the swing in the inclinometer. The contrast estimates for the nonnegligible contrasts are shown in Table 15.31. From the signs on the contrast estimates we

\begin{table}
\begin{tabular}{c c c c c c c} \hline Source of variation & Degrees of freedom & Sum of squares & Mean square & Ratio & \(p\)-value \\ \hline \(A\) & 2 & 0.6316 & 0.3158 & & & \\ Linear \(A\) & 1 & 0.5798 & 0.5798 & 22.73 & 0.0005 \\ Quadratic \(A\) & 1 & 0.0519 & 0.0519 & 2.03 & 0.1794 \\ \(B\) & 2 & 0.1358 & 0.0679 & & & \\ Linear \(B\) & 1 & 0.0581 & 0.0581 & 2.28 & 0.1571 \\ Quadratic \(B\) & 1 & 0.0777 & 0.0777 & 3.05 & 0.1064 \\ \(C\) & 2 & 9.8448 & 4.9224 & & & \\ Linear \(C\) & 1 & 9.8241 & 9.8241 & 385.18 & 0.0001 \\ Quadratic \(C\) & 1 & 0.0207 & 0.0207 & 0.81 & 0.3852 \\ \(D\) & 2 & 18.8987 & 9.4493 & & & \\ Linear \(D\) & 1 & 18.3769 & 18.3769 & 720.53 & 0.0001 \\ Quadratic \(D\) & 1 & 0.5217 & 0.5217 & 20.46 & 0.0007 \\ \(E\) & 2 & 7.0366 & 3.5183 & & & \\ Linear \(E\) & 1 & 7.0044 & 7.0044 & 274.63 & 0.0001 \\ Quadratic \(E\) & 1 & 0.0322 & 0.0322 & 1.26 & 0.2829 \\ \(F\) & 2 & 9.5150 & 4.7575 & & & \\ Linear \(F\) & 1 & 9.4043 & 9.4043 & 368.73 & 0.0001 \\ Quadratic \(F\) & 1 & 0.1106 & 0.1106 & 4.34 & 0.0593 \\ \(G\) & 2 & 0.0354 & 0.0177 & 0.69 & 0.5184 \\ Error & 12 & 0.3061 & 0.0255 & & & \\ Total & 26 & 46.4039 & & & & \\ \hline \end{tabular}
\end{table}
Table 15.31: Contrast estimates (log var response) for the nonnegligible contrastssee that in order to reduce the variability of the swing, factors \(A\), \(C\), and \(F\) should be set at their low levels, while \(E\) should be set at its high level and, from the main effect plot in Fig. 15.8(a) \(D\) should also be set at its high level.

In order to reduce the size of the swing, we need to use as response variable the average swing for each design combination (averaged over the noise combinations). These are listed in Table 15.29. The analysis of variance (shown in Table 15.32) identifies the linear trends of factors \(C\), \(D\), \(E\), and \(F\) as having large effects on the swing. The contrast estimates are shown in Table 15.33. The signs of the estimates suggest that factors \(D\) and \(E\) should be set at their high levels and factors \(C\) and \(F\) at their low levels. Since this agrees with the conclusions of the analysis of variability, it is possible to reduce the size and the variability of the swing simultaneously.

Plots of the least squares estimates of the effect of the levels of factor \(D\) for both log sample variance and average response are shown in Fig. 15.8. The conclusions of the experiment are that the dimensions of the flexure and bob-weight (_A_, \(C\), _F_) should be decreased, while the dimensions of the flange (_D_, _E_) should be increased. The experimenters comment in the article that the results match what would be expected by engineering principles. The SAS and R commands for analyzing this product array experiment are discussed in Examples 15.9.1 and 15.10.1, respectively.

\begin{table}
\begin{tabular}{c c c c c c} \hline Source of variation & Degrees of freedom & Sum of squares & Mean square & Ratio & _p_-value \\ \hline \(A\) & 2 & 0.1288 & 0.0644 & & \\ Linear \(A\) & 1 & 0.1023 & 0.1023 & 0.53 & 0.4813 \\ Quadratic \(A\) & 1 & 0.0264 & 0.0264 & 0.14 & 0.7183 \\ \(B\) & 2 & 0.2899 & 0.1449 & & \\ Linear \(B\) & 1 & 0.2850 & 0.2850 & 1.47 & 0.2486 \\ Quadratic \(B\) & 1 & 0.0049 & 0.0049 & 0.03 & 0.8768 \\ \(C\) & 2 & 12.9528 & 6.4764 & & \\ Linear \(C\) & 1 & 12.8863 & 12.8863 & 66.48 & 0.0001 \\ Quadratic \(C\) & 1 & 0.0665 & 0.0665 & 0.34 & 0.5689 \\ \(D\) & 2 & 24.6042 & 12.3021 & & \\ Linear \(D\) & 1 & 22.9193 & 22.9193 & 118.23 & 0.0001 \\ Quadratic \(D\) & 1 & 1.6850 & 1.6850 & 8.69 & 0.0122 \\ \(E\) & 2 & 9.0561 & 4.5280 & & \\ Linear \(E\) & 1 & 7.9385 & 7.9385 & 40.95 & 0.0001 \\ Quadratic \(E\) & 1 & 1.1177 & 1.1177 & 5.77 & 0.0334 \\ \(F\) & 2 & 11.5710 & 5.7855 & & \\ Linear \(F\) & 1 & 11.2476 & 11.2476 & 58.02 & 0.0001 \\ Quadratic \(F\) & 1 & 0.3234 & 0.3234 & 1.67 & 0.2208 \\ \(G\) & 2 & 0.6725 & 0.3362 & 1.73 & 0.2179 \\ Error & 12 & 2.3262 & 0.1938 & & \\ Total & 26 & 61.6014 & & & \\ \hline \end{tabular}
\end{table}
Table 15.33: Contrast estimates (average response)

### Small Screening Designs: Orthogonal Main Effect Plans

#### 15.8.1 Saturated Designs

A design is called _saturated_ if it uses only \(n\) treatment combinations, observed once each, to estimate \(n-1\) factorial contrasts plus a mean. Saturated designs were studied in Sect. 7.5, p. 219, under the heading "one observation per cell". Due to the lack of degrees of freedom for estimating \(\sigma^{2}\), half-normal probability plots and the Voss-Wang method of simultaneous confidence intervals were used to identify contrasts with large effects. Similarly, the soup fractional factorial experiment in Sect. 15.2.3, p. 499, used a saturated design with \(n=16\) observations to measure a mean, 5 main effects and 10 two-factor interactions, using a half-normal probability plot for identifying unusually large contrasts.

In the extreme case, a saturated design may have only \(n\) observations for measuring the main effects of \(p=n-1\) factors plus a mean, in which case interactions cannot be measured separately from the main effects. If the \(n-1\) main effect contrasts are orthogonal, such designs are known as _orthogonal main-effect plans_. For example, the two designs in Table 21, p. 517, are saturated orthogonal main-effect plans for measuring the main effects of three factors, and the design of Table 22 is a saturated orthogonal main effect plan for measuring the main effects of 7 two-level factors. The design discussed in Sect. 15.3.2, p. 511, is an orthogonal main effect plan for four 3-level factors and \(n=9\) observations, and so is the design of Table 28, p. 523.

Orthogonal main-effect plans can be used in the early stages of experimentation with the objective of finding the factors with large main effects, and with the intention of investigating their interactions later. Implicitly, such a strategy assumes that any factors which interact will also have large main effects and so will not be screened out in the initial experiment. This assumption may not, of course, be true. For example, in the soup experiment of Sect. 15.2.3, the largest effects by far were the \(BE\) interaction and the \(E\) main effect, but the main effect of \(B\) was extremely small. So, if only the main effects had been estimated in a screening experiment, factor \(B\) would not have been selected for follow up and the large \(BE\) interaction would not have been detected. Nevertheless, it does appear that in many experiments both factor main effects do tend to appear large when the corresponding two factors

Figure 8: Plots of the effect of the levels of factor \(D\) for the inclinometer experiment, where \(x_{ijklump}\) denotes average response and \(v_{ijklump}\) denotes the log sample variance \(\ln(s^{2})\) for corresponding design factor combinations

[MISSING_PAGE_FAIL:547]

[MISSING_PAGE_FAIL:548]

(here, wheat bran) for large scale production of L(+) lactic acid. The fifteen factors that were studied consisted of three physical factors (which we label _A_-_C_), a buffer (_D_), and eleven nutrients (_E_-_N_, _P_).

The Plackett-Burman design that was used can be obtained by cycling from the generator of Table 15.63. The design and the responses (grams of lactic acid per 10 grams of wheat bran) are shown in Table 15.35 before randomization. The 15 main effect contrast estimates (with divisor 1.0) and a corresponding half-normal probability plot are shown in Table 15.36 and Fig. 15.9.

We can see that with only \(n=16\) observations, it is possible to identify 7 (or possibly 8) of the 15 factors as likely to be the most influential in the lactic acid production. In order of size of contrast estimate, the 8 factors with the largest main effects are those labeled \(F\), \(B\), \(G\), \(K\), \(L\), \(I\), \(E\), and \(N\), which are all nutrients except for \(B\) which is a physical factor. These 8 factors can then be followed up in a later experiment, and their interactions examined. Since the main effect estimates for the five factors \(F\), \(G\), \(L\), \(I\), and \(E\) are all positive, the experimenters suggested that these should be examined at higher levels in the next experiment.

The estimate for the main effect of nutrient \(K\) is negative, and the experimenters commented that the wheat bran is already rich in this nutrient, so this nutrient may not need to be added in future experiments. The low level of factor \(N\) had already been set at zero, so a negative main effect estimate suggests that this nutrient, too, need not be added in future. The factor \(B\) main effect estimate is also negative and it was suggested that this be retained at its low level. Thus, main effects of only 5 factors and their interactions need to be followed up in future and this could be done in a full factorial experiment with 32 observations, or a resolution V half fraction with 16 observations. 

It is not necessary to assign all of the columns of an orthogonal main effect plan to factors. For example, the design of Table 15.35 could have been used to measure the main effects of factors _A_-_L_ only and, if so, this would no longer be a saturated design--there would be 3 degrees of freedom for error. Similarly, seven of the 13 columns of the orthogonal main effect plan \(L\)27(313) of Table 15.65 was used as a non-saturated orthogonal main effect plan for the seven 3-level design factors in the

\begin{table}
\begin{tabular}{c c c c c c c c} \hline A & B & C & D & E & F & G & H \\ −0.065 & −0.370 & −0.044 & −0.076 & 0.238 & 0.428 & 0.349 & −0.016 \\ \hline I & J & K & L & M & N & P & \\
0.276 & 0.036 & −0.331 & 0.287 & −0.026 & −0.143 & 0.088 & \\ \hline \end{tabular}
\end{table}
Table 15.36: Contrast estimates for the lactic acid experiment

Figure 15.9: Half-normal probability plot of normalized contrast absolute estimates for the lactic acid experiment

inclinometer experiment of Sect. 15.7.1. The orthogonal array \(L_{18}(3^{7}\times 2)\) indicated in the right hand side of Table 15.64 is a non-saturated orthogonal main effect plan with two degrees of freedom for error.

#### Supersaturated Designs

A design is called _supersaturated_ if the number of factorial effects to be estimated, plus the mean, exceeds the number of observations. In some sense, all the regular fractional factorial designs in the earlier sections are supersaturated if an insufficient number of interactions can be assumed to be negligible. For instance, in the sludge experiment of Example 15.2.1, p. 502, there were only \(n=8\) observations but, ideally, 5 main effects, 10 interactions and a mean were of interest. Similarly, in the refinery experiment of Example 15.3.1, p. 507, there were 4 main effects (requiring 2 degrees of freedom each), 6 two-factor interactions (requiring 4 degrees of freedom each) and a mean of interest - a total of 33 factorial effects, but only \(n=27\) observations could be taken. In both of these examples, and others like them, contrasts were either in the defining relation and could not be measured at all, or were measurable within a set of aliased contrasts. Aliased contrast estimators were completely correlated and non-aliased contrast estimators were independent.

However, the word _supersaturated_ is not usually applied to fractions with alias schemes. Rather, the term is usually reserved for designs in which, although there are fewer observations than contrasts of interest plus the mean, _some information can be gained on all contrasts_. To achieve this, one must give up the idea of independent estimates and allow some or all contrast estimators to be correlated. In the extreme case of fewer observations than the number of factors (\(n<p\)), it is usually necessary to estimate main effects only and to postpone consideration of interactions among important factors to a later date.

Since the contrast estimates will be correlated, we would like the correlations to be as small as possible. The correlation between contrast estimators can be calculated using the information about the covariance of two contrast estimators from Sect. 6.7.2, and dividing by the square root of the product of their variances to obtain the formula for correlation. Following Sect. 6.7.2, p. 172, the estimators of the two contrasts \(\Sigma c_{i}\tau_{i}\) and \(\Sigma k_{s}\tau_{s}\), with one observation per treatment combination in the design, have correlation

\[\text{Corr}\left(\sum_{i=1}^{n}c_{i}Y_{i}\sum_{s=1}^{n}k_{s}Y_{s}\right)=\frac {\sum_{i=1}^{n}\sum_{s=1}^{n}c_{i}k_{s}}{\sqrt{\sum c_{i}^{2}\sum k_{s}^{2}}}\,.\]

For two-level factors, each of the \(n\) contrast coefficients is \(-1\) or \(+1\), so

\[\text{Corr}\left(\sum_{i=1}^{n}c_{i}Y_{i}\sum_{s=1}^{n}k_{s}Y_{s}\right)\ =\ \frac{1}{n}\sum_{i=1}^{n}\sum_{s=1}^{n}c_{i}k_{s}\,. \tag{15.8.1}\]

In general, our recommendation is only to consider using a supersaturated design if the largest correlation between two columns is at most 1/3 and if there are likely to be very few large main effects, say at most \(n/3\) (effect sparsity), (see Example 15.8.2 for problems that may be encountered in supersaturated designs when there are many large effects.)

[MISSING_PAGE_FAIL:551]

#### Analysis of a Supersaturated Design

In a supersaturated design, there are too many factors (and too few observations) to fit a model by least squares that contains all main effects so, typically, smaller models are investigated. But, even so, contrast estimates are not likely to be independent which means that half normal probability plots cannot be used here. Even when there are few large main effects, any analysis of supersaturated designs is tricky due to the hidden aliases. Various sophisticated methods of analysis have been researched, including certain "penalized regression" techniques which are outside the scope of this book. One simple method is to compare the fit of all possible regression models (Chap. 8) containing first one variable, then two variables, then three variables, and so on, up to \(p=n-1\) variables; a technique called _all-subsets regression_. There are still decisions to be made on how to select the best of these models, and most software packages will present options for these. Here, we will compare only the \(R^{2}\) values for models (see (8.6.1) in Sect. 8.6.1), but alternative more sophisticated methods would be preferable. Research is still continuing today on the best methods of selecting influential factors (or variables) when the number of observations is so small. With so few observations, the selected model should be taken only as a possible selection of the most influential factors, and not as a model to explain the data. The potentially influential factors that are identified must be followed up in a future experiment; some of the identified factors may have only appeared to have had large effects due to the hidden aliasing.

##### 8.2.2 Identifying influential factors

In this example, we examine how the contrast correlations, that are an unavoidable part of a supersaturated design, might affect the identification of the factors that influence the response. Let us start with an example using the orthogonal main effects plan with \(n=12\) observations in Table 15.34 and label the columns to be the main effect contrasts of the ten factors \(A\), \(B\), \(\ldots\), \(J\). This same design is shown in columns 3-12 of Table 15.39, p. 537, together with two sets of responses listed as \(y_{BD}\) and \(y_{BDH}\) in the first two columns. The data \(y_{BD}\) in the first column were created by assuming that the contrast main effect values for \(B\) and \(D\) are 16 and 24, respectively, and all other main effect values are randomly selected from a \(N(0,2)\) distribution and random errors from a N(0,1) distribution. Using data \(y_{BD}\), we calculate the contrast estimates by multiplying the contrast coefficient by the corresponding response and dividing by \(v/2=6\), we obtain the estimates in Table 15.38. Since we used an orthogonal main effects plan (Plackett-Burman design), these are independent estimates. It can be seen that factors \(B\) and \(D\) clearly have the largest main effects and these would be selected as the only two influential factors. An all subsets regression will also identify these two factors as the most influential, and the regression model is

\[\hat{y}=34.70+7.62x_{2}+12.62x_{4}\,\]

where \(x_{2}\) and \(x_{4}\) are the coded levels \(\pm 1\) of factors \(B\) and \(D\) and, when multiplied by 2, the corresponding parameter estimates match the contrast estimates in Table 15.38. (The difference of a factor of 2 is due to the fact that the levels \(\pm 1\) are 2 apart and are treated as actual values rather than coded levels for the regression model).

\begin{table}
\begin{tabular}{c c c c c c c c c c} \hline \(A\) & \(B\) & \(C\) & \(D\) & \(E\) & \(F\) & \(G\) & \(H\) & \(J\) & \(K\) \\ −1.84 & 15.24 & 1.37 & 25.24 & −0.23 & 0.08 & −1.30 & −0.78 & 1.55 & −0.05 \\ \hline \end{tabular}
\end{table}
Table 15.38: Main effect contrast estimates obtained from the Plackett–Burman design in Example 15.8.2Now, taking the column labeled \(K\) in Table 15.39 as the branching column and keeping only those rows corresponding to \(+1\) in this column, we obtain the supersaturated design with \(n_{ssd}=6\) observations in Table 15.37.

An all-subsets regression would again select factors \(B\) and \(D\). A regression model containing these two factors has \(R^{2}\), so accounts for 97.7% of the variability in the data. The fitted model is

\[\hat{y}=34.62+7.08x_{2}+11.97x_{4}\,,\]

which is very similar to that obtained from the orthogonal main effects plan. However, with so few observations, the model should not be used for prediction; it should only be used as a guide to which factors are to be followed up in a future experiment. At the follow-up stage, a predictive model can be fitted, and the interaction between \(B\) and \(D\) can be examined. Also, notice that the number of large main effects in this example is, as recommended, not more than \(n_{ssd}/3=2\).

If we try to use this design in a situation where there are, say, three large main effects, the contrast correlations will most likely prevent the correct factors from being selected. For example, the data set \(y_{BDH}\) in Table 15.39 was created to correspond to true values of the main effects of \(B\), \(D\) and \(H\) equal to 16, 24, 14, respectively, and these influential factors will be selected when using the orthogonal main effects plan. But from the supersaturated design, only factor \(D\) can be detected, and an all-subsets regression will identify \(C\) as a second influential factor. This is due to the hidden aliasing in which the main effect contrast of \(C\) is defined by the main effect contrasts of \(B\), \(D\) and \(H\), as described above. 

Example 15.8.2 illustrates that supersaturated designs can be successful in detecting the important factors _provided that there is only a small number_ of these (say, at most \(n_{ssd}/3\)) compared with the number of observations, \(n_{ssd}\). Analysis of the data in Example 15.8.2 is illustrated in Sects. 15.9.3 and 15.10.3, for the SAS and R software respectively.

#### 15.8.3 Saturated Orthogonal Main Effect Plans Plus Interactions

Saturated orthogonal main effect plans which are equivalent to regular fractions do not give scope for estimating interactions independently of main effects. One can draw interaction plots as we did in Chaps. 6 and 7, but since the interactions are aliased with main effects, one cannot separate out the information. However, non-regular saturated orthogonal main effect plans for \(n\) not a power of 2 do, in general, offer the ability to gain some information on a few 2-factor interactions.

For example, if we take the Plackett-Burman design of Table 15.34, p. 531, and add the \(AB\) and \(AC\) interaction contrasts, we obtain the set of contrasts in Table 15.39. Notice that neither interaction column is identical to any main effect column and all correlations of interaction columns with main effect columns are 0.333 or \(-0.333\). After adding interaction contrasts to the plan, such designs are supersaturated and so the same cautions and methods of analysis discussed in the previous section apply. Much more has been written on the topic of estimating interactions for non-regular fractions. A summary can be found in the paper of Xu et al. (2009).

An alternative possibility of measuring not only added interactions but also quadratic trends in main effects is given by the definitive screening designs outlined in the next section.

[MISSING_PAGE_EMPTY:8489]

Definitive screening designs are supersaturated in the sense that, for \(p\) factors, they use only \(2p+1\) observations to measure a total of \(p(p+3)/2\) trend contrasts plus a mean (e.g. if there are \(p=4\) factors, a definitive screening design uses 9 observations to measure 8 linear and quadratic main effect trend contrasts, 6 interaction linear\(\times\)linear trend contrasts and a mean). Like supersaturated designs, definitive screening designs may be analyzed using all-subsets regression or a more sophisticated "penalized regression" technique. As in Chap. 7, if the selected model contains linear\(\times\)linear interaction terms, the constituent linear main effect terms should be included too.

#### Vaccine experiment

An experiment, described by Erler, de Mas, Ramsey, and Henderson in _Biotechnology Letters_ (2013), was run to study the effect of \(p=6\) factors on a particular chemical reaction related to a candidate vaccine product. The experimenters were interested in the linear and quadratic main effects of the factors and the linear\(\times\)linear interactions, so there were 28 contrasts of interest. They used the definitive screening design from the paper of Jones and Nachtsheim (2011), which is shown in Table 15.40, plus some extra repeats of the final treatment combination (which we are not using here).

The response is a measure of "extent of polymerization" and is shown in the last column of Table 15.40. The data were collected in a random order. An all-subsets regression run with all linear terms \(x_{i}\) (with values as in Table 15.40), quadratic terms \(x_{i}^{2}\), and linear\(\times\)linear terms \(x_{i}x_{j}\), selects the linear trends in \(A\), \(F\), and \(D\) as being the most influential, with the possible addition of the linear\(C\times\)linear\(D\) trend. The regression model involving these four effects, together with the linear \(C\) main effect is

\[\hat{y}=14.92+10.62x_{1}+1.16x_{3}+3.90x_{4}+5.46x_{6}+1.98x_{3}x_{4}\,\]

and this accounts for 98% of the variability in the data. 

### Using SAS Software

#### Fractional Factorials

The analysis of a fractional factorial experiment by computer is identical to that of a single-replicate factorial experiment (Sect. 7.6, p. 225) except that only one effect should be entered into the model from each line of the aliasing scheme (and none from the defining relation). If two aliased effects are entered into the model, the Type I sum of squares and degrees of freedom will be zero for the second effect entered, and the Type III sum of squares and degrees of freedom will be zero for both effects.

In Table 15.41 we show a straightforward program for analyzing the sludge experiment of Example 15.2.1. The cell-means model in terms of the treatment combinations TC is used. (Variables A-E are created for later use.) Using PROC GLM, the analysis of variance is generated in the usual way by the MODEL statement, while the contrast estimates are obtained by the ESTIMATE statements, using the contrast coefficients listed in Table 15.7 (p. 503). The output is shown in Fig. 15.10. The main effects are each aliased with 2-factor (and 3-factor) interactions (see p. 503). The 2-factor interactions \(AC\) and \(BC\) are aliased with \(BE\) and \(AE\), respectively. Since there is only one observation on each of the observed treatment combinations, the cell-means model leaves no degrees of freedom for error--this is why the \(p\)-values and values of test statistics and standard errors are either missing or meaningless. The inclusion of the DIVISOR=4 options in the ESTIMATE statements ensures that all the contrasts listed in Table 15.7 will be divided by \(v/2=4\) and give the same estimates as those in Table 15.8 (p. 503).

In Table 15.42, we show the SAS program for the equivalent model written in terms of main-effect and interaction parameters. The ESTIMATE statements for the main effects need no divisors, as they are automatically divided by 4 (the number of observations on each of the high and low levels). However, the ESTIMATE statements for the interaction contrasts include the option DIVISOR=2, to increase the actual divisor by a factor of 2. Without this option, the interaction estimates would be calculated with divisor 2 (the number of observations on each combination of levels of the two factors). The main-effect and interaction sums of squares are shown in Fig. 15.11. The output from the ESTIMATE statements is identical to that obtained from the cell-means model.

Again, there are no degrees of freedom for error, since a term has been included in the model from every row of the aliasing scheme. If all 2-factor interactions can be assumed to be negligible, then \(AC\) and \(BC\) would be omitted from the model, leaving 2 degrees of freedom for error.

Consider what would happen if two aliased terms were entered into the model. The defining relation for the \(\frac{1}{4}\)-fraction was stated in Example 15.2.1 to be \(I=ABD=CDE=ABCE\). Consequently, \(A\) is aliased with \(BD\). Adding \(BD\) into the model subsequent to \(A\) would give Type I sum of squares and degrees of freedom for \(BD\) equal to zero. This is because \(BD\) adds no more information if \(A\) is already in the model. The Type III sums of squares would be zero for both \(A\) and \(BD\), since each would be added into the model assuming that the other is already in the model.

#### Design for the Control of Noise Variability

We now turn to the analysis of experiments involving design and noise factors, often known as Taguchi experiments. These were discussed in Sect. 15.7. There are two approaches to the analysis. The first approach involves the analysis of the mean and variance of the response observed for each design-treatment combination, calculated over the levels of the noise factors. The second approach involves

\begin{table}
\begin{tabular}{c} DATA SLUDGE; \\ INPUT A B C D E Y; \\ TC = 10000*A + 1000*B + 100*C + 10*D + E; \\ LINES; \\
0 0 0 1 0 195 \\
0 0 1 1 1 496 \\
0 1 0 0 1 87 \\
0 1 1 0 0 1371 \\
1 0 0 0 1 102 \\
1 0 1 0 0 1001 \\
1 1 0 1 0 354 \\
1 1 1 1 1 775 \\ ; \\ PROC GLM; \\ CLASS TC; \\ MODEL Y = TC; \\ ESTIMATE ’A’ TC -1 -1 -1 -1 1 1 1 1 1 / DIVISOR = 4; \\ ESTIMATE ’B’ TC -1 -1 1 1 -1 -1 1 1 / DIVISOR = 4; \\ ESTIMATE ’C’ TC -1 -1 1 -1 1 -1 -1 1 1 / DIVISOR = 4; \\ ESTIMATE ’D’ TC 1 1 -1 -1 -1 -1 -1 1 1 / DIVISOR = 4; \\ ESTIMATE ’E’ TC -1 1 1 -1 -1 -1 1 -1 1 / DIVISOR = 4; \\ ESTIMATE ’AC’ TC 1 -1 -1 1 1 -1 -1 1 -1 1 / DIVISOR = 4; \\ ESTIMATE ’BC’ TC 1 -1 -1 1 1 -1 -1 -1 1 / DIVISOR = 4; \\ \end{tabular}
\end{table}
Table 15.41: SAS program for the sludge experiment—cell-means model 

[MISSING_PAGE_EMPTY:8492]

[MISSING_PAGE_EMPTY:8493]

[MISSING_PAGE_EMPTY:8494]

PROC REG;  MODEL Y = A B C D E F G H I J / SELECTION = R SQUARE BEST = 6; The SELECTION=R SQUARE options asks SAS to check \(R^{2}\) for linear models containing \(k\) variables, for all \(k=1,2,3,\ldots,n_{d}-1\). The BEST=6 options asks SAS to list the 6 sets of factors producing models with the 6 largest \(R^{2}\).

For example, suppose we set BEST=4, for the supersaturated design obtained from Table 15.39 with rows corresponding to \(+1\) in the branching column \(K\), and use the data \(y_{BD}\). Then, we would obtain the output in the left part of Table 15.44 (where we have deleted the fourth selection for the one- and two-factor models). From this table, we can see that the factors \(B\) and \(D\), taken together, account for 97.7% of the variation in the data and little is gained from adding a third factor.

The right part of Table 15.44 shows the results of running the R SQUARE option using the data set \(y_{BDH}\) of Table 15.39. From this, one would most likely select factors \(C\) and \(D\) (incorrectly). Notice that the sets of \(k=3\) best factors indicate that selection of any three of \(A\), \(C\), \(D\), \(G\) seems to be equivalent. This anomaly can be explained by the hidden aliasing which can be discovered by running PROC REG without any options, which says:

 F = -A + D - E  G = A - C - D  H = -B - C - D  I = -B - D + E  J = -A + B + C + D - E and we see that the contrasts for \(A\), \(C\), \(D\) and \(G\) are linearly related. The correct selection of factors for these data is \(B\), \(D\) and \(H\). A linear model containing the main effects of three factors has an \(R^{2}\) of only 0.971, which is still high but unlikely to be the set of three factors chosen. Thus, when there are many large effects as compared with the number of observations, their detection is difficult and, perhaps, impossible.

### Using R Software

#### Fractional Factorials

The analysis of a fractional factorial experiment by computer is identical to that of a single-replicate factorial experiment (Sect. 7.7, p. 230) except that only one effect should be entered into the model from each line of the aliasing scheme (and none from the defining relation). If two aliased effects are

\begin{table}
\begin{tabular}{l l l l l l} \hline Number in model & R-Square & Variables in model & Number in model & R-Square & Variables in model \\ \hline
1 & 0.6597 & D & 1 & 0.7111 & C \\
1 & 0.3808 & E & 1 & 0.5778 & D \\
1 & 0.3452 & H & 1 & 0.2694 & E \\ \hline
2 & 0.9774 & B D & 2 & 0.9693 & C D \\
2 & 0.8730 & E I & 2 & 0.8670 & C G \\
2 & 0.8672 & C H & 2 & 0.7970 & C H \\ \hline
3 & 0.9985 & B D G & 3 & 0.9957 & A C G \\
3 & 0.9871 & B D I & 3 & 0.9957 & C D G \\
3 & 0.9871 & B D E & 3 & 0.9957 & A C D \\
3 & 0.9871 & D E I & 3 & 0.9957 & A D G \\ \hline \end{tabular}
\end{table}
Table 15.44: Results of the R SQUARE option 

[MISSING_PAGE_EMPTY:8496]

by the lsmeans function and saved as lsmTC, and using the contrast coefficients listed in Table 15.7 (p. 503). Nicely formatted output is obtained by providing the contrasts as a list, including a name (i.e. A, B, etc.) for each.

The main effects are each aliased with 2-factor (and 3-factor) interactions (see p. 503). The 2-factor interactions \(AC\) and \(BC\) are aliased with \(BE\) and \(AE\), respectively. Since there is only one observation on each of the observed treatment combinations, the cell-means model leaves no degrees of freedom for error--this is why the standard errors, test statistics and \(p\)-values generated by contrast are "not a number" (NaN). The inclusion of the divisor 4 each contrast ensures that all the contrasts listed in Table 15.7 will be divided by \(v/2=4\) and give the same estimates as those in Table 15.8 (p. 503).

In Table 15.46, we show a continuation of the R program of Table 15.45, illustrating the analysis using a factorial effects model, providing selected output. Main effect and interaction contrast estimates are computed using the contrast statement of the least squares means function lsmeans. All of the contrasts as specified use coefficients \(c_{ijk}=\pm 1/4\). For the main effects, the specified coefficients \(\pm 1\) are automatically divided by 4, averaging over the four combinations of the other two factors. For the two-factor interaction contrasts, the coefficients \(\pm 1/2\) are specified and are automatically divided by 2, averaging over the two observations on each combination of these two factors. The main-effect and interaction sums of squares are shown in Table 15.46. The contrast estimates (not shown) are identical to those obtained from the cell-means model.

Again, there are no degrees of freedom for error, since a term has been included in the model from every row of the aliasing scheme. If all 2-factor interactions can be assumed to be negligible, then \(AC\) and \(BC\) would be omitted from the model, leaving 2 degrees of freedom for error.

\begin{table}
\begin{tabular}{l r r} \multicolumn{3}{l}{ \(>\) \# Analysis of variance: factorial effects model} \\ \multicolumn{3}{l}{ \(>\) modelFE = lm(y \({}^{\sim}\) fA + fB + fcc + fD + fE + fA:fC + fB:fC, data = sludge.data)} \\ \multicolumn{3}{l}{ \(>\) anova(modelFE)} \\ \multicolumn{3}{l}{ Analysis of Variance Table} \\ \multicolumn{3}{l}{ Response: y} \\ \multicolumn{3}{l}{ Df Sum Sq Mean Sq F value Pr(\textgreater{}F)} \\ \multicolumn{3}{l}{ fA} & 1 & 861 & 861 \\ \multicolumn{3}{l}{ fB} & 1 & 78606 & 78606 \\ \multicolumn{3}{l}{ fC} & 1 & 1054878 & 1054878 \\ \multicolumn{3}{l}{ fD} & 1 & 68635 & 68635 \\ \multicolumn{3}{l}{ fE} & 1 & 266815 & 266815 \\ \multicolumn{3}{l}{ fA:fC} & 1 & 8778 & 8778 \\ \multicolumn{3}{l}{ fB:fC} & 1 & 31878 & 31878 \\ \multicolumn{3}{l}{ Residuals 0} & 0 \\ \end{tabular}
\end{table}
Table 15.46: R program (continued) for the sludge experiment—five-way model Consider what would happen if two aliased terms were entered into the model. The defining relation for the \(\frac{1}{4}\)-fraction was stated in Example 15.2.1 to be \(I=ABD=CDE=ABCE\). Consequently, \(A\) is aliased with \(BD\). Adding \(BD\) into the model subsequent to \(A\) would give Type I sum of squares and degrees of freedom for \(BD\) equal to zero. This is because \(BD\) adds no more information if \(A\) is already in the model. The Type III sums of squares would be zero for both \(A\) and \(BD\), since each would be added into the model assuming that the other is already in the model.

#### 15.10.2 Design for the Control of Noise Variability

We now turn to the analysis of experiments involving design and noise factors, often known as Taguchi experiments. These were discussed in Sect. 15.7. There are two approaches to the analysis. The first approach involves the analysis of the mean and variance of the response observed for each design-treatment combination, calculated over the levels of the noise factors. The second approach involves the study of design-by-noise interactions. The first approach requires every noise combination to be observed with every design combination (that is, a product array), and the second approach requires randomization of all observed combinations of noise and design factors taken together.

#### _Example 15.10.1_ Inclinometer experiment-product-array approach

The inclinometer experiment was described in Sect. 15.7.1, and the data are shown in Table 15.29 (p. 526). Since this is a product array, the analysis will be done on the average and log variance of the responses over the levels of the noise factors, and these do not need to be identified in the R program input. Thus, the R program in Table 15.47 reads in the data corresponding to each combination of levels of the seven design factors (\(A\)-\(G\)) without identifying the levels of the noise factors. The average Avy and the log sample variance LnVar of the observations for each design-treatment combination is computed and added to the data set. Since only 27 (i.e., \(3^{3}\)) of the \(3^{7}\) design combinations are observed, we have a \(3^{7-4}\) fractional factorial experiment with two possible response variables.

Two analyses are requested in Table 15.47. The first uses the response variable LnVar. After fitting the linear model that includes main effects but no interactions via the lm function, an analysis of variance table is requested via the anova statement. The least squares means for the levels of each design factor are requested by the lsmeans function, and these can be used to prepare plots such as those shown in Fig. 15.8 (p. 529). Also, the contrast function uses the saved least squares means to estimate and test the linear and quadratic trends for each design factor. This use of lsmeans is only shown in the program for design factor \(A\) but can be used to obtain least squares means for the remaining design factors and the trend contrast estimates for \(B\)-\(F\), (since they each have equally-spaced levels). A regression model is also fit, including linear and quadratic terms for each design factor, to generate the sum of squares associated with the linear and quadratic contrasts. This approach also provides the correct linear and quadratic trend contrast sums of squares for \(G\), even though the levels of \(G\) are not equally spaced. The final section of the program in Table 15.47 uses the response variable Avy. The output is similar to that shown in Tables 15.30, 15.31, 15.32 and 15.33, pp. 527-528. 

For a mixed array, in which observed combinations of noise and design factors taken together are randomized, the analysis is done in a similar way to that of Chap. 7. The model should include the main effects of the design and noise factors and at least the design-by-noise interactions. The design-by-noise interactions help in identifying those design factors whose levels give the most stable response as the noise factor levels change. Interaction plots for the significant design-by-noise interactions are made in the same way as those described in Sect. 6.9.3. If the noise factor levels are placed on the horizontal axis as in Fig. 15.7, the levels of the design factor(s) that are most robust to the noise level fluctuations are those whose average responses result in lines closest to horizontal across the noise factor levels (cf. level 3 of factor \(A\) in Fig. 15.7(b), p. 525).

[MISSING_PAGE_FAIL:564]

[MISSING_PAGE_FAIL:565]

software regsubsets command, for the supersaturated design obtained from Table 15.39 with rows corresponding to +1 in the branching column \(K\), and the data \(y_{BD}\).

The regsubsets call fits all possible models containing up to nvmax = 3 factors and displays the nbest = 3 of each size. The statement

as.data.frame(summary.outssd$outmat) produces a list of these best models with stars indicating which factors have been fitted in the model. The \(R^{2}\) values for the listed models are obtained from the round(summary.outssd$rsq, 4) command, where the number 4 specifies the number of decimal places. The fourth entry in the list of \(R^{2}\) values corresponds to the model containing \(B\) and \(D\); we see that the \(R^{2}=0.9774\), and little is gained by including other factors.

Notice the warning message in the output that says there were 5 linear dependencies found. These are the hidden aliases that can be identified by running

alias(aov(y A + B + C + D + E + F + G + H + I + J, ssd)) and observing that

F = -A + D - E  G = A - C - D  H = -B - C - D  I = -B - D + E  J = -A + B + C + D - E

If we try to use this same design for the data set \(y_{BDH}\) from Table 15.39, we obtain

\[\begin{array}{rrrr}&\omit\span\omit\span\omit\span\omit\span\omit\span\omit \span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span \omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit \span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit \span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit \span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit \span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit \span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit \span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit \span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit \span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit \span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit \span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit \span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit \span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit \span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit \span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit \span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit \span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit \span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span \omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit \span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit \span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit \span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span \omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit \span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span\omit\span \omit\span\omit\span\omit\span\omit\spanExercise 8 of Chap. 13. Explain the circumstances under which a half fraction would be preferred to a single-replicate factorial experiment.
2. **Mangold experiment, continued** The mangold experiment in Sect. 13.5, p. 447, was a single replicate confounded design for a \(2^{5}\) experiment in \(b=4\) blocks of size 8. The five factors were Sulphate of Ammonia (factor \(A\) at levels 0 or 0.6 cwt per acre), Superphosphate (factor \(B\) at levels 0 or 0.5 cwt per acre), Muriate of Potash (factor \(C\) at levels 0 or 1.0 cwt per acre), Agricultural Salt (factor \(D\) at levels 0 or 5 cwt per acre), and Dung (factor \(E\) at levels 0 or 10 tons per acre). All of the 3-, 4-, and 5-factor interactions were expected to be negligible. The two three-factor interactions \(ABD\), \(BCE\) and their product \(ACDE\) were selected for confounding. Suppose that the data from only the third block had been available, so that we have a \(\frac{1}{4}\)-fraction. The data are reproduced in Table 50. 1. Write down the aliasing scheme for this fractional factorial experiment. 2. Analyze the data. What conclusions can you draw? 3. Comparing your conclusions with those of Sect. 13.5, what extra information do you gain by running the single-replicate design instead of the fraction? 4. When would you recommend that an experimenter consider using a fractional factorial design rather than a single-replicate design?
3. **Dye experiment, continued** The dye experiment was discussed in Sect. 14.2.4 (p. 478). There were three factors: the concentration of inorganic material \(M\) in the free water in the reaction mixture (factor \(A\) at three equally spaced levels), the volume of free water in the reaction mixture (factor \(B\) at three equally spaced levels), and the concentration of inorganic material \(N\) in the free water in the reaction mixture (factor \(C\) at three equally spaced levels). The data for the first replicate of the original experiment were given in Table 6 (p. 479) and the first block is reproduced in Table 51. The design for

\begin{table}
\begin{tabular}{c c c c c c c c c}  & & \multicolumn{6}{c}{Treatment combinations (Yield)} \\
000 & 021 & 012 & 110 & 101 & 122 & 220 & 211 & 202 \\ (74) & (130) & (56) & (110) & (166) & (227) & (195) & (146) & (90) \\ \end{tabular}
\end{table}
Table 51: Volume of dyestuff for Block I of the dye experiment

\begin{table}
\begin{tabular}{c c c c c c c}  & \multicolumn{6}{c}{Treatment combinations (Response)} \\
00101 & 111001 & 01110 & 0000 & 11001 & 11100 & 00000 & 10111 \\ (896) & (1284) & (996) & (860) & (1184) & (984) & (740) & (1468) \\ \end{tabular}
\end{table}
Table 50: Yields (in pounds) of mangold roots for Block III of the mangold experiment the first replicate was a single-replicate design that confounded (\(AB^{2}C^{2}\); \(A^{2}BC\)). Analyze the data of Block I as though it had come from a \(\frac{1}{3}\)-fraction. State your conclusions.
4. **Sugar beet experiment, continued** The sugar beet experiment described in Exercise 6 of Chap. 14 concerned the effects of three standard fertilizers, nitrogen, phosphate, and potassium (factors \(N\), \(P\), and \(K\)), each at three equally spaced levels, on sugar beet yield. The experiment was run as a single-replicate confounding the contrasts (\(NP^{2}K\); \(N^{2}PK^{2}\)). Suppose the only data available were those of Block III, reproduced in Table 15.52. 1. If the only data available were those from Block III, write out the aliasing scheme for the design. 2. Analyze the data from Block III as though they came from a \(\frac{1}{3}\)-fraction. State your conclusions.
5. **Flour experiment, continued** Suppose that the data from Block II of the \(4\times 2^{4}\) experiment in Table 15.16 (p. 514) had been lost, so that only Block I remained. This would then constitute a \(\frac{1}{4}\)-fraction. 1. Write out the aliasing scheme for the design. What is the resolution number. Is this a good design? 2. Bearing in mind the purpose of the experiment, can you find a better \(\frac{1}{4}\)-fraction? If so, write out the design and its aliasing scheme. 3. Analyze the data from Block I of Table 15.16. What can you conclude?
6. **Handwheel experiment** E.N. Corlett and G. Gregory describe an experiment in the 1960 issue of _Applied Statistics_ that was concerned with finding the design of a machine tool handwheel that would maximize the accuracy on the part of the operator in the setting of the machine tool handwheel. The apparatus consisted of an optical dividing head with a dial mounted onto a mandrel to which was connected the handwheel spindle. The spindle was provided with an adjustable friction brake. The operator first offset the dial by 15\({}^{\circ}\) and then moved the handwheel so that a line on the dial was brought "into coincidence with a fixed line on the dividing head, making the final adjustment by means of a series of taps by hand on the handwheel rim." Seven factors, each at two levels (coded 0 and 1) were investigated as follows. 1. Handwheel diameter (5.5 in., 10 in.) 2. Dial diameter (4 in., 8 in.) 3. Thickness of the dial line (0.008 in., 0.064 in.) 4. Friction of the spindle (7.5 lb.-in., 45 lb.-in.) 4.

\begin{table}
\begin{tabular}{c c c c c c c c} \hline  & & \multicolumn{6}{c}{Treatment combinations (Yield)} \\ \hline
202 & 020 & 210 & 111 & 001 & 122 & 221 & 012 & 100 \\ (2198) & (2093) & (2354) & (2268) & (1926) & (2152) & (2349) & (2025) & (2106) \\ \hline \end{tabular}
\end{table}
Table 15.52: Yields of sugar beet for Block III of the sugar-beet experiment 

[MISSING_PAGE_FAIL:569]

days, which meant that a \(2^{7-1}\) fractional factorial experiment was required, divided into 4 blocks of 16. The highest-order interaction was selected for the defining relation of the fraction, that is, \(I=ABCDEFG\). Only two operators were used for the experiment, one for each level of practice. The difference between these operators was not of interest, only the interaction of the level of practice with the other factors. Rather unusually, then, the main effect of \(F\) was selected as one of the contrasts for confounding. All the 2-factor interactions and most of the 3-factor interactions were thought to be of interest. Unlikely 3-factor interactions included \(ACG\) and \(BDE\), which were also chosen for confounding with blocks. The complete set of confounded contrasts was \(F,ACG,ACFG\) together with its set of aliases \(ABCDEG,BDEF,BDE\). All other main-effect, 2-factor, and 3-factor interaction contrasts could be estimated. The data obtained from the experiment are shown in Table 15.53. 1. Write out the aliasing scheme for the design. 2. Using a computer package, estimate the (estimable) main-effect and interaction contrasts. 3. Prepare a half-normal probability plot of the contrast estimates and identify the most important main effects and interactions. 4. The authors of the article point out that if the responses are normally distributed and \(n\) is large (where \(n\) is the number of repeated observations, 25 in this experiment), then the response variable \(\ln(s^{2})\) has approximately constant variance equal to \(2/(n-1)\). Calculate the standard error for each of the contrasts estimated in part (c). Using Bonferroni's method with an individual significance level of 0.001 for each test (giving an overall level of at most 0.06), which main effects and interactions are significantly different from zero? Do these results agree with the results from part (c)? Discuss why or why not. 5. Draw interaction plots of the important interactions and discuss recommended settings for the six factors \(A\), \(B\), \(C\), \(D\), \(E\), and \(G\) for the practiced and nonpracticed operators individually. 6. Would you recommend further experimentation? If so, which factors and which settings would you recommend? Can you suggest a suitable design?
7. **Paint experiment** 1. Suppose that you need to design an experiment involving 6 factors (\(A\), \(B\), \(C\), \(D\), \(E\), \(F\)) at 2 levels each (64 treatment combinations) and that only 8 observations can be taken. You decide to sacrifice information on the \(ABF\), \(ACDF\), and \(ABCE\) contrasts. Write out the defining relation and the two rows of the aliasing scheme showing the aliasing of \(A\) and the aliasing of \(AC\). 2. Explain what aliasing means. 3. An experiment was run in Germany by S. Eibl, U. Kess, and F. Pukelsheim (_Journal of Quality Technology_, 1992) on the thickness of a paint coating. Prior to the experiment, the thickness achieved was around 2 mm, much higher than the target 0.8 mm. They selected the following six factors, each at two levels: \[\begin{array}{ll}A:\text{belt speed}&B:\text{tube width}&C:\text{pump pressure}\\ D:\text{paint viscosity}&E:\text{tube height}&F:\text{heating temperature} \end{array}\] They used the \(\frac{1}{8}\)-fraction with the aliasing scheme in part (a), and they decided to ignore all interactions for this first experiment. Since they wanted to monitor the variation of the thickness, they took four observations on each of the 8 treatment combinations in the fraction. 2.

The data are shown in Table 16.1, p. 570, where the two levels of each factor are coded as -1 and 1 and shown for factors _A_-_F_ in the columns labeled _z_A_-_z_F_. Calculate the analysis of variance table and contrast estimates using response variable LNVAR (the log variance). What do you conclude? 4. Assuming that the order of observations was completely randomized, calculate the analysis of variance table and also contrast estimates of interest, using the 32 observations separately (without combining them into an average). Remembering that the goal is to reduce the thickness, what conclusions would you draw from this particular experiment? 5. The experimenters decided to run a followup experiment with at most 16 observations. You can use any of the original 6 factors and you can change the levels from their original settings. The ultimate goal is to achieve a coating of 0.8 mm. Suggest a followup experiment.
8. **Anatase experiment** R.E. Olsen and coauthors described several experiments in the _Journal of Porous Materials_ (2014). These concerned the study of anatase (a form of titanium dioxide) as a catalyst support. Specific catalyst support properties are required, such as certain surface area, pore volume, and pore diameter. Samples were prepared by mixing various chemicals with water in specified orders and speeds to produce a "slurry". For half the observations, the slurry was (i) dried, (ii) rinsed with distilled water and (iii) calcinated; this was called the DRC procedure. For the remaining observations, (ii) and (iii) were interchanged to give the DCR procedure. In the first of their experiments, all factors had two levels, coded here as 0 or 1. These factors were \(A\) Mixing order, \(B\) speed of water addition (slow, fast), \(C\) amount of water (7 ml, 25 ml), \(D\) rinsing order (DRC, DCR), \(E\) drying time (3 h, 24 h), \(F\) drying temperature (25 degC, 100 degC), \(G\) calcination ramp rate (2 degC/min, 20 degC/min), \(H\) calcination temperature (400 degC, 700 degC), \(I\) calcination time (2 h, 20 h), \(J\) amount of an aluminium compound added (5, 22). A 210-6 resolution III fraction was

\begin{table}
\begin{tabular}{c c c c c c c c c c} \hline \(A\) & \(B\) & \(C\) & \(D\) & \(E\) & \(F\) & \(G\) & \(H\) & \(I\) & \(J\) & Pore diameter \\ \hline
0 & 0 & 0 & 0 & 1 & 0 & 0 & 1 & 0 & 0 & 6.4 \\
1 & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 1 & 1 & 5.7 \\
0 & 1 & 0 & 0 & 0 & 1 & 0 & 1 & 1 & 1 & 6.1 \\
1 & 1 & 0 & 0 & 1 & 1 & 1 & 1 & 0 & 0 & 7.6 \\
0 & 0 & 1 & 0 & 0 & 1 & 1 & 0 & 0 & 1 & 3.5 \\
1 & 0 & 1 & 0 & 1 & 1 & 0 & 0 & 1 & 0 & 3.5 \\
0 & 1 & 1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 3.7 \\
1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 6.5 \\
0 & 0 & 0 & 1 & 0 & 1 & 1 & 0 & 1 & 0 & 10.1 \\
1 & 0 & 0 & 1 & 1 & 1 & 0 & 0 & 0 & 1 & 3.6 \\
0 & 1 & 0 & 1 & 1 & 0 & 1 & 0 & 0 & 1 & 15.6 \\
1 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 1 & 0 & 12.3 \\
0 & 0 & 1 & 1 & 1 & 0 & 0 & 1 & 1 & 1 & 12.1 \\
1 & 0 & 1 & 1 & 0 & 0 & 1 & 1 & 0 & 0 & 17.3 \\
0 & 1 & 1 & 1 & 0 & 1 & 0 & 1 & 0 & 0 & 14.9 \\
1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 15.3 \\ \hline \end{tabular} _Source_ Olsen et al. (2014), _Journal of Porous Materials_, 21, (c) 2014, Springer Science + Business Media New York. With permission of Springer

\end{table}
Table 15.54: 210−6 resolution III fraction and pore diameter (nm) for the anatase experiment of Exercise 8run. Several responses were measured, including the pore diameters which are listed together with the fraction in Table 15.54. The observations were taken in a random order (not shown here). 1. Part of the aliasing scheme for the design is: \[E = ACD,\ F = BCD\,\ G = ACD,\ H = CD,\ I = ABCD,\ J = ABC\.\] Write out the defining relation for the fraction (a total of 63 contrasts): 2. Fifteen factorial effects can be included in the model. This can include the 10 main effects. Suggest five interaction contrasts to include (these cannot be aliased with main effects nor with each other.) 3. Estimate the 15 contrasts in your model and plot a half normal probability plot. 4. From part (c), which factors seem to affect the pore diameter the most. Suppose you were going to follow up these factors and their interactions in more detail in a later experiment. How would you design such an experiment if you could take 16 observations?
9. **Flour early experiment** The flour experiment was introduced in Example 15.5.1, p. 513. In Table 15.55, we show part of the design for an early experiment (the first in a series of four experiments). Six ingredients, \(A\), \(B\), \(C\), \(D\), \(E\), \(F\), added to the flour were to be investigated in the experiment. In addition, there were three noise factors: Factor \(P\) (which was a combination of factors \(N\) and \(S\) in Example 15.5.1) had two levels ("high yeast with long proof time" or "low yeast with short proof time"), Factor \(Q\), (as in Example 15.5.1, two levels "undermixing, little water, heavy pressure" or "overmixing, much water, little pressure"), and Factor \(R\) (two levels, underbake or overbake). A crossed array was selected. The noise array was a \(\frac{1}{2}\)-fraction with defining relation \(I=PQR\). Each of the four noise combinations was run on a single day, so that the experiment ran over four days. The design array was a \(\frac{1}{4}\)-fraction with defining relation \(I=ABCD=BCEF=ADEF\), and this was run on each day. Thus the noise contrasts are confounded with days and cannot be analyzed. However, the object of the experiment was to examine the average yield (specific volume, ml/100 g) and the variance of the yield for the design factors across the noise factors. 1. Calculate the average yield and the log variance of the yield for each design-treatment combination. 2. Analyze the two sets of data separately. What recommendations would you make if the objective is to reduce the variability and increase the specific volume?
10. **Injection molding experiment** S.R. Schmidt and R.G. Launsby in their book _Understanding Industrial Designed Experiments_ describe an experiment on the effect of six factors on the shrinkage of a part produced by injection molding. The six factors were injection velocity (factor \(A\)), cooling time (factor \(B\)), barrel zone temperature (factor \(C\)), mold temperature (factor \(D\)), hold pressure (factor \(E\)), and back pressure (factor \(F\)). Each factor had two levels coded 0 and 1. There were two responses of interest, the length and width of the part after shrinkage. The purpose of the experiment was to find settings of the six variables that would enable the parts to be "on target," that is, a post-shrinkage length of 14.5 units and width of 9.35 units.

The orthogonal array in Table 15.22, p. 518, was selected with columns columns 1-6 labeled \(A\), \(B\), \(D\), \(C\), \(E\), \(F\), and columns 5 and 6 multiplied by \(-1\). One degree of freedom (corresponding to column 7) is available to measure \(\sigma^{2}\) or one of the two-factor interactions. Five parts were measured at each treatment combination, and the lengths and widths are recorded in Table 15.56.

1. Write down the defining relation for the \(\frac{1}{8}\)-fraction and the aliasing scheme. The investigators assumed that all the interactions were negligible. If they had not done so, which interactions could have been measured?
2. For the length data, calculate the average response and the standard deviation of the response for each treatment combination.
3. Can you recommend which factors should be investigated more thoroughly in order to find a setting that would give the required length and also factors that could be set to reduce the variability?
4. Repeat parts (a) and (b) for the width data.
5. Can you make any overall recommendation?
6. Write down the assumptions on the model that would need to be true in order to interpret the analysis of variance. Are these assumptions likely to be valid for this experiment?

11. **Spectrometer experiment, continued** Read the details of the spectrometer experiment in Exercise 10 of Chap. 7. You will need to have access to your solutions to that exercise to answer this question. Suppose that you are consultant for a different company and that they wish to run a similar experiment, with the same five factors, but with a total of 64 observations. To keep things simple, you might recommend that factors \(A\) and \(C\) be examined at 2 levels each rather than 3 levels in your first experiment (even though you may suspect that some of the factors have quadratic trends).

\begin{table}
\begin{tabular}{c c c c c} \hline Design combinations & \multicolumn{4}{c}{Noise combinations} \\  & Day 1 & Day 2 & Day 3 & Day 4 \\  & (111) & (101) & (000) & (011) \\ \hline
000000 & 519 & 446 & 337 & 415 \\
000011 & 503 & 468 & 343 & 418 \\
001101 & 567 & 471 & 355 & 424 \\
001110 & 552 & 489 & 361 & 425 \\
010101 & 534 & 466 & 356 & 431 \\
010110 & 549 & 461 & 354 & 427 \\
011000 & 560 & 480 & 345 & 437 \\
011011 & 535 & 477 & 363 & 418 \\
100100 & 558 & 483 & 376 & 418 \\
100111 & 551 & 472 & 349 & 426 \\
101001 & 576 & 487 & 358 & 434 \\
101010 & 569 & 494 & 357 & 444 \\
110001 & 562 & 474 & 358 & 404 \\
110010 & 569 & 494 & 348 & 400 \\
111100 & 568 & 478 & 367 & 463 \\
111111 & 551 & 500 & 373 & 462 \\ \hline \end{tabular} _Source_ Tuck et al. (1993). Copyright © 1993 Blackwell Publishers. Reprinted with permission

\end{table}
Table 15.55: Specific volume for part of experiment 1 of the flour early experiment Thus, you have a \(2^{5}\) experiment. List 5 interactions that you are particularly interested in studying. You should use information from your answer to (a) and (b) of Exercise 10 of Chap. 7 in choosing the interactions. Design a factorial experiment in 4 blocks of size 8. State exactly how you chose your design. Write out at least three of the treatment combinations in two of the blocks and explain how you obtained them.
12. **Design of industrial experiment** Suppose that you are asked to design an experiment for 6 treatment factors each having two levels. Only 64 observations can be taken in total, and these should be divided into 8 blocks of size 8. Suppose that you decide to confound the interaction contrasts \(ABD\), \(DEF\), and \(ACDF\). 1. Can all the other interaction contrasts be estimated? 2. What does the statement "\(ABD\) is confounded" mean? 3. How would you obtain the 8 blocks? Write out two blocks as an example. 4. Suppose that the budget is cut before the experiment can take place, and only 8 observations can be taken in total. How would you decide which 8 observations to take? What can be estimated? 5. Suppose that you were fairly sure that all interactions involving 4 factors or more were negligible and that neither \(D\) nor \(F\) interacts with any of the other factors. Suppose that the analysis of variance table obtained from the results of the experiment is as in Table 15.7. What would you investigate in a followup experiment? Give your reasons.

\begin{table}
\begin{tabular}{c c c c c c c c c c c c c c} \hline \multicolumn{4}{c}{Source of variation} & \multicolumn{2}{c}{Degrees of freedom} & \multicolumn{2}{c}{Sum of squares} & Mean square & Ratio & \(p\)-value \\ \hline \(A\) & & 1 & 262.205 & & 262.205 & & 54.57 & 0.0857 \\ \(B\) & & 1 & 11.045 & & 11.045 & & 2.30 & 0.3712 \\ \(C\) & & 1 & 981.245 & & 981.245 & & 204.21 & 0.0445 \\ \(D\) & & 1 & 5.120 & & 5.120 & & 1.07 & 0.4899 \\ \(E\) & & 1 & 1568.000 & & 1568.000 & & 326.33 & 0.0352 \\ \(F\) & & 1 & 8.820 & & 8.820 & & 1.84 & 0.4048 \\ Error & & 1 & 4.805 & & 4.805 & & & & & \\ Total & & 7 & 2841.240 & & & & & & & & \\ \hline \end{tabular}
\end{table}
Table 15.56: Lengths and widths of parts after shrinkage in the injection molding experiment

\begin{table}
\begin{tabular}{c c c c c c c c c c c c c c} \hline \multicolumn{4}{c}{Treatment combinations} & \multicolumn{4}{c}{Length (Deviation from 14.5) \(\times 10^{4}\)} & \multicolumn{4}{c}{Width (Deviation from 9.35) \(\times 10^{4}\)} \\ \(A\) & \(B\) & \(C\) & \(D\) & \(E\) & \(F\) & & & & & & & & & \\ \hline
0 & 0 & 0 & 0 & 0 & 0 & 0 & 5 & 0 & 0 & 5 & 75 & 60 & 70 & 85 & 90 \\
0 & 0 & 0 & 1 & 1 & 1 & 75 & 90 & 70 & 65 & 65 & 50 & 40 & 40 & 40 & 45 \\
0 & 1 & 1 & 0 & 0 & 1 & 45 & 50 & 45 & 45 & 45 & 45 & 45 & 45 & 50 & 40 \\
0 & 1 & 1 & 1 & 1 & 0 & 100 & 105 & 105 & 110 & 105 & 130 & 130 & 125 & 135 & 135 \\
1 & 0 & 1 & 0 & 1 & 0 & 105 & 110 & 105 & 120 & 100 & 55 & 60 & 60 & 55 & 60 \\
1 & 0 & 1 & 1 & 0 & 1 & 45 & 55 & 65 & 50 & 50 & 80 & 65 & 50 & 40 & 45 \\
1 & 1 & 0 & 0 & 1 & 1 & 150 & 140 & 155 & 50 & 145 & 100 & 80 & 85 & 90 & 85 \\
1 & 1 & 0 & 1 & 0 & 0 & 55 & 65 & 55 & 55 & 60 & 65 & 60 & 65 & 65 & 60 \\ \hline \end{tabular}
\end{table}
Table 15.57: Analysis of variance for the industrial experiment 

[MISSING_PAGE_FAIL:575]

3. Using the _first_ column of the design in Table 15.58 as a branching column, create a supersaturated design corresponding to \(+1\) in the branching column. 4. The supersaturated design in part (c) has 10 observations which may not be quite sufficient to be able to detect four large main effects. Run an all-subsets regression using the 10 observations. How many of the four important factors can be detected and what are their main effect estimates?
15. **Anatase experiment** The anatase experiment was described in Exercise 8. After the initial experiment, several further experiments were run. Table 15.59 shows one of the definitive screening designs (where factor \(D\) of Exercise 8 has been set at level DCR, and factor \(A\) held constant). The response shown is pore diameter (nm), The randomized order of the observations is shown in the original paper. The design allows linear and quadratic trends in the main effects of some factors and some of the linear\(\times\)linear interactions to be measured. 1. Use an all subsets regression to find a model that explains much of the variability in the data (\(R^{2}\) at least 0.90). Remember to include the main effects of any factors that are involved in large linear\(\times\)linear interactions. 2. If you were to design a follow-up experiment, which factors (and interactions) would you examine? Suggest a suitable design if you could take 16 more observations. _Sources_ Olsen et al. (2014), _Journal of Porous Materials_, 21, (c) 2014, Springer Science + Business Media New York. With permission of Springer

\begin{table}
\begin{tabular}{c c c c c c c c c} \hline \(B\) & \(C\) & \(E\) & \(F\) & \(G\) & \(H\) & \(I\) & \(J\) & Pore diameter \\ \hline \(0\) & \(-1\) & \(1\) & \(1\) & \(-1\) & \(1\) & \(1\) & \(1\) & \(9.0\) \\ \(0\) & \(1\) & \(-1\) & \(-1\) & \(1\) & \(-1\) & \(-1\) & \(-1\) & \(10.3\) \\ \(-1\) & \(0\) & \(-1\) & \(1\) & \(1\) & \(1\) & \(1\) & \(-1\) & \(14.6\) \\ \(1\) & \(0\) & \(1\) & \(-1\) & \(-1\) & \(-1\) & \(-1\) & \(1\) & \(16.9\) \\ \(-1\) & \(-1\) & \(0\) & \(1\) & \(1\) & \(-1\) & \(-1\) & \(0\) & \(6.6\) \\ \(1\) & \(1\) & \(0\) & \(-1\) & \(-1\) & \(1\) & \(1\) & \(-1\) & \(13.3\) \\ \(1\) & \(-1\) & \(1\) & \(0\) & \(1\) & \(1\) & \(-1\) & \(-1\) & \(15.3\) \\ \(-1\) & \(1\) & \(-1\) & \(0\) & \(-1\) & \(-1\) & \(1\) & \(1\) & \(7.8\) \\ \(-1\) & \(-1\) & \(1\) & \(-1\) & \(0\) & \(-1\) & \(1\) & \(-1\) & \(11.0\) \\ \(1\) & \(1\) & \(-1\) & \(1\) & \(0\) & \(1\) & \(-1\) & \(1\) & \(14.0\) \\ \(1\) & \(-1\) & \(-1\) & \(-1\) & \(1\) & \(0\) & \(1\) & \(1\) & \(11.2\) \\ \(-1\) & \(1\) & \(1\) & \(1\) & \(-1\) & \(0\) & \(-1\) & \(-1\) & \(9.3\) \\ \(-1\) & \(1\) & \(1\) & \(-1\) & \(1\) & \(1\) & \(0\) & \(1\) & \(8.5\) \\ \(1\) & \(-1\) & \(-1\) & \(1\) & \(-1\) & \(-1\) & \(0\) & \(-1\) & \(10.0\) \\ \(1\) & \(1\) & \(1\) & \(1\) & \(1\) & \(-1\) & \(1\) & \(1\) & \(0\) & \(18.6\) \\ \(-1\) & \(-1\) & \(-1\) & \(-1\) & \(-1\) & \(1\) & \(-1\) & \(0\) & \(11.8\) \\ \(0\) & \(0\) & \(0\) & \(0\) & \(0\) & \(0\) & \(0\) & \(0\) & \(12.5\) \\ \hline \end{tabular}
\end{table}
Table 15.59: Definitive screening design and pore diameter (nm) for the anatase experiment of Exercise 15

\begin{table}
\begin{tabular}{c c c c} \hline \(2^{p-s}\) & \(v\) & Defining relation & Equations \\ \hline \(2_{\mbox{III}}^{5-2}\) & 8 & \(I=\Delta BCE=ABD=CDE\) & \(a_{4}=a_{1}+a_{2}\) \\  & & (\(AC\)) & \(a_{5}=a_{1}+a_{2}+a_{3}\) \\ \(2_{\mbox{IV}}^{6-2}\) & 16 & \(I=\Delta BCD=CDEF=ABEF\) & \(a_{4}=a_{1}+a_{2}+a_{3}\) \\  & & (\(ACE\)) & \(a_{6}=a_{3}+a_{4}+a_{5}\) \\ \(2_{\mbox{IV}}^{7-2}\) & 32 & \(I=\Delta BCDE=\Delta BFG=CDEFG\) & \(a_{5}=a_{1}+a_{2}+a_{3}+a_{4}\) \\  & & (\(AEF\)) & \(a_{7}=a_{1}+a_{2}+a_{6}\) \\ \(2_{\mbox{V}}^{8-2}\) & 64 & \(I=\Delta BCDE=DEFGH=ABCFGH\) & \(a_{5}=a_{1}+a_{2}+a_{3}+a_{4}\) \\  & & (\(CEF\)) & \(a_{8}=a_{4}+a_{5}+a_{6}+a_{7}\) \\ \hline \(2_{\mbox{III}}^{6-3}\) & 8 & \(I=BCD=\Delta BE=ACDE\) & \(a_{4}=a_{2}+a_{3}\) \\  & & \(=\Delta BCF=ADF=CEF\) & \(a_{5}=a_{1}+a_{2}\) \\  & & \(=\Delta BEF\) (\(AC\)) & \(a_{6}=a_{1}+a_{2}+a_{3}\) \\ \(2_{\mbox{IV}}^{7-3}\) & 16 & \(I=\Delta BCD=CDEF=ABEF\) & \(a_{4}=a_{1}+a_{2}+a_{3}\) \\  & & \(=\Delta CEG=BDEG=ADFG\) & \(a_{6}=a_{3}+a_{4}+a_{5}\) \\  & & \(=BCFG\) (\(ACF\)) & \(a_{7}=a_{1}+a_{3}+a_{5}\) \\ \(2_{\mbox{IV}}^{8-3}\) & 32 & \(I=\Delta BCD=CDEF=ABEF\) & \(a_{4}=a_{1}+a_{2}+a_{3}\) \\  & & \(=\Delta CEGH=BDEGH=ADFGH\) & \(a_{6}=a_{3}+a_{4}+a_{5}\) \\  & & \(=BCFGH\) (\(ABG\)) & \(a_{8}=a_{1}+a_{3}+a_{5}+a_{7}\) \\ \(2_{\mbox{IV}}^{9-3}\) & 64 & \(I=CDEF=ACEGH=ADFGH\) & \(a_{4}=a_{1}+a_{2}+a_{3}\) \\  & & \(=\Delta BCDJ=ABEFJ=BDEGHJ\) & \(a_{8}=a_{1}+a_{3}+a_{5}+a_{7}\) \\  & & \(=BCFGHJ\) (\(ACF\)) & \(a_{9}=a_{1}+a_{2}+a_{3}+a_{4}\) \\ \hline \(2_{\mbox{III}}^{7-4}\) & 8 & \(I=\Delta BCD=BCE=ADE\) & \(a_{4}=a_{1}+a_{2}+a_{3}\) \\  & & \(=\Delta ACF=BDF=ABEF\) & \(a_{5}=a_{2}+a_{3}\) \\  & & \(=CDEF=ABG=CDG\) & \(a_{6}=a_{1}+a_{3}\) \\  & & \(=ACEG=BDEG=BCFG\) & \(a_{7}=a_{1}+a_{2}\) \\  & & \(=ADFG=EFG=ABCDEFG\) & \\ \(2_{\mbox{IV}}^{8-4}\) & 16 & \(I=\Delta BCD=CDEF=ABEF\) & \(a_{4}=a_{1}+a_{2}+a_{3}\) \\  & & \(=\Delta DFG=BCFG=ACEG\) & \(a_{6}=a_{3}+a_{4}+a_{5}\) \\  & & \(=BDEG=ABGH=CDGH\) & \(a_{7}=a_{1}+a_{4}+a_{6}\) \\  & & \(=ABCDEFGH=EFGH=BDFH\) & \(a_{8}=a_{1}+a_{2}+a_{7}\) \\  & & \(=ACFH=BCEH=ADEH\) & \\  & & (\(ADH\)) & \\ \(2_{\mbox{IV}}^{9\to 4}\) & 32 & \(I=ABCD=CDEF=ABEF\) & \(a_{4}=a_{1}+a_{2}+a_{3}\) \\  & & \(=ADFGH=BCFGH=ACEGH\) & \(a_{6}=a_{3}+a_{4}+a_{5}\) \\  & & \(=BDEGH=ABGJ=CDGJ\) & \(a_{7}=a_{1}+a_{4}+a_{5}+a_{6}\) \\  & & \(=ABCDEFGH=EFGJ=BDFHJ\) & \(a_{8}=a_{1}+a_{2}+a_{7}\) \\  & & \(=ACFHJ=BCEHJ=ADEHJ\) & \\  & & (\(ABH\)) & \\ \hline \end{tabular}
\end{table}
Table 60: \(2^{p-s}\) fractions of \(2^{p}\) experiments. For each defining relation, \(s\) independent generators are underlined, and \(s\) corresponding equations are given. To obtain the \(v=2^{p-s}\) treatment combinations in the fraction, list all \(v\) combinations of levels \(a_{i}\) of the \(p-s\) factors not determined by the equations, then use the equations modulo 2 to complete each treatment combination. For two blocks, confound the effect in parentheses and its aliases

[MISSING_PAGE_EMPTY:8513]

[MISSING_PAGE_EMPTY:8514]

\begin{table}
\begin{tabular}{c c c c c c c c c} \hline  & & & & & & & & & For \(L_{18}(3^{7}\times 2)\) & replace \\  & & & & & & & & 6-level column by the \\  & & & & & & & & two columns below \\ \hline

[MISSING_PAGE_POST]

 \hline \end{tabular}
\end{table}
Table 15.64: Orthogonal arrays for 18 observations: \(L_{18}(3^{6}\times 6)\) and \(L_{18}(3^{7}\times 2)\)

\begin{table}
\begin{tabular}{c c c c c c c c c c c c c}  & \multicolumn{10}{c}{Columns} \\

[MISSING_PAGE_POST]

 \hline \(A\) & \(B\) & & & & & & & \(D\) & \(E\) & \(F\) & \(G\) & & & \\ \end{tabular}
\end{table}
Table 5.65: A \(3^{p}\) orthogonal array for 27 observations: \(L_{27}(3^{13})\)

### 16.1 Introduction

Response surface methodology was developed by Box and Wilson in 1951 to aid the improvement of manufacturing processes in the chemical industry. The purpose was to optimize chemical reactions to obtain, for example, high yield and purity at low cost. This was accomplished through the use of sequential experimentation involving factors such as temperature, pressure, duration of reaction, and proportion of reactants. The same methodology can be used to model or optimize any response that is affected by the levels of one or more quantitative factors. The models are generalizations of the polynomial regression models studied in Chap. 8.

The general scenario is as follows. The response is a quantitative continuous variable (e.g., yield, purity, cost), and the mean response is a smooth but unknown function of the levels of \(p\) factors (e.g., temperature, pressure), and the levels are real-valued and accurately controllable. The mean response, when plotted as a function of the treatment combinations, is a surface in \(p+1\) dimensions, called the _response surface_. For example, Fig. 16.1 shows a response surface for two factors \(A\) and \(B\).

We will denote the levels of \(A\) by values of \(x_{1}\) or \(x_{A}\) and the levels of \(B\) by values of \(x_{2}\) or \(x_{B}\). We will denote a treatment combination by \(\mathbf{x}=(x_{1},\,x_{2},\,\ldots,\,x_{p})\) or by \(\mathbf{x}=(x_{A},\,x_{B},\,\ldots,\,x_{P})\) and the mean response at \(\mathbf{x}\) by \(\eta_{\mathbf{x}}=E[Y_{\mathbf{x}}]\). The general response surface model is of the form

\[Y_{\mathbf{x}}=\eta_{\mathbf{x}}+\epsilon_{\mathbf{x}}\,,\]

where \(\epsilon_{\mathbf{x}}\) is a random error variable.

The objective of obtaining a response surface is twofold:

1. to locate a feasible treatment combination \(\mathbf{x}\) for which the mean response is maximized (or minimized, or equal to a specific target value); and
2. to estimate the response surface in the vicinity of this good location or region, in order to better understand the "local" effects of the factors on the mean response.

In general, throughout the chapter we will think about maximizing the response, but we show via an example that exactly the same techniques can be used for minimizing a response. The techniques can easily be adapted when the goal is to have the response close to a target value.

One possible approach to achieving the objective involves collecting observations at each location on a grid of treatment combinations spanning the entire experimental region of interest (as suggested by Fig. 16.1). However, the number of observations required by such a comprehensive approach can be very large, and it grows very quickly as the number of factors under study increases. Also, somewhat sophisticated modeling techniques would generally be needed to obtain an adequate fit of a model over the entire region. Instead, it is generally more efficient to conduct a sequence of small "local" experiments with which to search out the location of the peak mean response and then to study its vicinity.

Seeking out the peak is analogous to climbing an unfamiliar mountain under conditions of limited visibility--the mountain is the response surface, and your location on the mountainside is a treatment combination, say **x\({}_{a}\)**. Standing at position **x\({}_{a}\)**, you look around and can see enough to determine in which direction to go to continue a steep ascent. Then you climb in the determined direction as long as it continues to take you up, not looking about last you lose footing. Then you stop and look around again to determine whether you are at the top of the mountain or in which direction you need to continue your ascent. Of course, when you reach a peak, due to the limited visibility, you may not be sure that you have actually reached the highest peak.

How does one do this experimentally? Looking around with limited visibility is equivalent to analyzing the data of a _local experiment_, consisting of observations on treatment combinations **x** close to your current position, **x\({}_{a}\)**. The local terrain is assessed by fitting a local model. Collecting observations in sufficiently close proximity to one another generally allows the local response surface to be well approximated by a rather simple polynomial regression model. When still far from the peak, a first-order model is often adequate. The fitted first-order model is a plane, from which the direction or _path of steepest ascent_ is easily determined. Then observations are collected along this path as long as the response continues to increase. When the response stops increasing, another local experiment can be conducted to determine a new path of steepest ascent. This process can be iterated until the first-order model no longer adequately describes the local true surface. For example, close to the peak, the true surface generally exhibits greater curvature, and a first-order regression model becomes inadequate, exhibiting lack of fit. A larger number of observations is needed to fit a higher-order model with which to locate and study the vicinity of the peak. Typically, a second-order model is suitable.

A flow chart describing the steps in this process is shown in Fig. 16.2. While a surface is difficult to envisage in more than three dimensions, the process can work well for any number of factors. How well it works depends on several decisions requiring judgment on the part of the experimenter. The first part of this chapter (Sect. 16.2) looks at the left-hand portion of the flow chart and investigates first-order designs and first-order models, including lack of fit and the path of steepest ascent. Section 16.3

Figure 16.1: Hypothetical response surface for two factors

addresses the right-hand portion of the flow chart, which becomes relevant when the vicinity of the peak is reached. Second-order designs and models are described. More details about second-order designs are given in Sect. 16.4, and an experiment conducted in the flour milling industry is described in Sect. 16.5. The collection of observations as a block design is discussed in Sect. 16.6. Sections 16.7 and 16.8 describe the use of the SAS and R software, respectively.

### First-Order Designs and Analysis

#### Models

Before the peak of the response surface is reached, a small local experiment is conducted to assess the local terrain. If the local experiment is not in the vicinity of the peak, then a first-order regression model often provides an adequate approximation to the local response surface. For \(p\) factors, the standard _first-order model_ is a first-order polynomial regression model:

Figure 16.2: Flow chart for response surface methods

\[Y_{{\bf x},t}=\beta_{0}+\beta_{1}x_{1}+\cdots+\beta_{p}x_{p}+\epsilon_{{\bf x},t}\, \tag{16.2.1}\]

where \(Y_{{\bf x},t}\) denotes the \(t\)th observation at treatment combination \({\bf x}=(x_{1},\ldots,\,x_{p})\), and the error variables \(\epsilon_{{\bf x},t}\) are assumed to be independent with \(N(0,\sigma^{2})\) distributions. The parameter \(\beta_{i}\) is a measure of the local _linear effect_ of the \(i\)th factor (\(i=1,\,\ldots,\,p\)).

We often code the levels of each factor in each local experiment so that zero represents the _midrange_ of the levels of the factor (the average of the highest and lowest levels included in the experiment) and \(+1\) and \(-1\) represent the highest and lowest levels of the factor, respectively. For the \(i\)th factor, such coded levels \(z_{i}\) are obtained as

\[z_{i}=(x_{i}-m_{i})/\,h_{i}\, \tag{16.2.2}\]

where \(m_{i}\) denotes the midrange of the values of \(x_{i}\) of the \(i\)th factor, and \(h_{i}\) denotes the _half-range_--half of the range. So, in terms of coded levels, the center of the design corresponds to the point \({\bf z}_{0}=(0,\,0,\,\ldots,\,0)\).

The first-order model (16.2.1) can be rewritten in terms of the coded factor levels as follows:

\[Y_{{\bf z},t}=\gamma_{0}+\gamma_{1}z_{1}+\cdots+\gamma_{p}z_{p}+\epsilon_{{\bf z },t}. \tag{16.2.3}\]

The parameters in models (16.2.1) and (16.2.3) are related, since

\[\beta_{0}=\gamma_{0}-\sum_{i}m_{i}\,\gamma_{i}/\,h_{i}\quad\mbox{and}\quad\beta _{i}=\gamma_{i}/\,h_{i}\ \ (i=1,\,2,\ldots,\,p)\.\]

A design for estimating the parameters of a first-order model is called a _first-order design_. A first-order design should (i) allow for efficient estimation of each linear effect \(\beta_{i}\) or \(\gamma_{i}\), (ii) allow a test for lack of fit of the first-order model, and (iii) be expandable to a good second-order design.

As long as there is no significant model lack of fit but there are significant linear effects, the fitted first-order model can be used to estimate the path of steepest ascent. If there is significant lack of fit of the first-order model, then additional observations may be collected to augment the first-order design so that a second-order polynomial regression model can be fitted to the data.

If there is no significant model lack of fit and also no significant linear effects, then more data may be needed to increase precision of the parameter estimators. Alternatively, the experimenters may need to change the factors under study or increase the range of levels.

#### Standard First-Order Designs

Throughout the rest of Sect. 16.2, we consider designs which we refer to as _standard first-order designs_. These designs consist of \(n_{f}\) "factorial points" and \(n_{0}\) "center points." The _factorial points_ consist of the treatment combinations of a \(2^{p}\) factorial experiment run as a completely randomized design as in Chap. 7, or a \(2^{p-s}\) fractional factorial design of Resolution III or higher. The _center points_ are observations collected at the center of the local region under study; that is, at \(z_{0}=(0,\,0,\,\ldots,\,0)\). These are needed to provide error degrees of freedom and to provide adequate power for a test for model lack of fit.

Standard first-order designs are _orthogonal_, which means that

1. for each factor, the sum of the coded levels used in the design is zero, (\(\sum z_{i}=0\), summing over observations), so half of the \(n_{f}\) factorial points in the design have each factor at its high level and the other half have each factor at its low level; and
2. for each pair of factors, the sum of cross products of the coded levels in the design is zero (\(\sum z_{i}z_{j}=0\), summing over observations).

The factorial portion of the design is chosen to be at least Resolution III so that the linear effects can be estimated. Higher resolution allows model lack of fit due to two-factor interaction effects to be tested. The \(2^{p-s}\) orthogonal fractional factorial designs and the Plackett-Burman designs of Chap. 15 are the most efficient designs for estimation of the linear effects.

#### Least Squares Estimation

The method of least squares (as shown in optional Sect. 8.3) is used to fit a first-order model to the data. Denote the fitted model by

\[\hat{y}_{\mathbf{x}}=\hat{\beta}_{0}+\hat{\beta}_{1}x_{1}+\cdots+\hat{\beta}_{p} x_{p} \tag{16.2.4}\]

or, in coded form,

\[\hat{y}_{\mathbf{z}}=\hat{\gamma}_{0}+\hat{\gamma}_{1}z_{1}+\cdots+\hat{\gamma }_{p}z_{p}\,. \tag{16.2.5}\]

If a standard first-order design is used, with the extreme levels of each factor coded as \(+1\) and \(-1\), then the least squares estimator \(\hat{\gamma}_{i}\) of the linear effect \(\gamma_{i}\) of the \(i\)th factor is

\[\hat{\gamma}_{i}=(\overline{Y}_{z_{i}(+1)}-\overline{Y}_{z_{i}(-1)})/2\,, \tag{16.2.6}\]

where \(\overline{Y}_{z_{i}(+1)}\) and \(\overline{Y}_{z_{i}(-1)}\) denote the averages of the response variables at the high and the low level of the \(i\)th factor, respectively. The parameter \(2\gamma_{i}\) denotes the change in the mean response between the high and low levels of the \(i\)th factor. This is the same as the main-effect contrast for the \(i\)th factor. The least squares estimator of \(\beta_{i}\) in the uncoded model is \(\hat{\beta}_{i}=\hat{\gamma}_{i}/h_{i}\), where \(h_{i}\) is the half-range of the uncoded levels of the \(i\)th factor.

##### 2.2.1 _Paint experiment, continued_

Several experiments were run in Germany by Eibl et al. (1992) on the thickness of a paint coating. The first experiment in the series was examined in Exercise 7 of Chap. 15. To study how to decrease the mean thickness, the experimenters selected the following six factors, each at two levels:

\[\begin{array}{l}A:\text{ belt speed}\qquad\quad B:\text{ tube width }\,C:\text{ pump pressure}\\ D:\text{ paint viscosity }\,E:\text{ tube height }F:\text{ heating temperature}\end{array}\]

They used a \(2^{6-3}_{III}\) fractional factorial design with defining relation

\[I=BCD=ADE=ABCE=ABF=ACDF=BDEF=CEF.\]The experimenters decided to ignore all interactions for this first experiment. Since they wanted to monitor the variation of the paint thickness, they took four observations on each of the 8 treatment combinations in the fraction. The data are shown in Table 16.1, with factor levels coded as -1 and 1. If the data were collected in a completely random order, model (16.2.5) can be fitted using the 32 individual observations.

Using _zA_,..., _zF_ rather than _z1_,..., _z6_ to denote the factor levels, the fitted first-order model for the mean response is

\[\hat{y}_{\mathbf{z}} = \hat{\gamma}_{0} + \hat{\gamma}_{A}z_{A} + \cdots + \hat{\gamma}_{F}z_{F}\] \[= 1.42 - 0.32z_{A} + 0.21z_{B} + 0.12z_{C} + 0.07z_{D} - 0.03z_{E} - 0.01z_{F}\;,\]

where, for example, the parameter estimate \(\hat{\gamma}_{D}\) is calculated as

\[\hat{\gamma}_{D} = (\overline{y}_{z_{D}(+1)} - \overline{y}_{z_{D}(-1)})/2 = (1.493125 - 1.348125)/2 = 0.0725 \approx 0.07\;,\]

where \(\overline{y}_{z_{D}(+1)}\) is the average of the observations with \(D\) at its high level and \(\overline{y}_{z_{D}(-1)}\) is the average of the observations with \(D\) at its low level. 

#### Checking Model Assumptions

Before progressing with the analysis of the fitted model, the model assumptions should be checked. We shall discuss tests for model lack of fit in Sect. 16.2.6.

If there is no model lack of fit, then the error assumptions may be checked using residual plots. If the observations were collected sequentially in a known run order, then the residuals are plotted against run order to check for independence of observations. Residuals are plotted against predicted values to assess equality of error variances. Normality is checked by plotting residuals versus normal scores.

#### Analysis of Variance

Suppose that a standard first-order design has been used, with the extreme levels of each factor coded as -1 and +1. Under the first-order model, it follows from Eq. (16.2.6) that

\begin{table}
\begin{tabular}{r r r r r r r r r r r} \hline _zA_ & _zB_ & _zC_ & _zD_ & _zE_ & _zF_ & _y_**z1** & _y_**z2** & _y_**z3** & _y_**z4** & \(\overline{y}_{\mathbf{z}}\) & \(s_{\mathbf{z}}^{2}\) \\ \hline
1 & \(-1\) & \(1\) & \(-1\) & \(-1\) & \(-1\) & \(-1\) & 1.09 & 1.12 & 0.83 & 0.88 & 0.9800 & 0.021400 \\ \(-1\) & \(-1\) & \(1\) & \(-1\) & \(1\) & 1 & 1.62 & 1.49 & 1.48 & 1.59 & 1.5450 & 0.004967 \\
1 & \(1\) & \(-1\) & \(-1\) & \(-1\) & \(-1\) & 1 & 0.88 & 1.29 & 1.04 & 1.31 & 1.1300 & 0.042867 \\ \(-1\) & \(1\) & \(-1\) & \(-1\) & 1 & \(-1\) & 1.83 & 1.65 & 1.71 & 1.76 & 1.7375 & 0.005825 \\ \(-1\) & \(-1\) & \(-1\) & 1 & \(-1\) & 1 & 1.46 & 1.51 & 1.59 & 1.40 & 1.4900 & 0.006467 \\
1 & \(-1\) & \(-1\) & 1 & 1 & \(-1\) & 0.74 & 0.98 & 0.79 & 0.83 & 0.8350 & 0.010700 \\ \(-1\) & \(1\) & \(1\) & 1 & \(-1\) & \(-1\) & 2.05 & 2.17 & 2.36 & 2.12 & 2.1750 & 0.017633 \\
1 & \(1\) & \(1\) & 1 & 1 & 1 & 1.51 & 1.46 & 1.42 & 1.40 & 1.4475 & 0.002358 \\ \hline \end{tabular}
\end{table}
Table 16.1: Paint thickness for the paint experiment \[\text{Var}(\hat{\gamma}_{i})=\left(\frac{\sigma^{2}}{n_{f}/2}+\frac{\sigma^{2}}{n_ {f}/2}\right)/4=\sigma^{2}/n_{f}\,\]

for any \(i=A\), \(B\), \(C\),.... The sum of squares for testing that the main-effect contrast \(\gamma_{A}\) is zero (that is, \(H_{0}^{A}:\gamma_{A}=0\) against \(H_{A}^{A}:\gamma_{A}\neq 0\)) is

\[s\text{s}A\ =\ \hat{\gamma}_{A}^{2}/(1/n_{f})\ =\ n_{f}\hat{\gamma}_{A}^{2}\,\]

and since there is only one degree of freedom for the \(A\) contrast, \(\text{m}\text{s}A=\text{s}\text{s}A\). For the first-order model and a standard first-order design, we have expected mean square

\[E[\text{M}\text{s}A]\ =\ n_{f}E[\hat{\gamma}_{A}^{2}]\ =\ n_{f}\text{Var}(\hat{ \gamma}_{A})+n_{f}(E[\hat{\gamma}_{A}])^{2}\ =\ \sigma^{2}+n_{f}\gamma_{A}^{2}\.\]

It can also be shown that \(\text{m}\text{s}E=\text{s}\text{s}E/(n-p-1)\) is an unbiased estimate of \(\sigma^{2}\), where \(\text{s}\text{s}E\) is obtained by subtraction in the analysis of variance table. Consequently, the decision rule for testing \(H_{0}^{A}\) against \(H_{A}^{A}\) is

\[\text{reject }H_{0}^{A}\quad\text{if}\quad\text{m}\text{s}A/\text{m}\text{s}E \ >\ F_{1,n-p-1,\alpha}\,.\]

Similar formulae hold for each main effect. The analysis of variance for the first-order model and a standard first-order design will be illustrated for the paint experiment.

##### 2.2.2 _Paint experiment, continued_

The paint experiment was discussed in Example 2.1, and the data were given in Table 2.1. The purpose of the experiment was to study the effects of six factors on paint thickness. The experimental design consisted of four observations on each of the treatment combinations of a \(2^{6-3}_{III}\) design, which is an orthogonal factorial design with \(n_{f}=32\) factorial points and no center points. The analysis of variance for a first order model is shown in Table 2.2, together with the expected mean squares. The linear effect of each of factors \(A\), \(B\), \(C\), and \(D\) is significantly different from zero, but factors \(E\) and \(F\) appear to have little effect on the response.

\begin{table}
\begin{tabular}{c c c c c c c} \hline Source of variation & Degrees of freedom & Sum of squares & Mean square & Ratio & \(p\)-value & Expected mean square \\ \hline \(A\) & 1 & 3.2640 & 3.2640 & 242.07 & 0.0001 & \(\sigma^{2}+32\gamma_{A}^{2}\) \\ \(B\) & 1 & 1.3448 & 1.3448 & 99.73 & 0.0001 & \(\sigma^{2}+32\gamma_{B}^{2}\) \\ \(C\) & 1 & 0.4560 & 0.4560 & 33.82 & 0.0001 & \(\sigma^{2}+32\gamma_{C}^{2}\) \\ \(D\) & 1 & 0.1540 & 0.1540 & 11.42 & 0.0024 & \(\sigma^{2}+32\gamma_{D}^{2}\) \\ \(E\) & 1 & 0.0221 & 0.0221 & 1.64 & 0.2127 & \(\sigma^{2}+32\gamma_{E}^{2}\) \\ \(F\) & 1 & 0.0066 & 0.0066 & 0.49 & 0.4902 & \(\sigma^{2}+32\gamma_{F}^{2}\) \\ Error & 25 & 0.3371 & 0.0135 & & & \(\sigma^{2}\) \\ Total & 31 & 5.5846 & & & & \\ \hline \multicolumn{6}{c}{Computational formulae} \\ \hline \(\text{s}\text{s}\text{i}=n_{f}\hat{\gamma}_{i}^{2}=n_{f}(\nabla_{z_{i}(+1)}- \nabla_{z_{i}(-1)})^{2}/4\), for \(i=A\), \(B\), \(C\), \(\ldots\) & & & \\ \(\text{s}\text{s}\text{E}\text{ by subtraction}\) & & & \(\text{s}

#### Tests for Lack of Fit

A first-order design allows the experimenter to determine when the first-order model is no longer adequate, provided that there are more design points than first-order model parameters, and the design includes replication at one or more points. There is said to be model _lack of fit_ when the model does not adequately represent the mean response as a function of the factor levels. Lack of fit of the first-order model occurs when the local response surface is no longer a plane.

##### Generic Test

Let \(n_{d}\) denote the number of _distinct_ coded treatment combinations \(\mathbf{z}\). For each treatment combination for which there is replication, the sample variance \(s_{\mathbf{z}}^{2}\) of the \(n_{\mathbf{z}}\) observations at that treatment combination provides an unbiased estimate of the error variance \(\sigma^{2}\), whether or not there is model lack of fit. These sample variances can be pooled together to obtain a _sum of squares for pure error_

\[\text{ssPE}=\sum_{\mathbf{z}}(n_{\mathbf{z}}-1)s_{\mathbf{z}}^{2} \tag{16.2.7}\]

with \(n-n_{d}\) degrees of freedom, giving a _mean square for pure error_

\[\text{msPE}=\text{ssPE}/(n-n_{d})\;,\]

with \(E[\text{msPE}]=\sigma^{2}\). The error sum of squares ssE with \(n-p-1\) degrees of freedom is obtained from fitting the first-order model (Table 16.2), and the difference

\[\text{ssLOF}=\text{ssE}-\text{ssPE} \tag{16.2.8}\]

is called the _sum of squares for lack of fit_. The corresponding mean square is

\[\text{msLOF}=\text{ssLOF}/(n_{d}-p-1)\;.\]

The expected mean square is \(E[\text{msLOF}]=\sigma^{2}+\theta^{2}\), where \(\theta^{2}\) is a quadratic function of any higher order parameters that are estimable due to the inclusion of more design points than needed to fit the first order model. Then the ratio

\[\text{msLOF}/\text{msPE}\]

is used to test the null hypothesis of no model lack of fit. The null hypothesis is rejected at level \(\alpha\) if this ratio exceeds \(F_{n_{d}-p-1,n-n_{d},\alpha}\). This lack-of-fit test is summarized in Table 16.3.

##### _Example 16.2.3_

Paint experiment, continued

The paint experiment was described in Example 16.2.1. The analysis of variance for the first-order model was shown in Table 16.2, giving ssE = 0.3371 with 25 degrees of freedom. There were \(n_{\mathbf{z}}=4\) observations at each of eight factorial points, and the corresponding eight sample variances, each with three degrees of freedom, were given in Table 16.1, p. 570. These eight sample variances can be pooled together to obtain

\[\text{ssPE}=\sum_{\mathbf{z}}(4-1)s_{\mathbf{z}}^{2}=0.3367\]based on \(n-n_{d}=32-8=24\) degrees of freedom. The sum of squares for lack of fit is

\[\text{ssLOF}=\text{ssE}-\text{ssPE}=0.3371-0.3367=0.0004\,,\]

and the test is summarized in Table 4. Since the \(p\)-value is large, there is no evidence of lack of fit of the first-order model. 

#### Test for Second-Order Lack of Fit

If the generic test indicates lack of fit of the first-order model, this provides no insight into why the model is not fitting well. To understand the nature of the lack of fit, it can be helpful to consider what the mean square for lack of fit measures in terms of higher-order models. If the first-order model is inadequate, the next possibility is that a second-order model would provide an adequate approximation to the local response surface. If so, then lack of fit of the first-order model is attributable to the presence of either two-factor interactions or to quadratic effects or to both.

If the only lack of fit is due to two-factor interaction effects, this corresponds to a twisting of the response surface. Such lack of fit can be tested if the first-order design allows estimation of two-factor interactions in addition to providing error degrees of freedom. In the paint experiment, for example, it is possible to estimate the \(AC\) interaction effect, in addition to the six main effects, provided that all other interaction effects are known to be negligible.

If the center of the experimental design is near the peak of the response surface, then one would expect quadratic effects, or curvature, to be present and a higher mean response near the design center than at the factorial points. Multiple center points \(\mathbf{z}_{0}=(0,\ldots,0)\) are usually included in a first-order design, because comparison of the mean response at the center of the design region with the mean response at the factorial points provides an effective test for lack of fit due to quadratic effects.

So, to assess second-order lack of fit we fit a second-order polynomial regression model under the alternative hypothesis. With respect to the coded factor levels, the standard _second-order model_ for \(p\) factors is

\begin{table}
\begin{tabular}{c c c c c c} \hline Source of variation & Degrees of freedom & Sum of squares & Mean square & Ratio & \(p\)-value \\ \hline Lack of fit & 1 & 0.0004 & 0.0004 & 0.03 & 0.8594 \\ Pure error & 24 & 0.3367 & 0.0140 & & \\ Error & 25 & 0.3371 & 0.0135 & & \\ \hline \end{tabular}
\end{table}
Table 4: Generic lack-of-fit test for the paint experiment

\begin{table}
\begin{tabular}{c c c c c c} \hline Source of variation & Degrees of freedom & Sum of squares & Mean square & Ratio & Expected mean square \\ \hline Lack of fit & \(n_{d}-p-1\) & ssLOF & msLOF & msLOF/msPE & \(\sigma^{2}+\theta^{2}\) \\ Pure Error & \(n-n_{d}\) & ssPE & msPE & & \(\sigma^{2}\) \\ Error & \(n-p-1\) & ssE & & & \\ \hline \multicolumn{6}{c}{Computational formulae} \\ \hline ssE from Table 2, ssPE \(=\sum_{\mathbf{z}}(n_{\mathbf{z}}-1)s_{\mathbf{z}}^{2}\), ssLOF by subtraction, \(n_{d}\) distinct design points, \(n\) observations total, \(p\) factors, \(\theta\) depends on the nature of estimable model lack of fit \\ \hline \end{tabular}
\end{table}
Table 3: Generic lack-of-fit test for the first-order model 

[MISSING_PAGE_FAIL:591]

process. In the final experiments, conducted in the vicinity of minimum thickness variation, response surface methods were utilized to study the effects of anode-cathode separation (factor _A_) and cathodic current density (factor _B_) on the standard deviation of coating thickness. One experiment used the factorial points of a single replicate \(2^{2}\) design, augmented by two center points. The response was the standard deviation (in \(\mu\)m) of copper-plating thickness. The coded and uncoded factor levels, together with the resulting data, are given in Table 6.

The midrange of levels of factor \(A\) is \((11.5+9.5)/2=10.5\), and the half-range is \((11.5-9.5)/2.0=1.0\). So the coded levels are given by

\[z_{A}=x_{A}-10.5\,.\]

The midrange and half-range of the factor \(B\) levels are \((41+31)/2=36\) and \((41-31)/2=5\), respectively, so the coded levels of factor \(B\) are

\[z_{B}=(x_{B}-36)/5\,.\]

Table 7 shows the analysis of variance, including tests for lack of fit, due to a second-order model. The analyses are identical for coded and uncoded factor levels. There are significant quadratic effects--an indication that quadratic terms for either or both of factors \(A\) and \(B\) are needed to adequately model the response surface. The first-order design is inadequate, then, because not all parameters in

\begin{table}
\begin{tabular}{c c c c c} \hline \multicolumn{2}{c}{Anode–cathode separation (in.)} & \multicolumn{2}{c}{Current density (asf)} & \multicolumn{2}{c}{Standard deviation (\(\mu\)m)} \\ \hline Coded & Uncoded & Coded & Uncoded & \\ \hline \(-1\) & 9.5 & \(-1\) & 31 & 5.60 \\ \(-1\) & 9.5 & 1 & 41 & 6.45 \\ \(1\) & 11.5 & \(-1\) & 31 & 4.84 \\ \(1\) & 11.5 & 1 & 41 & 5.19 \\ \(0\) & 10.5 & 0 & 36 & 4.32 \\ \(0\) & 10.5 & 0 & 36 & 4.25 \\ \hline \end{tabular}
\end{table}
Table 6: Data for the acid copper pattern plating experiment

\begin{table}
\begin{tabular}{l l l l l} \hline Source of variation & Degrees of freedom & Sum of squares & Mean square & Ratio & Expected mean square \\ \hline Interaction & \(m\) & ssf = ssAB + \(\cdots\) & msf & \(\frac{msf}{ms\text{p}E}\) & \(\sigma^{2}+\frac{n_{f}}{m}\theta_{1}\) \\ Quadratic & 1 & ssQ & msQ & \(\frac{msQ}{ms\text{p}E}\) & \(\sigma^{2}+\frac{n_{0}n_{f}}{n}\theta_{2}^{2}\) \\ Higher-order & \(n_{d}-p-m-2\) & ssH & & & \\ Pure Error & \(n-n_{d}\) & ssPE & msPE & \(\sigma^{2}\) \\ Error & \(n-p-1\) & ssE & & & \\ \hline \multicolumn{4}{c}{Computational formulae} \\ \hline \(\text{ssAB}=n_{f}\gamma_{\text{AB}}^{2}=n_{f}\overline{\gamma}_{z_{AA\text{Z}}( +1)}-\overline{\gamma}_{z_{AA\text{Z}}(-1)})^{2}/4\) & & & ssE from Table 6: \\ \(\text{ssQ}=(n_{0}n_{f}/n)^{2}(\overline{\gamma}_{f}-\overline{\gamma}_{0})^{2}\) & & & \(\theta_{1}=\gamma_{AB}^{2}+\cdots\) \\ \(\text{ssPE}=\sum_{\text{z}}(n_{\text{z}}-1)s_{\text{z}}^{2}\) & & & \(\theta_{2}=\gamma_{AA}+\gamma_{BB}+\cdots\) \\ \(\text{ssH}=(\text{ssE}-\text{ssPE})-\text{ssI}-\text{ssQ}\) & & & \\ \hline \end{tabular}
\end{table}
Table 5: Lack-of-fit test for the first-order model, given the data of a standard first-order design, with \(p\) factors \(A\), \(B\),... and \(m\) alias sets for interaction effects clear of main effects the second-order model are estimable. The solution is to collect some additional observations, as will be illustrated in Example 16.3.1. 

#### Path of Steepest Ascent

If there are significant linear effects and there is no significant lack of fit of the first-order model, then the _path of steepest ascent_ may be followed to climb towards the maximum of the response surface.

Given the fitted first-order regression model (16.2.5), the path of steepest ascent from the current position \(\mathbf{z}_{a}\) is determined as follows. If \(\hat{\gamma}_{i}\) is positive, increase \(z_{i}\) to increase predicted mean response \(\hat{y}_{\mathbf{z}}\). If \(\hat{\gamma}_{i}\) is negative, decrease \(z_{i}\) to increase \(\hat{y}_{\mathbf{z}}\). To follow the path of steepest ascent up the fitted response surface, change each \(z_{i}\) in proportion to the magnitude of \(\hat{\gamma}_{i}\). So, if the value \(z_{1}\) of the first factor is changed by \(u\hat{\gamma}_{1}\) units for some real number \(u\), then the level \(z_{i}\) of the \(i\)th factor should be changed by \(u\hat{\gamma}_{i}\) for each other factor \(i\).

The path of steepest ascent is defined above with respect to the coded variables. This presumes that the original variables have been coded in such a way to make the coded scales in some sense comparable. Since the original variable may be measured on scales that are not directly comparable, there is some art to the scaling of the coded variables.

##### Paint experiment, continued

The paint experiment was described in Example 16.2.1, p. 569. The experimenters conducted an experiment to study how to decrease the thickness of a paint coating from about 2 mm to the target 0.8 mm. Four observations were taken at each treatment combination of a \(2^{6-3}_{III}\) design and are shown in Table 16.1, p. 570.

The target thickness is approximately achieved at the experimental design point \(\mathbf{z}=(+1,\,-1,\,-1,\,+1,\,+1,\,-1)\) so perhaps no further analysis or experimentation is needed. Nevertheless, we will use these data to illustrate how to move efficiently towards the lower target response surface value.

Since a lower mean response is required, we need to identify the path of steepest _descent_. The fitted first-order model is obtained from Example 16.2.1 as

\[\hat{y}_{\mathbf{z}} = \hat{\gamma}_{0}+\hat{\gamma}_{A}z_{A}+\cdots+\hat{\gamma}_{F}z_{F}\] \[= 1.42-0.32z_{A}+0.21z_{B}+0.12z_{C}+0.07z_{D}-0.03z_{E}-0.01z_{F}\,.\]

\begin{table}
\begin{tabular}{l c c c c c c} \hline Source of variation & Degrees of freedom & Sum of squares & Mean square & Ratio & \(p\)-value & Expected mean square \\ \hline \(A\) & 1 & 1.0201 & 1.0201 & 1.46 & 0.3137 & \(\sigma^{2}+n_{f}\gamma_{A}^{2}\) \\ \(B\) & 1 & 0.3600 & 0.3600 & 0.51 & 0.5250 & \(\sigma^{2}+n_{f}\gamma_{B}^{2}\) \\ Error & 3 & 2.0986 & 0.6995 & & & \\ \hline Total & 5 & 3.4787 & & & & \\ \hline Interaction AB & 1 & 0.0625 & 0.0625 & 25.51 & 0.1244 & \(\sigma^{2}+n_{f}\gamma_{AB}^{2}\) \\ Quadratic & 1 & 2.0336 & 2.0336 & 830.05 & 0.0221 & \(\sigma^{2}+\frac{n_{0}n_{f}}{n}\theta^{2}\) \\ Pure error & 1 & 0.0025 & 0.0025 & & & \\ \hline Error & 3 & 2.0986 & 0.6995 & & & \\ \hline \end{tabular}
\end{table}
Table 7: Analysis of variance and lack-of-fit test for the acid copper pattern plating experiment The analysis of variance conducted in Example 16.2.2 suggests that only factors \(A\), \(B\), \(C\), and \(D\) significantly affect the response. So, these four factors should be adjusted in an attempt to reduce paint thickness.

Based on the signs of the parameter estimates in the fitted model, we ought to be able to effect a reduction in mean response if we increase the level of factor \(A\) and decrease the level of any of factors \(B\), \(C\), and \(D\). To follow the path of steepest descent, we change the levels of these factors each in proportion to the magnitude of its corresponding parameter estimate, \(\hat{\gamma}_{i}\). So, if we increase \(z_{A}\) by \(0.32u\) units for some real number \(u\), then we decrease \(z_{B}\) by \(0.21u\) units, decrease \(z_{C}\) by \(0.12u\) units, and decrease \(z_{D}\) by \(0.07u\) units.

Observations along the path of steepest descent moving away from the center of the current design, \(\mathbf{z}_{0}=(0,0,0,0,0,0)\), consist of treatment combinations \((0.32u,-0.21u,-0.12u,-0.07u,0,0)\) corresponding to increasing values of \(u\), such as \(u=3,3.5,4,\ldots\). The suggested values of \(u\) start at \(u=3\). This value is large enough to move the level of factor \(A\) near to the edge of the region of the current local experiment and corresponds to \(\hat{y}=0.9226\). For the value \(u=4\), the extrapolated prediction of the first order model is \(\hat{y}=0.7568\), already less than the target value of \(0.8\), making the step sizes reasonable or perhaps a bit too large. Certainly, other values of \(u\) could also have been chosen. Observations may then be collected along this path setting \(u\) equal to each value in turn until the target thickness is achieved, or until the response stops decreasing before reaching the target level. In the latter case, at the point of lowest response along the path another first-order design could be run to determine a new path of steepest descent. 

In the previous example, the effects of factors \(E\) and \(F\) were not found to be significantly different from zero, so their levels were not changed in following the estimated path of steepest descent. There are a variety of reasons why the effect of a factor may be negligible. The obvious reason is that response is independent of the factor. However, it could also be that the levels used for the factor may be near the optimal value, so the response surface may be relatively flat with respect to small changes in the level of that factor. Alternatively, the levels of the factor may simply be too close together to give rise to a detectable change in the mean response. In subsequent experiments, the levels of such factors can be chosen farther apart to guard against the last scenario.

### Second-Order Designs and Analysis

#### Models and Designs

Second-order designs and analysis are used when the test for lack of fit of the first-order model indicates that the vicinity of the maximum (or minimum) of the response surface has been reached and a second-order model should be fitted. For \(p\) factors, the standard second-order model is

\[Y_{\mathbf{x},t}=\beta_{0}+\sum_{i=1}^{p}\beta_{i}x_{i}+\sum_{i=1}^{p}\beta_{ ii}x_{i}^{2}+\sum_{i<j}\beta_{ij}x_{i}x_{j}+\epsilon_{\mathbf{x},t}\,, \tag{16.3.9}\]

where \(Y_{\mathbf{x},t}\) denotes the \(t\)th response observed for treatment combination \(\mathbf{x}=(x_{1},\,x_{2},\,\ldots,\,x_{p})\). The random-error variables \(\epsilon_{\mathbf{x},t}\) are assumed to be independent with \(N(0,\,\sigma^{2})\) distributions. The parameter \(\beta_{i}\) represents the linear effect of the \(i\)th factor. The parameter \(\beta_{ii}\) represents the quadratic effect of the \(i\)th factor, and \(\beta_{ij}\) represents the cross product effect, or interaction effect, between the \(i\)th and \(j\)th factors.

With respect to the coded factor levels \(z_{i}=(x_{i}-m_{i})/\,h_{i}\), the second-order model is

\[Y_{\mathbf{z},t}=\gamma_{0}+\sum_{i=1}^{p}\gamma_{i}z_{i}+\sum_{i=1}^{p}\gamma_{ ii}z_{i}^{2}+\sum_{i<j}\gamma_{ij}z_{i}z_{j}+\epsilon_{\mathbf{z},t}\;. \tag{16.3.10}\]

Experimental designs used to fit a second-order model are referred to as _second-order designs_. A second-order design should (i) allow for efficient estimation of the response surface, in the sense of having \(\text{Var}(\widehat{Y}_{\mathbf{z}})\) be small in the design region; (ii) allow a test for lack of fit of the second-order model; and (iii) allow for efficient estimation of all model parameters. Second-order designs must have at least \((p+1)(p+2)/2\) distinct design points; otherwise, not all of the \((p+1)(p+2)/2\) parameters in the second-order model can be estimated. We will consider only such designs in this chapter. Observations at even more points are needed, plus some replication, in order to be able to conduct a generic test for model lack of fit. Other properties of second-order designs that are sometimes desirable include rotatability, orthogonality, and orthogonal blocking--these will be discussed in Sects. 16.4.1-16.4.3.

The method of least squares is used to fit the second-order model to the data. This method is exactly as discussed in optional Sect. 8.3, with each second-order term \(z_{i}^{2}\) or \(z_{i}z_{j}\) being treated as a single regressor. In terms of the uncoded and coded factor levels, the fitted models are, respectively,

\[\hat{y}_{\mathbf{x}}=\hat{\beta}_{0}+\sum_{i}\hat{\beta}_{i}x_{i}+\sum_{i}\hat {\beta}_{ii}x_{i}^{2}+\sum_{i<j}\hat{\beta}_{ij}x_{i}x_{j} \tag{16.3.11}\]

and

\[\hat{y}_{\mathbf{z}}=\hat{\gamma}_{0}+\sum_{i}\hat{\gamma}_{i}z_{i}+\sum_{i} \hat{\gamma}_{ii}z_{i}^{2}+\sum_{i<j}\hat{\gamma}_{ij}z_{i}z_{j}\;, \tag{16.3.12}\]

where the parameters with hats denote the least squares estimates. Although it is possible to obtain explicit formulae for the least squares estimates for any specific design, the formulae for the quadratic parameter estimates \(\hat{\gamma}_{ii}\) are complicated. Consequently, we rely on statistical computer software to obtain the least squares estimates (see Sects. 16.7 and 16.8 for the use of the SAS and R software, respectively).

As long as there is no significant lack of fit, the fitted second-order model can be used to study the local response surface. Generally, there will be a unique treatment combination \(\mathbf{x}_{s}=(x_{s1},x_{s2},\ldots,x_{sp})\), called the _stationary point_, at which the fitted surface \(\hat{y}_{\mathbf{x}}\) is neither increasing or decreasing--the tangent plane is level. At the stationary point, \(\hat{y}_{\mathbf{x}}\) is maximized, minimized, or is at a saddle point. The surface near a _saddle point_ is reminiscent of a horse saddle--rising up from front to back but sloping down from side to side. A saddle point yields neither a maximum nor a minimum for the fitted model. Instead, these will be found at the boundary of the design region.

If there is significant lack of fit of the second-order model, a higher-order model could be used, or a more local experiment could be run.

#### Central Composite Designs

_Central composite designs_ were first described by Box and Wilson (1951), and they are nowadays the most popular second-order designs. Each design consists of a standard first-order design with \(n_{f}\) orthogonal factorial points and \(n_{0}\) center points, augmented by \(n_{a}\) "axial points."

We follow the convention of coding the factor levels so the factorial points have coded levels \(\pm 1\) for each factor. However, it should be noted that some software packages will recode the levels in a central composite design before doing the analysis. In SAS, for example, the default is to code the extreme levels of each factor as \(\pm 1\), whereas R allows the user to specify the coding. Under our convention, _axial points_ are points located at a specified distance \(\alpha\) from the design center in each direction on each axis defined by the coded factor levels. On the \(z_{i}\)-axis, for example, two axial points are obtained by setting \(z_{i}=\pm\alpha\), with \(z_{j}=0\) for all \(j\neq i\). Thus, if there are \(p\) factors, there are \(2p\) distinct axial points. Axial points are also commonly referred to as _star points_. Figure 16.3 shows central composite designs for \(p=2\) and \(p=3\) factors, with axial points represented by unfilled circles or balls.

A central composite design is easily built up from a standard first-order design by the addition of axial points, and possibly some extra factorial and center points. If the factorial portion of the design is a complete factorial or a fractional factorial of resolution V or more, all parameters of the second-order model are estimable. Otherwise, some aliasing will occur, and some terms will need to be omitted from the second-order model. A design should include enough replication, often at the center points, to allow for a test for model lack of fit. The axial points are located at a distance \(\alpha\) from the center of the design, where the choice of \(\alpha\) depends on the properties required of the design. A popular choice is \(\alpha=(n_{f})^{1/4}\) (see Sect. 16.4.1).

##### 16.3.1 Acid copper pattern plating experiment, continued

In Example 16.2.4, p. 574, a standard first-order design was used to study the effects of anode-cathode separation (factor \(A\)) and cathodic current density (factor \(B\)) on the standard deviation of a copper-plating thickness. The first-order design involved the \(n_{f}=4\) factorial points of a single-replicate \(2^{2}\) design, augmented by \(n_{0}=2\) center points. There was significant lack of fit of the first-order model, so additional observations needed to be taken in order to fit a second-order model. The experimenters augmented the first-order design with four axial points, using \(\alpha\approx(n_{f})^{1/4}=\sqrt{2}\), say \(\alpha=1.4142\), giving the central composite design and data shown in Table 16.8.

The second-order model is fitted by a computer regression package. In terms of the uncoded factor levels, the fitted model is given by

\[\hat{y}_{\mathbf{x}} = \hat{\beta}_{0}+\hat{\beta}_{A}x_{A}+\hat{\beta}_{B}x_{B}+\hat{ \beta}_{AA}x_{A}^{2}+\hat{\beta}_{BB}x_{B}^{2}+\hat{\beta}_{AB}x_{A}x_{B}\] \[= 84.1990-8.8689x_{A}-1.7526x_{B}\] \[\quad+0.4419x_{A}^{2}+0.0286x_{B}^{2}-0.0250x_{A}x_{B}\;,\]

and, in terms of the coded factor levels, \(z_{A}=(x_{A}-10.5)\), \(z_{B}=(x_{B}-36)/5\), the fitted model is

Figure 16.3: Central composite designs for \(p=2\) and \(p=3\) factors

\[\hat{y}_{\mathbf{z}} = \hat{\gamma}_{0}+\hat{\gamma}_{A}z_{A}+\hat{\gamma}_{B}z_{B}+\hat{ \gamma}_{AA}z_{A}^{2}+\hat{\gamma}_{BB}z_{B}^{2}+\hat{\gamma}_{AB}z_{A}z_{B}\] \[= 4.2850-0.4894z_{A}+0.2119z_{B}\] \[\quad+0.4419z_{A}^{2}+0.7144z_{B}^{2}-0.1250z_{A}z_{B}\,.\]

Figure 4 shows both a contour plot and a surface plot of the fitted model for uncoded factor levels. The stationary point is in the center of the ellipses. Clearly, the stationary point provides a minimum. The exact location of the stationary point will be determined in Sect. 16.3.5.

\begin{table}
\begin{tabular}{c c c c c} \hline \multicolumn{2}{c}{Anode–cathode separation (in.)} & \multicolumn{2}{c}{Current density (asf)} & \multicolumn{2}{c}{Standard deviation (μ.m)} \\ \hline Coded & Uncoded & Coded & Uncoded & \\ \hline \(-1.0000\) & 9.5000 & \(-1.0000\) & 31.0000 & 5.60 \\ \(-1.0000\) & 9.5000 & \(1.0000\) & 41.0000 & 6.45 \\ \(1.0000\) & 11.5000 & \(-1.0000\) & 31.0000 & 4.84 \\ \(1.0000\) & 11.5000 & \(1.0000\) & 41.0000 & 5.19 \\ \(0.0000\) & 10.5000 & \(0.0000\) & 36.0000 & 4.32 \\ \(0.0000\) & 10.5000 & \(0.0000\) & 36.0000 & 4.25 \\ \hline \(-1.4142\) & 9.0858 & \(0.0000\) & 36.0000 & 5.76 \\ \(1.4142\) & 11.9142 & \(0.0000\) & 36.0000 & 4.42 \\ \(0.0000\) & 10.5000 & \(-1.4142\) & 28.9290 & 5.46 \\ \(0.0000\) & 10.5000 & \(1.4142\) & 43.0710 & 5.81 \\ \hline \end{tabular} _Source_ Poon (1995). Reprinted with permission

\end{table}
Table 4: Data for the acid copper pattern plating experiment—central composite design

Figure 4: Response surface contour plot and response surface plot of fitted second-order model for the acid copper pattern plating experiment

#### Generic Test for Lack of Fit of the Second-Order Model

If the second-order design includes \(n_{d}\) distinct treatment combinations, with \(n_{d}\) larger than the number of parameters \((p+2)(p+1)/2\), and replication at one or more of these, then a generic test for lack of fit of the second-order model can be conducted, just as for the first-order model (Sect. 16.2.6). The sum of squares for pure error, ssPE, and the sum of squares for lack of fit, ssLOF, are calculated as in (16.2.7) and (16.2.8). The error sum of squares ssE and the error degrees of freedom are obtained from the analysis of variance table of the second-order model. The test proceeds exactly as in Table 16.3 except that the error degrees of freedom are \(n-[(p+2)(p+1)/2]\) and the degrees of freedom for lack of fit are then \(n_{d}-[(p+2)(p+1)/2]\). The test will be illustrated for the acid copper-plating experiment in Example 16.3.2 in the next subsection.

#### Analysis of Variance for a Second-Order Model

Table 16.9 shows an outline analysis of variance table for a central composite design and second-order model, assuming that all parameters are estimable. The degrees of freedom associated with the linear effects have been added (pooled) together, as have those of the quadratic effects and those of the interaction (cross product) effects. Sequential, or Type I, sums of squares are listed for each of these pooled sources of variation. These include the sum of squares for all linear terms, ss(\(L\)); the sum of squares for adding all quadratic terms to the model, given that all linear terms are already included, ss(\(Q|L\)); and the sum of squares for adding all interaction terms to the model, given that all linear and quadratic terms are already in the model, ss(\(I|L\), \(Q\)). Using these sequential sums of squares, the analysis of variance is the same whether factor levels are coded or not. The coefficients \(a_{i}\), \(a_{ii}\), and \(a_{ij}\) listed in the expected mean squares are positive and depend on the design and the model. If coded factor levels are used, the expected mean squares would involve the parameters \(\gamma\) instead of the parameters \(\beta\), but would have the same form.

If a central composite design is used and factor levels are coded in the usual way, the linear, quadratic and interaction sums of squares are independent of one another, so the corresponding sums of squares are the same, no matter in which order the terms are fitted. Also, the individual linear and interaction (cross product) parameters are estimated independently of one another and of the quadratic effects. The quadratic parameters are estimated independently of each other only if \(\alpha\) and the number of center points \(n_{0}\) are chosen to satisfy certain restrictions (see Sect. 16.4.2).

\begin{table}
\begin{tabular}{p{56.9pt} p{56.9pt} p{56.9pt} p{56.9pt} p{56.9pt} p{56.9pt}} \hline Source of variation & Degrees of freedom & Sum squares of (Type I) & Mean square (Type I) & Ratio & Expected mean square \\ \hline \(L\) & \(p\) & ss\(L\) & ms\(L\) & ms\(L\) & \(\sigma^{2}+\sum_{i}a_{i}\beta_{i}^{2}\) \\ \(Q|L\) & \(p\) & ss(\(Q|L\)) & ms(\(Q|L\)) & \(\frac{\text{ms}(Q|L)}{\text{ms}E}\) & \(\sigma^{2}+\sum_{i}a_{ii}\beta_{ii}^{2}\) \\ \(I|L\), \(Q\) & \(\frac{1}{2}\,p(p-1)\) & ss(\(I|L\), \(Q\)) & ms(\(I|L\), \(Q\)) & \(\frac{\text{ms}(I|L\), \(Q)}{\text{ms}E}\) & \(\sigma^{2}+\sum_{i<j}a_{ij}\beta_{ij}^{2}\) \\ Error & df & ssE & msE & & \(\sigma^{2}\) \\ Total & \(n-1\) & sstot & & & \\ \hline \multicolumn{6}{p{56.9pt}}{Formula: df = \(n-\frac{1}{2}(p+2)(p+1)\)} \\ \hline \end{tabular}
\end{table}
Table 16.9: Analysis of variance for a central composite design and second-order model

#### Example 16.3.2 Acid copper pattern plating experiment, continued

The data for the central composite design of the acid copper pattern plating experiment were shown in Table 16.8, p. 580. The analysis of variance for the coded data is given in Table 16.10. The table shows the decomposition of the linear sum of squares with respect to the individual linear effects. Each of the two quadratic effects is shown adjusted for the other quadratic effect. If we test each hypothesis at individual level 0.01, the linear effect of factor \(A\) is significantly different from zero, as is the adjusted quadratic effect of each factor. Consequently, the model should include these three terms. We would also include the linear effect of \(B\), since the higher-order (quadratic) term is included. The \(AB\)-interaction effect, or cross product effect, is not significantly different from zero.

Before settling on a final model, we should check the lack of fit of the second-order model. The only replication consisted of two center-point observations with values 4.32 and 4.25. The sample variance of these two observations is \(s_{0}^{2}=0.00245\), so ssPE = 0.00245 with one degree of freedom. From the analysis of variance table, Table 16.10, we see that ssE = 0.1161 with 4 degrees of freedom. So,

\[\text{ssLOF} = \text{ssE} - \text{ssPE} = 0.1161 - 0.00245 = 0.11365\]

with \(4 - 1 = 3\) degrees of freedom for lack of fit. There is significant lack of fit of the second-order model if

\[\text{msLOF}/\text{msPE} > F_{3,1,\alpha}\,,\]

for appropriate significance level \(\alpha\). Here,

\[\text{msLOF}/\text{msPE} = (0.11365/3)/(0.00245/1) = 15.463\,,\]

which is less than \(F_{3,1,0.10}=53.6\), so there is no significant lack of fit of the second-order model, and the model fitted in Example 16.3.1, p. 579, should be a reasonable approximation to the true surface in the local region under study (\(9.5 \leq x_{A} \leq 11.5;\ 31 \leq x_{B} \leq 41\)).

\begin{table}
\begin{tabular}{c c c c c c} \hline Source of variation & Degrees of freedom & Sum of squares & Mean square & Ratio & \(p\)-value \\ Linear & 2 & 2.2751 & & & \\ \(A_{\text{L}}\) & 1 & 1.9159 & 1.9159 & 65.99 & 0.0012 \\ \(B_{\text{L}}\) & 1 & 0.3591 & 0.3591 & 12.37 & 0.0245 \\ Quadratic & 2 & 2.4361 & & & \\ \(A_{\text{Q}}|B_{\text{Q}}\) & 1 & 0.8926 & 0.8926 & 30.74 & 0.0052 \\ \(B_{\text{Q}}|A_{\text{Q}}\) & 1 & 2.3330 & 2.3330 & 80.36 & 0.0009 \\ Interaction & 1 & 0.0625 & 0.0625 & 2.15 & 0.2162 \\ Error & 4 & 0.1161 & 0.0290 & & \\ Total & 9 & 4.8898 & & & \\ \hline \end{tabular}
\end{table}
Table 16.10: Analysis of variance for the acid copper pattern plating experiment

#### Canonical Analysis of a Second-Order Model

After fitting a second-order model, we need to (i) determine the location of the stationary point and (ii) characterize the stationary point as providing a response surface minimum, maximum, or saddle point. The nature of the response surface at the stationary point may be evident from contour or surface plots, as is the case in Fig. 16.4, or its characterization may be done via canonical analysis. We provide an overview and illustration of canonical analysis in this section, leaving the computations to software (see Sects. 16.7.2 and 16.8.2 for the use of the SAS and R software, respectively).

In response surface methods, it is customary to perform the canonical analysis using the model fit to the coded data. We think of each coded treatment combination \(\mathbf{z}\) as a point in \(p\)-dimensional space, \(\mathbf{z}=(z_{1},z_{2},\ldots,z_{p})\). Then the stationary point that we are trying to find is the point \(\mathbf{z}_{s}=(z_{s1},z_{s2},\ldots,z_{sp})\) at which the fitted response surface \(\hat{\mathbf{y}}_{\mathbf{z}}\) is neither increasing nor decreasing--the tangent plane is level. The stationary point can be obtained via calculus as the critical point of the fitted surface \(\hat{\mathbf{y}}_{\mathbf{z}}\). The stationary point \(\mathbf{x}_{s}\) for the model fit to the uncoded data can be obtained from \(\mathbf{z}_{s}\) by simply uncoding each factor level \(z_{si}\). In view of Eq. (16.2.2), this uncoding is accomplished by taking \(x_{si}=h_{i}\times z_{is}+m_{i}\), for \(i=1,2,\ldots,p\).

The second step--characterizing the response surface at the stationary point as a minimum, maximum, or saddle point--may be accomplished by putting the fitted second-order response surface into canonical form. To accomplish this, we change to a new coordinate system of points in two steps. First we set \(\mathbf{v}=\mathbf{z}-\mathbf{z}_{s}\), so that \(v_{l}=z_{l}-z_{si}\) for \(i=1,2,\ldots,p\). This moves the coordinate system so that the stationary point is at the origin with respect to the \(v_{l}\)-axes, so the stationary point is now \(\mathbf{v}_{s}=(0,0,\ldots,0)\). The other points \(\mathbf{v}=\mathbf{z}-\mathbf{z}_{s}\) measure position relative to the stationary point \(\mathbf{z}_{s}\). This eliminates all linear terms from the model. As the second step, the \(v_{l}\)-axes are rotated to obtain \(w_{l}\)-axes, with the rotation chosen to eliminate the cross product terms from the model.

In terms of each of these coordinate systems, the fitted model has the following equivalent representations:

\[\hat{\mathbf{y}}_{\mathbf{z}} =\hat{\mathbf{y}}_{0}+\sum_{i=1}^{p}\hat{\mathbf{\gamma}}_{l}z_{i }+\sum_{i=1}^{p}\hat{\mathbf{\gamma}}_{ii}z_{i}^{2}+\sum_{i<j}\hat{\mathbf{ \gamma}}_{ij}z_{i}z_{j}\;,\] \[\hat{\mathbf{y}}_{\mathbf{v}} =\hat{\mathbf{y}}_{\mathbf{v}_{s}}+\sum_{i=1}^{p}\hat{\mathbf{ \gamma}}_{ii}v_{i}^{2}+\sum_{i<j}\hat{\mathbf{\gamma}}_{ij}v_{i}v_{j}\;,\] \[\hat{\mathbf{y}}_{\mathbf{w}} =\hat{\mathbf{y}}_{\mathbf{w}_{s}}+\sum_{i=1}^{p}\hat{\mathbf{ \lambda}}_{ii}w_{i}^{2}\;,\]

where \(\hat{\mathbf{y}}_{\mathbf{v}_{s}}\) and \(\hat{\mathbf{y}}_{\mathbf{w}_{s}}\) are equal and each denotes the predicted response at the stationary point.

The last equation is said to be in _canonical form_, and in this form, we can immediately tell whether the stationary point is a maximum, a minimum, or a saddle point. If all of the \(\hat{\mathbf{\lambda}}_{ii}\)'s are negative, then the fitted model is concave down and has a maximum at the stationary point. If all of the \(\hat{\mathbf{\lambda}}_{ii}\)'s are positive, then the fitted model is concave up and has a minimum at the stationary point. If some of the \(\hat{\mathbf{\lambda}}_{ii}\)'s are positive and some are negative, the stationary point is a saddle point. The \(\hat{\mathbf{\lambda}}_{ii}\) are called the _canonical coefficients_.

If a specific \(\hat{\mathbf{\lambda}}_{ii}\) is relatively large in magnitude, then \(\hat{\mathbf{y}}_{\mathbf{w}}\) will change rapidly for changes away from the stationary point \(\mathbf{w}_{s}=(0,0,\ldots,0)\) in the \(w_{i}\) direction. Thus, if the stationary point is a saddle point and if \(\hat{\mathbf{\lambda}}_{\ell\ell}\) is the largest positive \(\hat{\mathbf{\lambda}}_{ii}\), movement in either direction away from the stationary point along the \(w_{\ell}\)-axis provides a path of steepest ascent. On the other hand, if a specific \(\hat{\mathbf{\lambda}}_{ii}\) is relativelysmall in magnitude, then \(\hat{y}_{\mathbf{w}}\) is relatively unaffected by changes away from the stationary point along the \(w_{i}\)-axis.

#### Acid copper pattern plating experiment, continued

In Example 16.3.1, p. 579, a second-order model was fitted to data collected from a central composite design. The experiment was run in order to study the effects of anode-cathode separation (factor \(A\)) and cathodic current density (factor \(B\)) on the standard deviation of copper-plating thickness. In terms of the coded factor levels \(z_{A}=(x_{A}-10.5)\), \(z_{B}=(x_{B}-36)/5\), the fitted model was

\[\hat{y}_{\mathbf{z}} = \hat{\gamma}_{0}+\hat{\gamma}_{A}z_{A}+\hat{\gamma}_{B}z_{B}+\hat {\gamma}_{AA}z_{A}^{2}+\hat{\gamma}_{BB}z_{B}^{2}+\hat{\gamma}_{AB}z_{A}z_{B}\] \[= 4.2850-0.4894z_{A}+0.2119z_{B}\] \[\quad+0.4419z_{A}^{2}+0.7144z_{B}^{2}-0.1250z_{A}z_{B}\,.\]

The following additional results are provided without computational details, since we are leaving those to software (see Sects. 16.7.2 and 16.8.2).

The stationary point is \(\mathbf{z}_{s}=(z_{sA},z_{sB})=(0.5395,\,-0.1011)\). Using these values of \(z_{A}\) and \(z_{B}\) in the fitted model, we obtain the predicted response at the stationary point to be \(\hat{y}_{\mathbf{z}_{s}}=4.1423\).

The canonical coefficients are \(\hat{\lambda}_{11}=0.7280\) and \(\hat{\lambda}_{22}=0.4282\). Since both canonical coefficients are positive, the stationary point minimizes the estimated standard deviation of coating thickness. Now, \(\hat{\lambda}_{11}\) is larger than \(\hat{\lambda}_{22}\)--nearly twice as large--so the surface will rise more rapidly as we move away from \(\mathbf{z}_{s}\) in the \(w_{1}\) direction than in the \(w_{2}\) direction.

The \(w_{1}\) canonical axis consists of all points \((z_{A},z_{B})\) of the form

\[(z_{sA},\ z_{sB})=(0.5395,\,-0.1011)+u(-0.2134,\,0.9770)\,.\]

The point \((-0.2134,\,0.9770)\) has been scaled to be one unit from the origin (i.e. \((-0.2134,\,0.9770)\) is a vector of length one), so a unit change in \(u\) corresponds to a step of size one along the \(w_{1}\)-axis. Since the second component of this point is nearly one, the \(w_{1}\)-axis is nearly parallel to the \(z_{2}\)-axis, or equivalently, to the \(B\) axis. This means that the coded level of \(B\) must be controlled more precisely than the coded level of \(A\) in order to maintain a minimum response. This conclusion is suggested by examining the fitted equation, since the coefficient of \(z_{B}^{2}\) is somewhat larger than those of \(z_{A}^{2}\) and \(z_{A}z_{B}\).

Likewise, the \(w_{2}\) canonical axis consists of all points \((z_{A},z_{B})\) of the form

\[(z_{sA},\ z_{sB})=(0.5395,\,-0.1011)+q(-0.9770,\,-0.2134)\,,\]

where a unit change in \(q\) corresponds to a step of size one along the \(w_{2}\)-axis. Since the first component of the point \((-0.9770,\,-0.2134)\) has magnitude nearly one, the \(w_{2}\)-axis is nearly parallel to the \(z_{A}\)-axis (or \(z_{1}\)-axis). 

The canonical analysis has been described and illustrated here in terms of the coded factor levels. The SAS and R software likewise do the canonical analysis in terms of coded factor levels, though SAS software codes the levels somewhat differently, which impacts the canonical coefficients.

#### Canonical Analysis Formulas (Optional)

This subsection requires the knowledge of matrices and vectors. Consider the fitted second-order model

\[\hat{y}_{\mathbf{z}}=\hat{\gamma}_{0}+\sum_{i}\hat{\gamma}_{i}z_{i}+\sum_{i}\hat{ \gamma}_{ii}z_{i}^{2}+\sum_{i<j}\hat{\gamma}_{ij}z_{i}z_{j}\]

for \(p\) factors. Let \(\mathbf{b}\) denote the \(p\times 1\) vector of linear parameter estimates, with \(i\)th entry \(\hat{\gamma}_{i}\). Let \(\mathbf{B}\) denote the \(p\times p\) matrix with \(i\)th diagonal element \(\hat{\gamma}_{ii}\) and with off-diagonal (\(ij\))th entry \(\hat{\gamma}_{ij}/2\). Then the least squares fitted model can be written in matrix terms as

\[\hat{y}_{\mathbf{z}}=\hat{\gamma}_{0}+\mathbf{z}^{\prime}\mathbf{b}+\mathbf{z} ^{\prime}\mathbf{B}\mathbf{z}\,.\]

Furthermore, the stationary point is

\[\mathbf{z}_{s}=-\frac{1}{2}\mathbf{B}^{-1}\mathbf{b}\,,\]

with corresponding predicted mean response

\[\hat{y}_{\mathbf{z}_{s}}\ =\ \hat{\gamma}_{0}-\mathbf{z}_{s}^{\prime}\mathbf{B} \mathbf{z}_{s}\ =\ \hat{\gamma}_{0}+\frac{1}{2}\mathbf{z}_{s}^{\prime}\mathbf{b}\,.\]

The _canonical coefficients_\(\hat{\lambda}_{ii}\) are the _eigenvalues_ of the matrix \(\mathbf{B}\). The _eigenvectors_ of \(\mathbf{B}\) determine the _canonical axes_, the canonical axis \(w_{i}\) being the normalized eigenvector of \(\mathbf{B}\) corresponding to the eigenvalue \(\hat{\lambda}_{ii}\). Obtaining the canonical coefficients and canonical axes using SAS and R software will be illustrated in Sects. 16.7.2 and 16.8.2, respectively.

#### Properties of Second-Order Designs: CCDs

In this section we discuss some desirable properties--rotatability, orthogonality, and orthogonal blocking--of second-order designs. The discussion here focuses on central composite designs (CCDs) because their properties can be controlled by judicious choice of the number of center points \(n_{0}\) and the distance \(\alpha\) of the axial points from the design center. In addition to rotatability, orthogonal blocking, and orthogonality, a design should include enough center points (say 3-6) to provide a reasonably sensitive test for lack of fit.

#### Rotatability

A design is _rotatable_ if the variance \(\text{Var}(\widehat{Y}_{\mathbf{z}})\) of the predicted response is the same for all coded points \(\mathbf{z}=(z_{1},z_{2},\ldots,z_{p})\) at any given distance \(d=(\sum_{i}z_{i}^{2})^{1/2}\) from the design center, \(\mathbf{z}_{0}=(0,0,\ldots,0)\). Thus, there is the same amount of information about the response surface at the same distance \(d\) in any direction from the design center. This is a reasonable requirement of a design, since data are generally collected without knowing in which direction from the design center the stationary point of the fitted surface will be located.

#### Rotatable Central Composite Designs

Suppose we take a central composite design for \(p\) factors, with one observation at each axial point located a distance \(\alpha\) from the design center, and with one observation at each of the \(n_{f}\) factorial points.

It can be shown that such a central composite design is rotatable if

\[\alpha=(n_{f})^{1/4}\,, \tag{16.4.13}\]

and if each axial point is observed \(r_{a}\) times, then the requirement for rotatability becomes

\[\alpha=(n_{f}/r_{a})^{1/4}\,.\]

The details can be found in the articles by Box and Hunter (1957) and Draper (1982).

##### _Example_ 16.4.1 Acid copper pattern plating experiment, continued

In Example 16.3.1, p. 579, a central composite design was used for \(p=2\) factors. The design involved one observation at each \(n_{f}=4\) factorial points and \(n_{a}=4\) axial points, plus two center points. If the model, in terms of coded factor levels, is fitted using \(\alpha=(n_{f})^{1/4}=\sqrt{2}\), the design is rotatable with respect to the coded factor levels. For example, it can be verified that the estimate of the variance is

\[\widehat{\rm Var}(\widehat{Y}_{\bf z})=0.0182\]

at each point \({\bf z}=(z_{1},z_{2})\) at distance \(\sqrt{2}\) from the design center. This includes each factorial point and each axial point. For comparison, \(\widehat{\rm Var}(\widehat{Y})=0.0145\) at the center point and \(\widehat{\rm Var}(\widehat{Y})=0.0100\) at the points \((-1,0)\), \((1,0)\), \((0,-1)\), and \((0,1)\), which are each a distance \(1.0\) from the design center. 

#### Orthogonality

The second-order model (16.3.10) includes \((p+1)(p+2)/2\) parameters, including the intercept \(\gamma_{0}\). A second-order design is _orthogonal_ if the sums of squares, ss(\(\gamma_{i}|\gamma_{0}\)) (\(i=1,2,\ldots,\,p\)), ss(\(\gamma_{ili}|\gamma_{0}\)) (\(i=1,2,\ldots,\,p\)), and ss(\(\gamma_{ij}|\gamma_{0}\)) (\(1\leq i<j\leq p\)), each adjusted for the intercept \(\gamma_{0}\), are independent. In the analysis of variance of an orthogonal design, the sums of squares associated with these \((p+2)(p+1)/2-1\) parameters are independent, and do not depend on the order in which the parameters are entered into the model. Orthogonality is advantageous if the experimenter is interested in evaluating which of the linear, quadratic, and cross product effects are significantly different from zero.

##### Orthogonal Central Composite Designs

Suppose we take a central composite design with one observation at each of the \(n_{f}\) factorial points and \(2p\) axial points, and with \(n_{0}\) observations at the center. As shown by Khuri and Cornell (1987), p. 119, the design is orthogonal if

\[(n_{f}+2\alpha^{2})^{2}=n_{f}n\,,\]

where \(n\) is the total number of observations; that is, \(n=n_{f}+2p+n_{0}\). So, a central composite design with \(n_{f}\) factorial points and \(2p\) axial points can be made orthogonal by appropriate choice of \(\alpha\) or \(n_{0}\). For example, if the number of center points is fixed at \(n_{0}\), then \(n\) is fixed, and a central composite design is orthogonal if

\[\alpha=\left(\frac{\sqrt{n_{f}n}-n_{f}}{2}\right)^{1/2}\,. \tag{16.4.14}\]If a central composite design is to be rotatable and \(n_{0}\) is not fixed, then we would choose \(\alpha=(n_{f})^{1/4}\), and the design would also be orthogonal if the number of center points was chosen to be

\[n_{0}=4\sqrt{n_{f}}+4-2p. \tag{16.4.15}\]

This may not be achievable, since \(n_{0}\) must be an integer. Rounding (16.4.15) to the nearest integer gives a rotatable design that is nearly orthogonal.

##### Flour production experiment

In Sect. 16.5, we will consider the last of four experiments described by Tuck et al. (1993) to develop robust bread flours. This experiment was run using a central composite design for three factors, with one observation at each of \(n_{f}=8\) factorial points and \(2p=6\) axial points. From Eq. (16.4.15), since \(\sqrt{n_{f}}=\sqrt{8}\) is not an integer, the design with \(n_{f}=8\) cannot be both orthogonal and rotatable. The experimenters used only \(n_{0}=2\) center points, giving \(n=16\) observations in total. From Eq. (16.4.14), the design is orthogonal if

\[\alpha=\left(\frac{\sqrt{(8)(16)}-8}{2}\right)^{1/2}\ =\ 1.2872\.\]

This value of \(\alpha\) was used by the experimenters. 

#### Orthogonal Blocking

If a second-order design is conducted as a block design, then the second-order model (16.3.10) is modified to include additive block effects. For \(p\) factors, the model is

\[Y_{h,\mathbf{z},t}=\gamma_{0}+\theta_{h}+\sum_{i=1}^{p}\gamma_{i}z_{i}+\sum_{i =1}^{p}\gamma_{ii}z_{i}^{2}+\sum_{i<j}\gamma_{ij}z_{i}z_{j}+\epsilon_{h, \mathbf{z},t}\, \tag{16.4.16}\]

where \(Y_{h,\mathbf{z},t}\) denotes the \(t\)th observation at coded treatment combination \(\mathbf{z}=(z_{1},\,z_{2},\,\ldots,\,z_{p})\) in block \(h\), and the error variables \(\epsilon_{h,\mathbf{z},t}\) are independent with \(N(0,\,\sigma^{2})\) distributions. The parameter \(\theta_{h}\) denotes the effect of the \(h\)th block, and the other parameters are defined as in the second-order model (16.3.10).

A design is said to have _orthogonal blocking_ if the least squares estimates of the linear, quadratic, and cross product effect parameters are the same under model (16.4.16), which includes block effects, as under the model (16.3.10) without block effects; that is, the linear, quadratic, and cross product effects are estimated independently of the block effects. The primary advantage of orthogonal blocking as compared with nonorthogonal blocking is that an orthogonally blocked design gives the smallest values of \(\text{Var}(\widehat{Y})\), \(\text{Var}(\hat{\gamma}_{i})\), \(\text{Var}(\hat{\gamma}_{ii})\), and \(\text{Var}(\hat{\gamma}_{ij})\). A second advantage is that a rotatable design conducted with orthogonal blocking is still rotatable.

Given a design in \(b\) blocks with orthogonal blocking, the analysis under the block design model (16.4.16) is almost the same as it would be under model (16.3.10) for the design with no blocking. However, the sum of squares for blocks is extracted from the sum of squares for error, and there are \(b-1\) degrees of freedom for blocks giving \(b-1\) fewer degrees of freedom for error. The sum of squares for blocks is

\[ss\theta=\sum_{h=1}^{b}k_{h}(\overline{y}_{h..}-\overline{y}_{...})^{2}=\sum_{ h=1}^{b}y_{h..}^{2}/k_{h}-y_{...}^{2}/n\,\]where \(y_{h..}\) is the sum of the observations in the \(h\)th block, \(k_{h}\) is the size of the \(h\)th block, and \(y_{...}\) is the sum of all \(n\) observations in the design.

In their 1957 article, Box and Hunter developed the following general conditions under which a second-order design can be blocked orthogonally.

1. Each block must be a first-order orthogonal design: that is, (i) for each block and each factor \(i\), the sum of coded levels of the factor, \(\sum z_{i}\), is zero; and (ii) for each block and each pair of factors \(i\) and \(j\), the sum of cross products, \(\sum z_{i}z_{j}\), is zero. (Each sum is over all the observations in the block.)
2. For each block and each factor \(i\), the sum of squares \(\sum z_{i}^{2}\) of the coded levels of the \(i\)th factor in the block must be proportional to the number of observations in the block.

##### Orthogonal Blocking of Central Composite Designs

For a central composite design, we first divide the observations into two blocks: an _axial-points block_ consisting of the \(n_{a}\) axial points plus \(n_{0a}\) center points, and a _factorial-points block_ consisting of the \(n_{f}\) factorial points plus \(n_{0f}\) center points. This division into blocks is natural if, for example, a first-order design results in lack of fit, so that axial and additional center points are added at a later date to build up to a second-order design. Each of the blocks is a first-order orthogonal design, meeting condition (1) for orthogonal blocking. Concerning condition (2), the sum of squares \(\sum z_{i}^{2}\) of the coded levels of each factor is \(2\alpha^{2}\) in the axial block and \(n_{f}\) in the factorial block. So, condition (2) requires that

\[\frac{2\alpha^{2}}{n_{f}}=\frac{n_{a}+n_{0a}}{n_{f}+n_{0f}}\.\]

Solving for \(\alpha\), a central composite design has orthogonal blocking if

\[\alpha=\left(\frac{n_{f}(n_{a}+n_{0a})}{2(n_{f}+n_{0f})}\right)^{1/2}. \tag{16.4.17}\]

The design is also rotatable if \(\alpha=(n_{f})^{1/4}\), in which case we require

\[n_{0f}=(\sqrt{n_{f}}/2)(n_{a}+n_{0a})-n_{f}. \tag{16.4.18}\]

If the numbers of center points, \(n_{0a}\) and \(n_{0f}\), in the blocks can be chosen to satisfy this equation, then the design will be rotatable and can be orthogonally blocked. When this is not possible, it is preferable to maintain orthogonal blocking but to relax rotatability. To accomplish this, the numbers \(n_{0a}\) and \(n_{0f}\) can be chosen such that Eq. (16.4.18) is approximately satisfied, and then \(\alpha\) can be computed from Eq. (16.4.17).

It is sometimes possible to block a central composite design orthogonally in more than two blocks. The axial block cannot be further subdivided, but the factorial block can sometimes be divided into \(2^{m}\) factorial blocks while maintaining orthogonal blocking if the number of factorial center points \(n_{0f}\) is divisible by \(2^{m}\) so the factorial center points can be equally divided among the \(2^{m}\) factorial blocks. This is done by confounding interaction effects between three or more factors. Box and Hunter (1957, p. 233) provide a table of blocking arrangements for rotatable and near-rotatable central composite designs. Notice that if center points are spread across \(b\) blocks, then they provide \(b-1\) fewer pure error degrees of freedom than they would in a design that is not blocked.

#### 16.4.3 PAH recovery experiment

Barnabas et al. (1995) used a central composite design to study the effects of four factors--pressure, temperature, extraction time, and methanol content--on the total recovery of polycyclic aromatic hydrocarbons (PAHs) when extracted from soil. The design was composed of \(n_{f}=2^{4}=16\) factorial points and \(n_{a}=2p=8\) axial points. Taking \(\alpha=16^{1/4}=2\) would give a rotatable design. From Eq. (16.4.18),

\[n_{0f}\ =\ (\sqrt{16}/2)(8+n_{0a})-16\ =\ 2n_{0a}\,,\]

so use of twice as many factorial center points as axial center points would give a rotatable design that could be orthogonally blocked.

The experimenters chose to use \(n_{0a}=2\) axial center points and \(n_{0f}=4\) factorial center points. This gave an axial block of size 10 and a factorial block of size 20. They then subdivided the factorial block into two blocks each of size 10 by confounding the four-factor interaction and including two of the four factorial center points in each factorial block. The resulting design was rotatable with orthogonal blocking. Analysis of the design is discussed in Sects. 16.7.2 and 16.8.2 using the SAS and R software packages, respectively. The design itself is shown in Tables 16.16 (p. 596) and 16.19 (p. 604), where the first ten observations comprise the first factorial block, the second ten the second factorial block, and the final ten the axial block. \(\square\)

### A Real Experiment: Flour Production Experiment, Continued

Tuck et al. (1993) described a series of four related experiments, involving quality improvement in the milling industry. The collective purpose of the experiments was to develop a bread flour that would give high loaf volume despite fluctuations in the bread-making process. We consider here their fourth experiment.

Bread flour consists of wheat plus a small number of minor ingredients. Their fourth experiment was concerned with the effects of three such ingredients (labeled design factors \(B\), \(C\), and \(D\)) on loaf volume. An orthogonal central composite design, involving eight factorial points, six axial points, and two center points, was used. For the axial points, the value \(\alpha=1.2872\) was used to make the design orthogonal (see Example 16.4.2).

When a product consists of a mixture of ingredients, and the total volume of the mixture is held constant, the fractions associated with the ingredients in the mixture necessarily sum to one. This has implications for the model and data analysis. However, in this experiment, the minor ingredients constituted such a small portion of the mixture that the total volume did not need to remain fixed, and standard response surface methods could be used to study the design factors.

There were a number of sources of variation in the production process that constituted noise factors. The production factors were paired in order to keep the experiment small. So, noise factor \(G\) represented oven bake and proof time, noise factor \(J\) represented yeast and water level, and noise factor \(K\) represented degree of mixing and moulding pressure. Each of these composite factors had two levels, "high" and "low." A \(2^{3-1}_{III}\) fraction in the composite noise factors was used, with defining relation

\[I\ =\ GJK\,.\]

The experimental design used was a product array. It included \(16\times 4=64\) observations--each of the 16 design factor combinations of the central composite design was observed with each of the four noise factor combinations of the noise array. Also, the noise factors were difficult to change, so eachnoise factor combination constituted a different block, and in each block the design factor treatment combinations (\(z_{B}z_{C}z_{D}\)) were randomly ordered. Observations were collected over two days using half-days as blocks, with the four blocks collected in the order (\(z_{G}z_{J}z_{K}\)) = 111, 100, 010, 001. As a result, noise factor effects are also confounded with changes in conditions from half-day to half-day. For each observation, three loaves were baked from a single dough, then the average specific volume of the three loaves recorded. The resulting data \(y_{h\mathbf{z}}\) are shown in Table 16.11.

For each of the 16 treatment combinations \(\mathbf{z}\) of the central composite design in turn, the sample mean \(\overline{y}_{\mathbf{z}}\) and the log sample variance (\(\times 100\)) were computed from the observations \(y_{h\mathbf{z}}\) in the four blocks (\(h=1,2,3,4\)). The effects of the design factors on these two response variables were studied separately by fitting second-order response surface regression models to each set of 16 responses.

The analysis of variance for fitting the second-order model to the response \(\overline{y}_{\mathbf{z}}\) is shown in Table 16.12. Because the design is orthogonal, the effects can be assessed for significance independently of their order of entry into the model. The only effects that are significantly different from zero at an individual significance level of 0.01 are the main effects of factors \(C\) and \(D\). The overall significance level for the nine tests is at most 0.09. The experimenters decided also to retain the main effect of factor \(B\), for which \(p=0.0204\). If the corresponding first-order model is fitted to \(\overline{y}_{\mathbf{.z}}\), we obtain

\[\hat{\overline{y}}_{\mathbf{.z}}=475.50+4.42z_{B}+10.24z_{C}+6.87z_{D}\;.\]

The coefficients of \(z_{B}\), \(z_{C}\), and \(z_{D}\) are all positive. Thus, increasing the level of design factors \(B\), \(C\), and \(D\) has a positive effect on the mean loaf specific volume.

The analysis of variance for the response \(100\log_{10}(s_{\mathbf{z}})\) is shown in Table 16.13. No effects can be regarded as significantly different from zero at an individual 0.01 significance level. However, in this setting it would not be particularly bad to make a Type I error, and if we raise the individual significance level we would select the linear effects of factors \(B\) and \(D\) and the quadratic effect of \(C\) as being the important effects. If the corresponding model is fitted and the linear effect of \(C\) is also included, we obtain

\begin{table}
\begin{tabular}{c c c c c c c c c} \hline \(z_{B}\) & \(z_{C}\) & \(z_{D}\) & \(y_{1\mathbf{z}}\) & \(y_{2\mathbf{z}}\) & \(y_{3\mathbf{z}}\) & \(y_{4\mathbf{z}}\) & \(\overline{y}_{\mathbf{.z}}\) & \(100\log_{10}(s_{\mathbf{z}})\) \\ \hline \(-1\) & \(-1\) & \(-1\) & 586 & 399 & 418 & 404 & 451.75 & 195.36 \\ \(-1\) & \(-1\) & 1 & 615 & 411 & 435 & 421 & 470.50 & 198.60 \\ \(-1\) & \(1\) & \(-1\) & 611 & 422 & 431 & 439 & 475.75 & 195.63 \\ \(-1\) & \(1\) & \(1\) & 639 & 436 & 444 & 454 & 493.25 & 198.88 \\ \(1\) & \(-1\) & \(-1\) & 603 & 422 & 400 & 430 & 463.75 & 197.17 \\ \(1\) & \(-1\) & \(1\) & 622 & 411 & 425 & 436 & 473.50 & 199.79 \\ \(1\) & \(1\) & \(-1\) & 634 & 471 & 436 & 425 & 491.50 &\[100\widetilde{\log_{10}}(s_{\mathbf{z}}) = 195.19+0.18z_{C}+3.35z_{C}^{2}+2.20z_{B}+2.49z_{D}\] \[\approx 195.19+3.35(z_{C}+0.027)^{2}+2.20z_{B}+2.49z_{D}\,.\]

Taking the two fitted models, we see that not only does the mean response increase as the levels of factors \(B\), \(C\), and \(D\) are increased, but so does the variability. The minimum variability with respect to factor \(C\) is achieved at \(z_{C}=-0.027\). However, the amount of factor \(C\) in the loaf cannot be negative, and so the minimum variability is achieved when the amount of factor \(C\), as well as factors \(B\) and \(D\), is zero.

The end result was that the experimenters set \(z_{C}=0\) to achieve low variability and adjusted the level of factor \(B\) (which has the slightly smaller effect on the variance, and may have been less costly than factor \(D\)) to raise mean response to the desired level.

\begin{table}
\begin{tabular}{c c c c c c} \hline Source of variation & Degrees of freedom & Sum of squares & Mean squares & Ratio & \(p\)-value \\ \hline \(z_{B}\) & 1 & 54.9174 & 54.9174 & 8.24 & 0.0284 \\ \(z_{C}\) & 1 & 0.3730 & 0.3730 & 0.06 & 0.8208 \\ \(z_{D}\) & 1 & 70.1514 & 70.1514 & 10.53 & 0.0176 \\ \(z_{B}^{2}\) & 1 & 0.6409 & 0.6409 & 0.10 & 0.7669 \\ \(z_{C}^{2}\) & 1 & 61.4625 & 61.4625 & 9.23 & 0.0229 \\ \(z_{D}^{2}\) & 1 & 7.8587 & 7.8587 & 1.18 & 0.3191 \\ \(z_{BZC}\) & 1 & 8.7175 & 8.7175 & 1.31 & 0.2963 \\ \(z_{BZD}\) & 1 & 2.6931 & 2.6931 & 0.40 & 0.5484 \\ \(z_{CZD}\) & 1 & 4.3269 & 4.3269 & 0.65 & 0.4511 \\ Error & 6 & 39.9752 & 6.6625 & & \\ Total & 15 & 251.1164 & & & \\ \hline \end{tabular}
\end{table}
Table 13: Flow production experiment: analysis of variance for \(100\log_{10}(s_{\mathbf{z}})\)

\begin{table}
\begin{tabular}{c c c c c c} \hline Source of variation & Degrees of freedom & Sum of squares & Mean square & Ratio & \(p\)-value \\ \hline \(z_{B}\) & 1 & 221.4366 & 221.4366 & 9.77 & 0.0204 \\ \(z_{C}\) & 1 & 1185.3603 & 1185.3603 & 52.30 & 0.0004 \\ \(z_{D}\) & 1 & 533.2415 & 533.2415 & 23.53 & 0.0029 \\ \(z_{B}^{2}\) & 1 & 48.0081 & 48.0081 & 2.12 & 0.1958 \\ \(z_{C}^{2}\) & 1 & 50.4906 & 50.4906 & 2.23 & 0.1862 \\ \(z_{D}^{2}\) & 1 & 1.1997 & 1.1997 & 0.05 & 0.8257 \\ \(z_{BZC}\) & 1 & 3.4453 & 3.4453 & 0.15 & 0.7101 \\ \(z_{BZD}\) &

### Box-Behnken Designs

A central composite design has five levels for each factor, +-1, +-a, 0. For a given experiment, circumstances may dictate the use of fewer levels, but at least three levels per factor are needed for quadratic terms to be estimable in the second-order model. Use of 3\(p\) factorial designs or regular 3_p__s_ fractional factorial designs might be considered. These tend to be large, however, and the smaller ones tend to be of resolution III or IV so that two-factor interactions are confounded with main effects or other two-factor interactions. For fitting a second-order response model a different type of design, called a _Box-Behnken design_, is often preferred, since interaction parameter estimates are not completely confounded, and in many cases, these designs are considerably smaller than 3_p__s_ fractional factorial designs.

A Box-Behnken design for \(p\) factors is constructed by a composition of an incomplete block design for \(p\) treatments in \(b\) blocks of size \(k\) and a 2\(k\) factorial design having factor levels coded +-1 and -1. The method of composition is illustrated in Example 16.6.1. In addition to the points generated by the composition, center points must be added to the design for all model parameters to be estimable.

A list of Box-Behnken designs can be found in the article of Box and Behnken (1960). The designs have \(p\) factors with each factor observed at 3 levels, for \(p\) = 3-7, 9-12, and 16. The designs for \(p\) = 4 and 7 are rotatable, and the others are nearly rotatable. The designs for \(p\) = 4-7, 9, 10, 12, and 16 allow orthogonal blocking. All of the designs possess a high degree of orthogonality, the only correlation being between the estimators of the intercept and the quadratic terms.

#### _Example 16.6.1_ Construction of a Box-Behnken Design: \(p\) = 4

Suppose we require a second-order design for \(p\) = 4 factors, each observed at three levels, and with a total of 27 observations. As illustrated by Box and Behnken (1960), a Box-Behnken design can be constructed from a composition of a balanced incomplete block design in \(b\) = 6 blocks of size \(k\) = 2 and a 22 factorial design as follows. The balanced incomplete block design, shown below left, consists of all possible combinations of four treatment labels taken two at a time. Shown to its right are the \(v\) = 4 treatment combinations of a 22 design, with factor levels coded +1 and -1. These two designs are composed as follows. In each of the six blocks of the incomplete block design, the treatment labels are replaced by the symbol +-1 and the blank "-" by 0 to give the Box-Behnken design represented in condensed form (and without center points) below right.

\[\left[\begin{array}{rrrr}1&2&-&-\\ -&-&3&4\\ 1&-&3&-\\ -&2&-&4\\ 1&-&-&4\\ -&2&3&-\end{array}\right]\text{ with }\left[\begin{array}{rrrr}-1&-1\\ -1&1\\ 1&-1\\ 1&1\end{array}\right]\text{ gives }\left[\begin{array}{rrrr}\pm 1&\pm 1&0&0\\ 0&0&\pm 1&\pm 1\\ \pm 1&0&\pm 1&0\\ 0&\pm 1&0&\pm 1\\ \pm 1&0&0&\pm 1\\ 0&\pm 1&\pm 1&0\end{array}\right]\]

The same design, but expanded out and augmented with three center points, is shown in Table 16.14. The first +-1 in each row of the condensed design is replaced by the first column of levels of the 22 design, the second +-1 is replaced by the second column of levels, and each 0 is replaced by a column of \(v\) = 4 zeros. With the addition of three center points, this gives the design with 27 treatmentcombinations shown as the 27 rows of Table 14. Although this design has the same number of treatment combinations as a \(3^{4-1}_{IV}\) design, it does not have complete confounding of the two-factor interactions in pairs. 

In general, the composition of an incomplete block design for \(p\) treatments in \(b\) blocks of size \(k\) with a factorial design with \(v=2^{k}\) treatment combinations yields a Box-Behnken design for \(p\) factors with \(bv\) treatment combinations. The \(i\)th of the \(k\) treatment labels in each block is replaced by the \(i\)th of the \(k\) columns of the factorial design, and each "\(-\)" is replaced by a column of \(v\) zeros.

In general, if the incomplete block design is a balanced incomplete block design with \(r=3\lambda\), as in Example 16.1, then the resulting Box-Behnken design is rotatable--otherwise not. If there does not exist a balanced incomplete block design with \(r=3\lambda\), then one can either use a balanced incomplete block design with \(r\neq 3\lambda\) or use a partially balanced incomplete block design. If a partially balanced incomplete block design is used, each pair of treatment labels must occur together in at least one block for all second-order model parameters to be estimable.

##### Orthogonal Blocking

Many Box-Behnken designs can be blocked orthogonally. The requirements for orthogonal blocking of a second-order design were given in Sect. 16.4.3, and these imply that a Box-Behnken design can be blocked orthogonally under either of two circumstances.

First, if the blocks of the incomplete block design in the composition can be partitioned into equireplicate sets, then the same partition of observations in the Box-Behnken design provides orthogonal blocking as long as the same number of center points is included in each block. Such is the case for the design of Example 16.1, since each pair of blocks in the balanced incomplete block design includes every treatment label exactly once. For the resulting Box-Behnken design in Table 14, each bracketed set of nine treatment combinations is a corresponding block with one center point included.

The second situation that allows orthogonal blocking occurs when interactions involving three or more factors can be confounded in the generating factorial design. An example follows:

Example 16.2: Example of orthogonal blocking

For \(p=4\) factors, the balanced incomplete block design with blocks consisting of the four combinations of three treatment labels can be combined with the \(2^{3}\) factorial design as follows.

\begin{table}
\begin{tabular}{c c c c} \hline \hline \(\begin{array}{cccc}-1&-1&0&0\\ -1&1&0&0\\ 1&-1&0&0\\ 1&1&0&0\\ 0&0&-1&-1\\ 0&0&-1&1\\ 0&0&1&-1\\ 0&0&1&1\\ 0&0&0&0\\ \end{array}\) & \(\begin{array}{cccc}\left[\begin{array}{cccc}-1&0&-1&0\\ -1&0&1&0\\ 1&0&-1&0\\ 1&0&1&0\\ 0&-1&0&-1\\ 0&1&0&-1\\ 0&0&0&0\\ \end{array}\right]\) & \(\begin{array}{cccc}\left[\begin{array}{cccc}-1&0&0&-1\\ -1&0&0&1\\ 1&0&0&-1\\ 1&0&0&1\\ 0&-1&-1&0\\ 0&1&1&0\\ 0&1&1&0\\ 0&0&0&0\\ \end{array}\right]\) \\ \hline \hline \end{tabular}
\end{table}
Table 14: Box–Behnken design: \(p=4\) factors, \(n=27\) treatment combinations\[\left[\begin{array}{rrrr}1&2&3&-\\ 1&2&-&4\\ 1&-&3&4\\ -&2&3&4\end{array}\right]\ \text{with}\ \left[\begin{array}{rrrr}-1&-1&-1\\ -1&-1&1\\ -1&1&-1\\ 1&-1&1\\ 1&-1&-1\\ 1&1&-1\\ 1&1&-1\\ 1&1&1\end{array}\right]\ \text{gives}\ \left[\begin{array}{rrrr}\pm 1&\pm 1&\pm 1 &0\\ \pm 1&\pm 1&0&\pm 1\\ \pm 1&0&\pm 1&\pm 1\\ 0&\pm 1&\pm 1&\pm 1\end{array}\right],\]

where the \(i\)th occurrence of \(\pm 1\) in any row of the combined design is replaced by the \(i\)th column of the factorial design, and each 0 in the combined design is replaced by a column of eight 0's. The resulting 32-run Box-Behnken design can be partitioned into two blocks of size 16 by confounding the three-factor interaction in the generating factorial design. Thus, treatment combinations in the combined design are divided into two blocks, the division depending on whether they include an even or odd number of factors at level "\(-1\)." An equal number of center points must be added to each block. 

### 16.7 Using SAS Software

In this section we illustrate the analysis of a standard first-order design and a central composite design using the SAS procedures GLM and RSREG, respectively.

#### Analysis of a Standard First-Order Design

The acid copper pattern plating experiment of Poon (1995) was introduced in Example 16.2.4 (p. 574). This small experiment involved four factorial points and two center points. A SAS program using the GLM procedure for the analysis of this standard first-order design is shown in Table 16.15. After reading

\begin{table}
\begin{tabular}{c c} \hline \multicolumn{2}{c}{* Enter data of the first-order design and code levels;} \\ DATA COPPER; & \multicolumn{2}{c}{INPUT XA XB S;} \\ ZA = (XA - 10.5); & \multicolumn{2}{c}{ZB = (XB - 36)/5;} \\ LINES; & \multicolumn{2}{c}{} \\
9.5 & 31 & 5.60 \\
9.5 & 41 & 6.45 \\
11.5 & 31 & 4.84 \\
11.5 & 41 & 5.19 \\
10.5 & 36 & 4.32 \\
10.5 & 36 & 4.25 \\ \multicolumn{2}{c}{;} \\
* Analysis of the first-order design; & \multicolumn{2}{c}{PROC GLM;} \\ MODEL S = ZA ZB; & \multicolumn{2}{c}{} \\
* Add model terms to test for lack of fit; & \multicolumn{2}{c}{PROC GLM;} \\ MODEL S = ZA ZB ZA*ZB ZA*ZA; & \multicolumn{2}{c}{} \\ \end{tabular}
\end{table}
Table 16.15: SAS program for first-order response surface regression the data and coding the factor levels, there are two calls of PROC GLM. Neither of these calls includes a CLASS statement, since the goal is to fit a regression model to the levels of the quantitative factors and not to compare the effects of their levels.

In the first call, the first-order model (16.2.3) is fitted, generating the output shown in Fig. 16.5. Neither main effect is significantly different from zero, indicating either that the experimental region is in the vicinity of the peak, or that neither factor affects the response.

In the second call of PROC GLM, the interaction term and one quadratic term are added to the model to test for lack of fit of the first-order model--the model would contain too many parameters if both quadratic terms were added. Some of the resulting output is shown in Fig. 16.6. At an overall level of

Figure 16.6: SAS output from the second call of PROC GLM: test for lack of fit of the first-order model

\begin{table}
\begin{tabular}{c c c c c c c}  & \multicolumn{4}{c}{Results Viewer - sasthml.htm} & \multicolumn{2}{c}{} \\  & \multicolumn{4}{c}{The GLM Procedure} \\  & \multicolumn{4}{c}{Dependent Variable: S} \\ Source & DF & Sum of Squares & Mean Square & F Value & Pr \textgreater{} F \\ Model & 2 & 1.38010000 & 0.69005000 & 0.99 & 0.4686 \\ Error & 3 & 2.09858333 & 0.69952778 & & \\ Corrected Total & 5 & 3.47868333 & & & \\ Source & DF & Type III SS & Mean Square & F Value & Pr \textgreater{} F \\ ZA & 1 & 1.02010000 & 1.02010000 & 1.46 & 0.3137 \\ ZB & 1 & 0.36000000 & 0.36000000 & 0.51 & 0.5250 \\ Parameter & Estimate & Standard Error & t Value & Pr \textgreater{} It \\ Intercept & 5.10833333 & 0.34144980 & 14.96 & 0.0006 \\ ZA & -0.505000000 & 0.41818889 & -1.21 & 0.3137 \\ ZB & 0.300000000 & 0.41818889 & 0.72 & 0.5250 \\ \end{tabular}
\end{table}
Table 16: SAS output from the first call of PROC GLM: analysis of variance and parameter estimates for a first-order design 0.10 for the four tests (each being done at individual level \(\alpha^{*}=0.025\)), the quadratic term ZA*ZA is significantly different from zero, indicating the presence of significant curvature. This fact caused the experimenters to add axial points to the first-order design to obtain a central composite design (see Example 16.3.1).

\begin{table}
\begin{tabular}{r r r r r r r} \hline DATA PAH; & & & & & & & \\ INPUT RUN B1 & B2 & PRES TEMP & ET & MC & Y; & \\ LINES; & & & & & & & \\

[MISSING_PAGE_POST]

 \end{tabular}
\end{table}
Table 16: SAS program for response surface regression (PAH recovery experiment)

#### Analysis of a Second-Order Design

The SAS procedure RSREG is used to fit a second-order response surface regression model. This is illustrated in Table 16.16 in the context of the PAH recovery experiment that was introduced in Example 16.4.3 (p. 589). A rotatable central composite design with orthogonal blocking was used to study the effects of four factors--pressure (PRES), temperature (TEMP), extraction time (ET), and methanol content (MC)--on the total recovery of polycyclic aromatic hydrocarbons (Y) when extracted from soil.

The SAS program shown in Table 16.16 reads the run number, the levels of the block indicator variables, the uncoded levels of the four factors, and the data into data set ONE. Until now, we have always declared a block variable to be a classification variable via the CLASS statement and listed its levels as \(1,2,\ldots,b\). However, PROC RSREG does not recognize classification variables, and if a single block factor were included in the model, it would be interpreted as a single covariate--a quantitative variable possessing one degree of freedom. We have included in the model the pair of covariates (B1, B2), for which we have selected the three coded pairs of levels (1, 0), (0, 1) and (\(-1,-1\)). The three pairs of levels distinguish the three blocks and provide two block degrees of freedom.

Only the factor _names_ need be listed in the MODEL statement in RSREG, as all quadratic and cross product terms in the factors are automatically included in the model. To avoid treatment-block interactions from being included, B1 and B2 are declared to be covariates. This is done via the option COVAR \(~{}=~{}2\), which indicates that the first two listed independent variables are covariates and should not be included in any interactions.

A generic test for model lack of fit can optionally be requested if the SAS data set has been sorted by the independent variables in the model to cluster replicated observations. PROC SORT is used to sort the data, and a test for lack of fit is requested via the option LACKFIT in the model statement of PROC RSREG.

PROC RSREG codes the levels of each factor so that \(+1\) and \(-1\) represent the extreme levels of each factor. For example, the axial points of a central composite design would typically be coded \(\pm 1\) by SAS software rather than the conventional \(\pm\alpha\). Figure 16.7 shows how SAS codes the factor levels, as well as the resulting analysis of variance table. The analysis of variance table includes Type I sums of squares for covariates, linear terms, quadratic terms, and cross product terms, adding the terms to the model in that order. These Type I sums of squares are the same, whether coded or uncoded factor levels are specified in the model statement. Observe that the cross product terms are not significantly different from zero, and there is no significant lack of fit of the model.

Type III sums of squares are also provided for each factor, pooling together the sums of squares for all terms--linear, quadratic and interaction--involving the factor. This information can be used for assessing whether any single factor can be removed from the model. These Type III sums of squares are also the same using either the coded or uncoded factor levels. The Type III sums of squares indicate that the factor methanol content (MC) is needed in the model, but perhaps not the other factors. Further analysis could explore what additional terms are needed, if any.

Figure 16.8 contains the parameter estimates and corresponding \(t\)-tests. Clearly the linear and quadratic methanol content terms are needed in the model, providing some clarification to the analysis of variance results.

In Fig. 16.9, the canonical analysis is shown, including the stationary point (Critical Value) in terms of both coded and uncoded factor levels; the predicted value at the stationary point; the canonical coefficients (Eigenvalues); classification of the stationary point as a maximum, minimum, or saddle point; and the direction of each canonical axis (Eigenvectors). The canonical coefficients and axes are with respect to the coded factor levels.

For this experiment, all eigenvalues (canonical coefficients) are negative, so the stationary point is a maximum. The eigenvectors are each scaled to be of length one. The last eigenvalue, with value \(-227.865046\), is the largest in magnitude. For the corresponding eigenvector, the primary component is that of MC with value \(0.994301\). So, the fitted model has greatest curvature at the stationary point when moving in either direction determined by this fourth eigenvector, which is nearly parallel to the MC-axis. This is evident from the contour plots in Fig. 16.10, where MC is the \(x\)-axis variable of plots (b), (e) and (f). Such a panel of contour plots is generated by inclusion of PLOTS = SURFACE as an option of PROC RSREG in Table 16.16, whereas changing the option to PLOTS = 3D would

Figure 16.7: SAS output from PROC RSREG: coding of factor levels, analysis of variance, and lack-of-fit test

generate response surface plots. Note that such graphics require ODS GRAPHICS ON, and PROC RSREG must run before turning ODS GRAPHICS OFF.

### Using R Software

In this section we illustrate the analysis of a standard first-order design and a central composite design using the response surface methods function rsm of the rsm library. We then illustrate generation of central composite and Box-Behnken designs using functions of the rsm package.

#### Analysis of a Standard First-Order Design

The acid copper pattern plating experiment of Poon (1995) was introduced in Example 16.2.4 (p. 574). This small experiment involved four factorial points and two center points. An R program and output for the analysis of this standard first-order design is shown in Tables 16.17 and 16.18. In Table 16.17,

Figure 16.8: SAS output from PROC RSREG: parameter estimates for uncoded and coded factor levels

the data are read from file, coded using the coded.data function of the rsm package, saved as copper1, and displayed.

In the R program continuation in Table 16.18, the first-order analysis is generated using the rsm function. In the statement

model1 = rsm(s ~ F0(zA, zB), data = copper1)

the syntax F0(zA, zB) fits the first order model in both coded response variables, using the coded data copper1, saving the results as model1. Then the summary(modell) command generates pertinent information, including: parameter estimates, standard errors, and corresponding _t_-tests; the analysis of variance table, including a lack-of-fit test; and the direction of steepest ascent with respect to coded and uncoded variables. Finally, the command

steepest(modell, dist=seq(0, 5, by = 1), descent = F)

provides predicted response at steps along the path of steepest ascent, stepping from the origin (which is the design center point for coded data) at distances from zero to five in unit increments, showing the location of each step in terms of the coded and uncoded predictor variables.

Based on the \(t\) tests, neither main effect is significantly different from zero, indicating either that the experimental region is in the vicinity of the peak, or that neither factor affects the response. The lack-of-fit test yields a _p_-value of 0.034, indicating significant lack-of-fit of the first order model, though the test does not distinguish whether this is due to interaction or quadratic effects. The reader may verify that the significant lack-of-fit is due to a quadratic effect. This fact caused the experimenters to add axial points to the first-order design to obtain a central composite design (see Example 16.3.1).

Figure 16.9: SAS output from PROC RSREG: canonical analysis

Figure 16.10: Response surface contour plots for the PAH recovery experiment

#### Analysis of a Second-Order Design

In the previous section, the syntax FO was used with the rsm function to fit a first order response surface regression model. Analogously, the syntax SO is used to fit a second order model. This is illustrated in the R program beginning in Table 16.19, in the context of the PAH recovery experiment that was introduced in Example 16.4.3 (p. 589). A rotatable central composite design with orthogonal blocking was used to study the effects of four factors--pressure (Pres), temperature (Temp), extraction time (ET), and methanol content (MC)--on the total recovery of polycyclic aromatic hydrocarbons (y) when extracted from soil.

The R program beginning in Table 16.19 reads the data from a file pah.txt which contains the run number, the block level, the uncoded levels of the four factors, and the response variable. A factor variable for blocks is created and all the information is saved in the data set pah.data. The function coded.data of the response surface methods package rsm then codes the levels of each of the factors, saving the coded data as pah.ccd.data. The data are then displayed (see Table 16.19), including the coding formulas. The coding formulas used here code the extreme levels of each factor as +-1, so the results presented here are consistent with those in the prior SAS software section, though one could certainly choose instead to code the levels of the factorial points as +-1.

The R program is continued in Table 16.20, where the output shown is all generated by the following two program lines.

model2 = rsm(y ~ fBlock + SO(zP, zT, zET, zMC), data = pah.ccd.data) summary(model2)

The first line fits the response surface regression model, saving the results as model2. Block effects are included in the model additively, whereas the syntax SO(zP, zT, zET, zMC) causes inclusion of all terms up to second order in the four factors, including linear, interaction, and quadratic effects. The summary command then generates the output shown in Table 16.20, as well as the canonical analysis shown in Table 16.21.

\begin{table}
\begin{tabular}{c} \hline > \# Read first 6 observations from file \\ > copper.data = head(read.table(‘data/copper.txt’’, header = T), 6) \\ > \# Code data \\ > \# install.packages(‘rsm’’) \\ > library(rsm) \\ > copper1 = coded.data(copper.data, zA ~ xA - 10.5, zB ~ (xB - 36)/5) \\ > copper1 \\ \end{tabular} 
\begin{tabular}{c} xA xB s \\ 1 9.5 31 5.60 \\ 2 9.5 41 6.45 \\ 3 11.5 31 4.84 \\ 5 10.5 36 4.32 \\ 6 10.5 36 4.25 \\ \end{tabular}
\end{table}
Table 16.17: R program and output for first-order response surface regression: data entry and codingIn Table 16.20, the analysis of variance table includes Type I sums of squares for blocks, linear or first order terms, two way interaction terms, and pure quadratic terms, adding the terms to the model in that order. These Type I sums of squares would be the same modeling either coded or uncoded factor levels. A lack-of-fit test is also provided. Observe that the cross product terms are not significantly different from zero, and there is no significant lack of fit of the model. The linear and quadratic components are clearly significant. Looking at the parameter estimates and corresponding \(t\)-tests in Table 16.20, clearly the linear and quadratic methanol content terms are needed in the model, providing some clarification to the analysis of variance results.

\begin{table}
\begin{tabular}{r r} \hline \hline \multicolumn{2}{c}{\(>\) \# First-order model analysis} \\ \multicolumn{2}{c}{\(>\) model1 = rsm(s \(\widetilde{\ }\)FO(zA, zB), data = copper1)} \\ \multicolumn{2}{c}{\(>\) summary(model1)} \\ \multicolumn{2}{c}{Call:} \\ \multicolumn{2}{c}{rsm(formula = s \(\widetilde{\ }\)FO(zA, zB), data = copper1)} \\ \multicolumn{2}{c}{Estimate Std. Error t value Pr(\textgreater{}|t|)} \\ \multicolumn{2}{c}{(Intercept) 5.108 0.341 14.96 0.00065} \\ \multicolumn{2}{c}{zA -0.505 0.418 -1.21 0.31373} \\ \multicolumn{2}{c}{zB 0.300 0.418 0.72 0.52495} \\ \multicolumn{2}{c}{Multiple R-squared: 0.397, Adjusted R-squared: -0.00545} \\ \multicolumn{2}{c}{F-statistic: 0.986 on 2 and 3 DF, p-value: 0.469} \\ \multicolumn{2}{c}{Analysis of Variance Table} \\ \multicolumn{2}{c}{Response: s} \\ \multicolumn{2}{c}{Df Sum Sq Mean Sq F value Pr(\textgreater{}F)} \\ \multicolumn{2}{c}{FO(zA, zB) 2 1.380 0.690 0.99 0.469} \\ \multicolumn{2}{c}{Residuals 3 2.099 0.700} \\ \multicolumn{2}{c}{Lack of fit 2 2.096 1.048 427.78 0.034} \\ \multicolumn{2}{c}{Pure error 1 0.002 0.002} \\ \multicolumn{2}{c}{Direction of steepest ascent (at radius 1):} \\ \multicolumn{2}{c}{zA zB} \\ \multicolumn{2}{c}{-0.85974 0.51074} \\ \multicolumn{2}{c}{Corresponding increment in original units:} \\ \multicolumn{2}{c}{xA xB} \\ \multicolumn{2}{c}{-0.85974 2.55368} \\ \multicolumn{2}{c}{\(>\) steepest(model1, dist = seq(0, 5, by = 1), descent = F)} \\ \multicolumn{2}{c}{Path of steepest ascent from ridge analysis:} \\ \multicolumn{2}{c}{dist zA zB | xA xB | yhat} \\ \multicolumn{2}{c}{1 0 0.000 0.000 | 10.500 36.000 | 5.108} \\ \multicolumn{2}{c}{2 1 -0.860 0.511 | 9.640 38.555} \\ \multicolumn{2}{c}{3 2 -1.720 1.021} \\ \multicolumn{2}{c}{4 3 -2.579 1.532 | 7.921 43.660} \\ \multicolumn{2}{c}{6 8.870} \\ \multicolumn{2}{c}{5 4 -3.439 2.043} \\ \multicolumn{2}{c}{7.061 46.215} \\ \multicolumn{2}{c}{7.458} \\ \multicolumn{2}{c}{6 5 -4.299 2.554} \\ \hline \hline \end{tabular}
\end{table}
Table 16.18: R program and output for first-order response surface regression: parameter estimates and analysis of variance In Table 16.21, the canonical analysis is shown, including: the stationary point expressed in terms of both coded and uncoded units; the eigenvalues, or canonical coefficients; and the eigenvectors, giving the direction of each canonical axis. The canonical coefficients and axes are with respect to the coded factor levels.

For this experiment, all eigenvalues (canonical coefficients) are negative, so the stationary point is a maximum. The eigenvectors are each scaled to be of length one. The last eigenvalue, with value \(-227.865\), is the largest in magnitude. For the corresponding eigenvector, the primary component is

\begin{table}
\begin{tabular}{r r} \hline \hline \multicolumn{2}{c}{\(>\) pah.data = read.table(‘data/pah.txt’’, header = T)} \\ \multicolumn{2}{c}{\(>\) pah.data\(\less\)fBlock = factor(pah.data\(\less\)Block)} \\ \multicolumn{2}{c}{\(>\) library(rsm)} \\ \multicolumn{2}{c}{\(>\) pah.ccd.data = coded.data(pah.data, zP ~ (Pres - 200)/100, + zT ~ (Temp - 70)/30, zET ~ (ET - 35)/25, zMC ~ (MC - 10)/10)} \\ \multicolumn{2}{c}{\(>\) pah.ccd.data} \\ \multicolumn{2}{c}{Run Block Pres Temp ET MC y fBlock} \\

[MISSING_PAGE_POST]

 \hline \hline \end{tabular}
\end{table}
Table 16.19: R program and output for second-order response surface regression: data entry and coding

[MISSING_PAGE_EMPTY:8557]

[MISSING_PAGE_FAIL:623]

[MISSING_PAGE_EMPTY:8559]

is in terms of coded variables, though the coding option allows the user to specify the coding formula relating each variable to its coded levels. By default, the design is randomized separately within each block, in which case the function stdorder can be used to display the design in standard, or unrandomized, order. One can specify a specific value of \(\alpha\) (e.g. alpha = 1.2872 for the flour experiment), or request that the value be set corresponding to a desired design property, such as: alpha = "rotatable" for a rotatable design; alpha = "orthogonal" for orthogonal blocking (not orthogonality); alpha = "spherical" for the axial and factorial points to be the same distance from the center points, and alpha = "faces" for the axial points to be on the faces of the cube (same as alpha = 1). Given a design, the variance function varfcn can generate a contour plot of the scaled variance for a given design and model, so one can see rotatability or non-rotatability, for example.

Using the bbd function, one can generate Box-Behnken designs for 3-7 factors, including designs with orthogonal blocking for either four factors and three blocks or five factors and two blocks.

For sake of completeness, the code for the acid copper pattern plating experiment illustrates one way to add data to the coded design data set, as needed for data analysis.

## Exercises

1. **Paint experiment, continued** The paint experiment of Eibl et al. (1992) was discussed in Example 16.2.1 (p. 569), where the first-order model was fitted to the data. For the fitted first-order model, do the following. 1. Plot the residuals versus run order, and use the plot to check the independence assumption. (The order of the observations was not randomized in this experiment. Rather, the observations were collected in the order they are shown row by row in Table 16.1, p. 570.) 2. Plot the residuals versus the predicted values, and use the plot to check the assumption of equal variance. 3. Plot the residuals versus their normal scores, and use the plot to check the normality assumption. 4. Verify that the design is orthogonal.
2. **Paint followup experiment** The data of the second paint experiment described by Eibl et al. (1992) are given in Table 16.23. This experiment involves factors \(A\)-\(D\), as these had significant effects in the first experiment (Example 16.2.1). The factors are \[\begin{array}{l}A\text{:\,belt speed}\qquad B\text{:\,tube width}\\ C\text{:\,pump pressure}\quad D\text{:\,paint viscosity}\end{array}\] All four factors are at lower levels than in the first experiment. Lowering the levels of factors \(B\)-\(D\) was indicated by the analysis of the first experiment. Lowering the level of factor \(A\) was based on a conjecture of the experimenters. 1. The experiment consists of two replicates of a half-fraction. Find the defining relation for the half-fraction. 2. Fit the first-order model, recoding the factor levels as \(\pm 1\). 3. Test for lack of fit of the first-order model. 2.

[MISSING_PAGE_FAIL:626]

[MISSING_PAGE_FAIL:627]

[MISSING_PAGE_FAIL:628]

2. Repeat the first analysis of variance of Sect. 16.5, for which the response variable was \(\overline{y}_{\mathbf{z}}\), after applying the transformation determined in part (a) to the observations \(y_{\mathbf{h}\mathbf{z}}\). Compare your conclusions with those reached in Sect. 16.5. 3. Repeat the second analysis of variance of Sect. 16.5, for which the response variable was \(100\log_{10}(s_{\mathbf{z}})\), after applying the transformation determined in part (a) to the observations \(y_{\mathbf{h}\mathbf{z}}\). Compare your conclusions to those reached in Sect. 16.5.
8. **Central composite design** Consider using a central composite design for three factors, to include eight factorial points and six axial points. 1. Determine the value of \(\alpha\) to make the design rotatable. 2. Investigate how \(\alpha\) and the number of center points should be chosen to make the design both rotatable and orthogonal, if possible. If this is not possible, how can the design be made rotatable and nearly orthogonal? 3. Investigate whether the design can be rotatable with orthogonal blocking. If not, then investigate whether orthogonal blocking is possible. If so, how many blocks could be used? Investigate whether orthogonal blocking and near rotatability is possible.
9. **Central composite design** Repeat Exercise 8 for a central composite design for four factors, to include 16 factorial points and eight axial points.
10. **Resin impurity experiment** An experiment was conducted using a design close to a central composite design to study the effects of drying time (hours) and temperature (\({}^{\circ}\)C) on the content \(y\) (ppm) of undesirable compounds in a resin. The data are shown in Table 16.26.

\begin{table}
\begin{tabular}{c c c c} Design point & Time & Temp. & \(y_{\mathbf{x},t}\) \\
1 & 7.0 & 232.4 & 18.5 \\
2 & 3.0 & 220.0 & 22.5 \\
3 & 11.0 & 220.0 & 17.2 \\
4 & 1.3 & 190.0 & 42.2 \\
5 & 7.0 & 190.0 & 28.6 \\
6 & 7.0 & 190.0 & 19.8 \\
7 & 7.0 & 190.0 & 23.6 \\
8 & 7.0 & 190.0 & 24.1 \\
9 & 7.0 & 190.0 & 24.2 \\
10 & 12.7 & 190.0 & 19.1 \\
11 & 3.0 & 160.0 & 54.1 \\
12 & 11.0 & 160.0 & 33.8 \\
13 & 7.0 & 147.6 & 55.4 \\ \end{tabular}
\end{table}
Table 16.26: Resin impurity content \(y_{\mathbf{z}t}\) (ppm)

[MISSING_PAGE_FAIL:630]

12. **Box-Behnken design** 1. Construct a Box-Behnken design for three factors based on the balanced incomplete block design for three treatments in three blocks of size two and the \(2^{2}\) factorial design. 2. Determine whether the design constructed in part (a) is rotatable. 3. For the design constructed in part (a), determine whether orthogonal blocking is possible.
13. **Box-Behnken design** 1. Construct a Box-Behnken design for five factors based on the balanced incomplete block design for five treatments in 10 blocks of size two. 2. Determine whether the design constructed in part (a) is rotatable. 3. For the design constructed in part (a), determine whether orthogonal blocking is possible.

### 17.1 Introduction

Until now, we have looked only at treatment factors whose levels have been specifically chosen. We have tested hypotheses about, and calculated confidence intervals for, comparisons in the effects of these particular treatment factor levels. These treatment effects are known as _fixed effects_, since we represent them in the model as unknown constants (parameters). Models that contain only fixed effects are called _fixed-effects models_.

As mentioned in step (f) of the checklist in Sect. 2.2, p. 7, there are occasions when we are interested in a large population of possible levels of a treatment factor, and the levels that are actually used in the experiment are a random sample from this population. The effects of the levels used in the experiment are then represented as random variables whose distributions are the distributions of values in the population. Such treatment-factor effects are called _random effects_, and the corresponding models are called _random-effects models_. We are not interested in just the levels that happen to be in the experiment. Rather, we are concerned with the variability of the effects of all the levels in the population. Consequently, random effects are handled somewhat differently from fixed effects. Some examples of experiments involving random effects are given in Sect. 17.2.

In Sect. 17.3 we look at experiments with a single random effect. The selection of sample sizes and model assumption checking are discussed in Sects. 17.4 and 17.5. These ideas are extended to experiments with two or more random effects in Sect. 17.6.

An experiment may involve both random and fixed effects, and the corresponding model is then known as a _mixed model_. Such experiments are discussed in Sect. 17.7. Block effects may also be random effects, and these are discussed in Sect. 17.9. Rules for obtaining confidence intervals and testing hypotheses for random effects are given in Sect. 17.8. The use of SAS and R software is considered in Sects. 17.10 and 17.11, respectively.

### 17.2 Some Examples

Before running an experiment, the checklist (Sect. 2.2, p. 7) should be completed as usual. In the case of a random effect, the treatment factor will have an extremely large number of levels, only a very small proportion of which can be observed in the experiment. Throughout this chapter, we will assume that the total possible number of levels of each treatment factor will be at least 100 times larger than the numbers of levels that can be observed. Typically, the population of possible levels _will_ meet thisrequirement, and for the purposes of writing down a model, we may regard the population as infinite. Otherwise, one needs to make a correction for a "finite population" in all of the formulae, and this is beyond the scope of this book. Some examples of "infinite" populations are given in Example 17.2.1.

#### 17.2.1 Infinite populations

Suppose that a manufacturer of canned tomato soup wishes to reduce the variability in the thickness of the soup. Suppose that the most likely causes of the variability are the quality of the cornflour (cornstarch) received from the supplier and the actions of the machine operators. Let us consider two different scenarios:

Scenario 1: The machine operators are highly skilled and have been with the company for a long time. Thus, the most likely cause of variability is the quality of the cornflour delivered to the company. The treatment factor is "cornflour," and its possible levels are all the possible batches of cornflour that the supplier could deliver. Theoretically, this is an infinite population of batches. We are interested not only in the batches of cornflour that have currently been delivered, but also in all those that might be delivered in the future. If we assume that the batches delivered to the company are a random sample from all batches that could be delivered, and if we take a random sample of delivered batches to be observed in the experiment, then the effect of the cornflour on the thickness is a random effect and can be modeled by a random variable.

Scenario 2: It is known that the quality of the cornflour is extremely consistent, so the most likely cause of variability is due to the different actions of the machine operators. The company is large and machine operators change quite frequently. Consequently, those that are available to take part in the experiment are only a small sample of all operators employed by the company at present or that might be employed in the future. If we can assume that the operators available for the experiment are representative of the population, then we can assume that they are similar to a random sample from a very large population of possible operators, present and future. Since we would like to know about the variability of the entire population, we model the effect of the operators as random variables, and call them random effects. 

In the absence of any blocking factors, a completely randomized design would be used. The levels of the random-effects treatment factor are first selected at random from the population of all possible levels, and then the experimental units are randomly assigned to these selected levels as usual. At step (h) of the checklist, we need to calculate the number of levels \(v\) of the treatment factor to be observed in the experiment in addition to \(r\), the number of observations on each level. Since this calculation uses the formulas for confidence intervals and hypothesis tests, we will postpone the discussion to Sect. 17.4. As a general rule, if the variability of the treatment effects is much greater than the error (measurement) variability, then \(v\) should be large and \(r\) small; and vice versa.

#### 17.2.2 Clean wool experiment

The clean wool experiment was reported by J.M. Cameron, of the National Bureau of Standards, in the 1951 volume of _Biometrics_. The following checklist has been compiled from the information given in the article.

1. **Define the objectives of the experiment**.

of wool present, i.e., on the amount of wool present after thorough cleaning--the "clean content." The clean content is expressed as the percentage the weight of the clean wool is of the original weight of the raw wool. The experiment was run in order to estimate the variability in "clean content" of bales of wool in a shipment.
2. **Identify all sources of variation**. (i) Treatment factors and their levels. The treatment factor was "wool bale" and its levels were the entire population of bales in a particular shipment. Seven bales were observed in the experiment, and these were selected at random from the shipment. The shipment was large enough to allow the bales used in the experiment to be regarded as a random sample from an infinite population of bales. The treatment factor "wool bale" was therefore regarded as a random effect. (ii) Experimental units. The experimental units were time slots, so that allocation of these to the levels of the treatment factor determined the order in which the wool bales were observed. (iii) Blocking factors, noise factors, and covariates. No nuisance factors were identified as major sources of variation.
3. **Choose a rule by which to assign the experimental units to the levels of the treatment factors**. A completely randomized design was selected.
4. **Specify the measurements to be made, the experimental procedure, and the anticipated difficulties**. A machine was used to bore through a bale of wool and extract a core of wool. Several cores were taken from each of the seven selected bales so that several observations on clean content could be made on each bale. Each core of wool was weighed and then cleaned by scouring, removing burrs, etc. After cleaning, the wool was reweighed and the clean content calculated as the ratio of the clean wool to the initial weight, times 100%. An anticipated difficulty was that the scouring process, which works well with large amounts of wool, proves difficult with a small core of wool, so that the experimental error observed in the experiment may be larger than would normally be observed in routine production.

The observations on the clean content of the seven bales are shown in Table 17.1. Model selection for this experiment and its analysis via SAS and R software are discussed in Sects. 17.10 and 17.11, respectively. \(\square\)

\begin{table}
\begin{tabular}{c c c c c c c c}  & \multicolumn{8}{c}{Bale} \\  & 1 & 2 & 3 & 4 & 5 & 6 & 7 \\ Clean content & 52.33 & 56.99 & 54.64 & 54.90 & 59.89 & 57.76 & 60.27 \\
56.26 & 58.69 & 57.48 & 60.08 & 57.76 & 59.68 & 60.30 \\
62.86 & 58.20 & 59.29 & 58.72 & 60.26 & 59.58 & 61.09 \\
50.46 & 57.35 & 57.51 & 55.61 & 57.53 & 58.08 & 61.45 \\ \end{tabular}
\end{table}
Table 17.1: Data for the clean wool experiment 

### One Random Effect

#### The Random-Effects One-Way Model

For a completely randomized design, with \(v\) randomly selected levels of a treatment factor \(T\), the random-effects one-way model is

\[Y_{it}=\mu+T_{i}+\epsilon_{it}\, \tag{17.3.1}\] \[\epsilon_{it}\sim N(0,\sigma^{2})\,\ \ T_{i}\sim N(0,\sigma_{T}^{2})\,\] \[\epsilon_{it}\,\text{'s and }T_{i}\text{'s are all mutually independent}\,\] \[t=1,\ldots,r_{i},\ \ i=1,\ldots,v\.\]

Compare this with the fixed-effects one-way analysis of variance model (3.3.1), p. 33. The form of the model and the error assumptions are exactly the same. The only difference is in the modeling of the treatment effect. Since the \(i\)th level of the treatment factor \(T\) observed in the experiment has been randomly selected from the "infinite" population, its observed effect is an observation of a random variable \(T_{i}\). The distribution of \(T_{i}\) is the distribution of treatment effects in the whole population. We have assumed in (17.3.1) that the population of effects follows a normal distribution with variance \(\sigma_{T}^{2}\), and this assumption will need to be checked along with the error assumptions. The mean of the treatment-effect population has been absorbed into the constant \(\mu\), so the distribution of \(T_{i}\) is listed as \(N(0,\sigma_{T}^{2})\). The variance \(\sigma_{T}^{2}\) is the parameter of interest, since if the effects of all of the treatment-factor levels are the same, then \(\sigma_{T}^{2}\) is zero. If the effects of the levels are quite different, then \(\sigma_{T}^{2}\) is quite large.

Our final assumption is one of independence. If the treatment-factor levels are selected at random, then the assumption of independence of \(T_{1},\,T_{2},\,\ldots,\,T_{v}\) is reasonable. However, if, as in Example 17.2.1 Scenario 2, the levels are a "convenient sample," then this assumption should be investigated carefully. Independence of the \(T_{i}\) and \(\epsilon_{it}\) requires that the treatment factor not affect any source of variation that has been absorbed into the error variable.

In a random-effects model, the expected value of the response is \(\mu\), since

\[E[Y_{it}]=E[\mu]+E[T_{i}]+E[\epsilon_{it}]=\mu\.\]

The variance of \(Y_{it}\) is

\[\text{Var}(Y_{it})=\text{Var}(\mu+T_{i}+\epsilon_{it})=\text{Var}(T_{i})+\text {Var}(\epsilon_{it})+2\text{Cov}(T_{i},\epsilon_{it})=\sigma_{T}^{2}+\sigma^{ 2}\,\]

since \(T_{i}\) and \(\epsilon_{it}\) are mutually independent and so have zero covariance. Therefore, the distribution of \(Y_{it}\) is

\[Y_{it}\sim N(\mu,\ \sigma_{T}^{2}+\sigma^{2}). \tag{17.3.2}\]

The two components \(\sigma_{T}^{2}\) and \(\sigma^{2}\) of the variance of \(Y_{it}\) are known as _variance components_. Observations on the same treatment are correlated, with

\[\text{Cov}(Y_{it},Y_{is})=\text{Cov}(\mu+T_{i}+\epsilon_{it},\,\mu+T_{i}+ \epsilon_{is})=\text{Var}(T_{i})=\sigma_{T}^{2}\.\]

#### Estimation of \(\sigma^{2}\)

In order to be able to test hypotheses about \(\sigma_{T}^{2}\) or to calculate confidence intervals, we need an unbiased estimate of \(\sigma^{2}\). The random-effects one-way model (17.3.1) is very similar to the fixed effects one-way analysis of variance model (3.3.1), p. 33, so a natural question is whether the fixed-effects mean square for error MSE provides an unbiased estimator for \(\sigma^{2}\) in the random-effects model also. The answer, happily, is "yes," and we can check it by calculating \(E[\text{MSE}]\) for the random-effects model, as shown below.

From (3.4.6), p. 39, the fixed-effects sum of squares for error is

\[\text{SSE}=\sum_{i=1}^{v}\sum_{t=1}^{r_{i}}Y_{it}^{2}-\sum_{i=1}^{v}r_{i} \overline{Y}_{i.}^{2}\.\]

Remember that the variance of a random variable \(X\) is calculated as \(\text{Var}(X)=E[X^{2}]-(E[X])^{2}\). So, we have

\[E[Y_{it}^{2}]=\text{Var}(Y_{it})+(E[Y_{it}])^{2}=(\sigma_{T}^{2}+\sigma^{2})+ \mu^{2}\,.\]

Now,

\[\overline{Y}_{i.}=\mu+T_{i}+\frac{1}{r_{i}}\sum_{t=1}^{r_{i}}\epsilon_{it}\,\]

so

\[\text{Var}(\overline{Y}_{i.})=\sigma_{T}^{2}+\frac{\sigma^{2}}{r_{i}}\ \ \text{and}\ \ E[\overline{Y}_{i.}]=\mu\,. \tag{17.3.3}\]

Consequently,

\[E[\overline{Y}_{i.}^{2}]=\left(\sigma_{T}^{2}+\frac{\sigma^{2}}{r_{i}}\right)+ \mu^{2}.\]

Thus,

\[E[\text{SSE}] =\sum_{i=1}^{v}\sum_{t=1}^{r_{i}}(\sigma_{T}^{2}+\sigma^{2}+\mu^{ 2})-\sum_{i=1}^{v}r_{i}\left(\sigma_{T}^{2}+\frac{\sigma^{2}}{r_{i}}+\mu^{2}\right)\] \[=n\sigma^{2}-v\sigma^{2}\ \ \left(\text{where}\ n=\sum_{i=1}^{v}r_{i}\right)\] \[=(n-v)\sigma^{2}\,,\]

giving

\[E[\text{MSE}]=E[\text{SSE}/(n-v)]=\sigma^{2}.\]

So MSE is an unbiased estimator for \(\sigma^{2}\), and the observed value of the mean square for error, msE, is an unbiased estimate for \(\sigma^{2}\) in the random-effects one-way model, as well as in the fixed-effects one-way model.

Confidence bounds for \(\sigma^{2}\) can be computed as under fixed-effects models (Sect. 3.4.6), that is,

\[\sigma^{2}\leq\frac{\text{ssE}}{\chi^{2}_{n-v,\,1-\alpha}}\,, \tag{17.3.4}\]

where \(\chi^{2}_{n-v,\,1-\alpha}\) is the percentile of the chi-squared distribution with \(n-v\) degrees of freedom and with probability of \(1-\alpha\) in the right-hand tail.

#### Estimation of \(\sigma^{2}_{T}\)

Since the fixed-effects mean square for error msE provides an unbiased estimate of \(\sigma^{2}\), the next question that is natural to ask is whether the fixed-effects mean square for treatments msT provides an unbiased estimate for \(\sigma^{2}_{T}\). The answer is "not quite," but we can certainly use it to find an estimate. Now msT = ssT/(\(v-1\)), and ssT is given in (3.5.11), p. 43, as

\[\text{ssT}=\sum_{i=1}^{v}r_{i}\overline{\nu}_{i.}^{2}-n\overline{\nu}_{..}^{2}\]

with corresponding random variable

\[\text{SST}=\sum_{i=1}^{v}r_{i}\overline{Y}_{i.}^{2}-n\overline{Y}_{..}^{2}\,.\]

Using the same type of calculation as in Sect. 17.3.2 above, we have

\[\overline{Y}_{..}=\mu\ +\ \frac{1}{n}\sum_{i}r_{i}T_{i}\ +\ \frac{1}{n}\sum_{i=1} ^{v}\sum_{t=1}^{r_{i}}\epsilon_{it}\,.\]

So

\[E[\overline{Y}_{..}]=\mu\ \ \ \text{and}\ \ \ \text{Var}(\overline{Y}_{..})= \frac{\sum r_{i}^{2}}{n^{2}}\sigma_{T}^{2}+\frac{n}{n^{2}}\sigma^{2}\,.\]

Also, from (17.3.3),

\[E[\overline{Y}_{i.}]=\mu\ \ \ \text{and}\ \ \ \text{Var}(\overline{Y}_{i.})= \sigma_{T}^{2}+\frac{\sigma^{2}}{r_{i}}.\]

Therefore,

\[E[SST]= \sum_{i=1}^{v}r_{i}\left(\sigma_{T}^{2}+\frac{\sigma^{2}}{r_{i}} +\mu^{2}\right)-n\left(\frac{\sum r_{i}^{2}}{n^{2}}\sigma_{T}^{2}+\frac{\sigma ^{2}}{n}+\mu^{2}\right)\] \[= \left(n-\frac{\sum r_{i}^{2}}{n}\right)\sigma_{T}^{2}+(v-1) \sigma^{2}\,.\]Since \(MST=SST/(v-1)\), we have

\[E[MST]=c\sigma_{T}^{2}+\sigma^{2},\ \text{where}\ c=\frac{n^{2}-\sum r_{i}^{2}}{n(v-1)}.\]

Notice that if all \(r_{i}\) are equal to \(r\), then \(n=vr\) and \(c=r\).

We see that MST is an unbiased estimator of \(c\sigma_{T}^{2}+\sigma^{2}\), not \(\sigma_{T}^{2}\). Nevertheless, we can easily find an unbiased estimator of \(\sigma_{T}^{2}\), since

\[E\left[\frac{MST-MSE}{c}\right]=\sigma_{T}^{2}\,. \tag{17.3.5}\]

It is, unfortunately, possible for the observed value of this estimator to be negative even though \(\sigma_{T}^{2}\) cannot be negative. This will occur when _msE_ happens to be greater than _msT_, and this is most likely when \(\sigma_{T}^{2}\) is close to zero. If _msE_ is considerably greater than _msT_, then the model should be questioned, as it is unlikely to be a good description of the data.

#### 17.3.1 Ice cream experiment

The following experiment was run by Sue Hubbard in 1986 to determine whether or not different flavors of ice cream melt at different speeds. A random sample of three flavors was selected from a large population of flavors offered to the customer by a single manufacturer in May 1986. It is not obvious that the selected flavors are representative of all possible ice cream flavors, since some may include an ingredient that inhibits melting. The theoretical population is therefore the population of all flavors that could be made with ingredients similar to those flavors available.

The three flavors of ice cream were stored in the same freezer in similar-sized containers. For each observation, one teasponful of ice cream was taken from the freezer, transferred to a plate, and the melting time at room temperature was observed to the nearest second. Eleven observations were taken on each flavor. These are shown, together with their order of observation, in Table 17.2 and plotted in Fig. 17.1.

Now,

\[\text{ss}E = \sum\sum y_{i}^{2}-11\sum\overline{y}_{i.}^{2}\] \[= 30,206,485-30,003,028.8181\] \[= 203,456.1819\,.\]

So an unbiased estimate of \(\sigma^{2}\) is

\[\text{ms}E\ =\ \text{ss}E/(33-3)\ =\ 6781.8727\ \text{seconds}^{2}\,.\]

\begin{table}
\begin{tabular}{c c c c c c c} \hline Flavor & \multicolumn{6}{c}{Time in seconds (order of observation)} \\ \hline
1 & 924 (1) & 876 (2) & 1150 (5) & 1053 (7) & 1041 (10) & 1037 (12) \\  & 1125 (15) & 1075 (16) & 1066 (20) & 977 (22) & 886 (25) & \\
2 & 891 (3) & 982 (4) & 1041 (8) & 1135 (13) & 1019 (14) & 1093 (18) \\  & 994 (27) & 960 (30) & 889 (31) & 967 (32) & 838 (33) & \\
3 & 817 (6) & 1032 (9) & 844 (11) & 841 (17) & 785 (19) & 823 (21) \\  & 846 (23) & 840 (24) & 848 (26) & 848 (28) & 832 (29) & \\ \hline \end{tabular}
\end{table}
Table 17.2: Melting times for three randomly selected flavors of ice cream. Order of observation in parentheses Similarly,

\[\begin{split} ssT&=11\sum\overline{y}_{i.}^{2}-33 \overline{y}_{\cdots}^{2}\\ &=30,003,028.8181-29,830,018.9393\\ &=173,009.8787\,.\end{split}\]

So \(\text{ms}T=\text{ss}T/(3-1)=86,504.9394\) seconds\({}^{2}\), and an unbiased estimate of \(\sigma_{T}^{2}\) is given by

\[\begin{split}\frac{\text{ms}T-\text{ms}E}{c}&=\frac {86,504.9394-6781.8727}{11}\\ &=7247.5515\text{ seconds}^{2}.\end{split}\]

#### Testing Equality of Treatment Effects

When the treatment factor has random effects, we are interested in the variability of the treatment effects in the entire population of levels, not just those in the experiment. Since the variance of the effects in the population is \(\sigma_{T}^{2}\), the null hypothesis of interest is of the form

\[H_{0}^{T}:\sigma_{T}^{2}=0\,,\]

and the alternative hypothesis is

\[H_{A}^{T}:\sigma_{T}^{2}>0.\]

It would be very convenient if we could use the same hypothesis-testing rule as we used for testing equality of treatment effects in the fixed-effects model. The fixed-effects decision rule was to reject the hypothesis of no difference in the treatments if \(\text{ms}T/\text{ms}E>F_{v-1,n-v,\alpha}\), (see (3.5.15), p. 43). Let us examine the ratio \(\text{ms}T/\text{ms}E\) in the random-effects one-way model (17.3.1). In Sect. 17.3.2 we showed that

\[E[\text{MSE}]=\sigma^{2}\,,\]

Figure 17.1: Plot of data for the ice cream experiment

and in Sect. 17.3.3 we showed that

\[E[\mbox{\it MST}]=c\sigma_{T}^{2}+\sigma^{2}\,,\]

where \(c=(n^{2}-\sum r_{i}^{2})/n(v-1)\), and if all \(r_{i}\) are equal to \(r\), then \(c=r\).

So, if \(H_{0}^{T}:\sigma_{T}^{2}=0\) is true, then the expected value of the numerator of the ratio MST/MSE is equal to \(\sigma^{2}\), the same as the expected value of the denominator. Then, if \(H_{0}^{T}\) is true, the ratio should be in the region of 1.0. But if \(\sigma_{T}^{2}\) is large, the expected value of the numerator is larger than the denominator, and the ratio should be large and positive. This situation is similar to that for the fixed-effects case. The only remaining question is whether MST/MSE has an \(F\) distribution with \(v-1\) and \(n-v\) degrees of freedom when \(H_{0}^{T}\) is true.

It can be shown that

\[\mbox{\it SST}/(c\sigma_{T}^{2}+\sigma^{2})\sim\chi_{v-1}^{2} \tag{17.3.6}\]

and

\[\mbox{\it SSE}/\sigma^{2}\sim\chi_{n-v}^{2}\]

and that SST and SSE are independent. Consequently, we have

\[\frac{\mbox{\it SST}/((c\sigma_{T}^{2}+\sigma^{2})(v-1))}{\mbox{\it SSE}/( \sigma^{2}(n-v))}=\frac{\mbox{\it MST}/(c\sigma_{T}^{2}+\sigma^{2})}{\mbox{ \it MSE}/\sigma^{2}}\sim\frac{\chi_{v-1}^{2}/(v-1)}{\chi_{n-v}^{2}/(n-v)}\sim F _{v-1,n-v}\,, \tag{17.3.7}\]

and when \(\sigma_{T}^{2}=0\), then

\[\frac{\mbox{\it MST}}{\mbox{\it MSE}}\sim F_{v-1,n-v}\,.\]

Thus, to test \(H_{0}:\sigma_{T}^{2}=0\) against \(H_{A}:\sigma_{T}^{2}>0\), our decision rule is to

\[\mbox{\rm reject}\ H_{0}^{T}\ \ \mbox{if}\ \ \frac{\mbox{\it ms}T}{\mbox{\it ms }E}>F_{v-1,n-v,\alpha} \tag{17.3.8}\]

for some chosen value of the significance level \(\alpha\). The test can be set out in an analysis of variance table in the usual way; see Table 17.3. We have included the expected mean squares in the table for easy reference.

Rather than testing whether or not the variance of the population of treatment effects is zero, it may be of more interest to test whether the variance is less than or equal to some proportion of the error

\begin{table}
\begin{tabular}{c c c c c c} \hline Source of variation & Degrees of freedom & Sum of squares & Mean squares & Ratio & Expected mean square \\ \hline Treatments & \(v-1\) & \(\mbox{\it ss}T\) & \(\frac{\mbox{\it ss}T}{v-1}\) & \(\frac{\mbox{\it ms}T}{\mbox{\it ms}E}\) & \(c\sigma_{T}^{2}+\sigma^{2}\) \\ Error & \(n-v\) & ssE & \(\frac{\mbox{\it ss}E}{n-v}\) & & \(\sigma^{2}\) \\ Total & \(n-1\) & sstot & & & \\ \hline \multicolumn{7}{c}{Computational formulae} \\ \hline \(\mbox{\it ss}T=\sum_{i}r_{i}\overline{y}_{i-}^{2}-n\overline{y}_{-}^{2}\) & & \(\mbox{\it ss}E=\sum_{i}\sum_{i}y_{it}^{2}-\sum_{i}r_{i}\overline{y}_{i.}^{2}\) \\ \(\mbox{\it sstot}=\sum_{i}\sum_{i}y_{it}^{2}-n\overline{y}_{-}^{2}\) & & \(c=\frac{n^{2}-\sum_{i}y_{it}^{2}}{n(v-1)}\) \\ \hline \end{tabular}
\end{table}
Table 17.3: Analysis of variance table for the random-effects one-way model variance, that is,

\[H_{0}^{\gamma T}:\sigma_{T}^{2}\leq\gamma\sigma^{2}\text{ and }H_{A}^{\gamma T}: \sigma_{T}^{2}>\gamma\sigma^{2},\]

for some constant \(\gamma\). From (17.3.7), we see that if \(H_{0}^{\gamma T}\) is true with \(\sigma_{T}^{2}=\gamma\sigma^{2}\), then

\[\frac{\text{MST}/(\sigma^{2}(c\sigma_{T}^{2}/\sigma^{2}+1))}{\text{MSE}/\sigma ^{2}}=\frac{\text{MST}}{\text{MSE}(c\gamma+1)}\sim F_{v-1,n-v}.\]

So, our decision rule (17.3.8) needs only the minor modification of including the constant (\(c\gamma+1\)), that is,

\[\text{reject }H_{0}^{\gamma T}\text{ if }\frac{\text{ms}T}{\text{ms}E}>(c \gamma+1)F_{v-1,n-v,\alpha}\,. \tag{17.3.9}\]

If we choose \(\gamma=0\), then the decision rule (17.3.9) reduces to rule (17.3.8) for testing the null hypothesis \(H_{0}^{T}:\sigma_{T}^{2}=0\) against its alternative hypothesis \(H_{A}^{T}:\sigma_{T}^{2}>0\).

#### _Example 17.3.2_ Ice cream experiment, continued

The analysis of variance table for the ice cream experiment of Example 17.3.1 is shown in Table 17.4. If we test the null hypothesis that the variance of melting times in the population of ice creams is negligible against the alternative hypothesis that it is not (that is, \(H_{0}^{T}:\sigma_{T}^{2}=0\) versus \(H_{A}^{T}:\sigma_{T}^{2}>0\)) with a Type I error probability of \(\alpha=0.05\), we would reject \(H_{0}^{T}\), since

\[\text{ms}T/\text{ms}E=12.76\ >\ F_{2,30,0.05}=3.32\,,\]

or equivalently, the \(p\)-value is less than \(0.05\).

In such an experiment there will clearly be considerable error variability in the data due to fluctuations of room temperature and the difficulty of determining the exact time at which the ice cream has melted completely. Variability in the melting time of different flavors is unlikely to be of interest to the experimenter unless it is larger than the error variability. Suppose, therefore, instead of testing the hypothesis \(H_{0}^{T}\) against \(H_{A}^{T}\), we test the null hypothesis \(H_{0}^{\gamma T}:\{\sigma_{T}^{2}\leq\sigma^{2}\}\) against \(H_{A}^{\gamma T}:\{\sigma_{T}^{2}>\sigma^{2}\}\). Since there are \(r=11\) observations on each ice cream, the constant is \(c=11\), and the hypothesis-testing rule (17.3.9) with \(\gamma=1.0\) becomes

\[\text{reject }H_{0}^{\gamma T}\text{ if }\frac{\text{ms}T}{\text{ms}E}>(11+ 1)F_{2,30,\alpha}\,,\]

that is,

\[\text{reject }H_{0}^{\gamma T}\text{ if }12.76>12\ F_{2,30,\alpha}.\]

\begin{table}
\begin{tabular}{c c c c c c} \hline Source of variation & Degrees of freedom & Sum of squares & Mean squares & Ratio & \(p\)-value \\ \hline Flavor & 2 & 173009.8788 & 86504.9394 & 12.76 & 0.0001 \\ Error & 30 & 203456.1818 & 6781.8727 & & \\ Total & 32 & 376466.0606 & & & \\ \hline \end{tabular}
\end{table}
Table 17.4: Analysis of variance table for the ice cream experiment It can be seen from the table in Appendix A.6 that for any practical choice of \(\alpha\), there is not sufficient evidence to reject the null hypothesis. Thus, although the variation in the melting times of the different flavors is significant, so apparently \(\sigma_{T}^{2}>0\), sufficient evidence has not been gathered to be able to claim that the variation is significantly larger than the error variation in the data. 

#### Confidence Intervals for Variance Components

We showed in Sect. 17.3.1, p. 618, that the response variable \(Y_{it}\) in a random-effects one-way model (17.3.1) has a normal distribution with variance \(\sigma^{2}+\sigma_{T}^{2}\), where \(\sigma^{2}\) is the variance of the error variables and \(\sigma_{T}^{2}\) is the variance of the treatment effects in the population. In order to assess the variability of the treatment-effect population, we may wish to calculate a confidence interval for \(\sigma_{T}^{2}\) or, alternatively, for \(\sigma_{T}^{2}/\sigma^{2}\) if we want to assess the treatment variability relative to the error variability. Since the latter is the easier calculation, we investigate this first.

**Confidence Intervals for \(\sigma_{T}^{2}/\sigma^{2}\)**

From (17.3.7), p. 623, we know that

\[\frac{\text{MST}}{\text{MSE}(c\sigma_{T}^{2}/\sigma^{2}+1)}\sim F_{v-1,n-v}\, \tag{17.3.10}\]

where \(c=(n^{2}-\Sigma r_{i}^{2})/(n(v-1))\), and if the \(r_{i}\) are all equal to \(r\), then \(c=r\). From this, we can write down an interval in which MST/MSE lies with probability \(1-\alpha\); that is,

\[P\Bigg{(}F_{v-1,n-v,1-\alpha/2}\leq\frac{\text{MST}}{\text{MSE}(c\sigma_{T}^{2 }/\sigma^{2}+1)}\leq F_{v-1,n-v,\alpha/2}\Bigg{)}=1-\alpha.\]

If we rearrange the left-hand inequality, we find that

\[c\sigma_{T}^{2}/\sigma^{2}\leq\frac{\text{MST}}{\text{MSE}\,F_{v-1,n-v,1- \alpha/2}}-1\,\]

and similarly for the right-hand inequality,

\[c\sigma_{T}^{2}/\sigma^{2}\geq\frac{\text{MST}}{\text{MSE}\,F_{v-1,n-v,\alpha /2}}-1\.\]

So, replacing the random variables by their observed values, we obtain a \(100(1-\alpha)\)% confidence interval for \(\sigma_{T}^{2}/\sigma^{2}\) as

\[\frac{1}{c}\Bigg{[}\frac{\text{ms}T}{\text{ms}E\,F_{v-1,n-v,\alpha/2}}-1\Bigg{]} \leq\frac{\sigma_{T}^{2}}{\sigma^{2}}\leq\ \ \frac{1}{c}\Bigg{[}\frac{\text{ms}T}{\text{ms}E\,F_{v-1,n-v,1-\alpha/2}}-1\ \Bigg{]}\.\]

A drawback of this interval is that if msT is not much larger than msE (or perhaps smaller), then it is possible for the left-hand end of the interval to be negative even though \(\sigma_{T}^{2}/\sigma^{2}\) can never be negative. Although we could replace a negative lower bound by zero, we will not do so, since it can result in a short interval, giving the misleading impression that the experiment was more accurate than it actually was.

For calculation of the interval, remember that \(F_{v-1,n-v,\alpha/2}\) denotes the percentile of the \(F_{v-1,n-v}\) distribution corresponding to a probability of \(\alpha/2\) in the right-hand tail. Also, \(F_{v-1,n-v,1-\alpha/2}\) denotes the percentile corresponding to a probability of \(\alpha/2\) in the left-hand tail, that is, \(1-\alpha/2\) in the right-hand tail. Since \(F_{v-1,n-v,1-\alpha/2}\) is not tabulated in Appendix A.6, it is important to note that

\[F_{v-1,n-v,1-\alpha/2}=(F_{n-v,v-1,\alpha/2})^{-1}. \tag{17.3.12}\]

#### (17.3.3 Ice cream experiment, continued

In the ice cream experiment of Examples 17.3.1 and 17.3.2, pp. 621 and 624, the variance \(\sigma_{T}^{2}\) in the melting times (in seconds) of the population of different flavors of ice cream is substantially greater than zero but not substantially greater than the error variance \(\sigma^{2}\). A confidence interval for \(\sigma_{T}^{2}/\sigma^{2}\) can be obtained using (17.3.11). The values \(\text{ms}T=86504.9394\), \(\text{ms}E=6781.8727\), \(v=3\), \(c=r=11\), and \(n=33\) are obtained from Example 17.3.2. From the table in Appendix A.6, we have

\[F_{2,30,.05}=3.32\ \ \ \text{and}\ \ \ F_{2,30,.95}=(F_{30,2,.05})^{-1}=(19.5)^{-1 }=0.0513\.\]

Therefore, the confidence interval (17.3.11) becomes

\[\frac{1}{11}\left(\frac{86504.9394}{(6781.8727)(3.32)}-1\right)\leq\frac{\sigma _{T}^{2}}{\sigma^{2}}\leq\frac{1}{11}\left(\frac{86504.9394}{(6781.8727)(0.0513 )}-1\right)\,\]

that is,

\[\sigma_{T}^{2}/\sigma^{2}\in(0.258,22.513)\.\]

This interval is too wide to be of much practical use, since it says that with 95% confidence, \(\sigma_{T}^{2}\) could be 4 times smaller or as much as 22 times bigger than \(\sigma^{2}\). However, the result does agree with the test of the null hypothesis \(H_{0}^{\gamma T}\) in Example 17.3.2, since the interval includes the value \(\sigma_{T}^{2}/\sigma^{2}=1.0\). 

As can be seen from Example 17.3.3, a confidence interval for \(\sigma_{T}^{2}/\sigma^{2}\) can be very wide. Not only do we need sufficient numbers of observations on each treatment in the experiment in order to keep a confidence interval narrow, but we also need a sufficiently large selection of treatments to represent the population. In Example 17.3.3, there were only \(v=3\) treatments to represent an entire population of ice cream flavors, and this has contributed to the lack of precision in the experiment. Calculation of sample sizes will be discussed in Sect. 17.4.

#### Confidence Intervals for \(\sigma_{T}^{2}\)

There are various methods of obtaining approximate \(100(1-\alpha)\)% confidence intervals for \(\sigma_{T}^{2}\). The only method that we shall give here is one that is useful when \(\sigma_{T}^{2}\) is not close to zero and that can be easily adapted when we have more complicated models.

First, remember that an unbiased estimator for \(\sigma_{T}^{2}\) was obtained in Eq. (17.3.5), p. 621, as

\[U=c^{-1}(\text{MST}-\text{MSE})\, \tag{17.3.13}\]

where \(c=(n^{2}-\Sigma r_{i}^{2})/(n(v-1))\), and \(c=r\) when the sample sizes are equal. If we can determine the distribution of \(U\), then we can easily find a confidence interval for \(\sigma_{T}^{2}\). We know that for the random-effects one-way model, \(\text{SST}/(c\sigma_{T}^{2}+\sigma^{2})\sim\chi_{v-1}^{2}\) and \(\text{SSE}/\sigma^{2}\sim\chi_{n-v}^{2}\) and that SST and SSE are independent. The exact distribution of \(U\) is therefore based on the difference of two chi-squared distributions each multiplied by a constant of unknown value, and this is not a standard tabulated distribution. However, it can be shown that a reasonable approximation to the true distribution of \(U/\sigma_{T}^{2}\) is a chi-squared distribution divided by its degrees of freedom \(x\), where \(x\) is estimated by

\[x=\frac{(\text{ms}T-\text{ms}E)^{2}}{\text{ms}T^{2}/(v-1)+\text{ms}E^{2}/(n-v )}. \tag{17.3.14}\]

In other words, the distribution of \(xU/E[U]\) is approximately \(\chi_{x}^{2}\). This result is related to the Satterthwaite approximation that we used in Sect. 5.6.3, p. 115 (Scheffe 1959, Sect. 7.5, gives the general result). Using this approximation, we can write down the approximate probability statement

\[P\left(\chi_{x,1-\alpha/2}^{2}\leq\frac{xU}{\sigma_{T}^{2}}\leq\chi_{x,\alpha/ 2}^{2}\right)\approx 1-\alpha\,.\]

If we rearrange the left-hand inequality, we obtain

\[\sigma_{T}^{2}\leq\frac{xU}{\chi_{x,1-\alpha/2}^{2}}\,,\]

and if we rearrange the right-hand inequality, we obtain

\[\frac{xU}{\chi_{x,\alpha/2}^{2}}\leq\sigma_{T}^{2}\,.\]

Consequently, we obtain an approximate 100(1\(-\alpha\))% confidence interval for \(\sigma_{T}^{2}\) as

\[\frac{xu}{\chi_{x,\alpha/2}^{2}}\leq\sigma_{T}^{2}\leq\frac{xu}{\chi_{x,1- \alpha/2}^{2}}\,, \tag{17.3.15}\]

where \(u\) is the observed value of \(U\); that is,

\[u=c^{-1}(\text{ms}T-\text{ms}E)\,. \tag{17.3.16}\]

##### 17.3.4 \(\text{Ice}\) cream experiment, continued

Suppose we require a 90% confidence interval for the variance of the melting times of the population of ice creams in the ice cream experiment of Examples 17.3.1 and 17.3.2, pp. 621 and 624. Using the information in those examples, we obtain the unbiased estimate (17.3.16) of \(\sigma_{T}^{2}\) as \(u=7247.5526\) seconds\({}^{2}\). The degrees of freedom \(x\) of the approximate distribution of \(U\) are calculated using (17.3.14), that is,

\[x=\frac{(86504.9394-6781.8727)^{2}}{(86504.9394)^{2}/2-(6781.8727)^{2}/30} \approx 1.7.\]

From Table 5 we can guess at the approximate values of \(\chi_{x,\,05}^{2}\) and \(\chi_{x,\,95}^{2}\) as

\[\chi_{1.7,\,05}^{2}\approx 5.3\;\;\;\text{and}\;\;\;\chi_{1.7,\,95}^{2}\approx 0.07\,.\]So a 90% confidence interval for \(\sigma_{T}^{2}\) is roughly

\[\sigma_{T}^{2} \in \left(\frac{(1.7)(7247.5515)}{5.3},\ \ \frac{(1.7)(7247.55)}{0.07}\right)\] \[= (2,324.69,\ \ 176,011.97)\]

Taking square roots and converting to minutes, we obtain the approximate 90% confidence interval for the standard deviation of melting times as

\[\sigma_{T}\in(0.8,\ 7.0)\ \text{minutes}.\]

Again, this interval is too wide for practical use, due to the small number of flavors examined from the population. 

### Sample Sizes for an Experiment with One Random Effect

For the fixed-effects one-way analysis of variance model, we looked at two different ways of determining sample sizes. The first method (Sect. 3.6) was based on the required power of the hypothesis test for detecting whether two treatment effects differ by more than a chosen quantity \(\Delta\). The second method (Sect. 4.5) was based on the required length of confidence intervals for one or more treatment contrasts.

For the random-effects one-way model, we need to determine both the number \(v\) of levels of the treatment factor to be observed in the experiment and the number \(r\) of observations to be taken on each of these levels. A glance at the formulae (17.3.11) and (17.3.15) shows that a calculation of \(v\) and \(r\) based on the lengths of confidence intervals will not be straightforward. Both formulae depend not only on the value of msE, but also on that of msT, both of which are unknown prior to the experiment. However, consideration of the variances of the estimators used to develop the confidence intervals helps us determine an appropriate balance between "more treatments" and "more replication."

Consider first the confidence interval for \(\sigma_{T}^{2}\) given in (17.3.15). The confidence interval should be tight if the variance of the unbiased estimator \(U\) is small. Assuming equal sample sizes, \(U=r^{-1}(\text{MST}-\text{MSE})\) has variance

\[\text{Var}(U)=\frac{2n^{2}(na\sigma_{T}^{2}/v+\sigma^{2})^{2}}{v^{2}(v-1)}+ \frac{2n^{2}\sigma^{4}}{v^{2}(n-v)}\]

for \(n>v\). (This follows because MST and MSE are independent, \(\text{SST}/(r\sigma_{T}^{2}+\sigma^{2})\sim\chi^{2}(v-1)\), \(\text{SSE}/\sigma^{2}\sim\chi^{2}(n-v)\), and the variance of a chi-squared random variable is twice its degrees of freedom.) We want this variance to be as small as possible. Suppose that the total number of observations \(n=rv\) is fixed by budget considerations and we require \(r\geq 2\) since replication is needed to estimate \(\sigma^{2}\), so \(v\leq n/2\). To minimize the first term of this variance, we require \(v\) as large as possible, corresponding to \(v=n/2\). It can be shown that the second term is minimized by taking \(v=2n/3\), or by taking \(v=n/2\) if we require equal sample sizes and \(r\geq 2\).

In summary, assuming equal replication with \(r\geq 2\), the variance of \(U\) is minimized by taking \(v=n/2\) and \(r=2\). In this case, our estimator would be \(U=(1/2)(\text{MST}-\text{MSE})\), for which \(\text{Var}(U)=8[(2\sigma_{T}^{4}+\sigma^{2})^{2}/(v-1)+\sigma^{4}/v]\) is as small as possible given equal replication with \(r\geq 2\).

We find a similar requirement resulting from a confidence interval for \(\sigma_{T}^{2}/\sigma^{2}\). The mean of an \(F\)-distribution with \(v-1\) and \(n-v\) degrees of freedom is \((n-v)/(n-v-2)\). So, from (17.3.10),p. 625, with \(c=r\), an unbiased estimator of \(\sigma_{T}^{2}/\sigma^{2}\) is given by

\[U=\frac{1}{r}\left[\frac{(n-v-2)}{(n-v)}\frac{\mbox{\small MST}}{\mbox{\small MSE }}\ -\ 1\right]\,,\]

and a narrow confidence interval should be obtained if we choose \(v\) and \(r\) to make \(\mbox{\rm Var}(U)\) small. The variance of an \(F\)-distribution with \(m\) and \(p\) degrees of freedom is

\[\frac{2p^{2}(m+p-2)}{m(p-2)^{2}(p-4)}\,.\]

It follows from (17.3.10), the definition of \(U\), and \(m=v-1\) and \(p=n-v\) that when the sample sizes are all equal to \(r\),

\[\mbox{\rm Var}(U)= \left(r\frac{\sigma_{T}^{2}}{\sigma^{2}}+1\right)^{2}\frac{1}{r^ {2}}\left(\frac{2(n-v)^{2}(n-3)(n-v-2)^{2}}{(v-1)(n-v-2)^{2}(n-v-4)(n-v)^{2}}\right)\] \[= \left(\frac{\sigma_{T}^{2}}{\sigma^{2}}+\frac{1}{r}\right)^{2} \left(\frac{2(n-3)}{(v-1)(n-v-4)}\right)\,.\]

So, if the number of observations \(n\) is fixed with \(n=rv\) and \(r\geq 2\), and if we expect that \(\sigma_{T}^{2}/\sigma^{2}>1/2\), say, then the squared term \((\sigma_{T}^{2}/\sigma^{2})^{2}\) from the first set of parentheses will be most important for determining the size of the variance--more important that the term \((1/r)^{2}\) or the cross-product term--and we need to minimize its coefficient, which is \(2(n-3)/((v-1)(n-v-4))\). This requires that \(v=(n-3)/2\), or \(v=n/2\) and \(r=2\) in the equireplicate case. On the other hand, in the more unusual case when \(\sigma_{T}^{2}\) is expected to be much smaller than \(\sigma^{2}\), then the squared term \((1/r)^{2}\) from the first set of parentheses will be most important for determining the size of the variance, and we need the minimum value of

\[\frac{1}{r^{2}}\left(\frac{2(n-3)}{(v-1)(n-v-4)}\right)\ =\ \frac{2v^{2}(n-3)}{n^{2}(v-1)(n-v-4)}\,,\]

and this occurs when \(v\) is as small as possible. However, it is unusual to be interested in \(\sigma_{T}^{2}/\sigma^{2}\) if this ratio is expected to be very small, so we discount this case.

In summary, the general recommendation again is to set \(v=n/2\) and \(r=2\). The exception is the extraordinary case where one plans such an experiment to study \(\sigma_{T}^{2}/\sigma^{2}\) but expects \(\sigma_{T}^{2}\) to be much smaller than \(\sigma^{2}\), in which case one should choose \(v\) to be small.

We can get a feel for how many observations \(n=rv\) are needed in total if we examine the power of the hypothesis test for testing \(H_{0}^{\gamma T}:\sigma_{T}^{2}\leq\gamma\sigma^{2}\) against the alternative hypothesis \(H_{A}^{\gamma T}:\sigma_{T}^{2}>\gamma\sigma^{2}\) (for a chosen \(\gamma\geq 0\)). The decision rule was given in (17.3.9), p. 624, as

\[\mbox{\rm reject}\ H_{0}^{\gamma T}\ \mbox{if}\ \frac{\mbox{\rm ms}T}{\mbox{\rm ms}E}>(c\gamma+1)F_{v-1,n-v,\alpha}=k,\ \mbox{\rm say}. \tag{17.4.17}\]

What is the probability of rejecting \(H_{0}^{\gamma T}\) if the true value of \(\sigma_{T}^{2}/\sigma^{2}\) is \(\Delta\)? In other words, what is the probability that \(\mbox{\rm MST}/\mbox{\rm MSE}>k\), when \(\sigma_{T}^{2}/\sigma^{2}\) is equal to \(\Delta\)? This is the power of the test at the value \(\Delta\). We can calculate the power from the knowledge that \[\frac{MST}{MSE(c\sigma_{T}^{2}/\sigma^{2}+1)}\sim F_{v-1,n-v}\,\]

see (17.3.12), p. 626. If \(\sigma_{T}^{2}/\sigma^{2}\) is equal to \(\Delta\), then

\[P\left(\frac{MST}{MSE}>k\right)=P\left(\frac{MST}{MSE(c\Delta+1)}>\frac{k}{c \Delta+1}\right).\]

Suppose we stipulate that the power must be \(\pi\) when \(\sigma_{T}^{2}/\sigma^{2}=\Delta\). Then, we must have that

\[\frac{k}{c\Delta+1}=F_{v-1,n-v,\pi}.\]

Remembering from (17.4.17) that \(k=(c\gamma+1)F_{v-1,n-v,\alpha}\), and that \((n-v)=v(r-1)\) and \(c=r\) for equal sample sizes, we obtain the equality

\[\frac{F_{v-1,v(r-1),\alpha}}{F_{v-1,v(r-1),\pi}}=\frac{r\Delta+1}{r\gamma+1}\.\]

So, we need to select \(\gamma\) and \(\alpha\) for testing \(H_{0}^{\gamma T}\) together with \(\Delta\) and \(\pi\). Then we can try to determine \(v\) and \(r\) by trial and error as illustrated in Example 17.4.1. Since \(F_{v-1,v(r-1),\pi}=(F_{v(r-1),v-1,1-\pi})^{-1}\), we try to find values of \(v\) and \(r\) such that

\[(F_{v-1,v(r-1),\alpha})(F_{v(r-1),v-1,1-\pi})\leq\frac{r\Delta+1}{r\gamma+1}. \tag{17.4.18}\]

#### _Example 17.4.1_Ice cream experiment, continued

In Example 17.3.2, p. 624, we were unable to reject the hypothesis \(H_{0}^{\gamma T}:\sigma_{T}^{2}\leq\sigma^{2}\) in favor of the hypothesis \(H_{A}^{\gamma T}:\sigma_{T}^{2}>\sigma^{2}\) at a significance level of \(\alpha=0.05\). Suppose we wish to repeat this experiment, still with \(\gamma=1.0\) and a Type I error probability of \(\alpha=0.05\). Suppose further that we would like to reject the hypothesis with high probability (say \(\pi=0.95\)) if the true value of \(\sigma_{T}^{2}/\sigma^{2}\) is at least \(\Delta=2.0\). How many ice cream flavors should we look at and how many observations should we take on each?

From (17.4.18), we need to find \(v\) and \(r\) such that

\[(F_{v-1,v(r-1),0.05})(F_{v(r-1),v-1,05})\leq(2r+1)/(r+1)\.\]

For the moment set \(r=11\), which is the value used by the experimenter in the ice cream experiment. Then \((2r+1)/(r+1)=23/12\approx 1.92\), and we have

\[\begin{array}{c c c c c}\hline v&F_{v-1,10v,05}&F_{10,v-1,05}&\text{Product}& \frac{2r+1}{r+1}\ \text{Action}\\ \hline 4&2.84&8.59&24.40&\Let us now reduce \(r\) to 3 and compute the required value of \(v\). Then \((2r+1)/(r+1)=1.75\), so

\[\begin{array}{ccccc}\hline v&F_{v-1,2v,.05}&F_{2v,v-1,.05}&\text{Product}&\frac {2r+1}{r+1}&\text{Action}\\ \hline 80&1.37&1.39&1.90&>&1.75&\text{Increase}\ v\\ 100&1.32&1.34&1.78&>&1.75&\text{Increase}\ v\\ 105&1.31&1.33&1.75&=&1.75&\text{Stop}\\ \hline\end{array}\]

So \(v\) in the region of 105 would be fine, requiring only \(n=315\) observations. In Exercise 2, the reader is asked to determine whether the use of \(r=2\) would require a smaller total number of observations. To greatly reduce the required number of observations, we would need to relax our requirement of such a high power to reject \(H_{0}^{\gamma T}:\sigma_{T}^{2}\leq\sigma^{2}\) when \(\sigma_{T}^{2}=2\sigma^{2}\). 

### Checking Assumptions on the Model

The simplest way to check the assumptions on the one-way random-effects model is to use residual plots in much the same way as for a fixed-effects one-way model. We need to check that the error assumptions are valid, that is,

\[\epsilon_{it}\sim N(0,\,\sigma^{2}),\ \ t=1,\ldots,r_{i}\,,\]

for each treatment factor level \(i\) (\(i=1,\ldots,\,v\)), and also that the assumptions on the random effect \(T_{i}\) are valid, that is,

\[T_{i}\sim N(0,\,\sigma_{T}^{2}),\ \ i=1,\ldots,v\,,\]

and that all random variables are mutually independent.

Checking the error assumptions is straightforward, since we proceed in exactly the same way as for the fixed-effects one-way model. We replace \(T_{i}\) in the model, temporarily, by the fixed effect \(\tau_{i}\). Then the residuals are defined as usual as

\[\widehat{e}_{it}=y_{it}-\widehat{y}_{it}=y_{it}-\overline{y}_{i}\,.\]

These are then standardized to obtain the standardized residuals \(z_{it}\) with standard deviation 1.0. We plot the standardized residuals versus treatment-factor levels, versus \(\widehat{y}_{it}\), versus order, and versus normal scores, as in Chap. 5, to check for outliers, independence, constant variance, and normality. Non-independence between the \(\epsilon_{it}\)'s and the \(T_{i}\)'s is not easy to detect, but unequal variances of the \(\epsilon_{it}\)'s indicates one form of the problem.

The normality assumption on the random effect \(T_{i}\) can be checked when the sample sizes are equal, unless \(v\) is too small. The treatment averages \(\overline{Y}_{i.}\) should have a \(N(\mu,\sigma_{T}^{2}+\sigma^{2}/r)\) distribution. So, if we standardize the observed averages \(\overline{y}_{i.}\) to have average value zero and sample standard deviation one, and we plot these standardized averages against their corresponding normal scores, we should roughly obtain a straight line--one that cuts the vertical axis at about zero and that has slope about one. It is important to check the normality assumption, since the analysis for random-effects models is not robust to nonnormality of the random effects. We can also use this normal probability plot to check for treatment effect outliers among the observed treatments. In an experiment such as the ice cream experiment, where only \(v=3\) levels of the treatment factor were observed, there is not enough data to be able to examine the distribution of the \(T_{i}\)'s in any detail. In Sects. 17.10 and 17.11 we will illustrate the assumption-checking procedures using the SAS and R software packages, respectively, and the data from the clean wool experiment that was described in Sect. 17.2.2, p. 615.

### Two or More Random Effects

#### Models and Examples

In the ice cream experiment of Example 17.3.1, p. 621, we modeled the ice cream effect as a random effect, since we were interested in the variability of the melting rates of varieties of a large population of all possible ice creams with similar ingredients. If the experimenter had also been interested in whether or not the container affects the melting time, then she might have randomly selected a number \(b\) of containers from the population of all possible containers. If one ice cream melts faster than another ice cream in one container, then it might be safe to assume that it melts faster, and by the same amount, in another container. In other words, the assumption of no ice cream\(\times\)container interaction might be reasonable. In this case a random two-way main-effects model (with no interaction) would be a possible model; that is,

\[Y_{ijt}=\mu+A_{i}+B_{j}+\epsilon_{ijt}\,, \tag{17.6.19}\] \[A_{i}\sim N(0,\,\sigma_{A}^{2}),\;\;\;B_{j}\sim N(0,\,\sigma_{B} ^{2}),\;\;\;\epsilon_{ijt}\sim N(0,\,\sigma^{2})\,,\] \[A_{i}\text{'s},\;\;B_{j}\text{'s}\text{ and }\epsilon_{ijt}\text{'s are all mutually independent}\] \[t=1,\ldots,\,r_{ij},\;\;\;i=1,\ldots,\,a,\;\;j=1,\ldots,\,b.\]

where \(A_{i}\) is the effect of the \(i\)th ice cream randomly selected from the population of ice creams whose effects on melting times follow a normal distribution with variance \(\sigma_{A}^{2}\) for each container, and where \(B_{j}\) is the effect of the \(j\)th container randomly selected from the population of containers whose effects on the melting times follow a normal distribution with variance \(\sigma_{B}^{2}\) for each ice cream. The number of observations \(r_{ij}\) to be taken on the (_ij_)th ice cream-container combination needs to be determined. Normally, we would select the \(r_{ij}\)'s to be equal if possible.

Alternatively, it may be expected that a slightly thicker container would show a greater difference in melting times of ice creams than would a thinner container. In other words, an interaction may be expected. In this case, we would add to model (17.6.19) a random effect representing the interaction, as shown in the random-effects two-way complete model (17.6.20):

\[Y_{jit}=\mu+A_{i}+B_{j}+(AB)_{ij}+\epsilon_{jit} \tag{17.6.20}\] \[A_{i}\sim N(0,\,\sigma_{A}^{2}),\;\;\;B_{j}\sim N(0,\,\sigma_{B} ^{2})\] \[(AB)_{ij}\sim N(0,\,\sigma_{AB}^{2}),\;\;\;\epsilon_{ijt}\sim N(0, \,\sigma^{2})\] \[A_{i}\text{'s},\;\;B_{j}\text{'s},\;\;(AB)_{ij}\text{'s and }\epsilon_{ijt}\text{'s are mutually independent}\] \[t=1,\ldots,r_{ij},\;\;\;i=1,\ldots,a,\;\;j=1,\ldots,b.\]

If \(\sigma_{AB}^{2}\) is positive, then there are _AB effects_ present--namely, main effects and interactions for the factors \(A\) and \(B\). If \(\sigma_{A}^{2}\) or \(\sigma_{B}^{2}\) is positive, then the corresponding main effects are present.

##### Ammunition experiment

W.A. Thompson, Jr. and J.R. Moore in the 1963 volume of _Technometrics_ describe an experiment concerning the muzzle velocity characteristics of ammunition for a field artillery weapon. They describe the ammunition as follows:Propelling charges and projectiles for this type of weapon are manufactured and stored separately in a such a way that any charge might be employed by the user to propel any projectile.... Both projectiles and charges are grouped into lots at the time of manufacture, each lot consisting of a large number of individual units assembled during a short period of time using essentially uniform components. Thus, it is hoped that the round to round dispersion [variability] in velocity will be reduced by using charges and projectiles from within lots.

The experiment involved the examination of a random sample of four charge lots (factor \(A\) with levels 1, 2, 3, 4) selected at random from a large population of charge lots, and four projectile lots (factor \(B\) with levels 1, 2, 3, 4) selected at random from a large population of projectile lots. A weapon surveillance test was conducted using one weapon under uniform ballistic conditions. The muzzle velocities were measured to the nearest foot per second. These are shown in Table 17.5, except that a constant has been added to each recorded velocity.

Since the lots involved in the experiment were randomly selected from large populations, a random-effects two-way complete model (17.6.20) was used in the analysis. 

In an experiment with more than two random-effects treatment factors, variables representing all of the main effects of the factors and some or all of their interactions would be included in the model in the obvious way. For example, an experiment with five random-effects treatment factors \(A\), \(B\), \(C\), \(D\), \(G\), in which interactions _AB_, _AC_, _BC_, _CD_, and _ABC_ were thought to be nonnegligible, would be modeled as follows:

\[Y_{ijklmt} = \mu + A_{i} + B_{j} + C_{k} + D_{l} + G_{m} + (\text{AB})_{ij} + (\text{AC})_{ik} + (\text{BC})_{jk} + (\text{CD})_{kl} + (\text{ABC})_{ijk} + \epsilon_{ijklmt},\] \[A_{i} \sim N(0,\,\sigma_{A}^{2}),\,\,\,\,B_{j} \sim N(0,\,\sigma_{B}^{2}),\,\,\,\,C_{k} \sim N(0,\,\sigma_{C}^{2}),\,\,\,\,D_{l} \sim N(0,\,\sigma_{D}^{2}),\,\,\,\,G_{m} \sim N(0,\,\sigma_{G}^{2}),\] \[(\text{AB})_{ij} \sim N(0,\,\sigma_{AB}^{2}),\,\,\,(\text{AC})_{ik} \sim N(0,\,\sigma_{AC}^{2}),\,\,\,(\text{BC})_{jk} \sim N(0,\,\sigma_{BC}^{2}),\,\,\,(\text{CD})_{kl} \sim N(0,\,\sigma_{CD}^{2}),\] \[(\text{ABC})_{ijk} \sim N(0,\,\sigma_{ABC}^{2}),\,\,\,\,\epsilon_{ijklmt} \sim N(0,\,\sigma^{2}),\] all random variables on the right-hand side of the model are mutually independent, \[t = 1,\ldots,\,r_{ijklm},\,\,\,\,i = 1,\ldots,a,\,\,\,j = 1,\ldots,b,\] \[k = 1,\ldots,c,\,\,\,\,l = 1,\ldots,d,\,\,\,\,m = 1,\ldots,g.\]

As for the fixed-effects models, if a high-order interaction is included in the model, then so are all of its "subinteractions" and constituent main effects; that is, if (_ABC_)_ijk_ is in the model, so are (_AB_)_ij_, (_AC_)_ik_, (_BC_)_jk_, _A_i_, \(B\), and _C_k_.

\begin{table}
\begin{tabular}{c c c c c}  & & \multicolumn{3}{c}{Charge lot} \\  & & 1 & 2 & 3 & 4 \\ Projectile lot & 1 & 63 & 56 & 69 & 78 \\  & & 78 & 58 & 63 & 79 \\  & 2 & 71 & 60 & 64 & 65 \\  & & 70 & 65 & 68 & 77 \\  & 3 & 72 & 58 & 69 & 63 \\  & & 55 & 55 & 71 & 72 \\  & 4 & 70 & 60 & 66 & 73 \\  & & 64 & 71 & 68 & 79 \\ \end{tabular}
\end{table}
Table 17.5: Data for the ammunition experiment 

#### Checking Model Assumptions

We may check the error assumptions by replacing temporarily all of the random effects by fixed effects, calculating the standardized residuals, and examining the residual plots in the usual way. Checking the assumptions of each random effect is not easy, since in a two-way or higher-way model there are generally few levels of each treatment factor observed, and the cell averages are not independent. Consequently, we will omit the model checks for the random-effect assumptions, and hope that any severe problems will show up through the analysis of the residuals.

#### Estimation of \(\sigma^{2}\)

In Sect. 17.3.2 we found that for the one-way random-effects model, an unbiased estimate of \(\sigma^{2}\) was given by msE, where msE was calculated exactly as for the fixed-effects one-way model. Perhaps this should not be surprising, since msE measures the variability in the data that is not accounted for by those sources of variation that were ignored in the experiment. An unbiased estimate for \(\sigma^{2}\) in _any_ random-effects model can be obtained from its fixed-effects model counterpart.

##### Unbiased estimate of \(\sigma^{2}\)

We will show that an unbiased estimate of \(\sigma^{2}\) in the random-effects two-way complete model is msE = ssE/(\(n-v\)), where

\[\text{ssE}=\left[\sum_{i}\sum_{j}\sum_{t}y_{ijt}^{2}-\sum_{i}\sum_{j}r_{ij} \overline{y}_{ij.}^{2}\right]\,,\]

as in (6.4.16) for the fixed-effects two-way complete model. First, note that

\[E[Y_{ijt}]=\mu\ \text{ and }\text{Var}(Y_{ijt})=\sigma_{A}^{2}+\sigma_{B}^{2}+ \sigma_{AB}^{2}+\sigma^{2}\]

for the random-effects two-way complete model. Also,

\[\overline{Y}_{ij.}=\mu+A_{i}+B_{j}+(AB)_{ij}+\sum_{t}\epsilon_{ijt}/r_{ij}\,.\]

So,

\[E[\overline{Y}_{ij.}]=\mu\ \ \text{ and }\ \ \text{Var}(\overline{Y}_{ij.})=\sigma_{A}^{2}+\sigma_{B}^{2}+\sigma_{AB}^{2}+\sigma^{2}/r_{ij.}\]

Thus, the expected value of the random variable SSE is

\[E\left[\text{SSE}\right] =E\left[\sum_{i}\sum_{j}\sum_{t}Y_{ijt}^{2}-\sum_{i}\sum_{j}r_{ij} \overline{Y}_{ij.}^{2}\right]\] \[=\sum_{i=1}^{a}\sum_{j=1}^{b}\sum_{t=1}^{r_{ij}}(\text{Var}(Y_{ijt })+E[Y_{ijt}]^{2})\]\[\begin{split}&-\sum_{i=1}^{a}\sum_{j=1}^{b}r_{ij}(\text{Var}( \overline{Y}_{ij.})+E[\overline{Y}_{ij.}]^{2})\\ &=\left(\sum_{i=1}^{a}\sum_{j=1}^{b}r_{ij}\right)\sigma^{2}-\sum_ {i=1}^{a}\sum_{j=1}^{b}\sigma^{2}=(n-v)\sigma^{2}\,,\end{split}\]

where \(n=\Sigma\,\Sigma r_{ij}\) and \(v=ab\). Consequently,

\[E[\text{MSE}]=E[\text{SSE}/(n-v)]=\sigma^{2}.\]

#### Estimation of Variance Components

In Sect. 17.3.3, p. 620, we found that for the random-effects one-way model,

\[E[\text{MST}]=c\sigma_{T}^{2}+\sigma^{2}\;\;,\;\;\;\text{where}\;c=\frac{n^{2 }-\sum r_{i}^{2}}{n(v-1)}\;,\]

where MST is the mean square for treatments from the fixed-effects one-way model, and where \(c=r\) if all the sample sizes are equal. From this, we were able to find an unbiased estimator for \(\sigma_{T}^{2}\), namely \((\text{MST}-\text{MSE})/c\).

For more complicated models, we will also be able to find unbiased estimators for the variance components using the fixed-effects mean squares, but each estimator must be calculated individually.

##### Unbiased estimate of \(\sigma_{B}^{2}\)

Suppose an experiment involves three random-effects treatment factors \(A\), \(B\), and \(D\) having \(a\), \(b\), and \(d\) levels, respectively, and suppose \(r\) observations are taken on each of the \(v=abd\) combinations. If the only interactions that are expected to be nonnegligible are \(AB\) and \(BD\), then, the model is

\[Y_{ijk}=\mu+A_{i}+B_{j}+D_{k}+(AB)_{ij}+(BD)_{jk}+\epsilon_{ijk}\;,\]

\[t=1,\ldots,r,\;\;i=1,\ldots,a,\;\;j=1,\ldots,b,\;\;k=1,\ldots,d\]

with the usual assumptions about the distributions of the random treatment effects and error variables.

Suppose we want an unbiased estimator for \(\sigma_{B}^{2}\). We start by investigating \(E[\text{MS}B]\), where \(\text{MS}B=\text{SS}B/(b-1)\). Using rule 4, p. 209, the sum of squares for \(B\) is

\[\text{ss}B=adr\sum_{j=1}^{b}\overline{y}_{j..}^{2}-abdr\overline{y}_{....}^{2}\;.\]

Now,

\[E[\overline{Y}_{j..}]=E[\overline{Y}_{....}]=\mu\]and

\[\text{Var}[\overline{Y}_{j..}] =\frac{\sigma_{A}^{2}}{a}+\sigma_{B}^{2}+\frac{\sigma_{D}^{2}}{d}+ \frac{\sigma_{AB}^{2}}{a}+\frac{\sigma_{BD}^{2}}{d}+\frac{\sigma^{2}}{adr}\,,\] \[\text{Var}[\overline{Y}_{....}] =\frac{\sigma_{A}^{2}}{a}+\frac{\sigma_{B}^{2}}{b}+\frac{\sigma_{D }^{2}}{d}+\frac{\sigma_{AB}^{2}}{ab}+\frac{\sigma_{BD}^{2}}{bd}+\frac{\sigma^{ 2}}{abdr}\,.\]

Consequently,

\[E[SSB] =adr\sum_{j}\left[Var(\overline{Y}_{j..})+E[\overline{Y}_{j..}]^{ 2}\right]-abdr\left[Var(\overline{Y}_{....})+E[\overline{Y}_{....}]^{2}\right]\] \[=adr(b-1)\sigma_{B}^{2}+dr(b-1)\sigma_{AB}^{2}+ar(b-1)\sigma_{BD} ^{2}+(b-1)\sigma^{2}\,.\]

So,

\[E[\text{MSB}]=adr\sigma_{B}^{2}+dr\sigma_{AB}^{2}+ar\sigma_{BD}^{2}+\sigma^{2}\,. \tag{17.6.21}\]

Thus, if we wish to find an unbiased estimator for \(\sigma_{B}^{2}\), we must find unbiased estimators also for \(\sigma_{AB}^{2}\) and \(\sigma_{BD}^{2}\). The logical place to look for these is at \(E[\text{MS}(\text{AB})]\) and \(E[\text{MS}(\text{BD})]\). We have

\[\text{ss}(\text{AB}) =dr\sum_{i=1}^{a}\sum_{j=1}^{b}\overline{y}_{ij..}^{2}-bdr\sum_{i =1}^{a}\overline{y}_{i...}^{2}-adr\sum_{j=1}^{b}\overline{y}_{j..}^{2}+abdr \overline{y}_{....}^{2}\,,\] \[\text{ss}(\text{BD}) =ar\sum_{j=1}^{b}\sum_{k=1}^{d}\overline{y}_{jk..}^{2}-adr\sum_{j =1}^{b}\overline{y}_{j..}^{2}-abr\sum_{k=1}^{d}\overline{y}_{-.k.}^{2}+abdr \overline{y}_{....}^{2}\,,\]

and

\[E[\overline{Y}_{ij..}] =E[\overline{Y}_{i...}]=E[\overline{Y}_{j..}]=E[\overline{Y}_{jk.}]=E[\overline{Y}_{..k.}]=[\overline{Y}_{....}]=\mu\,,\] \[\text{Var}[\overline{Y}_{ij..}] =\sigma_{A}^{2}+\sigma_{B}^{2}+\frac{\sigma_{D}^{2}}{d}+\sigma_{ AB}^{2}+\frac{\sigma_{BD}^{2}}{d}+\frac{\sigma^{2}}{dr}\,,\] \[\text{Var}[\overline{Y}_{i...}] =\sigma_{A}^{2}+\frac{\sigma_{B}^{2}}{b}+\frac{\sigma_{D}^{2}}{d }+\frac{\sigma_{AB}^{2}}{b}+\frac{\sigma_{BD}^{2}}{bd}+\frac{\sigma^{2}}{bdr}\,,\] \[\text{Var}[\overline{Y}_{jk.}] =\frac{\sigma_{A}^{2}}{a}+\sigma_{B}^{2}+\sigma_{D}^{2}+\frac{ \sigma_{AB}^{2}}{a}+\sigma_{BD}^{2}+\frac{\sigma^{2}}{ar}\,,\] \[\text{Var}[\overline{Y}_{..k.}] =\frac{\sigma_{A}^{2}}{a}+\frac{\sigma_{B}^{2}}{b}+\sigma_{D}^{2 }+\frac{\sigma_{AB}^{2}}{ab}+\frac{\sigma_{BD}^{2}}{b}+\frac{\sigma^{2}}{abr}\,,\]

as well as

\[E[\text{SS}(\text{AB})] =\left(dr\sum_{i}\sum_{j}\overline{Y}_{ij..}^{2}-bdr\sum_{i} \overline{Y}_{i...}^{2}\right)-(E[\text{SSB}])\] \[=adr(b-1)\sigma_{B}^{2}+adr(b-1)\sigma_{AB}^{2}+ar(b-1)\sigma_{ BD}^{2}+a(b-1)\sigma^{2}\] \[\quad-adr(b-1)\sigma_{B}^{2}-dr(b-1)\sigma_{AB}^{2}-ar(b-1) \sigma_{BD}^{2}-(b-1)\sigma^{2}\] \[=dr(a-1)(b-1)\sigma_{AB}^{2}+(a-1)(b-1)\sigma^{2}\,.\]So,

\[E[\mathit{MS}(AB)]=dr\sigma_{AB}^{2}+\sigma^{2}.\]

Similarly,

\[E[\mathit{MS}(BD)]=ar\sigma_{BD}^{2}+\sigma^{2}\.\]

Thus, an unbiased estimator for \(\sigma_{B}^{2}\) is

\[U=(\mathit{MS}\mathit{B}-\mathit{MS}(AB)-\mathit{MS}(BD)+\mathit{MSE})/( \mathit{adr})\,\]

and an unbiased estimate for \(\sigma_{B}^{2}\) is therefore

\[u=(\mathit{ms}\mathit{B}-\mathit{ms}(AB)-\mathit{ms}(BD)+\mathit{msE})/( \mathit{adr})\.\]

Calculation of expected mean squares is quite time-consuming, as was seen in Example 17.6.3. However, when sample sizes are all equal, we can exploit the pattern that emerges in studying such examples. All of the variance components that are involved in \(E[\mathit{MS}\mathit{B}]\) in (17.6.21) are those whose random effects include the same subscript as for \(B\) in the model. Specifically, \(B\) has subscript \(j\) in the model, and a \(j\) also occurs as subscript in \((\mathit{AB})_{\mathit{ij}}\), \((\mathit{BD})_{\mathit{jk}}\), and \(\epsilon_{\mathit{ijkt}}\). The constant in front of each variance component is the number of observations taken on each combination of subscripts; that is, there are \(\mathit{adr}\) observations on each of the \(b\) levels of \(B\), there are \(\mathit{dr}\) observations on each of the \(ab\) levels of \(\mathit{AB}\), and so on.

A similar pattern can be seen for \(E[\mathit{MS}(\mathit{AB})]\) and \(E[\mathit{MS}(\mathit{BD})]\). This gives us a general rule when sample sizes are equal (which we add to the 16 rules in Chap. 7):

17. To obtain the expected mean square for a main effect or interaction in a random-effects model, first note the subscripts on the term representing that effect in the model. Write down a variance component \(\sigma^{2}\) for the effect of interest, for the error, and for every interaction whose term in the model includes the noted set of subscripts. Multiply each variance component except \(\sigma^{2}\) by the number of observations taken on each level or combination of levels of the corresponding main effect or interaction. Add up the terms.

#### Confidence Intervals for Variance Components

In the previous subsection a rule was given for calculating the expected mean square corresponding to each term in the model, when the sample sizes are equal. For unequal sample sizes, the mean squares and expected mean squares are best calculated by a computer program.

From the list of expected mean squares, we can find an unbiased estimator for any given variance component, say \(\sigma_{*}^{2}\). Again, this was illustrated in Example 17.6.3. The estimator can always be a linear combination of mean squares, which, in general, we can write as \(U=\Sigma k_{i}(\mathit{MS})_{i}\), where \(k_{i}\) is the constant in front of the \(i\)th mean square in the linear combination. Then, an approximation to the distribution of \(xU/\sigma_{*}^{2}\) is a chi-squared distribution with \(x\) degrees of freedom, where

\[x=\frac{(\Sigma k_{i}(\mathit{ms})_{i})^{2}}{\Sigma k_{i}^{2}(\mathit{ms})_{i }^{2}/x_{i}} \tag{17.6.22}\]and where \(x_{i}\) is the number of degrees of freedom corresponding to the \(i\)th mean square and \((\text{ms})_{i}\) is the observed value of the \(i\)th mean square in the linear combination. An example of this formula was given in Sect. 17.3.5, p. 625, for the one-way model. A more complicated example is given below.

#### Calculation of degrees of freedom

We continue Example 17.6.3, which involved a random-effects model with five random effects \(A_{i}\), \(B_{j}\), and \(D_{k}\) (corresponding to main effects of factors \(A\), \(B\), and \(D\)), and \((AB)_{ij}\) and \((BD)_{jk}\) (corresponding to interactions \(AB\) and \(BD\)). An unbiased estimator for \(\sigma_{B}^{2}\) was shown to be

\[U=\Sigma k_{i}(\text{MS})_{i}=\text{MS}B/(adr)-\text{MS}(\text{AB})/(adr)-\text {MS}(\text{BD})/(adr)+\text{MSE}/(adr).\]

An approximation to the distribution of \(xU/\sigma_{B}^{2}\) is a \(\chi_{x}^{2}\) distribution, where \(x\) is given by (17.6.22), that is,

\[x =\frac{[(\text{ms}\text{B}-\text{ms}(\text{AB})-\text{ms}(\text{ BD})+\text{ms}\text{E})/(adr)]^{2}}{\frac{\text{ms}\text{B}^{2}}{(adr)^{2}(b-1)}+ \frac{\text{ms}(\text{AB})^{2}}{(adr)^{2}(a-1)(b-1)}+\frac{\text{ms}(\text{ BD})^{2}}{(adr)^{2}(b-1)(d-1)}+\frac{\text{ms}\text{E}^{2}}{(adr)^{2}dt}}\] \[=\frac{[\text{ms}\text{B}-\text{ms}(\text{AB})-\text{ms}(\text{ BD})+\text{ms}\text{E}]^{2}}{\frac{\text{ms}\text{B}^{2}}{(b-1)}+\frac{\text{ms}( \text{AB})^{2}}{(a-1)(b-1)}+\frac{\text{ms}(\text{BD})^{2}}{(b-1)(d-1)}+\frac{ \text{ms}\text{E}^{2}}{df}}\,,\]

where df is the number of degrees of freedom for error, which can be obtained, as usual, by subtraction. In this example, df is equal to

\[\text{df} =(abdr-1)-(a-1)-(b-1)-(d-1)\] \[\quad-(a-1)(b-1)-(b-1)(d-1)\] \[=ab(dr-1)-b(d-1)+1\,.\]

Once we know an approximate distribution for a variance component estimator, we can easily write down a probability statement and convert it to a confidence interval. Suppose that \(U=\Sigma k_{i}(\text{MS})_{i}\) is an unbiased estimator for \(\sigma_{*}^{2}\) and that \(xU/\sigma_{*}^{2}\) has approximately a \(\chi_{x}^{2}\) distribution; then

\[P\left(\chi_{x,1-\alpha/2}^{2}\ \leq\ xU/\sigma_{*}^{2}\ \leq\ \chi_{x,\alpha/2}^{2}\right)\approx 1-\alpha.\]

Then, if we observe the value of \(U\) to be \(u=\Sigma k_{i}(\text{ms})_{i}\), by manipulating the two inequalities in the probability statement we can obtain the following approximate \(100(1-\alpha)\)% confidence interval:

\[\frac{\cdot xu}{\chi_{x,\alpha/2}^{2}}\leq\sigma_{*}^{2}\leq\frac{xu}{\chi_{x, 1-\alpha/2}^{2}}\,, \tag{17.6.23}\]

where \(x\) is calculated as in (17.6.22). If the estimate \(u\) is negative or the calculated degrees of freedom \(x\) is extremely small, then this approximate confidence interval procedure should not be used.

#### Ammunition experiment, continued

The ammunition experiment was described in Example 17.6.1, p. 632, and the data were given in Table 17.5. A random-effects two-way complete model (17.6.20) was used. The mean squares for this model are calculated in exactly the same way as for the fixed-effects two-way complete model, and these are shown in the analysis of variance table, Table 17.6. Also listed in the table are the expected mean squares calculated as in rule 17, p. 637.

For example, to calculate the expected mean square for \(A\), we note that the subscript for the term \(A_{i}\) in the model is \(i\), and also that \(i\) is included among the subscripts of the terms \((AB)_{ij}\) and \(\epsilon_{ijt}\). This means that the expected mean square must include the three variance components

\[\sigma_{A}^{2},\ \ \sigma_{AB}^{2},\ \ \text{and}\ \ \sigma^{2}\,.\]

The constant in front of \(\sigma_{A}^{2}\) is 8, the number of observations on each charge lot, whereas the constant in front of \(\sigma_{AB}^{2}\) is 2, the number of observations on each combination of charge lot and projectile lot.

The expected mean square for \(AB\), \(E[\text{MS}(AB)]=2\sigma_{AB}^{2}+\sigma^{2}\), contains only two terms, since only the two terms \((AB)_{ij}\) and \(\epsilon_{ijt}\) in the model contain both \(i\) and \(j\) as subscripts. An unbiased estimator for \(\sigma_{A}^{2}\) is given by \(U=(MSA-\text{MS}(AB))/8\). Also, \(xU/\sigma_{A}^{2}\) has approximately a \(\chi_{x}^{2}\) distribution, where \(x\) is calculated as in (17.6.22). Thus, an unbiased estimate of \(\sigma_{A}^{2}\) from this experiment is

\[u\ =\ (\text{ms}A-\text{ms}(AB))/8\ =\ (223.04-28.63)/8=24.30\,,\]

and the number of degrees of freedom of the associated chi-squared distribution is

\[x=\frac{24.30^{2}}{\frac{223.04^{2}}{(8^{2})(3)}\ +\ \frac{28.63^{2}}{(8^{2})( 9)}}=2.27\,.\]

Therefore, an approximate 90% confidence interval (17.6.23) for \(\sigma_{A}^{2}\), the variance of velocities arising from the population of charge lots, is

\[\frac{(2.27)(24.3)}{\chi_{2.27,0.05}^{2}}\ \leq\ \sigma_{A}^{2}\ \leq\ \frac{(2.27)(24.3)}{\chi_{2.27,0.95}^{2}}\,,\]

and since \(\chi_{2.27,0.05}^{2}\approx 6.5\) and \(\chi_{2.27,0.05}^{2}\approx 0.17\), the approximate 90% confidence interval, in units of (feet per second)\({}^{2}\), is

\[8.49\ \leq\ \sigma_{A}^{2}\ \leq\ 324.48\,.\]

An approximate 90% confidence interval for the standard deviation of the velocity (in feet per second), obtained by taking square roots, is

\[2.91\ \leq\ \sigma_{A}\ \leq\ 18.01\,.\]

\begin{table}
\begin{tabular}{c c c c c} \hline Source of variation & Degrees of freedom & Sum of squares & Mean squares & Expected mean square \\ \hline Charge (\(A\)) & 3 & 669.12 & 223.04 & \(8\sigma_{A}^{2}+2\sigma_{AB}^{2}+\sigma^{2}\) \\ Projectile (\(B\)) & 3 & 92.12 & 30.71 & \(8\sigma_{B}^{2}+2\sigma_{AB}^{2}+\sigma^{2}\) \\ Interaction (\(AB\)) & 9 & 257.63 & 28.63 & \(2\sigma_{AB}^{2}+\sigma^{2}\) \\ Error & 16 & 516.00 & 32.25 & \(\sigma^{2}\) \\ \hline Total & 31 & 1534.87 & & \\ \hline \end{tabular}
\end{table}
Table 17.6: Two-way analysis of variance table for the ammunition experiment Before leaving this example, we note that an unbiased estimate for \(\sigma_{AB}^{2}\) calculated in this way is actually negative, since

\[u\ =\ (\text{ms}(AB)-\text{ms}E)/2\ =\ \ -1.81\,\]

and the calculation for \(x\), the number of degrees of freedom of the associated \(\chi^{2}\) distribution, is

\[x\ =\ \frac{(-1.81)^{2}}{\frac{28.63^{2}}{(2^{2})(9)}+\frac{32.25^{2}}{(2^{2})( 16)}}\ =\ 0.084\.\]

Thus, we are not able to say anything sensible about the variance of the interaction, other than that it appears to be very small. The interaction plot in Fig. 17.2 for the lots included in the experiment supports this conclusion. 

#### Hypothesis Tests for Variance Components

In order to focus the discussion, we will use the random-effects model of Example 17.6.3, p. 635; that is,

\[Y_{ijkt}=\mu+A_{i}+B_{j}+D_{k}+(AB)_{ij}+(BD)_{jk}+\epsilon_{ijkt}\,\]

\[t=1,\ldots,r\ ;\ \ i=1,\ldots,a\ ;\ \ j=1,\ldots,b\ ;\ \ k=1,\ldots,d\,\]

together with the usual assumptions about the distributions of the random variables. Some of the expected mean squares for this model were calculated in Example 17.6.3 and are listed, together with the remaining mean squares, in Table 17.7.

Testing the hypothesis \(H_{0}^{AB}:\{\sigma_{AB}^{2}=0\}\) against its alternative hypothesis \(H_{A}^{AB}:\{\sigma_{AB}^{2}>0\}\) is straightforward, since the corresponding expected mean square looks very similar to the situation that we had in the one-way model. If \(H_{0}^{AB}\) is true, then the numerator of the ratio ms(AB)\(/\)ms\(E\) is expected to be \(\sigma^{2}\), the same as the denominator. Otherwise, the numerator is expected to be larger. Consequently, the decision rule is

\[\text{reject}\ H_{0}^{AB}\ \text{if}\ \frac{\text{ms}(AB)}{\text{ms}E}>F_{(a-1)( b-1),df,\alpha}\]

Figure 17.2: Plot of average velocity against charge lot by projectile lot for the ammunition experiment

as usual, where the number of error degrees of freedom is

\[df=ab(dr-1)-b(d-1)+1\,.\]

We could modify this test as in (17.3.9), p. 624, so that the decision rule for testing \(H_{0}^{\gamma AB}:\{\sigma_{AB}^{2}\leq\gamma\sigma^{2}\}\) against \(H_{A}^{\gamma AB}:\{\sigma_{AB}^{2}>\gamma\sigma^{2}\}\) is

\[\text{reject}\,H_{0}^{\gamma AB}\text{ if }\frac{\text{ms}(AB)}{\text{ms}E}>(1+ dr\gamma)F_{(a-1)(b-1),df,\alpha}.\]

We have similar tests for \(H_{0}^{BD}\) against \(H_{A}^{BD}\), and \(H_{0}^{\gamma BD}\) against \(H_{A}^{\gamma BD}\).

Testing \(H_{0}^{A}:\sigma_{A}^{2}=0\) against \(H_{A}^{A}:\sigma_{A}^{2}>0\) is more complicated. Until now, we have used the same test statistics as we used in the fixed-effects case. But if we try to use \(\text{ms}A/\text{ms}E\) to test \(H_{0}^{A}\), we have a problem. If \(H_{0}^{A}\) is true, so that \(\sigma_{A}^{2}=0\), the expected value of the numerator is \(E[\text{MSA}]=dr\sigma_{AB}^{2}+\sigma^{2}\), while that of the denominator is \(E[\text{ms}E]=\sigma^{2}\). This suggests two things:

1. we should use \(\text{ms}(\text{AB})\) as the denominator, not \(\text{ms}E\), and
2. we should question whether it makes sense to test \(H_{0}^{A}\) if the interaction \(\text{AB}\) is significant.

The second point is, of course, exactly the same point that arose in the fixed-effects model, and the answer is usually "no, it makes no sense." Consequently, we generally test a main effect only when that factor is not involved in any significant interactions. Nevertheless, we shall still use the interaction mean square as the denominator in case an incorrect decision was made regarding the interaction. Consequently, the decision rule for testing \(H_{0}^{A}\) against \(H_{A}^{A}\) is

\[\text{reject}\,H_{0}^{A}\text{ if }\text{MSA}/\text{MSA}(\text{AB})>F_{a-1,(a-1)( b-1),\alpha}.\]

Notice that the second set of degrees of freedom for the \(F\)-distribution is the degrees of freedom corresponding to the denominator of the ratio. The test for \(H_{0}^{D}:\{\sigma_{D}^{2}=0\}\) is similar.

Obtaining a suitable denominator for testing the null hypothesis \(H_{0}^{B}:\{\sigma_{B}^{2}=0\}\) versus the alternative hypothesis \(H_{0}^{B}:\{\sigma_{B}^{2}>0\}\) is harder again. If \(H_{0}^{B}\) is true, so that \(\sigma_{B}^{2}=0\), then the expected value of \(\text{MSB}\) is

\[E[\text{MSB}]=dr\sigma_{AB}^{2}+ar\sigma_{BD}^{2}+\sigma^{2}\,.\]

We would generally want to test this hypothesis only if we believed that the interactions \(\text{AB}\) and \(\text{BD}\) were both negligible. Yet to be on the safe side, we would like a denominator with the same expected value. It can be verified that

\begin{table}
\begin{tabular}{c c c} \hline Effect & Degrees of freedom & Expected mean square \\ \hline \(A\) & \(a-1\) & \(bdr\sigma_{A}^{2}+dr\sigma_{AB}^{2}+\sigma^{2}\) \\ \(B\) & \(b-1\) & \(adr\sigma_{B}^{2}+dr\sigma_{AB}^{2}+ar\sigma_{BD}^{2}+\sigma^{2}\) \\ \(D\) & \(d-1\) & \(abr\sigma_{D}^{2}+ar\sigma_{BD}^{2}+\sigma^{2}\) \\ \(\text{AB}\) & \((a-1)(b-1)\) & \(dr\sigma_{AB}^{2}+\sigma^{2}\) \\ \(\text{BD}\) & \((b-1)(d-1)\) & \(ar\sigma_{BD}^{2}+\sigma^{2}\) \\ Error & \(df\) & \(\sigma^{2}\) \\ \hline \end{tabular}
\end{table}
Table 7.7: Expected mean squares and degrees of freedom for a random-effects three-way model with two interactions\[E[U]=E[\text{MS}(\text{AB})+\text{MS}(\text{BD})-\text{MSE}]=dr\sigma_{AB}^{2}+ar \sigma_{BD}^{2}+\sigma^{2}.\]

As in Sect. 17.3.5, \(xU/(dr\sigma_{AB}^{2}+ar\sigma_{BD}^{2}+\sigma^{2})\) has approximately a chi-squared distribution with degrees of freedom \(x\) calculated as in (17.6.22), p. 637; that is,

\[x=\frac{[\text{ms}(\text{AB})+\text{ms}(\text{BD})-\text{ms}E]^{2}}{\frac{[ \text{ms}(\text{AB})]^{2}}{(a-1)(b-1)}+\frac{[\text{ms}(\text{BD})]^{2}}{(b-1 )(d-1)}+\frac{[\text{ms}E]^{2}}{dt}}\,.\]

Therefore, if \(H_{0}\) is true, \(\text{ms}\text{B}/\text{U}\) has approximately an \(F_{b-1,x}\) distribution. So to test \(H_{0}^{B}\) against \(H_{A}^{B}\), the decision rule is

\[\text{reject}\,H_{0}^{B}\text{ if }\frac{\text{ms}\text{B}}{\text{ms}(\text{AB})+ \text{ms}(\text{BD})-\text{ms}E}>F_{(b-1),x,\alpha}.\]

#### 17.6.6 Ammunition experiment, continued

An unbiased estimate for the variance of the muzzle velocities due to the population of charge lots (factor \(A\)) was calculated to be \(u=24.3\) (feet per second)\({}^{2}\) in Example 17.6.5 for the ammunition experiment. A question is whether this value could be due to random error or whether the variance is really sizable; that is, we wish to test the hypothesis \(H_{0}^{A}:\{\sigma_{A}^{2}=0\}\) against the alternative hypothesis \(H_{A}^{A}:\{\sigma_{A}^{2}>0\}\). The interaction variability was found to be very small in Example 17.6.5, so the main-effect hypothesis makes sense. The expected mean squares for \(A\) and \(\text{AB}\) are listed in Table 17.6 as

\[\text{E}[\text{MSA}]\ =\ 8\sigma_{A}^{2}+2\sigma_{\text{AB}}^{2}+\sigma^{2}\]

and

\[\text{E}[\text{MS}(\text{AB})]\ =\ 2\sigma_{AB}^{2}+\sigma^{2}\,,\]

with 3 and 9 corresponding degrees of freedom, respectively. The decision rule, therefore, is

\[\text{reject}\,H_{0}^{A}\text{ if }\frac{\text{ms}\text{A}}{\text{ms}(\text{AB})} \ >\ F_{3,9,\alpha}\,.\]

If we select a Type I error probability of \(\alpha=0.05\), then \(F_{3,9,0.05}=3.86\). Since \(\text{ms}\text{A}/\text{ms}(\text{AB})=223.04/28.63=7.79\), we can conclude that \(\sigma_{A}^{2}>0\). 

#### 17.6.7 Sample Sizes

If we test main effects and interactions only when the higher-order interactions involving those factors are negligible, then we can adapt (17.4.18) by changing the degrees of freedom to match those in the decision rule being used.

### Mixed Models

Models that contain both random and fixed treatment effects are called _mixed models_. The analysis of random effects proceeds in exactly the same way as described in the previous sections. All that is needed is a way to write down the expected mean squares. The fixed effects can be analyzed as in Chaps. 3-7, except that, here, too, we may need to replace the mean square for error by a different appropriate mean square. We show how to calculate the expected mean squares for a mixed model in Sect. 17.7.1.

An interaction between two or more factors any of which has random effects will be regarded as a random effect, since the combination of levels observed in the experiment depends upon the random selection of levels of those factors that have random effects.

#### Expected Mean Squares and Hypothesis Tests

Expected mean squares can be obtained for a mixed model when the sample sizes are equal by modifying rule 17 on p. 637. We start by writing out the expected mean squares as though all the factors were random. We then collect all of the fixed effects and list them together as one "quadratic form." The quadratic form is a function of fixed-effect parameters such as \(\alpha_{i}^{*}=\alpha_{i}+(\overline{\alpha\beta})_{i}\) (see Example 17.7.1) that typically feature in fixed-effects models.

As an example, consider a model containing the main effects of factors \(A\), \(B\), and \(D\) and the interactions \(AB\) and \(BD\). Suppose that factors \(A\) and \(B\) have fixed effects, so that all of their levels of interest are observed in the experiment, and factor \(D\) has random effects, so that its levels form a large population of which only a random selection are observed in the experiment. Then interaction \(AB\) is a fixed effect, but interaction \(BD\) is a random effect.

We use \(\alpha_{i}\) to represent the effect of the \(i\)th level of \(A\), \(\beta_{j}\) to represent the effect of the \(j\)th level of \(B\), and \((\alpha\beta)_{ij}\) to represent their interaction. The effect of the \(k\)th randomly selected level of \(D\) is represented by the random variable \(D_{k}\), and the effect of the interaction between the \(j\)th specifically selected level of \(B\) and the \(k\)th randomly selected level of \(D\) is denoted by the random variable \((\beta D)_{jk}\). The model is then as follows:

\[Y_{ijkt}=\mu+\alpha_{i}+\beta_{j}+D_{k}+(\alpha\beta)_{ij}+(\beta D)_{jk}+ \epsilon_{ijkt}\,, \tag{17.24}\] \[D_{k}\sim N(0,\sigma_{D}^{2}),\ \ (\beta D)_{jk}\sim N(0, \sigma_{BD}^{2}),\ \ \epsilon_{ijkt}\sim N(0,\sigma^{2})\,,\] \[D_{k}\text{'s},\ (\beta D)_{jk}\text{'s and},\ \epsilon_{ijkt}\text{'s are all mutually independent,}\] \[t=1,\ldots,r,\ \ i=1,\ldots,a,\ \ j=1,\ldots,b,\ \ k=1,\ldots,d.\]

The expected mean squares for the corresponding random-effects model were calculated in Example 17.6.3 and are reproduced in the second column of Table 17.8. The expected mean squares for the above mixed model are given in the third column of Table 17.8 and are obtained by collecting the terms in the expected mean squares corresponding to the fixed effects into one quadratic form.

\begin{table}
\begin{tabular}{c c c} \hline Effect & For random-effects model & For mixed model \\ \hline \(A\) & \(bdr\sigma_{A}^{2}+dr\sigma_{AB}^{2}+\sigma^{2}\) & \(Q(A,\,AB)+\sigma^{2}\) \\ \(B\) & \(adr\sigma_{B}^{2}+dr\sigma_{AB}^{2}+ar\sigma_{BD}^{2}+\sigma^{2}\) & \(Q(B,\,AB)+ar\sigma_{BD}^{2}+\sigma^{2}\) \\ \(D\) & \(abr\sigma_{D}^{2}+ar\sigma_{BD}^{2}+\sigma^{2}\) & \(abr\sigma_{D}^{2}+ar\sigma_{BD}^{2}+\sigma^{2}\) \\ \(AB\) & \(dr\sigma_{AB}^{2}+\sigma^{2}\) & \(Q(\text{AB})+\sigma^{2}\) \\ \(BD\) & \(ar\sigma_{BD}^{2}+\sigma^{2}\) & \(ar\sigma_{BD}^{2}+\sigma^{2}\) \\ Error & \(\sigma^{2}\) & \(\sigma^{2}\) \\ \hline \end{tabular}
\end{table}
Table 17.8: Expected mean squares for a three-way mixed model The expected mean squares can all be verified by direct calculation. We illustrate the calculation for \(B\) in the following example. The term \(Q(B,\,AB)\) in _E[MSB]_ corresponds to a quadratic (i.e., squared) function of \(\beta_{j}^{a}=\beta_{j}+(\overline{\alpha\beta})_{j}\), a quantity that we are used to dealing with in fixed-effects models.

**Example 17.7.1**: Calculation of expected mean squares__

Consider an experiment with two fixed-effects treatment factors \(A\) and \(B\), and one random-effects treatment factor \(D\), and suppose that (17.7.24) is thought to be a reasonable model. Using rule 4 of Chap. 7, the fixed-effect sum of squares for \(B\) is

\[SSB=adr\sum_{j=1}^{b}\overline{Y}_{j..}^{2}-abdr\overline{Y}_{....}^{2}\,.\]

Now,

\[\overline{Y}_{j..} =\sum_{i=1}^{a}\sum_{k=1}^{d}\sum_{t=1}^{r}\ \ Y_{ijkt}/adr\] \[=\mu+\overline{\alpha}.+\beta_{j}+\overline{D}.+(\overline{\alpha \beta})_{j}+(\overline{\beta D})_{j.}+\overline{\epsilon}_{j..}\,.\]

So,

\[E[\overline{Y}_{j..}]=\mu+\overline{\alpha}.+\beta_{j}+(\overline{\alpha \beta})_{j}\ \ \text{and}\ \ \text{Var}(\overline{Y}_{j..})=\frac{\sigma_{D}^{2}}{d}+ \frac{\sigma_{BD}^{2}}{d}+\frac{\sigma^{2}}{adr}\,.\]

Similarly,

\[E[\overline{Y}_{....}]=\mu+\overline{\alpha}.+\overline{\beta}.+(\overline{ \alpha\beta})_{..}\ \ \text{and}\ \ \text{Var}(\overline{Y}_{....})=\frac{\sigma_{D}^{2}}{d}+\frac{\sigma_{BD}^{2}}{ bd}+\frac{\sigma^{2}}{abdr}\,.\]

Using the facts that \(\text{MSB}=\text{SSB}/(b-1)\) and \(E[X^{2}]=\text{Var}(X)+(E[X])^{2}\), we obtain

\[E[MSB] =\frac{adr}{(b-1)}\sum_{j=1}^{b}\left(\frac{\sigma_{D}^{2}}{d}+ \frac{\sigma_{BD}^{2}}{d}+\frac{\sigma^{2}}{adr}+[\mu+\overline{\alpha}.+\beta _{j}+(\overline{\alpha\beta})_{j}]^{2}\right)\] \[\quad-\frac{abdr}{(b-1)}\left(\frac{\sigma_{D}^{2}}{d}+\frac{ \sigma_{BD}^{2}}{bd}+\frac{\sigma^{2}}{abdr}+[\mu+\overline{\alpha}.+\overline {\beta}.+(\overline{\alpha\beta})_{..}]^{2}\right)\] \[=ar\sigma_{BD}^{2}+\sigma^{2}+Q(B,\,AB)\,,\]

where

\[Q(B,AB)=\frac{adr}{(b-1)}\sum_{j}\left[(\beta_{j}+(\overline{\alpha\beta})_{ j})-(\overline{\beta}.+(\overline{\alpha\beta})_{..})\right]^{2}\,.\]

\(\square\)

Notice that in Example 17.7.1, the quadratic form \(Q(B,\,AB)\) is equal to zero when all the \(\beta_{j}^{s}=\beta_{j}+(\overline{\alpha\beta})_{j}\) are equal. We can make use of this fact when looking for an appropriate denominator for the test ratio for testing \(H_{0}^{B}:\{\beta_{j}+(\overline{\alpha\beta})_{j}\) are all equal\(\}\). If this hypothesis is true, then \[E[MSB]=ar\sigma_{BD}^{2}+\sigma^{2}\,.\]

Consequently, a sensible denominator would be MS(BD), which has the same expected value (see Table 17.8). Thus, the decision rule for testing \(H_{0}^{B}\) against the alternative hypothesis that the \(\beta_{j}^{*}\) are not all equal is

\[\text{reject }H_{0}^{B}\text{ if }\frac{\text{ms}B}{\text{ms}(BD)}>F_{(b-1),(b-1)(d -1),\alpha}.\]

From Table 17.8 we can construct tests for the other relevant hypotheses in a similar manner. For example, to test the hypothesis

\[H_{0}^{AB}:\{(\alpha\beta)_{ij}-(\overline{\alpha\beta})_{i.}-(\overline{\alpha\beta})_{j}+(\overline{\alpha\beta})_{..}=0\,,\text{ for all }i,j\}\]

against the alternative hypothesis that the interaction contrasts are not all zero, the decision rule is

\[\text{reject }H_{0}^{AB}\text{ if }\frac{\text{ms}(AB)}{\text{ms}E}>F_{(a-1)(b-1),df,\alpha}\,,\]

where df is the number of error degrees of freedom.

To test the hypothesis \(H_{0}^{D}:\{\sigma_{D}^{2}=0\}\) against the alternative hypothesis \(H_{A}^{D}:\{\sigma_{D}^{2}>0\}\), the decision rule is

\[\text{reject }H_{0}^{D}\text{ if }\frac{\text{ms}D}{\text{ms}(BD)}>F_{d-1,(b-1)(d-1),\alpha}.\]

The test ratios are summarized in Table 17.9. Generally, we would not test a main-effect or interaction hypothesis unless all higher-order interactions involving these same factors were believed to be negligible. For some mixed models, as for random-effects models, the appropriate denominator for the test statistic may not be listed among the expected mean squares for the factors in the model. In this case, it would be necessary to calculate it, and the corresponding degrees of freedom, using (17.6.22), p. 637.

#### Confidence Intervals in Mixed Models

##### Confidence Intervals for Fixed Effects

For fixed effects in a mixed model with equal sample sizes, we may use all of the rules of Sect. 7.3, p. 209, exactly as if there were no random effects in the model, _except that we replace msE by the same mean square that was identified for hypothesis testing_--namely, used in the denominator of the test ratio--and the error degrees of freedom are also replaced. The necessity of doing this replacement

\begin{table}
\begin{tabular}{l l l} \hline Effect & \(E[MS]\) & Ratio \\ \hline \(A\) & \(Q(A,\,AB)+\sigma^{2}\) & msA/msE \\ \(B\) & \(Q(B,\,AB)+ar\sigma_{BD}^{2}+\sigma^{2}\) & msB/ms(BD) \\ \(D\) & \(abro_{D}^{2}+ar\sigma_{BD}^{2}+\sigma^{2}\) & msD/ms(BD) \\ \(AB\) & \(Q(\text{AB})+\sigma^{2}\) & ms(AB)/msE \\ \(BD\) & \(ar\sigma_{BD}^{2}+\sigma^{2}\) & ms(BD)/msE \\ \hline \end{tabular}
\end{table}
Table 17.9: Test ratios for a three-way mixed model is highlighted in Example 17.7.2. Apart from this, we may use the Bonferroni, Scheffe, Tukey, and Dunnett methods of multiple comparisons in the usual way. When the sample sizes are unequal, computing least squares estimates and appropriate standard errors is more complicated. Appropriate methods will be illustrated in Chaps. 18 and 19 using PROC MIXED in SAS software and using the lmer and lmeans functions in R.

#### 17.7.2 Calculation of confidence intervals

Consider an experiment with two fixed-effects treatment factors and a third treatment factor with random effects, for which the following model is thought to be reasonable (this is the same model that has been discussed throughout this subsection):

\[Y_{ijkt}=\mu+\alpha_{i}+\beta_{j}+D_{k}+(\alpha\beta)_{ij}+(\beta D)_{jk}+ \epsilon_{ijkt}.\]

The fixed part of the model is

\[\mu+\alpha_{i}+\beta_{j}+(\alpha\beta)_{ij}\,,\]

which looks exactly like one of the two-way analysis of variance models that was studied in Chap. 6.

Suppose we need confidence intervals for pairwise comparisons in the levels of \(A\) and of \(B\). Then, as usual, the least squares estimates for pairwise differences are

\[\widehat{\alpha}_{i}^{*}-\widehat{\alpha}_{p}^{*}=\left(\widehat{\alpha}_{i}+ \widehat{(\alpha\beta)}_{i}.\right)-\left(\widehat{\alpha}_{p}-\widehat{( \alpha\beta)}_{p}.\right)=\overline{y}_{i\ldots}-\overline{y}_{p\ldots}\]

and

\[\widehat{\beta}_{j}^{*}-\widehat{\beta}_{u}^{*}=\left(\widehat{\beta}_{j}+ \widehat{(\alpha\beta)}_{j}\right)-\left(\widehat{\beta}_{u}+\widehat{( \alpha\beta)}_{u}\right)=\overline{y}_{j\ldots}-\overline{y}_{u\ldots}\,.\]

Tables 17.8 (p. 643) and 17.9 (p. 645) suggest that msE should be used in the formulae for confidence intervals for \(\alpha_{i}^{*}-\alpha_{p}^{*}\), as usual, but that ms(BD) should be used in place of msE in the formulae for confidence intervals for \(\beta_{j}^{*}-\beta_{u}^{*}\). All confidence intervals are of the form

\[\text{(least squares estimate)}\pm(w)\times(\text{standard error)}\,.\]

The standard error is the square root of the estimated variance of the least squares estimator. Now,

\[\text{Var}(Y_{ijkt})=\sigma_{D}^{2}+\sigma_{BD}^{2}+\sigma^{2}\quad\text{ and}\quad\text{Var}(\overline{Y}_{j\ldots})=\frac{\sigma_{D}^{2}}{d}+\frac{\sigma_{BD}^{2}}{d}+\frac{\sigma^{2}}{ adr}\,.\]

The \(Y_{ijkt}\)'s are not independent. Observations on the same level of \(D\) are correlated. If two observations are taken on the same levels of \(B\) and \(D\), we have

\[\text{Cov}(Y_{ijkt}\,,\,\,Y_{pjks})=\sigma_{D}^{2}+\sigma_{BD}^{2}\,.\]

If two observations are taken on the same level of \(D\), but different levels of \(B\), then

\[\text{Cov}(Y_{ijkt}\,,\,\,Y_{pubs})=\sigma_{D}^{2}\,.\]All other pairs of response variables are independent. Consequently,

\[\text{Cov}(\overline{Y}_{j..}\,\ \overline{Y}_{u..}) = \frac{1}{a^{2}d^{2}r^{2}}\left[\sum_{i=1}^{a}\sum_{p=1}^{a}\sum_{k =1}^{d}\sum_{t=1}^{r}\sum_{s=1}^{r}\ \text{Cov}(Y_{ijkt},\,Y_{puks})\right]\] \[= \frac{1}{a^{2}d^{2}r^{2}}\left[a^{2}dr^{2}\sigma_{D}^{2}\right]\] \[= \frac{\sigma_{D}^{2}}{d}\,\]

and

\[\text{Var}(\overline{Y}_{j..}-\overline{Y}_{u..}) = \text{Var}(\overline{Y}_{j..})+\text{Var}(\overline{Y}_{u..})-2 \text{Cov}(\overline{Y}_{j..}\,\ \overline{Y}_{u..})\] \[= 2\left(\frac{\sigma_{D}^{2}}{d}+\frac{\sigma_{\text{BD}}^{2}}{d }+\frac{\sigma^{2}}{adr}\right)-2\left(\frac{\sigma_{D}^{2}}{d}\right)\] \[= \frac{2}{adr}\left(ar\sigma_{\text{BD}}^{2}+\sigma^{2}\right)\,\]

which is of the form \((\Sigma c_{i}^{2}/(adr))(ar\sigma_{BD}^{2}+\sigma^{2})\). Thus, we need to estimate \((ar\sigma_{\text{BD}}^{2}+\sigma^{2})\) rather than \(\sigma^{2}\), and an unbiased estimate is given by ms(BD). So, the standard error for \(\hat{\beta}_{j}^{*}-\hat{\beta}_{u}^{*}=\overline{Y}_{j..}-\overline{Y}_{u..}\) is \(((2/(adr))\text{ ms(BD)})^{1/2}\) with corresponding degrees of freedom \((b-1)(d-1)\). 

In some models, the necessary mean square will not be listed in the expected mean squares table, and (17.6.22), p. 637, and methods discussed there will need to be used to find an approximate mean square and degrees of freedom.

**Confidence Intervals for Variance Components**

In obtaining confidence intervals for variance components, only the random part of the model is used, or, equivalently, only the mean squares corresponding to random effects. Consequently, the formulae of Sect. 17.6.5 are used exactly as described for random-effects models.

### Rules for Analysis of Random-Effects and Mixed Models

Rules 1-7 of Sect. 7.3, p. 209, are valid for calculating degrees of freedom, sums of squares, and mean squares in random-effects and mixed models as well as in fixed-effects models. In addition, rules 8-16 are valid for analyzing fixed effects, except that \(\sigma^{2}\) and msE may need to be replaced. Rules 17-22 below summarize the results of this chapter. Rule 17 is an expanded version of rule 17 on p. 637.

#### Rules--Equal Sample Sizes

1. To obtain the expected mean square for a particular main effect or interaction, first make a note of the subscripts on the term representing that particular effect in the model. Write down variance components for the effect of interest, for the error, and for every interaction whose term in the model includes the noted set of subscripts. Gather up all variance components corresponding to fixed effects into one quadratic form \(Q\). Multiply any remaining variance component except \(\sigma^{2}\) by the number of observations taken on each level or combination of levels of the corresponding effect (main effect or interaction). Add up the terms.
18. To obtain the denominator of the test statistic for testing the null hypothesis that a main effect or interaction effect is zero, write down the expected mean square for the effect of interest (see rule 17). Cross out the term that would be zero if the null hypothesis were true. The denominator of the test statistic is the mean square, or linear combination of mean squares, \(u\), whose expected value is equal to the remaining expression.
19. For a random effect, let \(U=\Sigma k_{i}\text{MS}_{i}\) be the mean square or linear combination of mean squares whose expected value is equal to the variance component corresponding to the random effect. An exact or approximate 100(\(1-\alpha\))% confidence interval for this variance component is \[\left(\frac{xu}{\chi_{x,\alpha/2}^{2}}\ \,\ \ \frac{xu}{\chi_{x,1-\alpha/2}^{2}}\right),\] where \[x=\frac{[\Sigma k_{i}(\text{ms}_{i})]^{2}}{\Sigma[k_{i}(\text{ms}_{i})]^{2}/ x_{i}}\] and where \(u\) is the observed value of \(U\), \(\text{ms}_{i}\) is the observed value of \(\text{MS}_{i}\), and \(x_{i}\) is the number of degrees of freedom corresponding to \(\text{ms}_{i}\).
20. For a fixed effect, confidence intervals are obtained as in rule 14, p. 211, except that \(\text{ms}E\) is replaced by the denominator \(u\) from rule 18, and the number of error degrees of freedom is replaced by \(x\) in rule 19.
21. For a fixed effect, the decision rule for testing the hypothesis that the effect is zero is the same as that in rule 8, p. 210, for fixed-effects models, except that \(\text{ms}E\) is replaced by the denominator \(u\) from rule 18, and the number of error degrees of freedom is replaced by \(x\) in rule 19.
22. For a random effect, the decision rule for testing the hypothesis \(H_{0}\) that the corresponding variance component is zero against the alternative hypothesis that it is not zero is \[\text{reject}\ H_{0}\ \text{if}\ \frac{\text{ms}}{u}>F_{\nu,x,\alpha}\,,\] where \(\text{ms}\) is the mean square for the effect of interest and \(\nu\) the corresponding degrees of freedom, \(u\) is the observed value of the denominator as in rule 18, and \(x\) is the corresponding degrees of freedom calculated as in rule 19.

#### Controversy (Optional)

Before proceeding, we should mention that some other textbooks may present slightly different tables of expected mean squares. For example, the expected mean square for \(D\) in Table 17.8, which we have calculated as

\[E[\text{MSD}]=abr\sigma_{D}^{2}+ar\sigma_{\text{BD}}^{2}+\sigma^{2},\]

may in other texts be listed as

\[E[\text{MSD}]=abr\sigma_{D}^{2}+\sigma^{2}\,.\]This alternative listing occurs when constraints are placed on the model parameters involving fixed-effects factors, and it suggests use of the denominator _msE_ rather than _ms_(_BD_) in testing \(H_{0}^{D}:\{\sigma_{D}^{2}=0\}\) against \(H_{A}^{D}:\{\sigma_{D}^{2}>0\}\). A number of articles in the statistical literature have been written advocating one denominator rather than the other, and there still appears to be no consensus.

If we follow the line of reasoning that we have followed to this point, that normally we will examine main effects only when there is no interaction, then some of the controversy disappears. If \(\sigma_{BD}^{2}\) is really zero, then \(E[MSD]=abr\sigma_{D}^{2}+\sigma^{2}\) in both cases. Of course, due to variability of the data and uncertainty about whether or not \(\sigma_{BD}^{2}\) is really zero (or close to it), we still have to make the choice in practice. We have recommended using _ms_(_BD_) as the denominator if the objective is to test \(H_{0}^{D}:\sigma_{D}^{2}=0\). However, if interest is really in testing

\[H_{0}^{D+BD}:\{\sigma_{D}^{2}+b^{-1}\sigma_{BD}^{2}=0\}\;,\]

or equivalently

\[H_{0}^{D+BD}:\{\sigma_{D}^{2}=\sigma_{BD}^{2}=0\}\;,\]

then we would use _msE_ as the denominator.

The controversy originally arose from the formulation of the model. In our example, the model was given in (17.7.24), p. 643, and the controversy surrounds the random effect \((\beta D)_{jk}\). We have modeled this as a normally distributed random variable. Some authors add to the model the restriction \(\Sigma_{j}(\beta D)_{jk}=0\), and this leads to the canceling of the term in \(\sigma_{BD}^{2}\) when the expected mean square of \(D\) is calculated.

Hocking (1996, p. 569) shows that under this restriction, the hypothesis \(H_{0}^{D}\) is actually our hypothesis \(H_{0}^{D+BD}\). An explanation for this is as follows. If constraints are placed on the parameters, then the \((\beta D)_{jk}\) effects truly represent interaction effects, and \(\sigma_{BD}^{2}\) measures precisely variability in _BD_-interaction effects. However, if no constraints are placed on the parameters, then \(\sigma_{BD}^{2}\) being positive implies the presence of main effects of \(B\) and \(D\) as well as the presence of _BD_-interaction effects. In other words, the parameters \((\beta D)_{jk}\) represent "_BD_ effects" in model (17.7.24), though we have referred to them as _BD_-interaction effects. Thus, under our model (17.7.24), the hypothesis \(H_{0}^{D+BD}:\{\sigma_{D}^{2}=\sigma_{BD}^{2}=0\}\) is that there are no main effects of \(D\) (or _BD_ interactions). Also, there are no _BD_ interactions if \(\sigma_{BD}^{2}=0\), and there are no main effects of \(B\) (or _BD_ interactions) if \(\beta_{1}=\beta_{2}=\cdots=\beta_{b}\) and \(\sigma_{BD}^{2}=0\). From this viewpoint, the hypothesis \(H_{0}^{D}:\sigma_{D}^{2}=0\) is that there are no main effects of \(D\) if \(\sigma_{BD}^{2}\) is believed to be zero; otherwise, it is the hypothesis that main effects of \(D\) are no less negligible than _BD_ interactions.

Since there are problems inherent in placing restrictions on the model parameters, we prefer not to do so, and we prefer to use the set of expected mean squares in Table 17.7. If the parameters in the model are properly interpreted, then there is no controversy, and the appropriate test is determined by what is most sensible for the experiment at hand.

### Block Designs and Random Block Effects

In certain types of experiments, it is extremely common for the levels of a blocking factor to be randomly selected. For example, in medical, psychological, educational, or pharmaceutical experiments, blocks frequently represent subjects that have been selected at random from a large population of similar subjects. In agricultural experiments, blocks may represent different fields selected from a large variable population of fields. In industrial experiments, different machine operators may represent different levels of the blocking factor and may be similar to a random sample from a large population of possible operators. Raw material may be delivered to the factory in batches, a random selection of which are used as blocks in the experiment.

Since we are not interested in the blocking factor itself, its designation as random rather than fixed will affect the analysis only if the model includes a block\(\times\)treatment interaction. For example, suppose that factor \(D\) in Table 17.8 represents a random-effects blocking factor, and that \(A\) and \(B\) are two fixed-effects treatment factors. The analysis of factor \(A\), which has no interaction with \(D\), is unaffected by the designation of \(D\) as a random effect. However, the analysis of factor \(B\), which interacts with blocks, _is_ affected, since _msE_ in hypothesis tests and confidence intervals for contrasts in the levels of \(B\) will be replaced by _ms_(_BD_).

#### 17.9.1 Temperature experiment

The temperature experiment was run by M. Bowe, J. Cooper, J. Donato, S. Giust, and H. Schieman in 1994 to compare the times required for three different digital thermometers (factor \(A\) at \(a=3\) levels) to register body temperature at two different sites--in the mouth and under the arm--(factor \(B\) at \(b=2\) levels). Thus, there were six treatment combinations. Four subjects were selected at random from the American statistics graduate students at The Ohio State University, and each treatment combination was measured once for each subject. The experiment was designed as a randomized complete block design, with subjects representing blocks. The recorded times are shown in Table 17.10.

The four subjects used in the experiment are not themselves of interest. Of more interest is how the thermometers react on average over a large population of subjects. The population of American statistics graduate students at the university is large, but not infinite. However, the four subjects used in the experiment are, hopefully, representative of all possible American graduate students, and it is reasonable to model the subject (block) effect as a random effect.

Since subjects vary in body heat, it is possible that factor \(B\) (site) might interact with subject. It is also possible that different thermometers might act differently at the two different sites. Consequently the following model might be reasonable for this experiment.

\[Y_{hij}=\mu+S_{h}+\alpha_{i}+\beta_{j}+(\alpha\beta)_{ij}+(S\beta)_{ hj}+\epsilon_{hij}\,, \tag{17.9.25}\] \[h=1,2,3,4,\ \ i=1,2,3,\ \ j=1,2,\] \[S_{h}\sim N(0,\,\sigma_{S}^{2}),\ \ (S\beta)_{hij}\sim N(0,\, \sigma_{SB}^{2}),\ \ \epsilon_{hij}\sim N(0,\,\sigma^{2})\,,\] \[S_{h}\text{'s},\ \ (S\beta)_{hij}\text{'s and }\epsilon_{hij}\text{'s are all mutually independent}\,,\]

where all random variables on the right-hand side of the model are mutually independent, and where \(S_{h}\) represents the effect of the \(h\)th randomly selected subject (block), \(\alpha_{i}\) represents the effect of the \(i\)th specifically selected thermometer, and \(\beta_{j}\) represents the effect of the \(i\)th specifically selected site. This model is similar to mixed model (17.7.24) with \(S_{h}\) replacing \(D_{k}\). Consequently, the expected mean squares will be similar to those in Table 17.8, p. 643. The analysis of variance table is shown in Table 17.11.

\begin{table}
\begin{tabular}{c c c c c c c} Subject & \multicolumn{6}{c}{Treatment combination} \\ \cline{2-7}  & 11 & 12 & 21 & 22 & 31 & 32 \\
1 & 62.16 & 61.53 & 154.42 & 310.46 & 95.98 & 225.65 \\
2 & 65.63 & 63.70 & 132.30 & 284.64 & 98.50 & 241.63 \\
3 & 63.12 & 61.34 & 105.52 & 315.61 & 110.05 & 364.07 \\
4 & 61.51 & 61.54 & 94.88 & 294.16 & 107.93 & 304.58 \\ \end{tabular}
\end{table}
Table 17.10: Data (in seconds) for the temperature experiment We start by testing the two interaction hypotheses. To test the hypothesis \(H_{0}^{SB}:\{\sigma_{SB}^{2}=0\}\), that the subject by site interaction variance is negligible, against the alternative hypothesis that it is not negligible, using a significance level of 0.01 (so that the overall significance level will be at most 0.05), we

\[\text{reject }\,H_{0}^{SB}\,\text{ if }\,\frac{\text{ms}(SB)}{\text{ms}E}>F_{3,12,0.01}=5.95\,.\]

Since \(\text{ms}(SB)/\text{ms}E=1.51\), there is not sufficient evidence to conclude that the interaction variance is greater than zero (equivalently, the \(p\)-value is greater than 0.01). Before we can examine the site main effect, however, we also need to look at the thermometer by site interaction.

To test the hypothesis

\[H_{0}^{AB}:\{(\alpha\beta)_{ij}-(\alpha\beta)_{ip}-(\alpha\beta)_{uj}+(\alpha \beta)_{up},\text{ for all }i,j,u,p\}\]

against the alternative hypothesis that the interaction is not negligible, we

\[\text{reject }\,H_{0}^{AB}\,\text{ if }\,\frac{\text{ms}(AB)}{\text{ms}E}>F_{2,12,0.01}=6.93\,.\]

Since \(\text{ms}(AB)/\text{ms}E=27.28\), we reject \(H_{0}^{AB}\) and conclude that there is a thermometer\(\times\)site interaction. Thus, it is unlikely that the thermometer and site main effects are of interest. However, for illustration purposes, we ask whether the _average_ time taken for these three digital thermometers to register is the same whether used in the mouth or under the arm. Thus, we will test the hypothesis

\[H_{0}^{B}:\{\beta_{1}+(\overline{\alpha\beta})_{.1}=\beta_{2}+(\overline{\alpha\beta})_{.2}\}\,.\]

To test this hypothesis at significance level 0.01, we

\[\text{reject }\,H_{0}^{B}\,\text{ if }\,\frac{\text{ms}\text{B}}{\text{ms}(SB)}>F_{1,3,0.01}=29.5\,.\]

Since \(\text{ms}\text{B}/\text{ms}(SB)=71.06\), we reject \(H_{0}^{B}\) and conclude that it does make a difference in registering temperature (on average for these three thermometers) as to whether the thermometer is used in the mouth or under the arm. This conclusion is made on average over the three thermometers and over the whole population of similar graduate students.

\begin{table}
\begin{tabular}{c c c c c} \hline Source of variation & Degrees of freedom & Mean square & \(p\)-value & Expected mean square \\ \hline Subject (block) & 3 & 570.04 & \(-\) & \(-\) \\ Thermometer (\(A\)) & 2 & 52879.34 & 0.0001 & \(Q(A,\,\text{AB})+\sigma^{2}\) \\ Site (\(B\)) & 1 & 86029.60 & 0.0035 & \(Q(B,\,\text{AB})+3\sigma_{\text{SB}}^{2}+\sigma^{2}\) \\ Therm*Site (\(AB\)) & 2 & 21897.23 & 0.0001 & \(Q(\text{AB})+\sigma^{2}\) \\ Subject*Site (SB) & 3 & 1210.67 & 0.2625 & \(3\sigma_{\text{SB}}^{2}+\sigma^{2}\) \\ Error & 12 & 802.57 & & \(\sigma^{2}\) \\ Total & 23 & & & \\ \hline \end{tabular}
\end{table}
Table 17.11: Analysis of variance table for the mixed model temperature experiment 

### Using SAS Software

Section 17.10.1 illustrates the use of SAS software to check model assumptions on random effects. Then in Sect. 17.10.2, the analysis of mixed models using PROC GLM and PROC MIXED is illustrated, followed by an example of analysis of covariance to deal with a quadratic time trend. Finally in Sect. 17.10.3, the SAS DATA step and functions are used to do the sample size calculations of Example 17.4.1.

#### Checking Assumptions on the Model

Using the data of Table 17.1, p. 617, for the clean wool experiment, we illustrate some methods of checking model assumptions for a random-effects one-way model. The experimenters took observations on \(r=4\) cores of wool from each of \(v=7\) randomly selected wool bales.

We let the random variable \(T_{i}\) represent the true clean content of the \(i\)th randomly selected bale of wool from the shipment, and let \(Y_{it}=T_{i}+\epsilon_{it}\) represent the observed clean content of the \(t\)th core (observation) from the \(i\)th bale, where the error variable \(\epsilon_{it}\) includes the deviation from the true average clean content of the \(t\)th core from the \(i\)th bale, the measurement error, environmental conditions, etc.

First, we check the error assumptions by calculating and plotting the standardized residuals obtained as though the bale effects were fixed. The standardized residuals are calculated in the usual way and plotted against the levels of the treatment factor and the predicted values (see Sect. 5.8, p. 119). The latter plot, obtained by PROC SGPLOT, is shown in Fig. 17.3.

The most noticeable feature is that bale 1 gives rise to one very large standardized residual (an outlier). This means one of several things: Perhaps the data value is in error, so that this value is an outlier, or perhaps bale 1 is extremely more variable than the other bales in the population, or perhaps the error variables are not normally distributed. Let us suppose that we could go back to the original experimenters and that indeed, something unusual happened at this point during the time at which the observations were taken. If so, we could exclude this value. The new residual plot is shown in Fig. 17.4.

All standardized residuals now lie within the expected range for normally distributed errors. The plot gives us quite a lot of information about our sample of bales and possibly about the shipment of bales from which they were drawn. First, the average clean content of bale 1 is around 53, considerably

Figure 17.3: Residuals versus predicted values by bale type for the clean wool experimentbelow the others. This was the bale that had the supposed outlier. One might suspect that this bale either did not come from the same shipment or was contaminated at some point before being measured. On the other hand, the shipment may contain a number of "rogue bales," and this ought to be investigated. At the other end of the range, we see that bale 7 had the highest clean content and was least variable. Perhaps this is not too surprising, since a bale with 100% clean content would probably show no variability in the measurements taken on it. Thus, one might suspect that our model that includes normally distributed errors is not ideal for this situation. However, the plot of standardized residuals against normal scores does not show any anomalies (figure not shown).

In a one-way random-effects model, we can check the assumption that the treatment effects have a normal distribution by making a normal probability plot of the standardized treatment averages \(\overline{Y}_{i}\). against their normal scores. (This cannot be done for models with more than one random effect, since the treatment averages are not independent.) For the clean wool experiment, the normal probability plot is obtained by means of the statements in Table 17.12, and the resulting plot is shown in Fig. 17.5. If the normality assumption for the population of bales is satisfied, the standardized bale averages should roughly lie along a line (with slope 1.0) through (0, 0). In Fig. 17.5, we see that this is roughly the case.

In summary, the random-effects one-way model with the standard distribution assumptions does not fit these data too well, since variances apparently are not constant or there is an outlier. Nevertheless, we have established that the population of bales in this shipment is extremely variable. Selected bales 1 and 7 appear to be somewhat different from the other five selected bales. Perhaps the shipment is

\begin{table}
\begin{tabular}{c} PROC SORT; BY BALE; PROC MEANS NOPRINT; BY BALE; VAR CONTENT; OUTPUT OUT = WOOL2 MEAN = AVCONT; PROC STANDARD STD = 1.0 MEAN = 0.0; VAR AVCONT; PROC RANK NORMAL = BLOM; VAR AVCONT; RANKS NSCORE; PROC SGPLOT; SCATTER X = NSCORE Y = AVCONT / GROUP = BALE; \\ PROC MEANS NOPRINT; BY BALE; VAR CONTENT; VAR CONTENT; OUTPUT OUT = WOOL2 MEAN = AVCONT; PROC STANDARD STD = 1.0 MEAN = 0.0; VAR AVCONT; PROC RANK NORMAL = BLOM; VAR AVCONT; RANKS NSCORE; PROC SGPLOT; SCATTER X = NSCORE Y = AVCONT / GROUP = BALE; \\ \end{tabular}
\end{table}
Table 17.12: SAS program to plot standardized treatment averages against their normal scores

Figure 17.4: Residuals versus predicted values for the clean wool experiment, excluding the outlier

made up of dissimilar subpopulations (perhaps from different sources). This should be checked, since it may give a clue as to how to improve the wool clean content in the future.

#### Estimation and Hypothesis Testing

##### PROC GLM

Analysis of variance tables for random-effects and mixed models are obtained using PROC GLM in exactly the same way as for fixed-effects models. The additional expected mean squares column can be obtained very easily by inserting a RANDOM statement immediately after the model statement. All random effects should be listed in the RANDOM statement, as shown, for example, in Table 17.13 for the temperature experiment of Example 17.9.1, p. 650. The denominators, calculated as explained throughout this chapter, can be obtained by adding the option TEST to the RANDOM statement, as shown in the following example. The actual denominators are printed out as well as the \(p\)-values.

The output is shown in Fig. 17.6. The first few lines reproduce the expected mean squares that were calculated by hand in Table 17.7, p. 641. The remainder of the output gives the TYPE III sums of

\begin{table}
\begin{tabular}{c} DATA TEMPR; \\ INPUT THERM SITE SUBJ TIME; \\ LINES; \\
1 1 1 62.16 \\
1 2 1 61.53 \\
: : : \\
3 2 4 304.58 \\ ; \\ PROC GLM; \\ ODS EXCLUDE LSMeanCL; \\ CLASS THERM SITE SUBJ; \\ MODEL TIME = SUBJ THERM SITE THERM*SITE SUBJ*SITE; \\ RANDOM SUBJ SUBJ*SITE / TEST; \\ CONTRAST ‘SITE1-SITE2’ SITE 1 -1 / E = SUBJ*SITE; \\ LSMEANS SITE / CL PDIFF E = SUBJ*SITE; \\ \end{tabular}
\end{table}
Table 17.13: SAS program for the temperature experiment squares, but instead of calculating the usual test ratios with msE as the denominator, the TEST option on the RANDOM statement has caused the denominator ms(subjxsite) to be used where appropriate.

All pairwise comparisons of fixed effects can be estimated using the LSMEANS statement, which allows the correct variance estimator to be specified. For example, the statement

LSMEANS SITE / CL PDIFF E = SUBJ*SITE;

will use the subjxsite interaction mean square as the variance estimate for comparing sites, rather than the error mean square. The LSMEANS statement provides a confidence interval for the pairwise comparison of sites, and also a \(p\)-value for testing equality of the two site effects. The ODS statement is used to exclude printing of the confidence intervals (limits) for site level means, since the standard errors would be incorrectly estimated using ms(subjxsite); the reader is asked in Exercise 9 to verify that Var(\(\overset{\rightarrow}{Y}_{\cdot\cdot\cdot j}\)) = (\(3\sigma_{S}^{2}+3\sigma_{SB}^{2}+\sigma^{2}\))/12 for the \(j\)th site under model (17.9.25), p. 650.

Any contrast for the fixed effects can be estimated as usual using the ESTIMATE statement, though the standard error is computed using MSE whether or not this is appropriate. Confidence intervals can be calculated by hand and the mean squared error replaced by the denominator used in the test procedures if necessary. For testing individual contrasts, the CONTRAST statement can be used and the required denominator can be specified. For example, the statement

CONTRAST 'SITE1-SITE2' SITE 1 -1 / E = SUBJ*SITE;

will use the subjxsite interaction mean square as the variance estimate for comparing sites as appropriate.

The deficiencies of PROC GLM in computing standard errors are overcome by PROC MIXED, introduced next.

##### PROC MIXED

The SAS package includes an alternative procedure PROC MIXED, explicitly designed to cope with random-effects and mixed models. The statements that generate the same set of information as in Fig. 17.6 are

 PROC MIXED METHOD = TYPE3;  CLASS THERM SITE SUBJ;  MODEL TIME = THERM SITE THERM*SITE / DDFM = SAT;  RANDOM SUBJ SUBJ*SITE;  LSMEANS SITE / CL DIFF;

For PROC MIXED, the MODEL statement only contains fixed effects, with random effects specified in the RANDOM statement. The option METHOD=TYPE3 causes the model to be fit by the method of least squares, as used by PROC GLM. Estimates of the variance components are also calculated by this procedure and, under the option METHOD=TYPE3, they match those one could compute by hand from GLM output. An important advantage of PROC MIXED is that standard errors of means and contrasts are automatically correctly estimated under mixed models, even if composite estimates are needed, as is the case here for site treatment means, for example. The DDFM=SAT option in the MODEL statement causes Satterthwaite's approximation to be used to compute degrees of freedom associated with any composite variance estimates, as may be needed for either \(F\)-statistic denominators or standard error estimates.

Throughout this chapter we have discussed the analysis of mixed and random effects models using the _analysis of variance approach_--namely, fitting the model by least squares as if all effects were fixed, obtaining a corresponding analysis of variance table, then using the expected mean squares to obtain unbiased estimates of the variance components and to determine appropriate \(F\)-statistic denominators and standard error estimates. The variance component estimates so obtained are called _analysis of variance estimates_. For balanced data under normality, the least squares estimates of any estimable fixed effects are best linear unbiased estimates, and the analysis of variance estimates of variance components are minimum variance unbiased estimates, but the variance component estimates can be negative, as happens in the above example where the subjects variance component estimate is \(\hat{\sigma}_{S}^{2}=[\text{\it ms}(\text{SUBJ})-\text{\it ms}(\text{SITE*SUBJ})]/6 \approx-106.77\).

There are other more sophisticated statistical methods for estimating variance components that prevent the estimates from ever being negative, and that are generally preferable for unbalanced data. One such approach involves estimation of the variance components by _restricted maximum likelihood_ (ReML). This approach, implemented in PROC MIXED, will be discussed in Chap. 19.

#### Covariates

Before leaving this section, we will examine a more complicated model. The plot of standardized residuals against order of observation by flavor for the ice cream experiment (Example 17.3.1, p. 621) is shown in Fig. 17.7. This plot suggests that there may be a quadratic time trend in the data.

We define two extra variables \(X\) and \(X\)2 in the DATA statement as follows,

DATA ICE;  INPUT FLAVOR MELTTIME ORDER;  X=ORDER-16.5;  X2=X*X;  LINES;  i 924 1 ;  i ;

Figure 17.6: SAS software analysis of variance for the temperature experiment

and we add these variables to the model statement, so the code for PROC GLM becomes

PROC GLM;  CLASS FLAVOR;  MODEL MELTTIME = X X2 FLAVOR;  RANDOM FLAVOR / TEST;

The variable X is just the same as ORDER, except that we have subtracted the average order 16.5. This helps to reduce computational problems in the model fitting. The Type III sums of squares and the expected mean squares are shown in Fig. 17.8. We see that the quadratic effect of time order is quite substantial and that from the list of expected mean squares, our estimate of the variance of melting times due to flavor (var(FLAVOR)) must be calculated as

\[\hat{\sigma}_{T}^{2}=\frac{94179.139-4497.426}{9.6478}=9359.62\;\text{seconds}^{2}\]

or \(\hat{\sigma}_{T}=96.75\) seconds, which is a little larger than the estimate of \(\hat{\sigma}_{T}=85.13\) seconds that we obtained in Example 17.3.4, p. 627. Examination of the residuals in the new model shows that the error assumptions are fairly well satisfied. In Exercise 8, the reader is asked to recalculate the confidence intervals for \(\sigma_{T}^{2}\) and \(\sigma_{T}^{2}/\sigma^{2}\) using the new model.

#### Sample Size Calculations

In this section, a program in the SAS DATA step is used to do the sample size calculations of Example 17.4.1, p. 630, for the ice cream experiment. Recall, in testing the hypothesis \(H_{0}^{\gamma T}:\sigma_{T}^{2}\leq\sigma^{2}\) against the hypothesis \(H_{A}^{\gamma T}:\sigma_{T}^{2}>\sigma^{2}\) at a significance level of \(\alpha=0.05\), the goal is to be able to reject the null hypothesis with probability \(\pi=0.95\) if the true value of \(\sigma_{T}^{2}/\sigma^{2}\) is at least \(\Delta=2.0\). In Example 17.4.1, trial and error was used to determine the number \(v\) of ice cream flavors we should look at if we took \(r=11\) or \(r=3\) observations on each. Recall, to achieve the desired power for given \(r\), we need to find \(v\) such that

\[(F_{v-1,v(r-1),05})(F_{v(r-1),v-1,05})\leq(2r+1)/(r+1)\;.\]

The calculations are illustrated in the SAS program in Table 17.14, and the corresponding output is displayed in Fig. 17.9. In the SAS program, for each value \(r=11\) and \(r=3\), the SAS function FINV

Figure 17.7: Plot of the standardized residuals against order of observation by flavor for the ice cream experiment

is used to compute the quantile values \(F_{v-1,v(r-1),05}\) and \(F_{v(r-1),v-1,05}\) for each value \(v=2,3,\ldots\), either stopping when the above inequality is satisfied, giving the required value of \(v\) and the result "Enough data", or reaching \(v=200\) and giving the result "Need more data". The results displayed in Fig. 17.9 are a bit more precise than those given in Example 17.4.1.

\begin{table}
\begin{tabular}{c c c c c c} DATA POWER; & & & & & \\ ALPHA=0.05; POWER=0.95; & & & & & \\ DO R=11,3; & & & & & \\ RATIO = (2*R+1)/(R+1); & & & & & \\ RESULT=”Need more data”; & & & & & \\ V=1; & & & & & \\ DO WHILE (RESULT=”Need more data” and V \textless{} 201); & & & & & \\ V=V+1; & & & & & \\ DF1=V-1; & DF2=V*(R-1); & & & & \\ F1 = FINV(1-ALPHA,DF1,DF2); & * Compute F(DF1,DF2,ALPHA); & & & & \\ F2 = FINV(POWER,DF2,DF1); & & * Compute F(DF2,DF1,1-POWER); & & & \\ PRODUCT=F1*F2; & & & & & \\ IF PRODUCT \textless{} RATIO THEN RESULT=”Enough data”; & & & & & \\ END; & & & & & \\ OUTPUT; * Output results to data set; & & & & & \\ END; * End R loop; & & & & & \\ \end{tabular} ; & & & & & \\ PROC PRINT; & & & & & & \\ VAR R V RESULT POWER ALPHA F1 F2 PRODUCT RATIO DF1 DF2; & & & & & \\ \end{tabular}
\end{table}
Table 17.14: SAS program doing sample size calculations for the ice cream experiment

Figure 17.8: SAS software analysis of variance for the ice cream experiment

### Using R Software

Section 17.11.1 illustrates the use of R to check model assumptions on random effects. Then in Sect. 17.11.2, the analysis of fixed effects in mixed models using aov is illustrated. Finally in Sect. 17.11.3, an R function is defined to do the sample size calculations of Example 17.4.1.

#### Checking Assumptions on the Model

Using the data of Table 17.1, p. 617, for the clean wool experiment, we illustrate some methods of checking model assumptions for a random-effects one-way model. The experimenters took observations on \(r=4\) cores of wool from each of \(v=7\) randomly selected wool bales.

We let the random variable \(T_{i}\) represent the true clean content of the \(i\)th randomly selected bale of wool from the shipment, and let \(Y_{it}=T_{i}+\epsilon_{it}\) represent the observed clean content of the \(t\)th core (observation) from the \(i\)th bale, where the error variable \(\epsilon_{it}\) includes the deviation from the true average clean content of the \(t\)th core from the \(i\)th bale, the measurement error, environmental conditions, etc.

First, we check the error assumptions by calculating and plotting the standardized residuals obtained as though the bale effects were fixed. The standardized residuals are calculated in the usual way and plotted against the levels of the treatment factor and the predicted values (see Sect. 5.9, p. 126). The latter plot, obtained from the statements

 plot(z ~ typed, data=wool.data, ylab="Standardized Residuals", las=1,  type="n") # Suppress plotting of circles  text(z ~ typed, bale, cex=0.75, data=wool.data) # Plot bale number  mtext("Plotting symbol is bale", side=3, adj=1, line=1) # Margin text  abline(h=0) is shown in Fig. 17.10. The plotted symbols indicate the bales from which the residuals arose.

The most noticeable feature is that bale 1 gives rise to one very large standardized residual (an outlier). This means one of several things: Perhaps the data value is in error, so that this value is an outlier, or perhaps bale 1 is extremely more variable than the other bales in the population, or perhaps the error variables are not normally distributed. Let us suppose that we could go back to the original experimenters and that indeed, something unusual happened at this point during the time at which the observations were taken. If so, we could exclude this value. The new residual plot is shown in Fig. 17.11.

All standardized residuals now lie within the expected range for normally distributed errors. The plot gives us quite a lot of information about our sample of bales and possibly about the shipment of bales from which they were drawn. First, the average clean content of bale 1 is around 53, considerably

Figure 17.9: SAS software sample size calculations for the ice cream experimentbelow the others. This was the bale that had the supposed outlier. One might suspect that this bale either did not come from the same shipment or was contaminated at some point before being measured. On the other hand, the shipment may contain a number of "rogue bales," and this ought to be investigated. At the other end of the range, we see that bale 7 had the highest clean content and was least variable. Perhaps this is not too surprising, since a bale with 100% clean content would probably show no variability in the measurements taken on it. Thus, one might suspect that our model that includes normally distributed errors is not ideal for this situation. However, the plot of standardized residuals against normal scores does not show any anomalies (figure not shown).

In a one-way random-effects model, we can check the assumption that the treatment effects have a normal distribution by making a normal probability plot of the standardized treatment averages \(\overline{Y}_{i}\). against their normal scores. (This cannot be done for models with more than one random effect, since the treatment averages are not independent.) For the clean wool experiment, the normal probability plot is obtained by means of the statements in Table 17.15, and the resulting plot is shown in Fig. 17.12. If the normality assumption for the population of bales is satisfied, the standardized bale averages should roughly lie along a line (with slope 1.0) through (0, 0). In Fig. 17.12, we see that this is roughly the case.

In summary, the random-effects one-way model with the standard distribution assumptions does not fit these data too well, since variances apparently are not constant or there is an outlier. Nevertheless, we have established that the population of bales in this shipment is extremely variable. Selected bales 1 and 7 appear to be somewhat different from the other five selected bales. Perhaps the shipment is

Figure 17.11: Residuals versus predicted values for the clean wool experiment, excluding the outlier

Figure 17.10: Residuals versus predicted values for the clean wool experiment

made up of dissimilar subpopulations (perhaps from different sources). This should be checked, since it may give a clue as to how to improve the wool clean content in the future.

#### Estimation and Hypothesis Testing

##### Analysis of Fixed Effects in Mixed Models

Analysis of variance \(F\)-tests for fixed effects in mixed models are obtained in essentially the same way as for fixed-effects models. The aov function is used to fit the linear model by least squares, but with the following changes: random effects are entered into the model as error terms, and the summary command is used to generate the analysis of variance \(F\) tests for fixed effects.

Sample R code is shown in Table 16 for the temperature experiment of Example 17.9.1, p. 650. \(F\)-tests for fixed effects are generated by the second block of code. In the model specified for the aov function, the term

 Error(fSubj + fSubj:fSite)

calls the Error function in R, modeling subject main effects and subject-site interactions as random effects, and allowing their use as error terms for tests and for estimating standard errors for confidence intervals for means and fixed effect contrasts as appropriate. Each model can include only one Error function call, but the call may include multiple random effects, with two in this example. The expected mean squares are not displayed, but correct \(F\)-tests are generated for fixed effects. In particular, the denominators, calculated as explained throughout this chapter, are automatically obtained by modeling the random effects as error terms as in this sample code. Tests for fixed effects are provided, including the appropriate test statistic denominator used.

\begin{table}
\begin{tabular}{c} AvgContent = by(wood.datasy, wool.data$$bale, mean) \# Col of means (by bale) \\ \# Standardized treatment means \\ StdzdAvg = (AvgContent - mean(AvgContent))/sd(AvgContent - mean(AvgContent)) \\ \# Normal scores \\ nscore = qqnorm(StdzdAvg)$x \\ plot(StdzdAvg – nscore, ylab=“Standardized Trtmt Means”, las=1) \\ qqline(StdzdAvg) \# Line through 1st and 3rd quantile points \\ \end{tabular}
\end{table}
Table 16: R program to plot standardized treatment averages against their normal scores

Figure 16: Normal probability plot of the standardized treatment averages for the clean wool experiment

Corresponding output is shown in Table 17.17. The first block of output code shows information for subjects, though it is not used for any tests. The second block of output displays the \(F\) test for the main effect of site, using the mean square for subject-site interaction as the denominator of the \(F\) statistic. In the third block of output, thermometer main effects and thermometer-site interactions are each tested using the usual mean squared error as the denominator of the corresponding \(F\) statistics.

Treatment means and pairwise comparisons of fixed effects can be estimated using the lmeans function of the lmeans package, as illustrated by the last block of code in Table 17.16. The correct variance estimators are automatically chosen. For example, for confidence limits for site level means, the reader is asked in Exercise 9 to verify that \(\text{Var}(\overline{Y}_{\cdot j})=(3\sigma_{S}^{2}+3\sigma_{SB}^{2}+\sigma^{2 })/12\) for the \(j\)th site under model (17.9.25), p. 650. R computes the corresponding estimate, using Satterthwaite's method to compute the corresponding number of degrees of freedom, and provides corresponding lower and upper 95% confidence limits.

The last two lines of code in Table 17.16 concern the site main-effect contrast, providing information for estimation and testing this pairwise comparison. The corresponding output, displayed last in Table 17.17, correctly uses the subject-site interaction mean square to estimate the standard error for comparing sites. If site had more than two levels, one could apply Tukey's method, for example, by including the option adjust="tukey" in the contrast function as follows.

 summary(contrast(lsmSite, method="pairwise", adjust="tukey"),  infer=c(T,T), level=0.95, side="two-sided") Also, any contrast for the fixed effects can be estimated using the following more generic syntax, and the list could be expanded to included multiple named contrasts separated by commas.

 summary(contrast(lsmSite, list(Pairwise=c(1,-1))),  infer=c(T,T), level=0.95, side="two-sided

In each case, R will automatically compute an appropriate standard error estimate, which for the pairwise site contrast involves the subject-site interaction mean square.

\begin{table}
\begin{tabular}{r} \hline \hline tempr.data = read.table(‘data/temperature.txt’’, header=T) \\ \hline tempr.data = within(tempr.data, { fThermo = factor(Therm); fSite = factor(Site); fSubj = factor(Subj) }) \\  head(tempr.data, 3) \\ \hline \# Least squares anova, specifying random effects as error terms \\  options(contrasts = c(‘contr.sum’’, ‘contr.poly’’)) \\  model1 = aov(Time ~~ fThermo + fSite + fTherm:fSite \\  + Error(fSubj + fSubj:fSite), data=tempr.data) \\  summary(model1) \\ \hline \# Means and contrasts: estimates, CIs, tests \\  library(lsmeans) \\  lsmSite = lsmeans(model1, ~~ fSite) \# Compute and save lsmeans \\  confint(lsmSite, level=0.95) \# Display lsmeans and 95\% CIs \\  \# Pairwise comparison \\  summary(contrast(lsmSite, method="pairwise"), \\  infer=c(T,T), level=0.95, side="two-sided") \\ \hline \hline \end{tabular}
\end{table}
Table 17.16: R program for the temperature experiment 

#### Analysis of Random Effects

Tests for random effects are not provided by the code discussed above for analysis fixed effects in mixed models. Still, the necessary means squares are provided, or they can be obtained by fitting a model treating all effects, including random effects, as fixed. So, based on expected mean squares, one could conduct the appropriate tests of random effects by hand for any balanced mixed- or random-effects model. The following section mentions another approach.

\begin{table}
\begin{tabular}{r} \hline \hline \(>\) model1 = aov(Time \textasciitilde{}fTherm + fSite + fTherm:fSite \\ + + Error(fSubj + fSubj:fSite), data=tempr.data) \\ \(>\) summary(model1) \\ \end{tabular}
\end{table}
Table 17.17: R analysis of fixed effects for the temperature experiment

#### Other Approaches

Throughout this chapter we have discussed the analysis of mixed and random effects models using the _analysis of variance approach_--namely, fitting the model by least squares as if all effects were fixed, obtaining a corresponding analysis of variance table, then using the expected mean squares to obtain unbiased estimates of the variance components and to determine appropriate \(F\)-statistic denominators and standard error estimates. The variance component estimates so obtained are called _analysis of variance estimates_. For balanced data under normality, the least squares estimates of any estimable fixed effects are best linear unbiased estimates, and the analysis of variance estimates of variance components are minimum variance unbiased estimates, but the variance component estimates can be negative, as happens in the recently discussed temperature experiment, where the subjects variance component estimate is \(\hat{\sigma}_{S}^{2}=[\text{ms}(\text{fSubj})-\text{ms}(\text{fSubj}\text{:fSite} )]/6\approx-106.83\).

There are other more sophisticated statistical methods for estimating variance components that prevent the estimates from ever being negative, and that are generally preferable for unbalanced data. One such approach involves estimation of the variance components by _restricted maximum likelihood_ (ReML). This approach will be discussed in Chap. 18.

#### Sample Size Calculations

In this section, an R function is defined to do the sample size calculations of Example 17.4.1, p. 630, for the ice cream experiment. Recall, in testing the hypothesis \(H_{0}^{\gamma T}:\sigma_{T}^{2}\leq\sigma^{2}\) against the hypothesis \(H_{A}^{\gamma T}:\sigma_{T}^{2}>\sigma^{2}\) at a significance level of \(\alpha=0.05\), the goal is to be able to reject the null hypothesis with probability \(\pi=0.95\) if the true value of \(\sigma_{T}^{2}/\sigma^{2}\) is at least \(\Delta=2.0\). In Example 17.4.1, trial and error was used to determine the number \(v\) of ice cream flavors we should look at if we took \(r=11\) or \(r=3\) observations on each. Recall, to achieve the desired power for given \(r\), we need to find \(v\) such that

\[(F_{v-1,v(r-1),\,.05})(F_{v(r-1),\,v-1,\,.05})\leq(2r+1)/(r+1)\,.\]

Table 17.18 contains the R program and corresponding output. A user-defined function, compute.v.given.r, is defined to do the computations. This function inputs an \(r\) value and the specified significance level and power. Given this information, the new function uses the standard R function qf to compute the quantile values \(F_{v-1,\,v(r-1),\,.05}\) and \(F_{v(r-1),\,v-1,\,.05}\) for each value \(v=2,\,3,\ldots\), either stopping when the above inequality is satisfied, giving the required value of \(v\) and the result "Power = 0.95" (for power = 0.95, say), or reaching \(v=200\) and giving the result "Power \(<0.95\)". Once done, the function returns all pertinent information. After the new function compute.v.given.r has been defined in Table 17.18, it is called first for \(r=11\) and then for \(r=3\), each time using significance level 0.05 and power 0.95. The results returned by the function calls, displayed in the bottom of Table 17.18, are a bit more precise than those given in Example 17.4.1.

[MISSING_PAGE_EMPTY:8617]

4. Test the hypothesis that the variance of the alcohol concentrations is at most five times the error variance versus the alternative hypothesis that it is not. Use a significance level of \(\alpha=0.05\).
2. **Ice cream experiment, continued** As in Example 17.4.1, p. 630, suppose the ice cream experiment is to be repeated, with \(\gamma=1.0\) and with a Type I error probability of \(\alpha=.05\). Suppose that we would like to reject the null hypothesis \(H_{0}^{-7T}:\{\sigma_{T}^{2}\leq\sigma^{2}\}\) with probability \(\pi=0.95\) if the true value of \(\sigma_{T}^{2}/\sigma^{2}\) is greater than \(\Delta=2.0\). How many ice cream flavors should be included in the experiment if \(r=2\) observations are to be taken on each? How many observations are needed? Is this an improvement over the result in the example for \(r=3\)? (Note: \(F_{150,150,.05}=1.309,F_{160,160,.05}=1.298,F_{170,170,.05}=1.288,F_{180,180,.05 }=1.279\)).
3. **Random effects model** Consider the following random-effects model: \[\begin{array}{c}Y_{ijkmt}=\mu+A_{i}+B_{j}+C_{k}+D_{m}\\ \qquad\qquad+(\text{AB})_{ij}+(\text{BC})_{jk}+(\text{BD})_{jm}+\epsilon_{ ijkmt}\,,\\ i=1,\ldots,a,\;\;j=1,\ldots,b,\;\;k=1,\ldots,c,\\ m=1,\ldots,d,\;\;t=1,\ldots,r,\\ A_{i}\sim N(0,\sigma_{A}^{2}),\;\;B_{j}\sim N(0,\sigma_{B}^{2}),\;\;C_{k}\sim N (0,\sigma_{C}^{2})\,,\\ D_{m}\sim N(0,\sigma_{D}^{2}),\;\;(\text{AB})_{ij}\sim N(0,\sigma_{AB}^{2}),\; \;(\text{BC})_{jk}\sim N(0,\sigma_{BC}^{2})\,,\\ (BD)_{jm}\sim N(0,\sigma_{BD}^{2}),\;\;\epsilon_{ijkmt}\sim N(0,\sigma^{2})\,, \end{array}\] where all random variables on the right hand side of the model are mutually independent. 1. Write out the expected mean squares for all main effects and interactions in the model. 2. How would you test the null hypothesis \(H_{0}^{A}:\{\sigma_{A}^{2}=0\}\) against the alternative hypothesis \(H_{A}^{A}:\{\sigma_{A}^{2}>0\}\)? 3. How would you test the null hypothesis \(H_{0}^{B}:\{\sigma_{B}^{2}=0\}\) against the alternative hypothesis \(H_{A}^{B}:\{\sigma_{B}^{2}>0\}\)? 4. Give formulae for unbiased estimates of \(\sigma_{BD}^{2}\) and \(\sigma_{B}^{2}\). 5. Give formulae for individual 95% confidence intervals for \(\sigma_{BD}^{2}\) and \(\sigma_{B}^{2}\). What is the overall confidence level?
4. **Buttermilk biscuit experiment** The buttermilk biscuit experiment was run by Stacie Taylor in 1995 to find out which brands of refrigerated buttermilk biscuit give rise to the fluffiest biscuits. Three brands were examined (factor \(A\), 3 levels, fixed effect), all of which had claims to be light, fluffy, or flaky in their advertising campaigns. The biscuits were baked on a baking tray for 7 min in the center of an oven set to 425\({}^{\circ}\)F. Since only six biscuits could be baked at a time, the experiment was run as a general complete block design with blocks of size \(k=6\). 1. Use a mixed model with interaction to represent the data, where the random effect represents the block (run of the oven) and the fixed effect represents the biscuit brand. Write out the model including all of the assumptions.

* The data collected by the experimenter are shown in Table 17.20. As far as possible, check the assumptions on the model for these data.
* Write out the expected mean squares for all terms in the model.
* Draw a block\(\times\)brand interaction plot for those blocks observed in the experiment.
* Test the hypothesis that the variance in height of the biscuits due the population of block\(\times\)brand interactions is negligible against the alternative hypothesis that it is not negligible. Interpret your conclusions in terms of the plot in part (d).
* Calculate a set of 95% simultaneous confidence intervals for the pairwise comparisons between the brands. State your conclusions.
* **Candle experiment** An experiment to determine whether different colored candles (red, white, blue, yellow) burn at different speeds was conducted by Hsing-Chuan Tsai, Mei-Chiao Yang, Derek Wheeler, and Tom Schultz in 1989. Each experimenter collected four observations on each color in a random order, and "experimenter" was used as a blocking factor. Thus, the design was a general complete block design with \(v=4\), \(k=16\), \(b=4\), and \(s=4\). The resulting burning times (in seconds) are shown in Table 17.21. A pilot experiment indicated that treatments and blocks do interact. The candles used in the experiment were cake candles made by a single manufacturer. Analyze the experiment as though the experimenters represent a random sample from a large population of people who might use these candles in practice. Use a two-way mixed model with interaction.

\begin{table}
\begin{tabular}{c c c c c c c c} \hline \hline \multirow{2}{*}{Block} & \multicolumn{6}{c}{Position} \\ \cline{2-9}  & 1 & 2 & 3 & 4 & 5 & 6 \\ \hline
1 & 2 (150.0) & 1 (188.2) & 2 (177.8) & 3 (166.7) & 3 (187.5) & 1 (182.4) \\
2 & 1 (183.3) & 2 (183.3) & 2 (183.3) & 3 (176.5) & 1 (160.0) & 3 (187.5) \\
3 & 1 (178.9) & 3 (182.4) & 2 (193.8) & 3 (176.5) & 2 (188.9) & 1 (188.9) \\
4 & 2 (177.8) & 1 (145.5) & 3 (155.0) & 1 (173.7) & 3 (200.0) & 2 (187.5) \\
5 & 1 (205.6) & 3 (188.2) & 3 (142.9) & 2 (161.9) & 2 (177.8) & 1 (159.1) \\ \hline \end{tabular}
\end{table}
Table 17.20: Treatments and percentage change in height for the buttermilk biscuit experiment

\begin{table}
\begin{tabular}{c c c c c c c c} \hline \hline \multirow{2}{*}{Person} & \multicolumn{6}{c}{Color} \\ \cline{2-9}  & Red & White & Blue & Yellow \\ \hline
1 & 989 & 1032 & 1044 & 979 & 1011 & 951 & 974 & 998 \\  & 1077 & 1019 & 987 & 1031 & 928 & 1022 & 1033 & 1041 \\
2 & 899 & 912 & 847 & 880 & 899 & 800 & 886 & 859 \\  & 911 & 943 & 879 & 830 & 820 & 812 & 901 & 907 \\
3 & 898 & 840 & 840 & 952 & 909 & 790 & 950 & 992 \\  & 955 & 1005 & 961 & 915 & 871 & 905 & 920 & 890 \\
4 & 993 & 957 & 987 & 960 & 864 & 925 & 949 & 973 \\  & 1005 & 982 & 920 & 1001 & 824 & 790 & 978 & 938 \\ \hline \end{tabular}
\end{table}
Table 17.21: Data for the candle experiment (seconds)6. **Golf ball experiment** An experiment was planned by Tim Kelaghan in 1995 to examine whether different brands of golf balls travel on average the same distances when hit by amateur golfers. The experiment was planned with a specific selection of \(v=3\) golf balls and some number \(b\) of golfers to be determined. The experiment was to be run as a general complete block design with fixed treatment effects and random golfer effects. Since the golfer is aware of which brand of ball he or she is hitting, there may well be a golfer\(\times\)brand interaction. However, the differences between brands averaged over the interaction is important here. A small pilot experiment was conducted. There were only two golfers, and each hit \(s=6\) balls of each brand in a random order. Mis-hits were ignored. The distances that the balls traveled were recorded in yards and are shown in Table 17.22. 1. Use the pilot experiment data to calculate a 95% upper bound for the error variance \(\sigma^{2}\). 2. The experimenter wanted the main experiment to be able to calculate a set of simultaneous 95% confidence intervals for the pairwise differences in the brands, and he wanted the widths of these intervals to be at most 20 yards. Assuming that each golfer would hit about 18 balls in total, as in the pilot experiment, how many randomly selected golfers would be needed?
7. **Mixed model** Consider the following mixed model: \[\begin{array}{l}Y_{ijkmt}=\mu+\alpha_{i}+B_{j}+C_{k}+\delta_{m}+(\alpha B)_{ ij}+(\alpha\delta)_{im}\\ \qquad\qquad\qquad\qquad+(B\delta)_{jm}+(C\delta)_{km}+(\alpha B\delta)_{ijm}+ \epsilon_{ijkmt}\,,\\ i=1,\ldots,a,\;\;j=1,\ldots,b,\;\;k=1,\ldots,c,\\ m=1,\ldots,d,\;\;t=1,\ldots,r,\\ B_{j}\sim N(0,\sigma_{B}^{2}),\;\;C_{k}\sim N(0,\sigma_{C}^{2}),\;\;(\alpha B )_{ij}\sim N(0,\sigma_{AB}^{2}),\\ (B\delta)_{jm}\sim N(0,\sigma_{BD}^{2}),\;\;(C\delta)_{km}\sim N(0,\sigma_{ CD}^{2}),\\ (\alpha B\delta)_{ijm}\sim N(0,\sigma_{ABD}^{2}),\;\;\epsilon_{ijkmt}\sim N(0, \sigma^{2})\,,\end{array}\] \[\begin{array}{l}B_{j}\sim N(0,\sigma_{B}^{2}),\;\;C_{k}\sim N(0, \sigma_{C}^{2}),\;\;(\alpha B)_{ij}\sim N(0,\sigma_{AB}^{2}),\\ (B\delta)_{jm}\sim N(0,\sigma_{BD}^{2}),\;\;(C\delta)_{km}\sim N(0,\sigma_{ CD}^{2}),\\ (\alpha B\delta)_{ijm}\sim N(0,\sigma_{ABD}^{2}),\;\;\epsilon_{ijkmt}\sim N(0, \sigma^{2})\,,\end{array}\] where \(\alpha_{i}\) and \(\delta_{m}\) are fixed effects, all other effects are random effects, and all random variables on the right-hand side of the model are mutually independent.

\begin{table}
\begin{tabular}{c c c c c c c c} \hline \hline Golfer & Brand & \multicolumn{6}{c}{Distance} \\ \cline{3-8}  & & 1 & 2 & 3 & 4 & 5 & 6 \\ \hline
1 & 1 & 209 & 204 & 179 & 230 & 233 & 245 \\  & 2 & 188 & 211 & 242 & 222 & 187 & 233 \\  & 3 & 219 & 204 & 247 & 215 & 197 & 161 \\
2 & 1 & 240 & 207 & 192 & 190 & 226 & 188 \\  & 2 & 216 & 195 & 240 & 215 & 219 & 238 \\  & 3 & 195 & 221 & 205 & 192 & 183 & 230 \\ \hline \hline \end{tabular}
\end{table}
Table 17.22: Distances (in yards) traveled by balls in the golf experiment 1. Write out the expected mean squares for all main effects and interactions in the model.
2. How would you test the hypothesis \(H_{0}:\{\delta_{m}+(\overline{\alpha\delta})_{.m}\) all equal } against the alternative hypothesis that these parameters are not all equal?
3. Give a formula for an unbiased estimate of \(\sigma_{B}^{2}\).
4. Give a formula for a 95% confidence interval for \(\sigma_{B}^{2}\).

## 8 Ice cream experiment, continued

The ice cream experiment was described in Example 17.3.1, p. 621, and was analyzed in Examples 17.3.2-17.3.4 and 17.4.1. In Sect. 17.10, p. 657, a new model was suggested that involved a quadratic time trend.

1. What could account for a quadratic time trend?
2. Investigate the assumptions on the models with and without the quadratic time trend.
3. Redo the analyses of Examples 17.3.3 and 17.3.4 for the new model and compare your answers with the original model.
4. Which model do you prefer and why?

## 9 Temperature experiment, continued

The temperature experiment was described and analyzed in Example 17.9.1, with corresponding SAS and R software analysis provided in Sects. 17.10.2 and 17.11.2, respectively. The experiment was to compare the times required for three different digital thermometers (factor \(A\) at three levels) to register body temperature at two different sites--in the mouth and under the arm--(factor \(B\) at two levels). A randomized complete block design was used, with each of the six treatment combinations observed once on each of four subjects (factor \(S\) at four levels). Using the mixed model (17.9.25), p. 650, consider estimation of the treatment mean \(\bar{\mu}_{.j}=\mu+\bar{\alpha}_{.}+\beta_{j}+(\overline{\alpha\beta})_{.j}\) for the \(j\)th site.

1. Verify that \(\text{Var}(\overline{Y}_{.j})=(3\sigma_{S}^{2}+3\sigma_{SB}^{2}+\sigma^{2})/12\).
2. Provide an unbiased estimate of \(\text{Var}(\overline{Y}_{.j})\).
3. Compute the number of degrees of freedom associated with the estimate in part (b).
4. Given that \(\overline{y}_{.1}=96.00\), construct a 95% confidence interval for \(\bar{\mu}_{.1}\).

### 18.1 Introduction

A factor is said to be _nested_ within a second factor if each of its levels is observed in conjunction with just one level of the second factor. An example can be obtained from the clean wool experiment that was discussed in the last chapter. There, the objective of the experiment was to examine the variability of the "clean content" among bales of wool in a large shipment. Several bales were selected for examination, and several cores were taken from each bale and measured. Each core was taken from only one bale, so the cores (levels of the first factor) are observed in conjunction with only one bale (level of the second factor). In the above language, the cores are _nested within the bales_. In the original experiment, there was only one observation taken on each core. The variability of the different cores could not, therefore, be distinguished from measurement error, and their effects were not included explicitly in the model. Had there been more than one observation per core, we could have included in the model separate effects due to bales, cores nested within bales, and experimental error.

In this chapter we discuss how to recognize nested factors, how to formulate the associated models, and how to analyze the effects in these models. Many of the analysis techniques are similar to those in the previous chapter.

In the next section we discuss some examples of hypothetical experiments involving nested effects, and possible models to represent the data. In Sect. 18.3, we find the estimable contrasts for fixed-effects nested models and develop tests of hypotheses and confidence intervals for these. The more usual setting where the nested effects are random effects is discussed in Sect. 18.4 and, where possible, we borrow the formulae from the fixed effects setting as we did in Chap. 17. The rules of Chaps. 7 and 17 for finding degrees of freedom, sums of squares and expected mean squares and variance components are then extended to encompass nested models. The analysis of nested models using the SAS and R computer packages is discussed in Sects. 18.5 and 18.6, respectively.

### 18.2 Examples and Models

Nested factors are usually, but not always, random effects, and they are usually, but not always, blocking factors. In the following examples, we give a selection of different situations involving random effects and suggest some reasonable models to represent the data.

#### 18.2.1 Machine head experiment

Hicks (1956) describes a simple experiment to study the differences in the strain readings (the response) of four different heads on each of five different machines. The heads on each machine were supposedly all doing the same job and should have given rise to similar (nonvariable) readings.

Since each head was observed on only one machine, the heads were "nested within machines," giving twenty heads in total. Four observations were taken on each head. The usual two-way analysis of variance model is not appropriate here, since it would read

\[Y_{ijt} = \mu + \alpha_{i} + \beta_{j} + (\alpha\beta)_{ij} + \epsilon_{ijt}\,,\] \[\epsilon_{ijt} \sim N(0,\sigma^{2})\,,\] \[\epsilon_{ijt}'\text{s are mutually independent},\] \[t = 1,\ldots,4;\quad i = 1,\ldots,5;\quad j = 1,\ldots,4,\]

where, \(\alpha_{i}\) is the effect of the \(i\)th machine, \(\beta_{j}\) is the effect of the \(j\)th head, and (\(\alpha\beta)_{ij}\) is the extra effect of observing the \(i\)th machine and \(j\)th head together. This suggests that every head is observed on every machine, which was not the case. Instead, we need a notation that will clearly indicate the nested nature of the factors. One popular notation, which we shall adopt here, is to replace \(\beta_{j}\) + (\(\alpha\beta)_{ij}\) by \(\beta_{j(i)}\), where the parentheses indicate that we are looking at the head that happens to be numbered as the \(j\)_th head on the \(i\)th machine_. The _two-way nested model_ is then

\[Y_{ijt} = \mu + \alpha_{i} + \beta_{j(i)} + \epsilon_{ijt}\,, \tag{18.2.1}\] \[\epsilon_{ijt} \sim N(0,\sigma^{2})\,,\] \[\epsilon_{ijt}'\text{s are mutually independent},\] \[t = 1,\ldots,4;\quad i = 1,\ldots,5;\quad j = 1,\ldots,4.\]

We note in passing that the response \(Y_{ijt}\) could also be written as a nested effect \(Y_{t(ij)}\), since this represents the \(t\)th observation that is specific to the (\(ij\))th machine head. However, since this representation is not crucial to the analysis, we will continue to use the notation \(Y_{ijt}\) that we have used so far throughout the book.

One final consideration is whether the machine effects and head effects should be fixed or random. Let us first suppose that the five machines are the only machines of this type in the factory and that they are not due for replacement. The experimenter would then be interested in these five machines specifically, and their effects on the response would be modeled as fixed effects. Let us alternatively suppose that machine heads wear out and are continually being replaced. The experimenter would then be interested in the population of heads from which the particular twenty in the experiment were drawn. Consequently, the nested head effect would be modeled as a random effect. The model would be written as

\[Y_{ijt} = \mu + \alpha_{i} + B_{j(i)} + \epsilon_{ijt}\,, \tag{18.2.2}\] \[\epsilon_{ijt} \sim N(0,\sigma^{2})\,,\quad B_{j(i)} \sim N(0,\sigma^{2}_{B(A)})\,,\] \[\epsilon_{ijt}'\text{s and }B_{j(i)}'\text{s are all mutually independent},\] \[t = 1,\ldots,4;\quad i = 1,\ldots,5;\quad j = 1,\ldots,4,\]where \(\alpha_{i}\) is the effect of the \(i\)th machine, and \(\sigma^{2}_{B(A)}\) is the variance of responses from the population of machine heads that could be fitted on these five machines. Notice that all random variables on the right-hand side of the model are assumed to be mutually independent. 

In the previous example there were two treatment factors, one of whose levels were nested within those of the other. In the following experiment, there are two blocking factors, which are nested one within the other.

#### Efficiency experiment

An experiment was run in 1997 by Carina Dalton, Greg Krzys, Scott O'Dee, and Brad Welch to examine the assertion that "a person works more efficiently when there is no one looking over his or her shoulder." Twelve subjects were recruited for the experiment, and three of these were assigned to each of the four experimenters. Each subject was asked to complete a simple task--crossing through every occurrence of the letter "e" on a page of prose. There were two levels of the treatment factor. Level 1 required the assigned experimenter to look over the subject's shoulder while the task was being completed, and level 2 required the experimenter to be elsewhere in the room absorbed in a book. The response was the time taken to complete the task. Each subject was assigned both treatments, but in a randomized order.

The blocking factor in this experiment was subject. However, the subjects each worked with only one experimenter, and so the subject effects were nested within the experimenter effects.

The subjects were graduate students at The Ohio State University. Although they were not selected according to the rules of a simple random sample, let us suppose that they were a reasonable representation of that population. Let us also suppose that the variation among the techniques of the experimenters, who were also graduate students, was representative of a population of student experimenters. It might also be reasonable to assume that some subjects may be more perturbed than others about an experimenter watching them complete the task. In this case, we might wish to include a subject-treatment interaction in the model. However, there is only one observation per subject per treatment, so the subject-treatment interaction could not be distinguished from the random error.

A second possible model would be to include an experimenter-treatment interaction instead of a subject-treatment interaction. Such an interaction might occur if the actions of the four experimenters were not all identical. In this case the model would be

\[Y_{hqi} = \mu + E_{h} + S_{q(h)} + \alpha_{i} + (\alpha E)_{hi} + \epsilon_{hqi}\;,\] \[\epsilon_{hqi} \sim N(0,\sigma^{2})\;,\;\;\;S_{q(h)} \sim N(0,\sigma^{2}_{S(E)})\;,\;\;\;(\alpha E)_{hi} \sim N(0,\sigma^{2}_{EA})\;,\] \[\epsilon_{hqi}\text{'s},\,E_{h}\text{'s},\,S_{q(h)}\text{'s}\, \text{and}\,(\alpha E)_{hi}\text{'s}\,\text{are all mutually independent,}\] \[h = 1,\ldots,4;\;\;\;i = 1,\,2,\,3;\;\;\;i = 1,\,2.\]

where \(E_{h}\) is the effect of the \(h\)th randomly selected experimenter, \(S_{q(h)}\) is the effect of the \(q\)th randomly selected subject assigned to the \(h\)th experimenter, \(\alpha_{i}\) is the effect of the \(i\)th treatment, and \((\alpha E)_{hi}\) is the random effect representing the interaction between the \(h\)th experimenter and the \(i\)th treatment.

Lastly, we may also wish to include a time-order effect in the model, since the subjects may have been able to complete the task faster on the second occasion just due to familiarity. So we could add the extra term \(\gamma x_{hqi}\), where \(x_{hqi}\) is 1 or 2 according to whether the \((hq)\)th subject is assigned treatment \(i\) on the first or second occasion.

### Analysis of Nested Fixed Effects

#### Least Squares Estimates

Consider first the simplest possible fixed-effects nested model--the two-way nested model (18.2.1) that was suggested for the machine head experiment of Example 18.2.1; that is,

\[Y_{ijt}=\mu+\alpha_{i}+\beta_{j(i)}+\epsilon_{ijt}\,,\] \[\epsilon_{ijt}\sim N(0,\sigma^{2})\,,\] \[\epsilon_{ijt}\,\text{'s are mutually independent,}\] \[t=1,\ldots,r_{ij};\quad i=1,\ldots,a;\quad j=1,\ldots,b.\]

The error assumptions are examined in the same way as in Chap. 5 for the one-way analysis of variance model. In any model, the estimable contrasts are functions of the expected values of the response variables (see, for example, Sect. 3.4.1, p. 34). In the present model, \(E[Y_{ijt}]\) is equal to

\[E[Y_{ijt}]=\mu+\alpha_{i}+\beta_{j(i)}\,.\]

If we take an average over the subscripts \(t\) and \(j\), we find that a comparison of the levels of \(A\) averaged over the levels of \(B\) is estimable; that is, we can estimate pairwise comparisons such as

\[\left[\alpha_{i}+\overline{\beta}_{.(i)}\right]\ -\ \left[\alpha_{s}+ \overline{\beta}_{.(s)}\right]\,,\]

and we can estimate general contrasts such as

\[\sum_{i=1}^{a}c_{i}\left[\alpha_{i}+\overline{\beta}_{.(i)}\right]\,,\quad \text{with}\ \sum_{i=1}^{a}c_{i}=0\,.\]

We can also compare the effects of those levels of \(B\) that were observed in conjunction with the _same_ level of \(A\); that is,

\[\left[\alpha_{i}+\beta_{j(i)}\right]\ -\ \left[\alpha_{i}+\beta_{u(i)}\right] = \ \beta_{j(i)}\ -\ \beta_{u(i)}\,,\]

or, in general,

\[\sum_{j=1}^{b}d_{j}\beta_{j(i)}\,,\quad\text{with}\ \sum_{j=1}^{b}d_{j}=0\,, \quad\text{for any given}\ i\,.\]

To obtain the least squares estimators of estimable contrasts, we use the method of least squares to find parameter estimates that minimize the sum of squared errors

\[\sum_{i=1}^{a}\sum_{j=1}^{b}\sum_{t=1}^{r_{ij}}e_{ijt}^{2}=\sum_{i=1}^{a}\sum_ {j=1}^{b}\sum_{t=1}^{r_{ij}}\left(y_{ijt}-\mu-\alpha_{i}-\beta_{j(i)}\right)^ {2}\,.\]

Readers with a knowledge of calculus may verify (see Exercise 7) that the least squares estimate of \(\mu+\alpha_{i}+\beta_{j(i)}\) is \(\overline{y}_{ij}\). Consequently, the least squares estimator of\[\sum_{i=1}^{a}c_{i}\left[\alpha_{i}+\overline{\beta}_{.(i)}\right]\ \ \ \text{is}\ \ \sum_{i=1}^{a}c_{i}\overline{Y}_{i..}\]

with \(\Sigma c_{i}=0\). The corresponding variance is \(\Sigma c_{i}^{2}\sigma^{2}/r_{i..}\). Similarly, the least squares estimator of

\[\sum_{j=1}^{b}d_{j}\beta_{j(i)}\ \ \ \text{is}\ \ \sum_{j=1}^{b}d_{j}\overline{Y}_{ij.}\ \ \ \text{for any}\ i\]

with \(\Sigma d_{j}=0\). The corresponding variance is \(\Sigma d_{j}^{2}\sigma^{2}/r_{ij}\).

All of these formulae can easily be adapted to the case where \(B\) has a different number of levels for each level of \(A\) by replacing \(b\) by \(b_{i}\).

#### Estimation of \(\sigma^{2}\)

The error sum of squares is

\[\text{ssE} = \sum_{i=1}^{a}\sum_{j=1}^{b}\sum_{i=1}^{r_{ij}}\left(y_{ijt}- \hat{\mu}-\hat{\alpha}_{i}-\hat{\beta}_{j(i)}\right)^{2} \tag{18.3.3}\] \[= \sum_{i=1}^{a}\sum_{j=1}^{b}\sum_{i=1}^{r_{ij}}y_{ijt}^{2}-\sum_{ i=1}^{a}\sum_{j=1}^{b}r_{ij}\overline{y}_{ij.}^{2}. \tag{18.3.4}\]

A comparison with the formulae in Sect. 6.4 shows that everything that we have written so far about the fixed-effects two-way nested model could have been deduced from the fixed-effects two-way complete model after replacing \(\beta_{j}+(\alpha\beta)_{ij}\) by \(\beta_{j(i)}\). Therefore, we may also deduce that the error mean square, \(\text{msE}=\text{ssE}/(n-v)\), gives an unbiased estimate for \(\sigma^{2}\), and the corresponding random variable MSE has a chi-squared distribution with \(n-v\) degrees of freedom (where \(n=r_{..}\) and \(v=ab\)).

#### Confidence Intervals

We may obtain a 100(\(1-\alpha\))% confidence bound for \(\sigma^{2}\) from the information in the previous subsection; that is,

\[\sigma^{2}\ \ \leq\ \ \frac{\text{ssE}}{\chi_{n-v,1-\alpha}^{2}}\.\]

The derivation of the bound was explained in Sect. 3.4.6.

Confidence intervals for \(\Sigma c_{i}(\alpha_{i}+\overline{\beta}_{.(i)})\) and for \(\Sigma d_{j}\beta_{j(i)}\) may be obtained using the relevant methods from Chap. 4 together with the formulae \[\Sigma c_{i}\overline{Y}_{i..}\ \ \pm\ w\ \sqrt{\sum_{i}\left(\frac{c_{i}^{2}}{r_{i}}\right)\,{\rm msE}}\]

and

\[\Sigma d_{j}\overline{Y}_{ij..}\ \ \pm\ w\ \sqrt{\sum_{j}\left(\frac{d_{j}^{2}}{r_{ij}}\right)\,{\rm msE}}\,.\]

#### Hypothesis Testing

We may obtain a test of the null hypothesis that the levels of \(B\) have the same effect on the response within every given level of \(A\), that is,

\[H_{0}^{B(A)}:\{\beta_{1(i)}=\beta_{2(i)}=\ldots=\beta_{b(i)},\ {\rm for\ every}\ i=1,\ldots,a\}\,,\]

against the alternative hypothesis \(H_{A}^{B(A)}:\{H_{0}^{B(A)}\ \ {\rm is\ not\ true}\}\) by comparing the sum of squares for error (18.3.3) in the fixed-effects two-way nested model with the sum of squares for error in the reduced (one-way) model. The reduced model is

\[Y_{ijt}=\mu^{*}+\alpha_{i}+\epsilon_{ijt}\,,\]

and the error sum of squares is given by (3.4.4), p. 39, with an extra subscript; that is,

\[{\rm ssE}_{0}=\sum_{i=1}^{a}\sum_{j=1}^{b}\sum_{t=1}^{r_{ij}}(y_{ijt}- \overline{y}_{i..})^{2}\,.\]

The numerator of the test statistic is then

\[{\rm msB}(A)=\frac{{\rm ssB}(A)}{a(b-1)}\,,\]

where the number of degrees of freedom for \(B(A)\) is obtained as the difference between the error degrees of freedom in the reduced and full models; that is,

\[(n-a)-(n-v)\ =\ v-a\ =\ ab-a\ =\ a(b-1)\,,\]

and where

\[{\rm ssB}(A) = {\rm ssE}_{0}-{\rm ssE} \tag{18.3.5}\] \[= \sum_{i}\sum_{j}\sum_{t}(y_{ijt}-\overline{y}_{i..})^{2}-\sum_{i }\sum_{j}\sum_{t}(y_{ijt}-\overline{y}_{ij..})^{2}\] \[= \sum_{i}\sum_{j}\sum_{t}y_{ijt}^{2}-\sum_{i}r_{i..}\overline{y}_ {i..}^{2}-\sum_{i}\sum_{j}\sum_{t}y_{ijt}^{2}+\sum_{i}\sum_{j}r_{ij}\overline {y}_{ij.}^{2}\] \[= \sum_{i}\sum_{j}r_{ij}\overline{y}_{ij..}^{2}-\sum_{i}r_{i..} \overline{y}_{i..}^{2}\]\[=\sum_{i}\sum_{j}r_{ij}(\overline{y}_{ij.}-\overline{y}_{i..})^{2}\,. \tag{18.3.6}\]

The decision rule for testing \(H_{0}^{B(A)}\) versus \(H_{A}^{B(A)}\) at significance level \(\alpha\) is

\[\text{reject }H_{0}^{B(A)}\quad\text{if}\quad\frac{\text{ss}B(A)/a(b-1)}{\text{ ss}E/(n-ab)}\ >\ F_{a(b-1),n-ab,\alpha}\,.\]

Similarly, the decision rule for testing

\[H_{0}^{A}:\{\alpha_{i}+\overline{\beta}_{.(i)}\ \ \text{all equal}\}\]

against the alternative hypothesis \(H_{A}^{A}:\{H_{0}^{A}\text{ is false}\}\) is

\[\text{reject }H_{0}^{A}\ \text{if}\ \ \frac{\text{ss}A/(a-1)}{\text{ss}E/(n-ab)} \ >\ F_{a-1,n-ab,\alpha}\,,\]

where

\[\text{ss}A=\sum_{i}r_{i.}(\overline{y}_{i..}-\overline{y}_{...})^{2}=\sum_{i} r_{i.}\overline{y}_{i..}^{2}-n\overline{y}_{...}^{2}\,.\]

Notice that ssB(A) in the two-way nested model is equal to ssB + ssAB in the two-way complete model. Also, the degrees of freedom for \(B\)(A) in the nested model can be obtained as the sum of the degrees of freedom for \(B\) and \(AB\) in the complete model; that is,

\[(b-1)+(b-1)(a-1)\ =\ a(b-1)\,.\]

This link between the nested model and the corresponding complete model means that when the sample sizes are equal, we can obtain all the formulae we need from the rules in Chap. 7. This remains true for more complicated models also. For example, if we take the nested model

\[Y_{ijkt}=\mu+\alpha_{i}+\beta_{j(i)}+\gamma_{k(ij)}+\epsilon_{ijkt}\,,\]

we have the following equivalences with the terms of the three-way complete model:

\[\beta_{j(i)} =\beta_{j}+(\alpha\beta)_{ij}\,,\] \[\gamma_{k(ij)} =\gamma_{k}+(\alpha\gamma)_{ik}+(\beta\gamma)_{jk}+(\alpha\beta \gamma)_{ijk}\,;\]

so, for example, the sum of squares for \(C\)(AB) is

\[\text{ssC(AB)} =\text{ssC}+\text{ssAC}+\text{ssBC}+\text{ssABC}\] \[=\sum_{i}\sum_{j}\sum_{k}r_{ijk}\overline{y}_{ijk.}^{2}-\sum_{i} \sum_{j}r_{ij.}\overline{y}_{ij..}^{2}\] \[=\sum_{i}\sum_{j}\sum_{k}r_{ijk}(\overline{y}_{ijk.}-\overline{y }_{ij..})^{2}\,,\]

with degrees of freedom \[(c-1)\ +\ (a-1)(c-1)\ +\ (b-1)(c-1)\ +\ (a-1)(b-1)(c-1)\ =\ ab(c-1)\.\]

As with the crossed model, the degrees of freedom for _C(AB)_ give a clue to the subscripts needed in the formula for the sum of squares for _C(AB)_; that is, the degrees of freedom \(ab(c-1)=abc-ab\) suggest that the sum of squares for _C(AB)_ must contain the terms \(\overline{y}_{ijk}\). and \(\overline{y}_{ij\ldots}\), the latter with a minus sign.

To obtain the degrees of freedom corresponding to any effect, we notice that the degrees of freedom for \(A\) are the same as in the crossed model; that is, \((a-1)\). The degrees of freedom for _B(A)_ are \((b-1)+(a-1)(b-1)=a(b-1)\), and those for _C(AB)_ are \(ab(c-1)\). Thus we see a pattern. The number of degrees of freedom is the product of the numbers of levels corresponding to the factors in parentheses and one less than the numbers of levels corresponding to the factors not in parentheses. We may now modify rules 1 and 2 in Sect. 7.3 for equal sample sizes listed below. We also include rules 3 and 4 here for easy reference, although these remain the same.

1. Write down the name of the main effect or interaction of interest and the corresponding number of levels and subscripts. Include parentheses to denote nesting of factors.
2. The number of degrees of freedom \(\nu\) for any effect is the product of the numbers of levels corresponding to the factors in parentheses and one less than the numbers of levels corresponding to the factors not in parentheses.
3. Multiply out the number of degrees of freedom and replace each letter with the corresponding subscripts.
4. The sum of squares for testing the hypothesis that a main effect or an interaction is negligible is obtained as follows. Use each group of subscripts in rule 3 as the subscripts of a term \(\overline{y}\), averaging over all subscripts not present and keeping the same signs. Put the resulting estimate in parentheses, square it and sum over all possible subscripts. To expand the parentheses, square each term in the parentheses, keep the same signs, and sum over all possible subscripts.

The other rules remain the same. In particular, confidence intervals for \(\sum_{i=1}^{a}c_{i}\left(\alpha_{i}+\overline{\beta}_{\langle i\rangle}\right)\) and for \(\sum_{j=1}^{b}d_{j}\beta_{j\langle i\rangle}\) may be calculated using the usual multiple-comparison techniques of Chap. 4.

#### 7.3.1 Plastic experiment

Consider the following hypothetical experiment in which a manufacturer of molded plastic wishes to replace a standard ingredient by a cheaper alternative. The two ingredients form the two levels of the treatment factor to be studied. The manufacturing company has factories in three different parts of the country, and since different climates may affect the product differently, the experiment is to take place in each of the three locations. Within each factory, two operators oversee two machines each. The experiment will be run during the usual downtime of the machines.

A possible model for the experiment is

\[Y_{ijkut}=\mu+\alpha_{i}+\beta_{j\langle i\rangle}+\gamma_{k\langle ij\rangle }+\tau_{u}+(\tau\gamma)_{uk\langle ij\rangle}+\epsilon_{ijkut}\,\] \[\epsilon_{ijkut}\sim N(0,\sigma^{2})\,\] \[\epsilon_{ijkut}\ \text{'s are mutually independent,}\] \[t=1,\ldots,r;\quad i=1,2,3;\quad j=1,2;\quad k=1,2;\quad u=1,2;\]

where \(\alpha_{i}\) is the effect of the \(i\)th location, \(\beta_{j\langle i\rangle}\) is the effect of the \(j\)th operator at the \(i\)th location, \(\gamma_{k\langle ij\rangle}\) is the effect of the \(k\)th machine that is looked after by the \(j\)th operator at the \(i\)th location, \(\tau_{u}\) is the effect of the \(u\)th treatment, \((\tau\gamma)_{uk\langle ij\rangle}\) is the interaction effect between the \(u\)th treatment and \((ijk)\)th

[MISSING_PAGE_EMPTY:8630]

[MISSING_PAGE_FAIL:696]

\[\text{Var}(\overline{Y}_{i..}) = \text{Var}\left(\mu+\alpha_{i}+\frac{1}{b}\sum_{j=1}^{b}B_{j(i)}+ \frac{1}{br}\sum_{j=1}^{b}\sum_{t=1}^{r}\epsilon_{ijt}\right)\] \[= \frac{\sigma_{B(A)}^{2}}{b}+\frac{\sigma^{2}}{br}\,.\]

Similarly,

\[\text{Var}(\overline{Y}_{...})\;=\;\frac{\sigma_{B(A)}^{2}}{ab}+\frac{\sigma^{ 2}}{abr}\,.\]

Consequently, the expected value of the sum of squares for \(A\) is

\[E[\text{SSA}] = E\left[\,br\sum_{i=1}^{a}\overline{Y}_{i..}^{2}-abr\overline{Y}_ {...}^{2}\right]\] \[= \left[\,abr\left(\frac{\sigma_{B(A)}^{2}}{b}+\frac{\sigma^{2}}{ br}\right)\,+\,br\sum_{i}\left(\mu+\alpha_{i}\right)^{2}\right]\] \[-\;\left[\,abr\left(\frac{\sigma_{B(A)}^{2}}{ab}+\frac{\sigma^{2} }{abr}\right)\,+\,abr\sum_{i}\left(\mu+\overline{\alpha}_{.}\right)^{2}\right]\] \[= r(a-1)\sigma_{B(A)}^{2}+(a-1)\sigma^{2}+br\sum_{i}(\alpha_{i}- \overline{\alpha}_{.})^{2}\,.\]

Then, since MSA = SSA/(\(a\) - 1), we have

\[E[\text{MSA}] = \frac{br}{a-1}\sum_{i}(\alpha_{i}-\overline{\alpha}_{.})^{2}+r \sigma_{B(A)}^{2}+\sigma^{2}\] \[= Q(\alpha_{i})+r\sigma_{B(A)}^{2}+\sigma^{2}\,.\]

Similarly, the expected value of the sum of squares for \(B\) nested within \(A\) is

\[E[\text{SSB(A)}] = E\left[\,r\sum_{i=1}^{a}\sum_{j=1}^{b}\overline{Y}_{ij.}^{2}\,- \,br\sum_{i=1}^{1}\overline{Y}_{i..}^{2}\right]\] \[= \left[\,abr\left(\sigma_{B(A)}^{2}+\frac{\sigma^{2}}{r}\right)\, +\,br\sum_{i}\left(\mu+\alpha_{i}\right)^{2}\right]\] \[-\;\left[\,abr\left(\frac{\sigma_{B(A)}^{2}}{b}+\frac{\sigma^{2} }{br}\right)\,+\,br\sum_{i}\left(\mu+\alpha_{i}\right)^{2}\right]\] \[= ar(b-1)\sigma_{B(A)}^{2}+a(b-1)\sigma^{2}\,,\]

and, since MSB(\(A\)) = SSB(\(A\))/(\(a(b-1)\)), we have

\[E[\text{MSB}(A)]=r\sigma_{B(A)}^{2}+\sigma^{2}\,.\]These expected mean squares are listed in the last column of Table 18.2, and we may verify that they can all be obtained from rule 17 of Chap. 17. This rule, which applies also to more complicated mixed-effects nested models, says
17. To obtain the expected mean square for a particular main effect or interaction, first make a note of the subscripts on the term representing that particular effect in the model. Write down variance components for the effect of interest, for the error, and for every interaction whose term in the model includes the noted set of subscripts. Gather up all variance components corresponding to fixed effects into one quadratic form \(Q\). Multiply any remaining variance component except \(\sigma^{2}\) by the number of observations taken on each level or combination of levels of the corresponding effect (main effect or interaction). Add up the terms.

#### Estimation of Variance Components

The rules for obtaining confidence intervals for fixed effects or variance components also remain the same as those in Chap. 17 for non-nested models. Thus, we may obtain a confidence interval for a variance component in a mixed-effects nested model as follows:

19. For a random effect, let \(U=\Sigma k_{i}\,\text{M}\text{S}_{i}\) be the mean square or linear combination of mean squares whose expected value is equal to the variance component corresponding to the random effect. An exact or approximate 100(\(1-\alpha\))% confidence interval for this variance component is \[\left(\frac{xu}{\chi_{x,\alpha/2}^{2}}\ \,\ \ \frac{xu}{\chi_{x,1-\alpha/2}^{2}}\right),\] where \[x=\frac{[\Sigma\,k_{i}(\text{m}\text{s}_{i})]^{2}}{\Sigma[k_{i}(\text{m}\text{s}_{i})]^{2}/x_{i}}\,\] and where \(u\) is the observed value of \(U\), \(\text{m}\text{s}_{i}\) is the observed value of \(\text{M}\text{S}_{i}\), and \(x_{i}\) is the number of degrees of freedom corresponding to \(\text{m}\text{s}_{i}\).

For example, for the mixed-effects two-way nested model, we may estimate the variability of the response due to the effect of \(B\) within \(A\) as

\[u\ =\ \frac{\text{m}\text{s}\text{B}(A)-\text{m}\text{s}\text{E}}{r}\.\]

Then, using rule 19, we can obtain a 100(\(1-\alpha\))% confidence interval for \(\sigma^{2}_{B(A)}\) as

\[\left(\frac{xu}{\chi_{x,\alpha/2}^{2}}\,\ \ \frac{xu}{\chi_{x,1-\alpha/2}^{2}}\right),\]

where

\[x\ =\ \frac{(\text{m}\text{s}\text{B}(\text{A})-\text{m}\text{s}\text{E})^{2}}{ \frac{\text{m}\text{s}\text{B}(A^{2})}{\text{m}(b-1)}+\frac{\text{m}\text{s} \text{E}^{2}}{ab(r-1)}}\.\]

#### Hypothesis Testing

Hypothesis testing rules are also obtained from the rules in Chap. 17:

18. To obtain the denominator of the test statistic for testing the null hypothesis that a main effect or interaction effect is zero, write down the expected mean square for the effect of interest (see rule 17). Cross out the term that would be zero if the null hypothesis were true. The denominator of the test statistic is the mean square, or linear combination of mean squares, \(u\), whose expected value is equal to the remaining expression.
21. For a fixed effect, the decision rule for testing the hypothesis that the effect is zero is the same as that in rule 8, p. 210, for fixed-effects models except that msE is replaced by the denominator \(u\) from rule 18 and the number of error degrees of freedom is replaced by \(x\) in rule 19.
22. For a random effect, the decision rule for testing the hypothesis \(H_{0}\) that the corresponding variance component is zero against the alternative hypothesis that it is not zero is \[\text{reject }H_{0}\text{ if }\frac{\text{ms}}{u}>F_{\nu,x,\alpha}\,,\] where ms is the mean square for the effect of interest and \(\nu\) the corresponding degrees of freedom, \(u\) is the observed value of the denominator as in rule 18, and \(x\) is the corresponding degrees of freedom calculated as in rule 19.

For example, using the information in the expected mean squares column of Table 18.2 for the mixed-effects two-way nested model, the decision rule for testing the null hypothesis \(H_{0}^{B(A)}:\{\sigma_{B(A)}^{2}=0\}\) of no variability in the effect of \(B\) within each level of \(A\) against the alternative hypothesis \(H_{A}^{B(A)}:\{\sigma_{B(A)}^{2}>0\}\) is

\[\text{reject }H_{0}^{B(A)}\text{ if }\frac{\text{ms}B(A)}{\text{ms}E}>F_{a(b -1),ab(r-1),\alpha}\,, \tag{18.4.7}\]

at chosen significance level \(\alpha\).

To test the hypothesis \(H_{0}^{A}:\{\alpha_{1}=\alpha_{2}=\cdots=\alpha_{a}\}\) that the machine effects are the same averaged over their four heads, the decision rule at significance level \(\alpha\) is

\[\text{reject }H_{0}^{A}\text{ if }\frac{\text{ms}A}{\text{ms}B(A)}>F_{a-1,a( b-1),\alpha}\,. \tag{18.4.8}\]

#### Some Examples

##### Machine head experiment, continued

The data for the machine head experiment are listed in Table 18.3, and the analysis of variance table is shown in Table 18.4. One can show that the \(p\)-value for testing the hypothesis of no machine differences is 0.67, and we would conclude no difference in the effect on strain readings of the five machines. The test of the null hypothesis that the variance \(\sigma_{B(A)}^{2}\) of the population of possible heads fitted to the machines is zero has \(p\)-value 0.065. Only if our choice of significance level is greater than this value would we conclude nonzero variability among the heads.

An unbiased estimate of \(\sigma^{2}_{\text{B}(A)}\) is given by

\[\frac{\text{ms}\text{B}(A)-\text{ms}E}{r}\ =\ \frac{18.8583-10.7000}{4}\ =\ 2.0396\,,\]

and since,

\[x\ =\ \frac{(2.0396)^{2}}{\frac{(18.8583/4)^{2}}{15}\ +\ \frac{(10.70/4)^{2}}{60}}\ =\ 2.598\,,\]

a 90% confidence interval for \(\sigma^{2}_{\text{B}(A)}\) is given by

\[\left(\frac{(2.598)(2.0396)}{\chi^{2}_{2.598,.05}}\,\ \frac{(2.598)(2.0396)}{\chi^{2}_{2.598,.95}}\right)\approx\left(\frac{5.299}{6.90}\,\ \frac{5.299}{0.22}\right)=(0.77\,,\ 24.09)\]

measured in squared units of strain. 

#### _Example 18.4.2_ Soil experiment

Consider an experiment to compare analyses of soil samples with four treatment factors \(A\), \(B\), \(C\), and \(D\), where

* \(A\) is "method of analysis" and involves \(a=2\) specifically selected methods.
* \(B\) is "laboratory" and involves \(b=4\) specifically selected labs.
* \(C\) is "operator conducting the analysis" and there are \(c=3\) randomly selected operators in each lab.
* \(D\) is "location from which soil was taken" and involves \(d=3\) randomly selected locations.

\begin{table}
\begin{tabular}{c c c c c c c c c c c c c c c} \hline \multicolumn{2}{c}{Method.} & Head 1 & \multicolumn{4}{c}{Head 2} & Head 3 & Head 4 & Head 4 & \\ \hline
1 & 6 & 2 & 0 & 8 & 13 & 3 & 9 & 8 & 1 & 10 & 0 & 6 & 7 & 4 & 7 & 9 \\
2 & 10 & 9 & 7 & 12 & 2 & 1 & 1 & 10 & 4 & 1 & 7 & 9 & 0 & 3 & 4 & 1 \\
3 & 0 & 0 & 5 & 5 & 10 & 11 & 6 & 7 & 8 & 5 & 0 & 7 & 7 & 2 & 5 & 4 \\
4 & 11 & 0 & 6 & 4 & 5 & 10 & 8 & 3 & 1 & 8 & 9 & 4 & 0 & 8 & 6 & 5 \\
5 & 1 & 4 & 7 & 9 & 6 & 7 & 0 & 3 & 3 & 0 & 2 & 2 & 3 & 7 & 4 & 0 \\ \hline \end{tabular} _Source_ Hicks (1956). Copyright © 1956 American Society for Quality. Reprinted with permission

\end{table}
Table 3: Data for the machine head experiment Suppose the model is

\[Y_{ijkut} = \mu+\alpha_{i}+\beta_{j}+(\alpha\beta)_{ij}+C_{k(j)}+(\alpha C)_{ik(j )}+D_{u}\] \[\quad+(\alpha D)_{iu}+(\beta D)_{ju}+(\alpha\beta D)_{iju}+\epsilon _{ijkut}\,,\] \[C_{k(j)}\sim N(0,\sigma^{2}_{C(B)})\;;\;\;(\alpha C)_{ik(j)}\sim N (0,\sigma^{2}_{AC(B)})\;;\;\;D_{u}\sim N(0,\sigma^{2}_{D})\;;\;\;(\alpha D)_{iu} \sim N(0,\sigma^{2}_{AD})\] \[(\beta D)_{ju}\sim N(0,\sigma^{2}_{BD})\;;\;\;(\alpha\beta D)_{ iju}\sim N(0,\sigma^{2}_{ABD})\;;\;\;\epsilon_{ijkut}\sim N(0,\sigma^{2})\] \[\quad i=1,2\;;\;\;j=1,2,3,4\;;\;\;k=1,2,3\;;\;\;u=1,2,3\;;\;\;t=1,2\;;\]

where \(\alpha_{i}\) is the effect of the \(i\)th method of analysis, \(\beta_{j}\) is the effect of the \(j\)th laboratory, and \((\alpha\beta)_{ij}\) is the effect of their interaction; \(C_{k(j)}\) is the effect of the \(k\)th randomly selected operator in the \(k\)th laboratory and \((\alpha C)_{ik(j)}\) is the operator \(\times\) analysis method interaction; \(D_{u}\) is the effect of the \(u\)th randomly selected location from which the soil was selected and \((\alpha D)_{iu}\), \((\beta D)_{ju}\) and \((\alpha\beta D)_{iju}\) are respectively the interactions of the \(u\)th soil location with the \(i\)th method of analysis, the \(u\)th soil location with the \(j\)th laboratory, and the three-factor interaction of the \(u\)th soil location, \(i\)th method of analysis, and \(j\)th laboratory. Two observations are taken on each soil sample via each method of analysis by each operator.

The degrees of freedom, sums of squares, and expected mean squares for this model are obtained using rules 17-21 in Sects. 18.4.1-18.4.3 and are shown in Table 18.5.

The decision rule for testing the null hypothesis \(H^{ABD}_{0}:\{\sigma^{2}_{ABD}=0\}\) against the alternative hypothesis \(H^{ABD}_{A}:\{\sigma^{2}_{ABD}>0\}\) is given by

\[\mbox{reject }\;H^{ABD}_{0}\;\;\;\mbox{if}\;\;\;\;\frac{\mbox{ms}\mbox{ABD}}{ \mbox{ms}\mbox{E}}\;>\;F_{6,104,\alpha}\,.\]

If this hypothesis is not rejected, we may wish to examine the \(\mbox{AB}\), \(\mbox{AD}\), and \(\mbox{BD}\)interactions. The decision rule for testing the null hypothesis \(H^{BD}_{0}:\{\sigma^{2}_{\mbox{\scriptsize BD}}=0\}\) against the alternative hypothesis \(H^{BD}_{A}:\{\sigma^{2}_{\mbox{\scriptsize BD}}>0\}\) is given by

\[\mbox{reject }\;H^{BD}_{0}\;\;\;\mbox{if}\;\;\;\;\frac{\mbox{ms}\mbox{BD}}{ \mbox{ms}\mbox{ABD}}\;>\;F_{6,6,\alpha}\,.\]

The test for the \(\mbox{AD}\) interaction is similar, utilizing the test statistic \(\mbox{ms}\mbox{AD}/\mbox{ms}\mbox{ABD}\). To obtain a suitable denominator for testing

\[H^{AB}_{0}:\{(\alpha\beta)_{ij}-(\overline{\alpha\beta})_{i.}-(\overline{\alpha \beta})_{.j}+(\overline{\alpha\beta})_{.}=0,\;\;\;\mbox{for all }i,j\}\]

against the alternative hypothesis that the interaction is not zero, we need the denominator of the test statistic to be an unbiased estimator for

\[6\sigma^{2}_{AC(B)}+6\sigma^{2}_{ABD}+\sigma^{2}\,.\]

Such an estimator is

\[U=\mbox{MS}(AC(B))+\mbox{MS}(\mbox{ABD})-\mbox{MSE}\,.\]

This has approximately a \(\chi^{2}_{x}\) distribution with \[x=\frac{[\text{MS}(\text{AC}(B))+\text{MS}(\text{ABD})-\text{MSE}]^{2}}{\frac{\text{ MSAC}(B)^{2}}{8}+\frac{\text{MS}(\text{ABD})^{2}}{6}+\frac{\text{MSE}^{2}}{104}}\,.\]

Thus the decision rule for testing \(H_{0}^{\text{AB}}\) against \(H_{A}^{\text{AB}}\) is

\[\text{reject }\,H_{0}^{AB}\,\,\,\,\,\,\text{if}\,\,\,\,\,\frac{\text{ms}\text{AB}}{ U}\,\,>\,\,F_{3,x,\alpha}\,.\]

An unbiased estimate of \(\sigma_{\text{BD}}^{2}\) is

\[U=\frac{\text{ms}\text{BD}-\text{ms}\text{ABD}}{12}\,.\]

This has approximately a \(\chi_{x}^{2}\) distribution, where

\begin{table}
\begin{tabular}{c c c} \hline Effect & Degrees of freedom & Expected mean square \\ \hline \(A\) & \(a-1=1\) & \(Q(\alpha,\,\alpha\beta)+6\sigma_{\text{AC}(B)}^{2}+24\sigma_{\text{AD}}^{2}+6 \sigma_{\text{ABD}}^{2}+\sigma^{2}\) \\ \(B\) & \(b-1=3\) & \(Q(\beta,\,\alpha\beta)+12\sigma_{\text{C}(B)}^{2}+6\sigma_{\text{AC}(B)}^{2}+1 2\sigma_{\text{BD}}^{2}+6\sigma_{\text{ABD}}^{2}+\sigma^{2}\) \\ \(\text{AB}\) & \((a-1)(b-1)=3\) & \(Q(\alpha\beta)+6\sigma_{\text{AC}(B)}^{2}+6\sigma_{\text{ABD}}^{2}+\sigma^{2}\) \\ \(\text{C}(B)\) & \(b(c-1)=8\) & \(12\sigma_{\text{C}(B)}^{2}+6\sigma_{\text{AC}(B)}^{2}+\sigma^{2}\) \\ \(\text{AC}(B)\) & \((a-1)b(c-1)=8\) & \(6\sigma_{\text{AC}(B)}^{2}+\sigma^{2}\) \\ \(D\) & \(d-1=2\) & \(48\sigma_{D}^{2}+24\sigma_{\text{AD}}^{2}+12\sigma_{\text{BD}}^{2}+6\sigma_{ \text{ABD}}^{2}+\sigma^{2}\) \\ \(\text{AD}\) & \((a-1)(d-1)=2\) & \(24\sigma_{\text{AD}}^{2}+6\sigma_{\text{ABD}}^{2}+\sigma^{2}\) \\ \(\text{BD}\) & \((b-1)(d-1)=6\) & \(12\sigma_{\text{BD}}^{2}+6\sigma_{\text{ABD}}^{2}+\sigma^{2}\) \\ \(\text{ABD}\) & \((a-1)(b-1)(d-1)=6\) & \(6\sigma_{\text{ABD}}^{2}+\sigma^{2}\) \\ Error & subtraction = 104 & \(\sigma^{2}\) \\ Total & \(n-1=143\) \\ \hline Formulae & & \\ \hline ssA & \(72\Sigma_{i}\overline{y}_{i\ldots}^{2}-144\overline{y}_{i\ldots}^{2}\) \\ ssB & \(36\Sigma_{j}\overline{y}_{j\ldots}^{2}-144\overline{y}_{i\ldots}^{2}\) \\ ssAB & \(18\Sigma_{i}\Sigma_{j}\overline{y}_{j\ldots}^{2}-72\Sigma_{i}\overline{y}_{i \ldots}^{2}-36\Sigma_{j}\overline{y}_{j\ldots}^{2}+144\overline{y}_{i\ldots }^{2}\) \\ ssC(B) & \(12\Sigma_{j}\Sigma_{k}\overline{y}_{j\ldots}^{2}-36\Sigma_{j}\overline{y}_{j \ldots}^{2}\) \\ ssAC(B) & \(6\Sigma_{i}\Sigma_{j}\Sigma_{k}\overline{y}_{ijk\ldots}^{2}-18\Sigma_{i} \Sigma_{j}\overline{y}_{ij\ldots}^{2}-12\Sigma_{j}\Sigma_{k}\overline{y}_{j \ldots}^{2}+36\Sigma_{j}\overline{y}_{j\ldots}^{2}\) \\ ssD & \(48\Sigma_{k}\overline{y}_{i\ldots}^{2}-144\overline{y}_{i\ldots}^{2}\) \\ ssAD & \(24\Sigma_{i}\Sigma_{u}\overline{y}_{i\ldots}^{2}-72\Sigma_{i}\overline{y}_{i \ldots}^{2}-48\Sigma_{u}\overline{y}_{i\ldots}^{2}+144\overline{y}_{i\ldots }^{2}\) \\ ssBD & \(12\Sigma_{j}\Sigma_{u}\overline{y}_{j\ldots}^{2}-36\Sigma_{j}\overline{y}_{j \ldots}^{2}-48\Sigma_{u}\overline{y}_{i\ldots}^{2}+144\overline{y}_{i\ldots }^{2}\) \\ ssABD & \(6\Sigma_{i}\Sigma_{j}\Sigma_{u}\overline{y}_{i\ldots}^{2}-18\Sigma_{i}\Sigma_{ j}\overline{y}_{ij\ldots}^{2}-24\Sigma_{i}\Sigma_{u}\overline{y}_{i\ldots}^{2}-12\Sigma_{j} \Sigma_{u}\overline{y}_{j\ldots}^{2}\) \\  & \(+72\Sigma_{i}\overline{y}_{i\ldots}^{2}+36\Sigma_{j}\overline{y}_{j\ldots}^{2}+ 48\Sigma_{u}\overline{y}_{i\ldots}^{2}-144\overline{y}_{i\ldots}^{2}\) \\ sstot & \(\Sigma_{i}\Sigma_{j}\Sigma_{k}\Sigma_{u}\Sigma_{t}y_{ijklut}^{2}-144\overline{ y}_{i\ldots}^{2}\) \\ \hline \end{tabular}
\end{table}
Table 18: Degrees of freedom, sums of squares, and expected mean squares for the soil experiment \[x=\frac{u^{2}}{\frac{(\text{msBD}/12)^{2}}{6}\ \ +\ \ \frac{(\text{msABD}/12)^{2}}{6}}\,\]

and an approximate 95% confidence interval for \(\sigma_{\text{BD}}^{2}\) is

\[\left(u/\chi_{x,\alpha/2}^{2},\ \ u/\chi_{x,1-\alpha/2}^{2}\right)\.\]

Any one of the main effects \(A\), \(B\), or \(C(B)\) can be investigated if the interactions involving the corresponding factor are all negligible. The relevant formulae can be obtained along the same lines as those described above. 

### Using SAS Software

The SAS procedure PROC GLM can handle nested effects when they are described in the MODEL statement using notation of the form \(B(A)\). The RANDOM statement is used to obtain expected mean squares. The procedure PROC MIXED, which was described briefly in Chap. 17, can also be used. We will illustrate these procedures via the experiment in Sect. 18.5.1.

#### Voltage Experiment

An experiment was described by David Desmond in the 1954 issue of _Applied Statistics_ on reducing the variability of voltage regulators fitted to motor cars. The voltage regulator was required to operate within a range of 15.8-16.4 volts. When the experiment took place, records showed that about 18% of regulators required readjustment during inspection, and sometimes this figure rose to 50%. Despite the inspection procedure, some of the regulators reaching customers were still outside the specification limits, and complaints from customers were considered to be excessive.

The experiment was run in order to measure the variability in the regulator setting operation. Measurements were taken on 64 voltage regulators at each of four testing stations. The 64 regulators were selected at random from several different setting stations. In Table 18.6, we have reproduced the data for six of these setting stations, corresponding to 40 voltage regulators. Since the regulators were selected at random, we model their effects as random effects nested within setting station. For purposes of illustration, we consider the four testing stations and six setting stations as the only stations of interest and model them as fixed effects. In the original article, these were modeled as random effects.

The effect of testing station is crossed with the effect of setting station and with regulator. A model to describe the data can be written as

\[Y_{ijk}=\mu+\alpha_{i}+\beta_{j}+C_{k(j)}+\epsilon_{ijk}\,\] \[\epsilon_{ijk}\sim N(0,\sigma^{2})\,\ \ \ C_{k(j)}\sim N(0, \sigma_{C(B)}^{2})\,\] \[\epsilon_{ijk}\text{'s and }C_{k(j)}\text{'s are all mutually independent}\] \[i=1,\ldots,4;\ \ \ j=1,\ldots,6;\ \ \ k=1,\ldots,r_{j}\,\]

where \(\alpha_{i}\) is the effect of the \(i\)th testing station, \(\beta_{j}\) is the effect of the \(j\)th setting station, and \(C_{k(j)}\) is the effect of the \(k\)th randomly selected regulator from the \(j\)th setting station.

There is no reason to suspect that the testing stations would differ in their comparative results for different regulators, so there is no reason to expect a regulator \(\times\) testing station interaction. Since there is only one observation per regulator-testing station combination, we would not be able to distinguish such an interaction from experimental error. A SAS program for analyzing this model is shown in Table 18.7.

##### PROC GLM

A plot of the standardized residuals (not shown) highlights two rather large outliers. The two outlying observations are those highlighted in italics in Table 18.6, and we notice that they are from different regulators and different testing stations. If these outliers are removed, the output shown in Fig. 18.1 is obtained. The TEST option produces the correct denominators for the tests of \(H_{0}^{A}:\{\alpha_{1}=\alpha_{2}=\alpha_{3}=\alpha_{4}\}\), \(H_{0}^{B}:\{\beta_{1}=\beta_{2}=\cdots=\beta_{6}\}\) and \(H_{0}^{C(B)}:\{\sigma_{C(B)}^{2}=0\}\). If we select an overall significance level of \(\alpha=0.06\) for the three tests and do each test at level \(\alpha^{*}=0.02\), we see that there is a significant difference between testing stations, but not between setting stations. Also, the variance of the regulators within setting stations appears to be significantly different from zero. Mind you, the \(F\)-test for setting stations is somewhat approximate, not only because the denominator is a composite variance estimator, but also because the treatment type III mean squares may be slightly dependent as a consequence of the removal of the two outliers, causing a slight dependence of the numerator and denominator of the \(F\)-statistic.

Unbiased estimates of \(\sigma^{2}\) and \(\sigma_{C(B)}^{2}\) can be obtained from the listed expected mean squares as \(\hat{\sigma}^{2}=\mathsf{msE}=0.0268\) and

\begin{table}
\begin{tabular}{l l l l l l l l l l l l} \hline Set. sta. & Regulator & \multicolumn{4}{c}{Testing station (\(A\))} & \multicolumn{2}{c}{Set. sta. (\(B\))} & \multicolumn{2}{c}{Regulator (\(C\))} \\ \cline{3-11} (\(B\)) & (\(C\)) & & & & & & (\(B\)) & (\(C\)) & & & & \\ \cline{3-11}  & 1 & 2 & 3 & 4 & & & & 1 & 2 & 3 & 4 \\ \hline
1 & 1 & 16.5 & 16.5 & 16.6 & 16.6 & 4 & 1 & 16.1 & 16.0 & 16.0 & 16.2 \\  & 2 & 15.8 & 16.7 & 16.2 & 16.3 & 2 & 16.5 & 16.1 & 16.5 & 16.7 \\  & 3 & 16.2 & 16.5 & 15.8 & 16.1 & 3 & 16.2 & 17.0 & 16.4 & 16.7 \\  & 4 & 16.3 & 16.5 & 16.3 & 16.6 & 4 & 15.8 & 16.1 & 16.2 & 16.2 \\  & 5 & 16.2 & 16.1 & 16.3 & 16.5 & 5 & 16.2 & 16.1 & 16.4 & 16.2 \\  & 6 & 16.9 & 17.0 & 17.0 & 17.0 & 6 & 16.0 & 16.2 & 16.2 & 16.1 \\  & 7 & 16.0 & 16.2 & 16.0 & 16.0 & 7 & 16.0 & 16.0 & 16.1 & 16.0 \\  & 8 & 16.0 & 16.0 & 16.1 & 16.0 & & & & & & \\
2 & 1 & 16.0 & 16.1 & 16.0 & 16.1 & 5 & 1 & 15.5 & 15.6 & 15.4 & 15.8 \\  & 2 & _15.4_ & 16.4 & 16.8 & 16.7 & 2 & 15.8 & 16.2 & 16.0 & 16.2 \\  & 3 & 16.1 & 16.4 & 16.3 & 16.3 & 3 & 16.2 & _15.4_ & 16.1 & 16.3 \\  & 4 & 15.9 & 16.1 & 16.0 & 16.0 & 4 & 16.2 & 16.2 & 16.0 & 16.1 \\  & & & & & & & 5 & 16.1 & 16.2 & 16.3 & 16.2 \\  & & & & & & 6 & 16.1 & 16.1 & 16.0 & 16.1 \\
3 & 1 & 16.0 & 16.0 & 15.9 & 16.3 & 6 & 1 & 15.5 & 15.5 & 15.3 & 15.6 \\  & 2 & 15.8 & 16.0 & 16.3 & 16.0 & 2 & 16.0 & 15.6 & 15.7 & 16.2 \\  & 3 & 15.7 & 16.2 & 15.3 & 15.8 & 3 & 16.0 & 16.4 & 16.2 & 16.2 \\  & 4 & 16.2 & 16.4 & 16.4 & 16.6 & 4 & 15.8 & 16.5 & 16.2 & 16.2 \\  & 5 & 16.0 & 16.1 & 16.0 & 15.9 & 5 & 15.9 & 16.1 & 15.9 & 16.0 \\  & 6 & 16.1 & 16.1 & 16.1 & 16.1 & 6 & 15.9 & 16.1 & 15.8 & 15.7 \\  & 7 & 16.1 & 16.0 & 16.1 & 16.0 & 7 & 16.0 & 16.4 & 16.0 & 16.0 \\  & & & & & & 8 & 16.1 & 16.2 & 16.2 & 16.1 \\ \hline \end{tabular}
\end{table}
Table 18.6: Voltages for the voltage experiment \[\hat{\sigma}^{2}_{C(B)}\ =\ \frac{\text{ms}C(B)-\text{ms}E}{3.9499}\ =\ \frac{0.2405-0.0268}{3.9499}\ =\ 0.0541\,,\]

respectively. Thus the variability of the regulator strain readings is estimated to be about twice as large as the experimental error.

A 90% confidence interval for \(\sigma^{2}_{C(B)}/\sigma^{2}\) can be obtained by adapting the formula (17.3.11) as follows:

\[\begin{array}{l}\frac{1}{c}\left[\frac{\text{ms}C(B)}{\text{ms}E}\frac{F_{F_{1},\nu_{2},\alpha/2}}{\sigma^{2}}-1\right]\ \ \leq\ \frac{\sigma^{2}_{C(B)}}{\sigma^{2}}\ \leq\ \ \frac{1}{c}\left[\frac{\text{ms}C(B)}{\text{ms}E}\frac{F_{\nu_{1},\nu_{2},1-\alpha/2}}-1\right]\\ =\ \ \frac{1}{c}\left[\frac{0.2405}{0.0268\ F_{34,115,0.05}}-1\right]\ \ \leq\ \frac{\sigma^{2}_{C(B)}}{\sigma^{2}}\ \leq\ \frac{1}{c}\left[\frac{0.2405}{0.0268\ F_{34,115,0.95}}-1\right]\,.\end{array}\]

\begin{table}
\begin{tabular}{c} DATA VLT; \\ * Input setting station (B), regulator (C), \\ * testing station (A), and voltage; \\ INPUT B C A VOLTG; \\ LINES; \\ 1 1 1 16.5 \\ 1 1 2 16.5 \\ : : : : \\ 6 8 4 16.1 \\ ; \\ * Plot standardized residuals versus predicted values for all data; \\ PROC GLM; \\  CLASS A B C; \\  MODEL VOLTG = A B C(B); \\  RANDOM C(B) / TEST; \\  LSMEANS A / PDIFF = ALL CL ADJUST = TURKEY E = C(B); \\  COMPPUT OUT = RESIDS PREDICTED = PRED RESIDUAL = Z; \\  PROC STANDARD STD=1.0; \\  VAR Z; \\  PROC PLOT; * or use PROC SGPLOT; \\  PLOT 2*PRED = A Z*PRED = B Z*PRED = C / VREF = 0 VPOS = 19 HPOS = 50; \\ * Analysis without two outliers; \\  DATA VLT2; SET VLT; \\  IF B = 2 AND C = 2 AND A = 1 THEN DELETE; \\  IF B = 5 AND C = 3 AND A = 2 THEN DELETE; \\  PROC GLM; \\  CLASS A B C; \\  MODEL VOLTG = A B C(B); \\  RANDOM C(B) / TEST; \\  LSMEANS A / PDIFF = ALL CL ADJUST = TURKEY; \\ * The following should be approximately correct; \\  LSMEANS B / PDIFF = ALL CL ADJUST = TURKEY E = C(B); \\  PROC MIXED METHOD = TYPE3; \\  CLASS A B C; \\  MODEL VOLTG = A B / DDFM = SAT; \\  RANDOM C(B); \\  LSMEANS A B / CL PDIFF ADJUST = BON; \\ \end{tabular}
\end{table}
Table 7: SAS program to analyze a mixed-effects nested model Since \(E[\text{MSC}(B)]=\sigma^{2}+3.9499\sigma_{C(B)}^{2}\), the value of \(c=\) is 3.9499. So, using \(F_{34,115,0.05}\approx 1.52\) and \(F_{34,115,0.95}=(F_{115,34,0.05})^{-1}\approx 1.64^{-1}=0.61\), the confidence interval becomes

\[1.242\leq\frac{\sigma_{C(B)}^{2}}{\sigma^{2}}\leq 3.471\,.\]

The general conclusion of the experiment was that the differences between the four testing stations were of little practical importance. However, we note that the residual plots still indicate one or two large residuals, especially from testing station 2, so perhaps testing station 2 should have been examined a little more closely.

Much of the variability in the regulators appeared to be due to the inherent measurement error, and the experimenters concluded that it was not possible to set the regulators within the desired tolerance limits. A quality control scheme to ensure that the current quality did not deteriorate was put in place.

We note in passing that the effect of the outliers on the analysis was actually very small. If the two original outliers had been included in the analysis, the estimates \(\hat{\sigma}^{2}=0.0268\) and \(\hat{\sigma}_{C(B)}^{2}=0.0541\) would have changed to 0.0392 and 0.0461, respectively. There would also be little change in the \(p\)-values of the hypothesis tests. There is some benefit in retaining the entire data set, since the coefficient of \(\sigma_{C(B)}^{2}\) in the expected mean squares is then 4.0, as stated by rule 17 on p. 637.

Figure 18.1: SAS output for the voltage experiment

## PROC MIXED

The model can also be analyzed using the SAS procedure PROC MIXED and the analysis of variance approach as in Chap. 17. The SAS statements are shown in Table 7. The analysis of variance output from PROC MIXED (not shown) would match that generated by PROC GLM, because the option METHOD = TYPE3 implements the same least squares fit and the same analysis based on Type III sums of squares. An advantage of PROC MIXED is that it correctly estimates standard errors for means and contrasts. For example, some of the output generated by the LSMEANS statement for comparing setting stations (_B_) is shown in Fig. 8.2. Note that the standard error and associated degrees of freedom depend on the levels compared, due to the data imbalance caused by the removal of the two outliers. Composite variance estimates are used, and the degrees of freedom are obtained via Satterthwaite's approximation, due to the option DDFM = SAT in the MODEL statement. The changing number of degrees of freedom from one comparison to another indicates that the corresponding variance estimator also changes. Consequently, the Bonferroni method is used, since Tukey's method requires a common variance estimator, though the latter should also be approximately correct for such nearly balanced data. If the data were more than a little imbalanced, it would be preferable to use restricted maximum likelihood in PROC MIXED for variance components estimation--an approach to be discussed in Chap. 19.

### Using R Software

The analysis of variance approach can be used in R for the analysis of balanced designs involving random and nested effects. The aov function can fit such models. For example, if a model as specified in R includes the terms A and A:B but not B, then A:B represents the effects of \(B\) nested within \(A\).

Fig. 8.2: Output from PROC MIXED for the voltage experimentEquivalently, the notation A/B causes inclusion of the terms A and A:B if B is excluded. Random effects are designated by inclusion of a single Error function in the model. For example, if the model includes the terms A and Error(A:B) but excludes the term B, then A:B represents random effects of \(B\) nested within \(A\). The aov function fits models by least squares, the summary function provides the corresponding analysis of variance, including the usual (sometimes approximate) \(F\) tests for any fixed effects in the model, and the lsmeans function implements multiple comparison procedures. This analysis of variance approach using aov is appropriate and the computations dependable given a balanced design.

For unbalanced designs involving random effects, the data analysis can be accomplished by alternative methods involving estimation of the variance components by _restricted maximum likelihood_ (ReML). This approach can be implemented using the lmer function of the lme4 package to fit the model, the anova function to generate tests of fixed effects, and the lsmeans function for multiple comparisons. In our programs, we call the lmerTest package rather than lme4, as the former provides \(p\)-values for \(F\)-tests of fixed effects.

We will illustrate the above approaches in Sects. 18.6.2 and 18.6.3, respectively, using the experiment introduced in the following section.

#### Voltage Experiment

An experiment was described by David Desmond in the 1954 issue of _Applied Statistics_ on reducing the variability of voltage regulators fitted to motor cars. The voltage regulator was required to operate within a range of 15.8-16.4 volts. When the experiment took place, records showed that about 18% of regulators required readjustment during inspection, and sometimes this figure rose to 50%. Despite the inspection procedure, some of the regulators reaching customers were still outside the specification limits, and complaints from customers were considered to be excessive.

The experiment was run in order to measure the variability in the regulator setting operation. Measurements were taken on 64 voltage regulators at each of four testing stations. The 64 regulators were selected at random from several different setting stations. In Table 18.6 (p. 688), we have reproduced the data for six of these setting stations, corresponding to 40 voltage regulators. Since the regulators were selected at random, we model their effects as random effects nested within setting station. For purposes of illustration, we consider the four testing stations and six setting stations as the only stations of interest and model them as fixed effects. In the original article, these were modeled as random effects.

The effect of testing station is crossed with the effect of setting station and with regulator. A model to describe the data can be written as

\[Y_{ijk} = \mu + \alpha_{i} + \beta_{j} + C_{k(j)} + \epsilon_{ijk}\]

,

\[\epsilon_{ijk} \sim N(0,\sigma^{2})\]

,

\[C_{k(j)} \sim N(0,\sigma^{2}_{C(B)})\]

,

\[\epsilon_{ijk}\]

's and

\[C_{k(j)}\]

's are all mutually independent \[i = 1,\ldots,4;\quad j = 1,\ldots,6;\quad k = 1,\ldots,r_{j}\]

, where \(\alpha_{i}\) is the effect of the \(i\)th testing station, \(\beta_{j}\) is the effect of the \(j\)th setting station, and \(C_{k(j)}\) is the effect of the \(k\)th randomly selected regulator from the \(j\)th setting station.

There is no reason to suspect that the testing stations would differ in their comparative results for different regulators, so there is no reason to expect a regulator \(\times\) testing station interaction. Since there is only one observation per regulator-testing station combination, we would not be able to distinguish such an interaction from experimental error.

\begin{table}
\begin{tabular}{c} \hline \hline \(>\) voltage.data = read.table("data/voltage.txt", header=T) \\ \(>\) voltage.data = within(voltage.data, {fSetting = factor(Setting); \\ \(+\) fRegul = factor(Regul); fTesting = factor(Testing) }) \\ \(>\) head(voltage.data, 3) \\ Setting Regul Testing Voltg fTesting fRegul fSetting \\ 1 1 1 1 16.5 1 1 1 1 2 16.5 2 1 1 3 1 3 16.6 3 1 1 \\ \(>\) \# Least squares ANOVA \\ \(>\) \# Set contrast options for correct lsmeans and contrasts \\ \(>\) options(contrasts = c("contr.sum", "contr.poly")) \\ \(>\) model1 = aov(Voltg \(\widetilde{\) fSetting + fTesting + Error(fSetting:fRegul), \\ \(+\) data=voltage.data) \\ \(>\) summary(model1) \\ \(\quad\) Error: fSetting:fRegul \\ \(\quad\) Df Sum Sq Mean Sq F value Pr(\textgreater{}F) \\ \(\quad\) fSetting 5 2.91 0.582 2.6 0.043 \\ \(\quad\) Residuals 34 7.61 0.224 \\ \(\quad\) Error: Within \\ \(\quad\) Df Sum Sq Mean Sq F value Pr(\textgreater{}F) \\ \(\quad\) fTesting 3 0.70 0.2341 5.97 0.0008 \\ \(\quad\) Residuals 117 4.59 0.0392 \\ \(\quad\) \# Multiple comparisons: Tukey’s method \\ \(\quad\)\(>\) library(lsmeans) \\ \(\quad\)\(>\) lsmTesting1 = lsmeans(model1, \(\widetilde{\) fTesting) \\ \(\quad\)\(>\) summary(contrast(lsmTesting1, method="pairwise", adjust="tukey"), \\ \(\quad\)\(+\) infer=c(T,T), level=0.98, side="two-sided") \\ \(\quad\) contrast estimate SE df lower.CL upper.CL t.ratio p.value \\ 1 - 2 \(\quad\) -0.1550 0.044267 117 -0.285431 -0.024569 -3.502 0.0036 \\ 1 - 3 \(\quad\) -0.0825 0.044267 117 -0.212931 0.047931 -1.864 0.2494 \\ 1 - 4 \(\quad\) -0.1650 0.044267 117 -0.295431 -0.034569 -3.727 0.0017 \\ 2 - 3 \(\quad\) 0.0725 0.044267 117 -0.057931 0.202931 1.638 0.3616 \\ 2 - 4 \(\quad\) -0.0100 0.044267 117 -0.140431 0.120431 -0.226 0.9959 \\ 3 - 4 \(\quad\) -0.0825 0.044267 117 -0.212931 0.047931 -1.864 0.2494 \\ \(\quad\) Results are averaged over the levels of: fSetting \\ \(\quad\) Confidence level used: 0.98 \\ \(\quad\) Conf-level adjustment: tukey method for comparing a family of 4 estimates \\ \(\quad\) P value adjustment: tukey method for comparing a family of 4 estimates \\ \hline \hline \end{tabular}
\end{table}
Table 8: R program and selected output for analysis of a mixed-effects nested model by the analysis of variance approach 

#### Analysis Using Least Squares Estimates and aov

Table 18.8 contains an R program for analyzing model (18.6.9) using the aov function. The aov function, which fits models by ordinary least squares and takes an analysis of variance approach to the data analysis, works fine for models including random effects as long as the design is balanced. The summary function generates the appropriate _F_-tests for each fixed effect, including correct denominators for the tests of \(H_{0}^{A}:\{\alpha_{1}=\alpha_{2}=\alpha_{3}=\alpha_{4}\}\) and \(H_{0}^{B}:\{\beta_{1}=\beta_{2}=\cdots=\beta_{6}\}\). If we conduct both tests of fixed effects at level \(\alpha^{*}=0.02\), we see that there is a significant difference between testing stations (\(p=0.0008\)) but not between setting stations (\(p=0.043\)). Tukey's method is illustrated for comparing the effects of testing station. Code for comparing the effects of setting station is analogous.

Tests for random effects are not generated by the aov and summary functions. However, for balanced data, the appropriate tests can be constructed by hand from the mean squares and degrees of freedom generated by the summary function, based on the corresponding expected mean squares. Using rule 17 for estimation and hypothesis testing (p. 647), one can show that the expect mean square for regulators nested within setting is \(\sigma^{2}+4\,\sigma_{C(B)}^{2}\). So, to test \(H_{0}^{C(B)}:\{\sigma_{C(B)}^{2}=0\}\), the appropriate test statistic is \(F=\text{mS}C(B)/\text{mS}E=0.224/0.0392=5.714\) with 34 and 117 degrees of freedom, the mean square and degrees of freedom values being obtained from Table 18.8. The reader may verify that the null hypothesis would be rejected at level \(\alpha^{*}=0.02\) for example (\(p<0.001\)), corresponding to an overall significance level of \(\alpha=0.06\) for the three tests.

Unbiased estimates of \(\sigma^{2}\) and \(\sigma_{C(B)}^{2}\) can be obtained as \(\hat{\sigma}^{2}=\text{mS}E=0.0392\) and

\[\hat{\sigma}_{C(B)}^{2}\;=\;\frac{\text{mS}C(B)-\text{mS}E}{4}\;=\;\frac{0.224- 0.0392}{4}\;=\;0.0462\,,\]

respectively. Thus the variability of the regulator strain readings is estimated to be only slightly larger than the experimental error.

A 90% confidence interval for \(\sigma_{C(B)}^{2}/\sigma^{2}\) can be obtained by adapting the formula (17.3.11) as follows:

\[\begin{array}{rcl}\frac{1}{c}\left[\frac{\text{mS}C(B)}{\text{mS}E\;F_{1}, \nu_{2},\alpha/2}-1\right]&\leq&\frac{\sigma_{C(B)}^{2}}{\sigma^{2}}\leq& \frac{1}{c}\left[\frac{\text{mS}C(B)}{\text{mS}E\;F_{-1},\nu_{-},1-\alpha/2}- 1\right]\\ &=&\frac{1}{c}\left[\frac{0.224}{0.0462\;F_{34},117.0.05}-1\right]&\leq&\frac{ \sigma_{C(B)}^{2}}{\sigma^{2}}\leq&\frac{1}{c}\left[\frac{0.224}{0.0462\;F_{34 },117.0.95}-1\right]\,.\end{array}\]

Since \(E[MSC(B)]=\sigma^{2}+4\sigma_{C(B)}^{2}\), the value of \(c=\) is 4. So, using \(F_{34,117,0.05}\approx 1.533\) and \(F_{34,117,0.95}=\left(F_{117,34,0.05}\right)^{-1}\approx 1.635^{-1}=0.6116\), the confidence interval becomes

\[0.541\leq\frac{\sigma_{C(B)}^{2}}{\sigma^{2}}\leq 1.732\,.\]

The general conclusion of the experiment was that the differences between the four testing stations were of little practical importance. However, we note that the residual plots still indicate one or two large residuals, especially from testing station 2, so perhaps testing station 2 should have been examined a little more closely.

Much of the variability in the regulators appeared to be due to the inherent measurement error, and the experimenters concluded that it was not possible to set the regulators within the desired tolerance limits. A quality control scheme to ensure that the current quality did not deteriorate was put in place.

One advantage to the aov function and ordinary least squares is that residuals are available for checking model assumptions. A plot of the standardized residuals (not shown) highlights two rather large outliers. The two outlying observations are those highlighted in italics in Table 18.6, and we noticethat they are from different regulators and different testing stations. If these outliers were removed, one would need to use different methods for the data analysis, as illustrated in the next section.

#### Analysis Using Restricted Maximum Likelihood Estimation

Whether or not the design is balanced, model (18.6.9) can also be analyzed using restricted maximum likelihood (ReML) estimation. In particular, the variance components are estimated by restricted maximum likelihood, providing estimates which make the observed data most likely, subject to the restriction that the variance component estimates be non-negative. Given these variance component estimates, estimated generalized least squares estimates are computed for the fixed effects--generalized to take into account the unequal variances of observations as well as their correlations, and estimated since this variance-covariance structure is estimated. This approach will provide the same results as the analysis of variance approach if the design is balanced and all variance component estimates are positive, as is true for the voltage experiment. For further information about this approach, see Sect. 19.8.3.

Table 18.9 contains an R program and selected output for analyzing model (18.6.9) via this ReML-based approach, but excluding the two outliers. After the program reads all of the voltage data into the data set voltage.data, a new data set voltage2.data is created from it by taking the subset of voltage.data that satisfies two conditions that exclude the two outliers. For example, the first condition

!(fSetting == 2 & fRegul == 2 & fTesting == 1)

means not (!) to include observations with fSetting value 2 and (&) fRegul value 2 and fTesting value 1, thereby excluding the first outlier. The second outlier is similarly excluded by the second condition.

The lmer function fits model (18.6.9), estimating the variance components by restricted maximum likelihood estimation and the fixed effects by estimated generalized least squares estimation. In the model, specified as

\[\verb|Voltg~fSetting+fTesting+(1|fSetting:fRegul)|,\]

the term (1|fSetting:fRegul) causes inclusion of the random effects \(C_{k(j)}\)--one parameter for each combination of fSetting and fRegul. The anova function generates type 3 \(F\)-tests of the fixed effects--namely, for the effects of fSetting and fTesting. Finally, the lsameans command applies Tukey's method for each fixed-effects factor using a 98% confidence level, though the results are only displayed for testing stations.

We note in passing that the effect of the outliers on the analysis was actually very small. Comparing the results in Table 18.8 with the outliers to those in Table 18.9 without the outliers, there is little change in the \(p\)-values of the hypothesis tests, and Tukey's method yields the same significant comparisons. There is some benefit in retaining the entire voltage data set, since the analysis of variance approach can be used in R for models involving random effects if the design is balanced, in which case the analysis of variance approach is statistically efficient and provides a more complete data analysis.

## Exercises

1. **Viscosity experiment** An experiment was described by Johnson and Leone (1977, p. 744) to determine the viscosity of a polymeric material. The material was divided into two samples. The two samples were each divided into ten "aliquots." After preparation of these aliquots, they were divided into two subaliquots and a further step in the preparation made. Finally, each subaliquot was divided into two parts and the final step of the preparation made. The viscosity determinations are listed in Table 18.10.

\begin{table}
\begin{tabular}{c} \hline \hline \(>\) voltage.data = read.table("data/voltage.txt", header=T) \\ \(>\) voltage.data = within(voltage.data, {fSetting = factor(Setting); \\ \(+\) fRegul = factor(Regul); fTesting = factor(Testing) }) \\ \(>\) \# Drop two outliers, then reanalyze the data \\ \(>\) voltage2.data = subset(voltage.data, \\ \(+\)!(fSetting == 2 \& fRegul == 2 \& fTesting == 1) \\ \(+\) \&!(fSetting == 5 \& fRegul == 3 \& fTesting == 2) ) \\ \(>\) \# REML \\ \(>\) \# install.packages("lmerTest") \\ \(>\) library(lmerTest) \# Attaches/masks lmer and lsmeans, \\ \(>\) \# adding p-values to anova() \\ \(>\) model2 = lmer(Voltg \^{} fSetting + fTesting + (1|fSetting:fRegul), \\ \(+\) data=voltage2.data) \\ \(>\) anova(model2) \# F-tests for fixed effects \\ \(\;\) Analysis of Variance Table of type III with Satterthwaite approximation for degrees of freedom \\ \(\;\) Sum Sq Mean Sq NumDF DenDF F.value Pr(\textgreater{}F) \\ \(\;\) fSetting 0.312 0.0623 5 34 2.32 0.06419 \\ \(\;\) fTesting 0.590 0.1967 3 115 7.33 0.00015 \\ \(>\) \# Multiple comparisons \\ \(>\) library(lsmeans) \\ \(>\) lsmTesting2 = lsmeans(model2, \^{} fTesting) \\ \(>\) summary(contrast(lsmTesting2, method="pairwise", adjust="tukey"), \\ \(+\) infer=c(T,T), level=0.98, side="two-sided") \\ \(\;\) contrast estimate SE df lower.CL upper.CL t.ratio p.value \\ \(1\) - \(2\) -0.149846 0.037228 115.22 -0.259570 -0.040121 -4.025 0.0006 \\ \(1\) - \(3\) -0.055856 0.036922 115.10 -0.164681 0.052968 -1.513 0.4332 \\ \(1\) - \(4\) -0.138356 0.036922 115.10 -0.247181 -0.029532 -3.747 0.0016 \\ \(2\) - \(3\) 0.093989 0.036921 115.12 -0.014833 0.202811 2.546 0.0583 \\ \(2\) - \(4\) 0.011489 0.036921 115.12 -0.097333 0.120311 0.311 0.9895 \\ \(3\) - \(4\) -0.082500 0.036618 115.00 -0.190429 0.025429 -2.253 0.1154 \\ \end{tabular}
\end{table}
Table 18.9: R program and selected output for analysis of a mixed-effects nested model using restricted maximum likelihood estimation 1. Write down a model for the viscosity determinations allowing for variability in the samples, aliquots, subaliquots and parts. 2. Examine the error assumptions on your model. 3. Estimate the variances of all the random effects in the model. 4. Give a set of confidence intervals for the variances of all the random effects in the model at overall significance level 90%. At which step of the preparation is most of the variability introduced?
2. **Sleep experiment** Sleeping patterns can be classified according to periods of "deep sleep" and of "REM sleep" (rapid eye movement). An experiment is done to see how sleeping tablets and amount of daily activity affect the proportion of REM sleep. Three types of sleeping tablets are to be tested, coded 1, 2, 3 (where type 3 is a placebo). Twelve subjects are selected at random from a large population and are assigned at random to the levels of A, four to each level. Each subject is assigned an activity level for the day, and the proportion of REM sleep is monitored during that night. The four activity levels are: \[\begin{array}{l} {\text{B1}} = \text{read quietly all day,}\qquad {\text{B2}} = \text{walk 10 miles during the day,} \\ {\text{B3}} = \text{spend the day shopping,}\,{\text{B4}} = \text{play video games all day.} \\ \end{array}\] The experiment continues for four days, so that each subject is observed at each activity level in a random order. The model is assumed to be

\begin{table}
\begin{tabular}{c c c c c c} \hline Sample & Aliquot & \multicolumn{2}{c}{Subaliquot 1} & \multicolumn{2}{c}{Subaliquot 2} \\  & & Part 1 & Part 2 & Part 1 & Part 2 \\ \hline
1 & 1 & 59.8 & 59.4 & 58.2 & 63.5 \\  & 2 & 66.6 & 63.9 & 61.8 & 62.0 \\  & 3 & 64.9 & 68.8 & 66.3 & 63.5 \\  & 4 & 62.7 & 62.2 & 62.9 & 62.8 \\  & 5 & 59.5 & 61.0 & 54.6 & 61.5 \\  & 6 & 69.0 & 69.0 & 60.6 & 61.8 \\  & 7 & 64.5 & 66.8 & 60.2 & 57.4 \\  & 8 & 61.6 & 56.6 & 64.5 & 62.3 \\  & 9 & 64.5 & 61.3 & 72.7 & 72.4 \\  & 10 & 65.2 & 63.9 & 60.8 & 61.2 \\
2 & 1 & 59.8 & 61.2 & 60.0 & 65.0 \\  & 2 & 65.0 & 65.8 & 64.5 & 64.5 \\  & 3 & 65.0 & 65.2 & 65.5 & 63.5 \\  & 4 & 62.5 & 61.9 & 60.9 & 61.5 \\  & 5 & 59.8 & 60.9 & 56.0 & 57.2 \\  & 6 & 68.8 & 69.0 & 62.5 & 62.0 \\  & 7 & 65.2 & 65.6 & 61.0 & 59.3 \\  & 8 & 59.6 & 58.5 & 62.3 & 61.5 \\  & 9 & 61.0 & 64.0 & 73.0 & 71.7 \\  & 10 & 65.0 & 64.0 & 62.0 & 63.0 \\ \hline \end{tabular}
\end{table}
Table 18.10: Viscosity determinations for the viscosity experiment \[Y_{hijt}=\mu+S_{h(i)}+\alpha_{i}+\beta_{j}+(\alpha\beta)_{ij}+\epsilon_{hijt}\;,\] where \(\alpha_{i}\) is the effect of the \(i\)th sleeping tablet, \(\beta_{j}\) is the effect of the \(j\)th activity level, \((\alpha\beta)_{ij}\) is the effect of their interaction, \(S_{h(i)}\) is the effect of the \(h\)th random subject assigned to the \(i\)th sleeping tablet, and \(S_{h(i)}\sim N(0,\sigma^{2}_{S(A)})\) and \(\epsilon_{hijt}\sim N(0,\sigma^{2})\) and all \(S_{h(i)}\) and \(\epsilon_{hijt}\) are independent. 1. Write down the degrees of freedom and expected mean squares for the analysis of variance table. 2. Explain how to test the null hypothesis \(H^{A}_{0}:\{\alpha_{1}=\alpha_{2}=\alpha_{3}\}\) against the alternative hypothesis that at least two of the \(\alpha_{i}\) differ. 3. Explain how to test the null hypothesis \(H^{S(A)}_{0}:\{\sigma^{2}_{S(A)}=0\}\) against the alternative hypothesis \(H^{S(A)}_{A}:\{\sigma^{2}_{S(A)}>0\}\). 4. Suppose that the null hypothesis \[H^{AB}_{0}:\{(\alpha\beta)_{ij}-(\overline{\alpha\beta})_{i.}-(\overline{ \alpha\beta})_{.j}+(\overline{\alpha\beta})_{..},\;\;\mbox{for all $i$, $j$}\}\] appears to be correct. Which contrasts would be of particular interest to the experimenter? Why? Give formulas that would provide an overall 95% set of confidence intervals for your chosen contrasts. Give reasons for your choice of formula(s). 5. If the experimenter thought that a day effect would be important, how would you modify the design of the experiment and the model?
3. Consider the model \[Y_{ijkl}=\mu+\alpha_{i}+B_{j(i)}+C_{k(ji)}+\delta_{l}+(\alpha\delta)_{il}+(B \delta)_{lj(i)}+\epsilon_{ijkl}\;,\] 1. Calculate the expected mean squares for all effects in the model. 2. Which ratio would you use to test \(H_{0}:\{\delta_{l}+(\overline{\alpha\delta})_{.l}\;\;\mbox{all equal}\}? 3. Which ratio would you use to test \(H_{0}:\sigma^{2}_{A}=0\)?
4. **Titanium alloy experiment** An experiment described by Johnson and Leone (1977, p. 758) was performed by a company to investigate the effects of various factors on the "yield strength" of a particular titanium alloy. The factors investigated were: 1. vendors (4 fixed levels representing suppliers of raw material). 2. bar size (2 fixed levels representing standard sizes of bars of raw material). 3. batch (3 randomly selected levels nested within each combination of levels of \(A\) and \(C\)). 4. product type (2 fixed levels representing different types of finished product--forgedown and finished-forge blades). Three observations were taken on each treatment combination. A reasonable model was thought to be \[Y_{ijklt}=\mu+\alpha_{i}+\gamma_{j}+(\alpha\gamma)_{ij}+B_{k(ij)}+\delta_{l}\] \[\qquad\qquad\qquad\qquad+(\alpha\delta)_{il}+(\gamma\delta)_{jl}+(B \delta)_{kl(ij)}+\epsilon_{ijklt}\;,\] \[\epsilon_{ijklt}\sim N(0,\sigma^{2})\;,\;\;\;B_{k(ij)}\sim N(0,\sigma^{2}_ {B(AC)})\;,\;\;\;(B\delta)_{kl(ij)}\sim N(0,\sigma^{2}_{BD(AC)})\;,\] \[\qquad\qquad\qquad i=1,2,3,4;\;\;\;j=1,2;\;\;k=1,2,3;\;\;l=1,2;\;\; t=1,2,3,\] \[\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad \qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\]where \(\alpha_{i}\), \(\gamma_{j}\), and \(\delta_{l}\) represent the effects of the \(i\)th vendor, \(j\)th bar size, and \(l\)th product type, respectively, and \(B_{k(ij)}\) represents the effect of the \(k\)th randomly selected batch of the \(j\)th bar size made with bar stock from the \(i\)th vendor, and random variables on the right-hand side of the model are assumed to be mutually independent. 1. Write down the degrees of freedom and expected mean squares column of the analysis of variance table. 2. Give a formula for an approximate 95% confidence interval for \(\sigma^{2}_{B(AC)}\). 3. How would you test the hypothesis \[H_{0}:\{\text{no differences in yield strength of the titanium alloy}\] \[\text{can be attributed to the four vendors}\}\] against the alternative hypothesis \(H_{A}:\{H_{0}\text{ is false}\}\)?
5. **Titanium alloy experiment, continued** Suppose that factors \(C\) and \(D\) are to be investigated further in a followup experiment. Suppose that two new factors \(P\) and \(Q\) ("heat setting during processing" and "cooling method") are also to be investigated at two levels each. A followup experiment is required with the four factors \(C\), \(D\), \(P\), and \(Q\) at two levels each (a \(2^{4}\) experiment). Only sixteen observations will be taken, four for each vendor. It is known that the interactions \(CP\), \(CQ\), \(PQ\), \(CP\,Q\), and \(CDP\) are likely to be negligible. Also, there was information gained from the previous parts to Exercise 4 to suggest that all interactions of treatment factors with vendor can be assumed negligible. 1. Divide the 16 treatment combinations into four blocks of size four (one block for each vendor). Show your design explicitly, and indicate what should be randomized. 2. Write down a suitable model and the degrees of freedom column for the analysis of variance table for your design in part (a). 3. Before your design in part (a) is run, the management announces that in future, only one vendor will be used by the company. Also, your budget is cut, so that you can take only 8 observations. Thus, you need to design a \(\frac{1}{2}\)-fraction of a \(2^{4}\) experiment. In reviewing the list of negligible interactions above, you discover that two have been omitted. Interactions \(DP\) and \(CDQ\) are also known to be negligible. Choose a design and list the treatment combinations explicitly. (Hint: Try \(I=CP\,Q\).) State the aliasing scheme and a suitable model. Will there be any problems in interpreting the results of this experiment?
6. **Operator experiment** An experiment to identify the causes of variability in readings of a spectrometer was described in Exercise 10 of Chap. 7, p. 241. The same authors (Inman et al., _Journal of Quality Technology_, 1992) also described a study to determine how much of the variation in measured manganese concentration in steel was due to operator variation. Ten steel samples were sliced from a steel billet. Each operator was asked to measure the manganese content of each sample twice. The measurements taken by any one operator were done in a random order on a single day. There were four operators, who were regarded as representative of a large population of potential operators. 1. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 2. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 3. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 4. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 5. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 6. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 7. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 8. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 9. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 10. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 11. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 12. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 13. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 14. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 15. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 16. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 17. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 18. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 19. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 20. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 21. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 22. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 23. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 24. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 25. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 26. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 27. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 28. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 29. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 30. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 31. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 42. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 43. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 5. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 6. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 7. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 8. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 9. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 10. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 11. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 12. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 13. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 14. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 15. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 16. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 17. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 18. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 19. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 21. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 22. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 23. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 24. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 25. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 26. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 27. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 28. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 29. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 31. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 43. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 44. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 5. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 6. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 7. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 8. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 9. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 10. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 11. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 12. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 13. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 21. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 14. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 15. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 16. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 17. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 18. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 19. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 21. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 22. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 23. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 24. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 25. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 26. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 27. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 28. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 29. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 31. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 43. Write down model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 5. Write down model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 6. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 12. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 21. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 22. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 23. Write down model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 24. Write down model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 31. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 43. Write down model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 5. Write down model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 6. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 7. Write down model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 10. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 11. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 23. Write down model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 12. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 24. Write down model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 25. Write down model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 31. Write down model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 43. Write down model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 5. Write down model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 6. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 7. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 10. Write down model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 11. Write down a model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 24. Write down model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 12. Write down model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 25. Write down model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 26. Write down model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 27. Write down model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 28. Write down model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 29. Write down model for this experiment. Indicate clearly which effects are fixed, random, crossed, and nested. 21. Write down model for 2. Write down the degrees of freedom, the sums of squares, and the expected mean squares for each of the sources of variation in your model.
3. The authors analyzed this experiment using a gamma distribution to model the distribution of the error terms. Using the data in Table 18.11, investigate whether or not the normal distribution could be used (it may be necessary to take a transformation).
4. If the normal distribution can be used as a reasonable approximation to the error distribution, then analyze the experiment. In particular, obtain estimates of the variances of the random effects and identify the major sources of variation.
7. For the two-way nested fixed-effects model (18.2.1) on p. 672, show that the least squares estimator of \(\mu+\alpha_{i}+\beta_{j(i)}\) is given by \(\overline{Y}_{ij}\). [Hint: Differentiate the sum of squared errors with respect to \(\mu\), \(\alpha_{i}\) (\(i=1,\ldots,a\)), and \(\beta_{j(i)}\) (\(j=1,\ldots,b;\ i=1,\ldots,a\)), in turn. Set the resulting three sets of normal equations equal to zero. Show that the third set of equations adds to the first equation, and that the \(i\)th portion of the third set of equations adds to the \(i\)th equation in the second set. Thus, the first and second sets of equations are redundant, and \(a+1\) extra equations must be added to the set.]
8. **Red blood cell experiment** The trout experiment reported by Gutsell (_Biometrics_, 1951) was described in Exercise 15 of Chap. 3. As part of the same experiment, the red blood cell counts in the blood of brown trout were measured. Fish were put at random into eight troughs of water. Two troughs were assigned to each of the four levels of the treatment factor "sulfamerazine" (0, 5, 10, 15 grams per 100 pounds of fish added to the diet per day). After 42 days, five fish were selected at random from each trough and the red blood cell count from the blood of each fish was measured in two different counting chambers, giving two measurements per fish. The observations reported in Table 18.12, when multiplied by 5000, give the number of red blood cells per cubic millimeter of blood. A possible model for these data is \[Y_{ijkt}=\mu+\alpha_{i}+B_{j(i)}+C_{k(ij)}+\epsilon_{ijkt}\,,\] \[\epsilon_{ijkt}\sim N(0,\sigma^{2})\,,\ \ B_{j(i)}\sim N(0,\sigma^{2}_{B(A)})\,,\ \ C_{k(ij)}\sim N(0,\sigma^{2}_{C(AB)})\,,\] \[i=1,2,3,4;\ \ j=1,2;\ \ k=1,\ldots,5;\ \ t=1,2;\] \end{table}
Table 18.111: Manganese concentrations (percentages) for the operator experiment where \(\alpha_{i}\) is the effect of the \(i\)th level of sulfamerazine in the diet, \(B_{j(i)}\) is the effect of the \(j\)th randomly selected trough assigned to the \(i\)th level of sulfamerazine, and \(C_{k}\) is the effect of the \(k\)th randomly selected fish from the (\(ij\))th trough, and random variables on the right hand-side of the model are assumed to be mutually independent.

1. What are the experimental units and observational units in this experiment?
2. Since the data are counts, examine the assumptions of normally distributed errors and equal error variances by treatment. If the assumptions are not approximately satisfied, is there a transformation that can be used to correct the problem?
3. Write out the degrees of freedom and the expected mean squares for each term in the model.
4. Test the hypothesis that sulfamerazine has no effect on the red blood cell counts. Examine the linear and quadratic trends.
5. If the test in part (d) is rejected, calculate simultaneous 95% confidence intervals for pairwise comparisons in the effects of the sulfamerazine levels.

\begin{table}
\begin{tabular}{c c c c c c c c} \hline Fish & \multicolumn{4}{c}{0 gm suf.} & \multicolumn{4}{c}{5 gm suf.} \\ \cline{2-9}  & \multicolumn{2}{c}{Trough 1} & \multicolumn{2}{c}{Trough 2} & \multicolumn{2}{c}{Trough 1} & \multicolumn{2}{c}{Trough 2} \\ \hline
1 & 213 & 230 & 166 & 157 & 296 & 319 & 310 & 309 \\
2 & 253 & 231 & 206 & 185 & 278 & 258 & 241 & 270 \\
3 & 195 & 164 & 245 & 250 & 345 & 307 & 272 & 311 \\
4 & 193 & 203 & 213 & 181 & 322 & 372 & 254 & 237 \\
5 & 191 & 195 & 198 & 169 & 248 & 274 & 266 & 275 \\ \hline Fish & \multicolumn{4}{c}{10 gm suf.} & \multicolumn{4}{c}{15 gm suf.} \\ \cline{2-9}  & \multicolumn{2}{c}{Trough 1} & \multicolumn{2}{c}{Trough 2} & \multicolumn{2}{c}{Trough 1} & \multicolumn{2}{c}{Trough 2} \\ \hline
1 & 339 & 322 & 196 & 232 & 278 & 212 & 287 & 280 \\
2 & 282 & 285 & 205 & 186 & 275 & 311 & 221 & 243 \\
3 & 236 & 262 & 252 & 274 & 186 & 158 & 331 & 309 \\
4 & 252 & 209 & 245 & 216 & 301 & 281 & 231 & 244 \\
5 & 263 & 296 & 249 & 260 & 223 & 246 & 292 & 295 \\ \hline \end{tabular}
\end{table}
Table 18.12: Red blood cell counts from brown trout for the red blood cell experiment 

### 19.1 Introduction

Split-plot designs are needed when the levels of some treatment factors are more difficult to change during the experiment than those of others. The designs have a nested blocking structure. In a block design, the experimental units are nested within the blocks, and a separate random assignment of units to treatments is made within each block. In a split-plot design, the experimental units are called _split plots_, and are nested within _whole plots_, which themselves may or may not be nested within blocks.

The split plots within each whole plot are assigned at random to the levels of one or more of the treatment factors. The levels of other treatment factors are assigned to whole plots and remain constant for all split plots within a whole plot. Typically, these will be the factors whose levels are difficult to change, and the effects of their levels will be less precisely compared than those assigned to the split plots.

In Sect. 19.2 we show an example of an experiment designed as a split-plot design, together with a typical model for this type of design. The analysis of split-plot designs is discussed in Sect. 19.3 and illustrated via a second experiment. Designs with an extra level of nesting (split-split-plot designs) are briefly described in Sect. 19.4, and the issue of confounding treatment contrasts is introduced in Sect. 19.5. Section 19.6 introduces an experiment using a split-plot design without blocking. Section 19.7 introduces an experiment planned as a split-plot design with blocking, but that can also be viewed as a split-split-plot design. The use of SAS and R for analysis of split-plot designs is illustrated in Sects. 19.8 and 19.9, respectively.

### 19.2 Designs and Models

When a factorial experiment is run as a completely randomized design or a randomized complete block design, the levels of all the factors generally have to be changed frequently during the course of the experiment. For example, in Block I of the design in Table 13.13, p. 452, we see that as the experiment progressed on day 1, the level of the first factor had to be changed from 1 to 0 to 1 to 0 to 1, and the level of the second factor had to be changed from 0 to 1 to 0 to 1 to 0. The levels of the third and fourth factors also had to be changed four times. In most experiments this is no particular problem, but sometimes the level of one of the factors is _not_ particularly easy to change.

An experiment is described by Munro in his 1986 University of Southampton dissertation on the effect of lighting conditions (factor \(A\)) and the speed of a rotating drum (factor \(B\)) on a subject's abilityto focus on the center of the drum. In this experiment, it was easy to change the speed of rotation by the turn of a dial. The lighting conditions, however, took time to set up, and Munro wished to change these as seldom as possible. He therefore asked each subject to view all the rotation speeds (in a randomized order) under one set of lighting conditions during one session and return for a second session with different lighting conditions at a later date. Part of a possible design is shown in Table 19.1.

A whole plot is defined by a session for a particular subject. A split plot is defined by a time slot nested in a particular session for a particular subject. The two whole plots (sessions) within each block are assigned at random to the levels of one factor (_A_), and the four split plots (time slots) within each whole plot are assigned at random to the levels of the other factor (_B_).

If we look at the design in Table 19.1 and ignore factor \(B\), we see that the levels of \(A\) are assigned according to a randomized complete block design, where the \(s\) subjects play the role of blocks, the 2 whole plots per block play the role of experimental units, and the 2 levels of \(A\) are assigned at random to the 2 whole plots within each block. Assuming no block \(A\) interaction, the difference in the two levels of \(A\) could be analyzed like any randomized complete block design, using the whole-plot totals as the observations.

If we now look at the levels of \(B\), they have also been assigned according to a randomized complete block design, but this time, the whole plots play the role of the blocks, and the four split plots nested within each whole plot are assigned to the four levels of \(B\).

The analysis of the split-plot design is divided into two parts, reflecting this nested blocking system, each part with its own error. Analysis of the main effect of \(A\) involves comparisons of responses from split plots in different whole plots, whereas analysis of the main effect of \(B\) and the _AB_ interaction involve comparisons of responses from split plots within the same whole plots.

In general, split plots within a whole plot will be more similar than split plots in different whole plots. Consequently, within-whole-plot comparisons will generally be more precise than between-whole-plot comparisons. So, in the rotating drum experiment, the main effect of \(B\) and the _AB_ interaction will very likely be more precisely estimated than the main effect of \(A\).

Ignoring the effects of the treatment factors for the moment, the response could be modeled as

\[Y_{hpq} = \mu + \theta_{h} + \epsilon_{p(h)}^{W} + \epsilon_{q(hp)}^{S}\]

, where _th__h_ is the effect of the _h_th block, \(\epsilon_{p(h)}^{W}\) is the effect of the _p_th whole plot nested within the _h_th block, and \(\epsilon_{q(hp)}^{S}\) is the effect of the _q_th split plot nested within the _p_th whole plot in the _h_th block. We model the whole-plot and split-plot effects, and possibly the block effects, as random effects that are independent and normally distributed with mean 0 and variances \(\sigma_{W}^{2}\), \(\sigma_{S}^{2}\), and \(\sigma_{\theta}^{2}\), respectively.

Now, suppose that the levels of factor \(A\) are assigned to the whole plots, and in the _h_th block, the _p_th whole plot receives the _u_th assignment of the _i_th level of \(A\) (_i_ = 1,..., \(a\); \(u\) = 1,..., _l_). Also,

\begin{table}
\begin{tabular}{c c c c c}  & Whole plot 1 & Whole plot 2 \\  & (Session 1) & & (Session 2) \\ \cline{2-5} Block (Subject) & Level of \(A\) (Lighting) & Levels of \(B\) (Speed) & Level of \(A\) (Lighting) & Levels of \(B\) (Speed) \\ \hline I & 0 & 0 3 1 2 & 1 & 1 0 2 3 \\ II & 0 & 1 0 2 3 & 1 & 2 1 3 0 \\ III & 1 & 2 1 3 0 & 0 & 3 2 0 1 \\ ⋮ & ⋮ & ⋮ & ⋮ & ⋮ : ⋮ : \\ \(s\) & 0 & 0 1 3 2 & 1 & 2 3 1 0 \\ \hline \end{tabular}
\end{table}
Table 19.1: Part of a split-plot design for the rotating drum experiment suppose that the levels of factor \(B\) are assigned to the split plots, and in the (\(hp\))th whole plot, the \(q\)th split plot receives the \(t\)th assignment of the \(j\)th level of \(B\) (\(j=1,\ldots,b\); \(t=1,\ldots,m\)). Then the model includes the effects of \(A\), \(B\) and \(AB\), and \(p\) is replaced by \(iu\) and \(q\) is replaced by \(jt\), as follows:

\[\begin{array}{c}Y_{hiujt}=\mu+\theta_{h}+\alpha_{i}+\epsilon^{W}_{iu(h)}\\ \qquad\qquad\qquad\qquad+\beta_{j}+(\alpha\beta)_{ij}+\epsilon^{S}_{jt(hiu)} \,,\\ \qquad\qquad\qquad\qquad\qquad\epsilon^{W}_{iu(h)}\sim N(0,\,\sigma^{2}_{W})\,, \quad\epsilon^{S}_{jt(hiu)}\sim N(0,\,\sigma^{2}_{S})\,,\\ \qquad\qquad\qquad\qquad\epsilon^{W}_{iu(h)}\,\mbox{'s and }\epsilon^{S}_{jt(hiu)}\,\mbox{'s are all mutually independent,}\\ h=1,\ldots,s;\;\;i=1,\ldots,a;\;\;u=1,\ldots,\ell;\;\;j=1,\ldots,b;\;\;t=1, \ldots,m\;,\end{array} \tag{19.2.1}\]

where \(\theta_{h}\) is the effect of the \(h\)th block, \(\alpha_{i}\) is the effect of the \(i\)th level of factor \(A\) measured on the whole plots, the random variables \(\epsilon^{W}_{iu(h)}\) represent the random effects of the whole plots, \(\beta_{j}\) is the effect of the \(j\)th level of \(B\) measured on the split plots, (\(\alpha\beta)_{ij}\) is the interaction effect of \(A\) at level \(i\) and \(B\) at level \(j\), and the random variables \(\epsilon^{S}_{jt(hiu)}\) represent the random effects of the split plots.

The model (19.2.1) has been written on two lines to emphasize the two different parts of the design. In the design of Table 19.1, each level of \(A\) appears exactly once per block and each level of \(B\) appears exactly once per whole plot, so we may drop the subscripts \(u\) and \(t\), and the model for this design becomes

\[\begin{array}{c}Y_{hij}=\mu+\theta_{h}+\alpha_{i}+\epsilon^{W}_{i(h)}\\ \qquad\qquad\qquad\qquad+\beta_{j}+(\alpha\beta)_{ij}+\epsilon^{S}_{j(hi)}\,, \\ \qquad\qquad\qquad\epsilon^{W}_{i(h)}\sim N(0,\,\sigma^{2}_{W})\,,\quad \epsilon^{S}_{j(hi)}\sim N(0,\,\sigma^{2}_{S})\,,\\ \qquad\qquad\qquad\epsilon^{W}_{i(h)}\,\mbox{'s and }\,\epsilon^{S}_{j(hi)}\,\mbox{'s are all mutually independent,}\\ h=1,\ldots,s;\;\;i=1,\ldots,a;\;\;j=1,\ldots,b.\end{array} \tag{19.2.2}\]

In some experiments the whole plot is the largest unit, which is equivalent to there being only one block (\(s=1\)). In this case, model (19.2.1) becomes simpler, since the block effect \(\theta_{h}\) and all subscripts \(h\) are omitted:

\[\begin{array}{c}Y_{iujt}=\mu+\alpha_{i}+\epsilon^{W}_{iu}\\ \qquad\qquad\qquad\qquad+\beta_{j}+(\alpha\beta)_{ij}+\epsilon^{S}_{jt(iu)}\,, \\ \qquad\qquad\qquad\epsilon^{W}_{iu}\sim N(0,\,\sigma^{2}_{W})\,,\quad \epsilon^{S}_{jt(iu)}\sim N(0,\,\sigma^{2}_{S})\,,\\ \qquad\qquad\qquad\epsilon^{W}_{iu}\,\mbox{'s and }\,\epsilon^{S}_{jt(iu)}\,\mbox{'s are all mutually independent,}\\ i=1,\ldots,a;\;\;u=1,\ldots,\ell;\;\;j=1,\ldots,b;\;\;t=1,\ldots,m.\end{array} \tag{19.2.3}\]

For unequal sample sizes, the ranges of the subscripts would be modified in models (19.2.1) and (19.2.3).

### Analysis of a Split-Plot Design with Complete Blocks

In this section we consider only the case of equal sample sizes and randomized complete block designs for each of the treatment factors. There are then \(s\) blocks, each of which is divided into \(a\) whole plots, and each of these is subdivided into \(b\) split plots, giving a total of \(sab\) observations. Model (19.2.2) is used, and the degrees of freedom and sums of squares are calculated according to the rules in Chap. 18,as shown in the following two subsections. The analysis of variance is outlined in Table 19.2 and, for this setting, is appropriate whether the blocks are fixed or random. The analysis of a split plot design with incomplete blocks is illustrated in Sects. 19.8.4 and 19.9.4, using the SAS and R software, respectively.

#### 19.3.1 Split-Plot Analysis

Consider first the _split-plot analysis_, which is that part of the analysis (shown in the bottom half of the analysis of variance Table 19.2) that is based on the observations arising from the split plots within whole plots. There are \(sab-1\) total degrees of freedom, and the total sum of squares is

\[s\text{stot}=\sum_{h}\sum_{i}\sum_{j}y_{hij}^{2}-sab\overline{y}_{...}^{2}. \tag{19.3.4}\]

The \(b\) levels of factor \(B\) are assigned to the split plots within each whole plot according to a randomized complete block design. The \(sa\) whole plots are playing the role of \(sa\) blocks, so there are \(sa-1\) whole-plot degrees of freedom, and the whole-plot-total sum of squares is

\[ssW=b\sum_{h}\sum_{i}\overline{y}_{hi.}^{2}-sab\overline{y}_{...}^{2}. \tag{19.3.5}\]

Due to the fact that all levels of \(B\) are observed in every whole plot as in a randomized complete block design, the sum of squares for \(B\) needs no adjustment for whole plots, and is given by

\[ssB=sa\sum_{j}\overline{y}_{..j}^{2}-sab\overline{y}_{...}^{2} \tag{19.3.6}\]

corresponding to \(b-1\) degrees of freedom. The interaction between the factors \(A\) and \(B\) is also calculated as part of the split-plot analysis. Again, due to the complete block structure of both the

\begin{table}
\begin{tabular}{c c c c c} \hline Source of variation & Degrees of freedom & Sum of squares & Mean square & Ratio \\ \hline Block (Subjects) & \(s-1\) & \(ss\theta\) & – & – \\ \(A\) (Lighting) & \(a-1\) & \(ssA\) & msA & msA/msEW \\ Whole-plot error & \((s-1)(a-1)\) & \(ssEW\) & msEW & \\ \hline Whole-plot total & \(sa-1\) & \(ssW\) & – & – \\ \(B\) (Speed) & \(b-1\) & \(ssB\) & msB & msB/msE\({}_{S}\) \\ \(AB\) & \((a-1)(b-1)\) & \(ss(AB)\) & ms(AB) & ms(AB)/msE\({}_{S}\) \\ Split-plot error & \(a(b-1)(s-1)\) & \(ssE_{S}\) & msEs & \\ \hline Total & \(abs-1\) & \(s\text{stot}\) & & \\ \hline \multicolumn{5}{c}{Computational formulae} \\ \hline \(ss\theta=ab\Sigma_{h}\overline{y}_{..h}^{2}-sab\overline{y}_{..}^{2}\) & \(ssW=b\Sigma_{h}\Sigma_{i}\overline{y}_{hi.}^{2}-sab\overline{y}_{..}^{2}\) & & \\ \(ssA=sb\Sigma_{i}\overline{y}_{..i}^{2}-sab\overline{y}_{..}^{2}\) & \(ssB=sa\Sigma_{j}\overline{y}_{..j}^{2}-sab\overline{y}_{..}^{2}\) & & \\ \(ssEW=ssW-ss\theta-ssA\) & \(ss(AB)=s\Sigma_{i}\Sigma_{j}\overline{y}_{..j}^{2}-sb\Sigma_{i}\overline{y}_{..}^{2}\) & & \\ \(s\text{stot}=\Sigma_{h}\Sigma_{i}\Sigma_{j}y_{hij}^{2}-sab\overline{y}_{..}^{2}\) & \(-\) & \(sa\Sigma_{j}\overline{y}_{..j}^{2}+sab\overline{y}_{..}^{2}\) & & \\  & & \(ssE_{S}=\text{stot}-ssW-ssB-ss(AB)\) & & \\ \hline \end{tabular}
\end{table}
Table 19.2: Outline analysis of variance table for the rotating drum split-plot design whole-plot design and the split-plot design, the interaction sum of squares needs no adjustment for blocks. The number of interaction degrees of freedom is \((a-1)(b-1)=ab-a-b+1\), and the sum of squares is

\[\text{ss}(\text{AB})=s\sum_{i}\sum_{j}\vec{y}_{.ij}^{2}-sb\sum_{i}\vec{y}_{.i}^{ 2}-sa\sum_{j}\vec{y}_{..j}^{2}+sab\vec{y}_{....}^{2}\,. \tag{19.3.7}\]

Since there are \(b\) split plots nested within the \(sa\) whole plots, there are, in total, \(sa(b-1)\) split-plot degrees of freedom. Of these, \(b-1\) are used to measure the main effect of \(B\), and \((a-1)(b-1)\) are used to measure the AB interaction, leaving

\[sa(b-1)-(b-1)-(a-1)(b-1)=a(s-1)(b-1)\]

degrees of freedom for error. Equivalently, this can be obtained by subtraction of the whole-plot, \(B\), and \(AB\) degrees of freedom from the total

\[(sab-1)-(sa-1)-(b-1)-(a-1)(b-1)=a(s-1)(b-1)\,.\]

The split-plot error sum of squares can also be calculated by subtraction:

\[\text{ss}E_{S}=\text{sstot}-\text{ss}W-\text{ss}B-\text{ss}(\text{AB})\,. \tag{19.3.8}\]

The split-plot error mean square \(\text{ms}E_{S}=\text{ss}E_{S}/[a(s-1)(b-1)]\) is used as the error estimate in testing hypotheses and calculating confidence intervals for contrasts in \(B\) and \(\text{AB}\). Notice that we cannot compare the levels of factor \(A\) on the split plots, since within each whole plot the level of \(A\) is held constant. The \(A\) contrasts are, in fact, confounded with whole plots.

The sums of squares (19.3.4)-(19.3.8) and their associated degrees of freedom are summarized in the bottom half of the analysis of variance table shown in Table 19.2.

#### Whole-Plot Analysis

We now move on to the _whole-plot analysis_, which is the part of the analysis based on comparisons of whole-plot totals. The levels of \(A\) are assigned to the whole plots within blocks according to a randomized complete block design, and so the sum of squares for \(A\) needs no block adjustment. There are \(a-1\) degrees of freedom for \(A\), so the sum of squares is given by

\[\text{ss}A=sb\sum_{i}\vec{y}_{.i.}^{2}-sab\vec{y}_{....}^{2}\,. \tag{19.3.9}\]

There are \(s-1\) degrees of freedom for blocks, giving a block sum of squares of

\[\text{ss}\theta=ab\sum_{h}\vec{y}_{h..}^{2}-sab\vec{y}_{....}^{2}\,. \tag{19.3.10}\]

There are \(a\) whole plots nested within each of the \(s\) blocks, so there are, in total, \(s(a-1)\) whole-plot degrees of freedom. Of these, \(a-1\) are used to measure the effects of \(A\) leaving \((s-1)(a-1)\) degrees of freedom for whole-plot error. Equivalently, this can be obtained by the subtraction of the block and \(A\) degrees of freedom from the whole-plot total degrees of freedom \[(sa-1)-(s-1)-(a-1)=(s-1)(a-1)\,.\]

Similarly, the whole-plot error sum of squares, which is used in testing hypotheses and calculating confidence intervals for contrasts in factor \(A\), is obtained by subtraction:

\[\text{ss}E_{W}=\text{ss}W-\text{ss}\theta-\text{ss}A\,. \tag{19.3.11}\]

The sums of squares (19.3.9)-(19.3.11) and their corresponding degrees of freedom are summarized in the top half of Table 19.2 (p. 706).

If the whole plot is the largest unit--namely, if there is no blocking of the whole plots--then the sum of squares for blocks in Table 19.2 effectively gets pooled into the whole-plot error sum of squares. Then the latter, still used in testing hypotheses and calculating confidence intervals for contrasts in factor \(A\), is given by

\[\text{ss}E_{W}=\text{ss}W-\text{ss}A\,, \tag{19.3.12}\]

with \((sa-1)-(a-1)=a(s-1)\) degrees of freedom.

#### Contrasts Within and Between Whole Plots

The formulae for the least squares estimates of the main effect and interaction treatment contrasts are similar to those given by rule 10 of Sect. 7.3 for fixed effects, since no block adjustments are needed. Thus

\[\sum_{i}c_{i}\hat{\alpha}_{i}^{*} =\sum_{i}c_{i}\overline{y}_{.i.}\,, \tag{19.3.13}\] \[\sum_{j}d_{j}\hat{\beta}_{j}^{*} =\sum_{j}d_{j}\overline{y}_{.j}\,,\] \[\sum_{i}\sum_{j}k_{ij}\widehat{(\alpha\beta)}_{ij} =\sum_{i}\sum_{j}k_{ij}\overline{y}_{.ij}\,,\]

where \(\sum_{i}c_{i}=0\), \(\sum_{j}d_{j}=0\), and \(\sum_{i}k_{ij}=\sum_{j}k_{ij}=0\).

Consider the consequences of confounding factor \(A\) with whole plots. Using model (19.2.2), the corresponding main-effect-of-\(A\) contrast estimator can be expressed as

\[\sum_{i}c_{i}\hat{\alpha}_{i}^{*}=\sum_{i}c_{i}\overline{Y}_{.i.}=\sum_{i}c_{i }(\alpha_{i}^{*}+\overline{\epsilon}_{i(.)}^{W}+\overline{\epsilon}_{.(.i)}^{ S}).\]

Consequently, this estimator has mean \(\sum_{i}c_{i}\alpha_{i}^{*}\) and variance \(\sum_{i}(c_{i}^{2}/sb)(b\sigma_{W}^{2}+\sigma_{S}^{2})\), where \((b\sigma_{W}^{2}+\sigma_{S}^{2})\) replaces \(\sigma^{2}\) in rule 11 of Sect. 7.3 for fixed effects models. So, although main effects of \(A\) are confounded with whole plots, because the whole plot effects are random with mean zero, main effects of \(A\) are estimable but with larger variance reflecting whole plot variability in addition to split plot variability.

For the estimates in Eq. (19.3.13), the corresponding estimated variances reflect whether the contrasts are measured in terms of whole-plot differences (as for contrasts in the levels of \(A\)) or split-plot (within whole-plot) differences (as for contrasts in \(B\) or \(AB\)). The former use the whole-plot error mean square, and the latter use the split-plot error mean square as follows.

\[\widehat{\text{Var}}\left(\sum_{i}c_{i}\hat{\alpha}_{i}^{*}\right) =\sum_{i}\frac{c_{i}^{2}}{sb}\text{ }\text{m}\text{s}E_{W}\,, \tag{19.3.14}\] \[\widehat{\text{Var}}\left(\sum_{j}d_{j}\hat{\beta}_{j}^{*}\right) =\sum_{j}\frac{d_{j}^{2}}{sa}\text{ }\text{m}\text{s}E_{S}\,,\] \[\widehat{\text{Var}}\left(\sum_{i}\sum_{j}k_{ij}\widehat{(\alpha \beta)}_{ij}\right) =\sum_{i}\sum_{j}\frac{k_{ij}^{2}}{s}\text{ }\text{m}\text{s}E_{S}\,.\]

For main effect and interaction contrasts, the methods of multiple comparison of Bonferroni, Scheffe, Tukey, and Dunnett can be used as usual (incorporating either the whole-plot or split-plot error mean square as above). Inferences for other contrasts in the treatment effects \(\tau_{ij}=\alpha_{i}+\beta_{j}+(\alpha\beta)_{ij}\), such as all pairwise comparisons, are more complicated and are discussed later in this chapter.

#### A Real Experiment--Oats Experiment

An experiment on the yield of three varieties of oats (factor \(A\)) and four different levels of manure (factor \(B\)) was described by F. Yates in his 1935 paper _Complex Experiments_. The experimental area was divided into \(s=6\) blocks. Each of these was then subdivided into \(a=3\) whole plots. The varieties of oat were sown on the whole plots according to a randomized complete block design (so that every variety appeared in every block exactly once). Each whole plot was then divided into \(b=4\) split plots, and the levels of manure were applied to the split plots according to a randomized complete block design (so that every level of \(B\) appeared in every whole plot exactly once). The design, after randomization, is shown in Table 19.3, together with the yields in quarter pounds. Model (19.2.2) was used.

##### Analysis of Variance--Oats Experiment

Using the formulae (19.3.4)-(19.3.11), we obtain the sums of squares shown in Table 19.4. To test, at significance level \(\alpha=0.01\), the hypothesis \(H_{0}^{AB}\) that the interaction between variety and manure level is negligible against the alternative hypothesis that the interaction is not negligible, we reject \(H_{0}^{AB}\) if

\[\frac{\text{m}\text{s}(\text{A}\text{B})}{\text{m}\text{s}E_{S}}=\frac{53.63}{ 177.08}=0.30>F_{6,45,0.01}\,.\]

Since \(F_{6,45,0.01}\approx 3.2\), we do not reject \(H_{0}^{AB}\), and we conclude that the interaction is negligible.

The hypothesis \(H_{0}^{B}\) of no difference in yield due to the different levels of manure (averaged over variety) is also tested using the split-plot error mean square as the denominator. We reject \(H_{0}^{B}\) in favor of the alternative hypothesis, that the manure levels do affect yield of oats, if

\[\frac{\text{m}\text{s}B}{\text{m}\text{s}E_{S}}=\frac{6673.50}{177.08}=37.69>F_ {3,45,0.01}\,.\]

Since \(F_{3,45,0.01}\approx 4.3\), we conclude that these four manure levels have different effects on the yield of the oat varieties tested.

Factor \(A\) is measured on the whole plots, so the whole-plot error is used as the denominator of the test statistic. We reject the hypothesis \(H_{0}^{A}\) of no difference in the average yields of the different varieties averaged over the manure levels if 

[MISSING_PAGE_FAIL:725]

where \(\overline{y}_{.i.}\) is an average over the \(b=4\) split plots within the \(s=6\) whole plots (one per block) on which level \(i\) of \(A\) is measured. Similarly, \(\overline{y}_{.j}\) is an average over the \(sa=18\) split plots (one per whole plot) on which level \(j\) of \(B\) is measured. The confidence intervals are obtained from (19.3.13) and (19.3.14) as follows:

\[\alpha_{0}-\alpha_{1} \in \left((\overline{y}_{.0.}-\overline{y}_{.1.})\;\pm\;t_{2,10,0.01}^ {(0.5)}\sqrt{\frac{2}{24}\text{ms}E_{W}}\;\right)\] \[= \left(-6.875\;\pm\;3.53\sqrt{\frac{2}{24}(601.33)}\;\right)\] \[= \left(-6.875\;\pm\;24.99\right)=\left(-31.87,18.12\right),\] \[\alpha_{0}-\alpha_{2} = \left(-37.16,18.12\right),\] \[\beta_{0}-\beta_{1} \in \left((\overline{y}_{.0}-\overline{y}_{.1})\;\pm\;t_{3,45,0.01} ^{(0.5)}\sqrt{\frac{2}{18}\text{ms}E_{S}}\;\right)\] \[= \left(-19.5\;\pm\;3.09\sqrt{\frac{2}{18}(177.03)}\;\right)\] \[= \left(-19.5\;\pm\;13.70\right)=\left(-33.20,-5.79\right),\] \[\beta_{0}-\beta_{2} \in \left(-48.54,-21.13\right),\] \[\beta_{0}-\beta_{3} \in \left(-57.70,-30.30\right).\]

It is clear that the treatment-versus-control comparisons for the factor \(B\) manure levels are made more precisely (\(\text{msd}=13.70\)) than those for the factor \(A\) oat varieties (\(\text{msd}=24.99\)). This is primarily due to the much smaller error variance estimate, \(\text{ms}E_{S}<\text{ms}E_{W}\), which reflects the fact that split plots within a whole plot are generally more similar than split plots in different whole plots. There are also more degrees of freedom associated with the split-plot error than with the whole-plot error, which also helps to reduce the minimum significant difference. Comparisons for factor \(B\) are more precise, despite the fact that the means \(\overline{y}_{.i.}\) for factor \(A\) involve more observations.

### Split-Split-Plot Designs

In the split-plot designs illustrated in Sect. 19.2, the factor \(A\) contrasts were confounded with the whole-plot contrasts, so that the main effect of \(A\) was assessed against the whole-plot variability, while the main effect of \(B\) and the \(AB\) interaction were assessed against the split-plot variability. It is possible

\begin{table}
\begin{tabular}{l c c c c c} \hline Source of variation & Degrees of freedom & Sum of square & Mean square & Ratio & \(p\)-value \\ \hline Blocks & 5 & 15875.28 & 3175.06 & – & \\ \(A\) (variety) & 2 & 1786.36 & 893.18 & 1.49 & 0.2724 \\ Whole-plot error & 10 & 6013.31 & 601.33 & & \\ \hline Whole-plot total & 17 & 23674.94 & 1392.64 & & \\ \(B\) (manner) & 3 & 20020.50 & 6673.50 & 37.69 & 0.0001 \\ \(AB\) & 6 & 321.75 & 53.63 & 0.30 & 0.9322 \\ Split-plot error & 45 & 7968.75 & 177.08 & & \\ \hline Total & 71 & 51985.94 & & & \\ \hline \end{tabular}
\end{table}
Table 19.4: Analysis of variance for the oats split-plot experiment to extend this idea, and to divide the split plots into split split plots on which are assigned the levels of a third factor.

For example, in the drum rotation experiment described in Sect. 19.2, the experimenter used a third factor \(C\), the direction of rotation of the drum. A possible design for the experiment would be to ask each subject to be present at two sessions (whole plots) with a different lighting condition (\(A\)) at each session. In the first half of a session (split plot), set the direction of rotation (\(C\)), and run through each speed (\(B\)) in a random order (split split plots), changing the direction of rotation in the second half of the session. The design would then appear as in Table 19.5.

The model and analysis of variance table would have three parts, one for the whole plots nested within blocks together with the factor \(A\) effect, one for the split plots nested within whole plots together with the factor \(C\) effect and the \(AC\) interaction, and one for the split split plots nested within split plots together with the factor \(B\) effect and the other interactions, as shown in model (19.4.15):

\[Y_{hijk} = \mu +\theta_{h}+\alpha_{i}+\epsilon_{i(h)}^{W}\] \[+\gamma_{j}+(\alpha\gamma)_{ij}+\epsilon_{j(hi)}^{S}\] \[+\beta_{k}+(\alpha\beta)_{ik}+(\gamma\beta)_{jk}+(\alpha\gamma \beta)_{ijk}+\epsilon_{k(hij)}^{\text{SS}}\,.\]

The analysis of variance table, shown in Table 19.6, has three sections, reflecting the three parts of the model, and is illustrated through a real experiment in Sect. 19.7.3.

\begin{table}
\begin{tabular}{l l l l} \hline Source of variation & Degrees of freedom & Mean square & Ratio \\ \hline Blocks (subjects) & \(s-1\) & ms\(\theta\) & \\ \(A\) (lighting) & \(a-1\) & msA & msA/msE\({}_{W}\) \\ Whole-plot error & \((s-1)(a-1)\) & msE\({}_{W}\) & \\ \hline Whole-plot total & \(sa-1\) & msW & \\ \(C\) (direction) & \(c-1\) & msC & msC/msE\({}_{S}\) \\ \(AC\) & \((a-1)(c-1)\) & ms(AC) & ms(AC)/msE\({}_{S}\) \\ Split-plot error & \(a(s-1)(c-1)\) & msE\({}_{S}\) & \\ \hline Split-plot total & \(sac-1\) & msE\({}_{S}\) & \\ \(B\) & \(b-1\) & msB & msB/msE\({}_{\text{SS}}\) \\ \(AB\) & \((a-1)(b-1)\) & ms(AB) & ms(AB)/msE\({}_{\text{SS}}\) \\ CB & \((c-1)(b-1)\) & ms(CB) & ms(CB)/msE\({}_{\text{SS}}\) \\ ACB & \((a-1)(c-1)(b-1)\) & ms(ACB) & ms(ACB)/msE\({}_{\text{SS}}\) \\ Split-split-plot error & \(ac(s-1)(b-1)\) & msE\({}_{\text{SS}}\) & \\ \hline Total & \(sacb-1\) & mstot & \\ \hline \end{tabular}
\end{table}
Table 19.6: Analysis of variance for a split-split-plot design

\begin{table}
\begin{tabular}{l c c c c c c} \hline  & & & \multicolumn{2}{c}{Split-plot 1} & \multicolumn{2}{c}{Split-plot 2} \\  & & & \multicolumn{2}{c}{First half session} & \multicolumn{2}{c}{Second half session} \\ \cline{4-7} Block & Whole-plot & Level of \(A\) (Session) & Level of \(A\) (Light) & Level of \(C\) (Direction) & Levels of \(B\) (Speed) & Level of \(C\) (Direction) & Levels of \(B\) (Speed) \\ \hline I & 1 & 0 & 1 & 0 3 1 2 & 0 & 2 1 3 0 \\  & 2 & 1 & 0 & 1 0 2 3 & 1 & 3 2 0 1 \\ II & 1 & 1 & 1 & 1 0 2 3 & 0 & 0 3 1 2 \\  & 2 & 0 & 0 & 2 1 3 0 & 1 & 3 2 0 1 \\ : & : & : & : : & : : : & : : : & : : : : : : : \\ \hline \end{tabular}
\end{table}
Table 19.5: Part of a split-split-plot design for the rotating drum experiment 

### Split-Plot Confounding

If there are a number of different factors involved in a split-plot design, the size of the whole plots may not be large enough to allow a randomized complete block design to be used for the split-plot factors. We can obtain smaller blocks by confounding one or more interaction contrasts as we did for the single-replicate designs in Chap. 13. For example, suppose a two-replicate \(2^{4}\) experiment is to be conducted for treatment factors \(A\), \(B\), \(C\), and \(D\), and for practical reasons, the observations are to be divided into eight whole plots of size four. Suppose that the levels of \(A\) are sufficiently difficult to change that it is decided to change the level only after each whole plot of four observations is taken. The \(A\) contrasts are confounded with the whole plots, since each whole plot is assigned only one level of \(A\).

Now, only four of the eight combinations of factors \(B\), \(C\), and \(D\) can be taken in any one whole plot. Thus, ignoring factor \(A\), a design with \(b=8\) whole plots of size \(k=4\) and \(v=8\) treatment labels is required. An incomplete block design, such as a cyclic design, would be a possible choice. However, since a split-plot design is a complex design to analyze, it is better to select a repeated single-replicate design, so that we know exactly what is confounded with the whole plots. If we choose to confound BCD with the whole plots, as well as \(A\), then ABCD will also be confounded. The single-replicate design that confounds \(A\), BCD, and ABCD is obtained from the equations

\[\begin{array}{rll}a_{1}&=&0\text{ or }1\text{ mod }2\,,\\ a_{2}+a_{3}+a_{4}&=&0\text{ or }1\text{ mod }2\,.\end{array}\]

If we repeat this single-replicate design twice, we obtain the split-plot plan shown in Table 19.7. Before this plan can be used, the eight whole plots would need to be randomly ordered, and the four split plots within each whole plot would need to be randomly ordered. An outline analysis of variance table is shown in Table 19.8.

### A Real Experiment--UAV Experiment

Sriram Mahadevan (2009) conducted three experiments at Wright State University to evaluate the performance of a semi-automated computer display system designed to support a human operator's ability to monitor and control the complex dynamic operation of multiple unmanned aerial vehicles (UAVs) when the UAVs are involved in multiple combat-related tasks. One of his experiments was conducted to examine the effects of different visual tools on the task performance efficiency and situation awareness of a single operator at a computer display to monitor and control dual-task scenarios involving UAVs.

The experiment involved 16 subjects (factor \(W\)) and \(a=2\) cue conditions (factor \(A\)), with eight of the 16 participants utilizing a baseline user interface with basic visual tools (\(A=1\)), and with

\begin{table}
\begin{tabular}{c c c c c c c c c c c c} \hline Whole plot & \(A\) & Levels of \(B\), \(C\), \(D\) on the split plots & Whole plot & \(A\) & Levels of \(B\), \(C\), \(D\) on the split plots \\ \hline I & 0 & 000 & 011 & 101 & 110 & II & 1 & 001 & 010 & 100 & 111 \\ III & 0 & 001 & 010 & 100 & 111 & IV & 1 & 000 & 011 & 101 & 110 \\ V & 0 & 000 & 011 & 101 & 110 & VI & 1 & 001 & 010 & 100 & 111 \\ VII & 0 & 001 & 010 & 100 & 111 & VIII & 1 & 000 & 011 & 101 & 110 \\ \hline \end{tabular}
\end{table}
Table 19.7: A split-plot confounded \(2^{4}\) experiment in 8 whole plots of size 4the other eight participants utilizing an advanced user interface involving more advanced visual tools (\(A=2\)). Each subject ran through eight trials--one at each combination of task similarity (factor \(B\), with \(b=2\) levels) and task complexity (factor \(C\), with \(c=4\) levels). Task similarity depended on whether the primary and secondary tasks (which were done concurrently) were similar (coded 1), each task being a suppression-of-enemy-air-defenses (SEAD) mission, or dissimilar (coded 2), the primary and secondary tasks being SEAD and reconnaissance missions, respectively. Task complexity corresponds to the number of UAVs in the scenario, the levels being: simple-simple if both the primary and secondary tasks each involves two UAVs; simple-complex if the primary and secondary tasks involve two and four UAVs, respectively; complex-simple if the primary and secondary tasks involve four and two UAVs, respectively; and complex-complex if both the primary and secondary tasks each involves four UAVs. These levels were coded 1, 2, 3, 4, respectively.

This may be viewed as a split-plot design, with subjects serving as the whole plots, and with the eight trials per subject serving as the split plots. Main effects of cue are comparisons between subjects (i.e. between whole plots), since subjects are nested within cue levels, whereas main effects of \(B\) and \(C\) and all interactions are comparisons within whole plots.

One of the response variables measured was the time taken to perform situation awareness perception tasks in the primary task, yielding the data shown in Table 9.9. The model, including all treatment effects, is as follows.

\begin{table}
\begin{tabular}{l l l l} \hline Source of variation & Degrees of freedom & Mean square & Ratio \\ \hline \(A\) & 1 & msA & \(\text{msA}/\text{msE}_{W}\) \\ \(B\)CD & 1 & ms(BCD) & \(\text{ms}(BCD)/\text{msE}_{W}\) \\ \(ABCD\) & 1 & ms(ABCD) & \(\text{ms}(ABCD)/\text{msE}_{W}\) \\ Whole-plot error & 4 & msE\({}_{W}\) & \\ \hline Whole-plot total & 7 & msW & \\ \(B\) & 1 & msB & \(\text{msB}/\text{msE}_{S}\) \\ \(C\) & 1 & msC & \(\text{msC}/\text{msE}_{S}\) \\ \(D\) & 1 & msD & \(\text{msD}/\text{msE}_{S}\) \\ \(BC\) & 1 & ms(BC) & \(\text{ms}(\text{BC})/\text{msE}_{S}\) \\ \(BD\) & 1 & ms(BD) & \(\text{ms}(\text{BD})/\text{msE}_{S}\) \\ \(CD\) & 1 & ms(CD) & \(\text{ms}(\text{CD})/\text{msE}_{S}\) \\ \(AB\) & 1 & ms(AB) & \(\text{ms}(\text{AB})/\text{msE}_{S}\) \\ AC & 1 & ms(AC) & \(\text{ms}(\text{AC})/\text{msE}_{S}\) \\ AD & 1 & ms(AD) & \(\text{ms}(\text{AD})/\text{msE}_{S}\) \\ ABC & 1 & ms(ABC) & \(\text{ms}\text{ABC}/\text{msE}_{S}\) \\ \(ABD\) & 1 & ms(ABD) & \(\text{ms}(\text{ABD})/\text{msE}_{S}\) \\ \(ACD\) & 1 & ms(ACD) & \(\text{ms}(\text{ACD})/\text{msE}_{S}\) \\ Split-plot error & 12 & msE\({}_{S}\) & \\ Total & 31 & & \\ \hline \end{tabular}
\end{table}
Table 9.8: Outline analysis of variance table for a split-plot confounded \(2^{4}\) experiment in 8 whole plots of size 4\[Y_{i\mu jk} = \mu+\alpha_{i}+\epsilon_{iu}^{W}\] \[+\beta_{j}+\gamma_{k}+(\alpha\beta)_{lj}+(\alpha\gamma)_{ik}+( \beta\gamma)_{jk}+(\alpha\beta\gamma)_{ijk}+\epsilon_{jk(iu)}^{S}\,,\] \[\epsilon_{iu}^{W}\sim N(0,\,\sigma_{W}^{2})\,,\;\;\;\epsilon_{jk( iu)}^{S}\sim N(0,\,\sigma_{S}^{2})\,,\] \[\epsilon_{iu}^{W}\,\,\text{'s}\,\text{and}\,\epsilon_{jk(iu)}^{S} \text{'s}\,\text{are all mutually independent,}\] \[i=1,\,2;\;\;u=1,\,\ldots,\,8;\;\;j=1,\,2;\;\;k=1,\,2,\,3,\,4\,,\]

This is analogous to model (19.2.1), except: (i) this model excludes block effects (\(s=1\)); (ii) it includes the factorial effects \(\gamma_{k}\), (\(\alpha\gamma)_{ik}\), (\(\beta\gamma)_{jk}\), and (\(\alpha\beta\gamma)_{ijk}\) associated with factor \(C\), all estimated as split-plot differences; and (iii) there is no replication of treatments within whole plots (\(m=1\)).

#### Analysis of Variance

The analysis of variance table for the UAV experiment, given in Table 19.10, is similar to the one in Table 19.4 for the oats experiment, except for the following. There are no block effects, so the whole-plot error is obtained by subtraction as

\[\text{ss}E_{W}=\text{ss}W-\text{ss}A\,,\]

with the corresponding degrees of freedom adjusted accordingly. Also, more treatment effects are involved in the split-plot analysis so the error sum of squares, obtained by subtraction of other effect sums of squares from the total sum of squares, is

\begin{table}
\begin{tabular}{c c|c c c|c c c c} \hline \hline \multicolumn{2}{c}{\(B\) (Similarity)} & \multicolumn{4}{c}{1} & \multicolumn{4}{c}{2} \\ \cline{3-10} \multicolumn{2}{c}{\(C\) (Complexity)} & 1 & 2 & 3 & 4 & 1 & 2 & 3 & 4 \\ \hline \(A\) (Cue) & \(W\) (Subject) & & & & & & & & \\ \hline
1 & 1 & 29 & 28 & 49 & 46 & 36 & 35 & 42 & 48 \\  & 2 & 26 & 26 & 53 & 42 & 35 & 40 & 46 & 44 \\  & 3 & 33 & 25 & 45 & 56 & 34 & 36 & 40 & 40 \\  & 4 & 27 & 28 & 44 & 47 & 36 & 32 & 50 & 54 \\  & 5 & 31 & 26 & 47 & 48 & 33 & 36 & 44 & 60 \\  & 6 & 28 & 27 & 51 & 41 & 31 & 34 & 38 & 43 \\  & 7 & 34 & 28 & 57 & 44 & 34 & 32 & 49 & 35 \\  & 8 & 25 & 35 & 50 & 54 & 35 & 50 & 45 & 48 \\ \hline
2 & 1 & 15 & 13 & 16 & 18 & 21 & 18 & 20 & 21 \\  & 2 & 12 & 11 & 19 & 22 & 18 & 19 & 25 & 22 \\  & 3 & 14 & 13 & 21 & 19 & 25 & 23 & 21 & 23 \\  & 4 & 18 & 16 & 17 & 20 & 24 & 27 & 25 & 24 \\  & 5 & 15 & 15 & 18 & 21 & 19 & 20 & 21 & 21 \\  & 6 & 13 & 16 & 19 & 17 & 21 & 22 & 23 & 25 \\  & 7 & 17 & 18 & 20 & 16 & 22 & 23 & 27 & 24 \\  & 8 & 14 & 14 & 16 & 19 & 20 & 21 & 22 & 22 \\ \hline \hline \end{tabular} _Source Mahadevan (2009). Copyright © 2009 Sriram Mahadevan. Reprinted with permission_

\end{table}
Table 19.9: Split-plot design and times (in seconds) for the UAV experiment: situation awareness perception in the primary task \[\text{ss}E_{S}=\text{sstot}-\text{ss}W-\text{ss}B-\text{ss}C-\text{ss}(\text{AB})- \text{ss}(\text{AC})-\text{ss}(\text{BC})-\text{ss}(\text{ABC})\,.\]

Factor \(A\) is tested relative to whole-plot error, while the other treatment effects are tested relative to the split-plot error. As one can see from the \(p\)-values in Table 19.10, all treatment main and interaction effects are significant at the individual \(\alpha=.01\) levels, except for the ABC interaction which has a \(p\)-value slightly larger than \(.01\).

#### Multiple Comparisons

The experimenter was interested in the main effect of cue, averaged over the other factors; that is,

\[\alpha_{1}^{*}-\alpha_{2}^{*}=[\alpha_{1}+(\overline{\alpha\beta})_{1.}+( \overline{\alpha\gamma})_{1.}+(\overline{\alpha\beta\gamma})_{1..}]-[\alpha_{2 }+(\overline{\alpha\beta})_{2.}+(\overline{\alpha\gamma})_{2.}+(\overline{ \alpha\beta\gamma})_{2.}],\]

comparing the effects of the two cue conditions, averaging over combinations of levels of similarity and complexity. Paralleling the discussion in Sect. 19.3: the least squares estimate of the main effect of cue is

\[\hat{\alpha}_{1}^{*}-\hat{\alpha}_{2}^{*}=\overline{y}_{1...}-\overline{y}_{2...}=39.4531-19.3906=20.0625\text{ seconds};\]

also, \(\text{Var}(\overline{Y}_{1...}-\overline{Y}_{2...})=\text{Var}[(\overline{ \epsilon}_{1.}^{W}+\overline{\epsilon}_{\cdot(1.}^{S}))-(\overline{\epsilon}_ {2.}^{W}+\overline{\epsilon}_{\cdot(2.}^{S}))]=2(\sigma_{W}^{2}/8+\sigma_{S}^{2 }/64)=\sigma_{W}^{2}/4+\sigma_{S}^{2}/32\), and this is estimated by \(\text{ms}E_{W}/32\). So, with 99% confidence,

\[\alpha_{1}^{*}-\alpha_{2}^{*} \in \left((\overline{y}_{1..}-\overline{y}_{2...})\,\pm\,t_{14,0.005 }\sqrt{\text{ms}E_{W}/32}\,\right)\] \[= \left(20.0625\,\pm\,2.977\sqrt{18.58/32}\,\right)\] \[= \left(20.0625\,\pm\,2.2684\right)=\left(17.7941,\,\,22.3309\right).\]

Hence, with 99% confidence, the main effect of cue is between 17.7941 and 22.3309 seconds so, on average, operators using the enhanced user interface spend between 17.7941 and 22.3309 seconds less time to perform the requested situation awareness perception tasks in the primary task than do operators using the baseline user interface.

\begin{table}
\begin{tabular}{c c c c c c} \hline Source of variation & Degrees of freedom & Sum of square & Mean square & Ratio & \(p\)-value \\ \hline \(A\) (cue) & 1 & 12880.13 & 12880.13 & 693.30 & 0.0001 \\ Whole-plot error & 14 & 260.09 & 18.58 & & \\ \hline Whole-plot total & 15 & 13140.22 & 876.01 & & \\ \(B\) (similarity) & 1 & 457.53 & 457.53 & 34.57 & 0.0001 \\ \(C\) (complexity) & 3 & 2470.03 & 823.34 & 62.22 & 0.0001 \\ \(\text{AB}\) & 1 & 98.00 & 98.00 & 7.41 & 0.0077 \\ \(\text{AC}\) & 3 & 1177.94 & 392.65 & 29.67 & 0.0001 \\ \(\text{BC}\) & 3 & 351.28 & 117.09 & 8.85 & 0.0001 \\ \(\text{ABC}\) & 3 & 153.31 & 51.10 & 3.86 & 0.0117 \\ Split-plot error & 98 & 1296.91 & 13.23 & & \\ \hline Total & 127 & 19145.22 & & & \\ \hline \end{tabular}
\end{table}
Table 19.10: Analysis of variance for UAV experiment Given the significant main effect of cue, coupled with the \(p\)-value of 0.0117 for the ABC interaction, the experimenter decided to also investigate the simple pairwise differences comparing the effect of cue at each of the eight combinations of the other two factors. For each such combination \(jk\) of \(BC\), the estimator of the simple pairwise difference

\[[\alpha_{1}+(\alpha\beta)_{1j}+(\alpha\gamma)_{1k}+(\alpha\beta\gamma)_{2jk}]-[ \alpha_{2}+(\alpha\beta)_{2j}+(\alpha\gamma)_{2k}+(\alpha\beta\gamma)_{2jk}] \tag{19.6.17}\]

is \(\overline{Y}_{1.jk}-\overline{Y}_{2.jk}\), with variance

\[\text{Var}[(\overline{\epsilon}_{1}^{W}+\overline{\epsilon}_{jk(1,)}^{S})-( \overline{\epsilon}_{2\cdot}^{W}+\overline{\epsilon}_{jk(2,)}^{S})]=2(\sigma_ {W}^{2}/8+\sigma_{S}^{2}/8)=(\sigma_{W}^{2}+\sigma_{S}^{2})/4.\]

These simple pairwise differences are neither within- nor between-whole-plot comparisons, so a composite variance estimator is needed. Now, \(E[MSE_{S}]=\sigma_{S}^{2}\). Also, one can show that \(E[MSE_{W}]=8\sigma_{W}^{2}+\sigma_{S}^{2}\), (by rule 17 of Sect. 17.8.1, there being 8 observations on each whole plot). So, the variance estimate is

\[(\text{msE}_{W}+7\text{msE}_{S})/32=(18.578+7(13.234))/32\approx 3.4755,\]

with estimated standard error 1.8643 obtained as the square root. The degrees of freedom associated with this variance estimate is computed using Satterthwaite's approximation as follows:

\[\text{d}f=\frac{(\text{msE}_{W}+7\text{msE}_{S})^{2}}{(\text{msE}_{W})^{2}/14+ (7\text{msE}_{S})^{2}/98}=\frac{12,369}{24.6533+87.5659}\approx 110\,.\]

So for example, an individual 99% confidence interval for (19.6.17) has minimum significant difference \(\text{msd}=(t_{110,0.005})(1.8643)=(2.621)(1.8643)\approx 4.8863\). The corresponding simple pairwise difference estimates are as follows,

\[\frac{jk}{\overline{y}_{.1jk}-\overline{y}_{.2jk}}\text{14.375 13.375 31.250 28.250 13.000 15.250 21.250 23.750}\]

where levels 1 and 2 of \(B\) are similar and dissimilar, respectively, and levels 1-4 of \(C\) are simple-simple, simple-complex, complex-simple, and complex-complex, respectively. Since each of these simple pairwise difference estimates exceeds the minimum significant difference 4.8863 and is positive, the enhanced user interface provides significant mean time reductions in performing the requested situation awareness perception tasks in the primary task for each combination of task similarity and task complexity. The overall significance level for testing these eight differences would have been at most 0.08, had these comparisons been preplanned. While they perhaps were not, one can also show that each of these comparisons is significantly nonzero with a \(p\)-value of less than 0.0001 when tested individually, and so one can feel rather confident that the effects are real.

### A Real Experiment--Mobile Computing Field Study

Mary Mc. Wesler (2001) conducted a field experiment to study the effective use of mobile computing devices for real-time navigation and situation awareness, with applications in the military domain. One goal of the experiment was to study the effects of display type and visual presentation format on navigational performance, taking information garnered from laboratory studies and putting it to the test in more realistic field studies. Two display types (factor \(A\)) were studied: a handheld, headdown

[MISSING_PAGE_FAIL:733]

Furthermore, construction of the design involved various pseudofactors. For example, the factor path (_P_) has been represented by pseudofactors: path direction \(P\)2 at two levels, corresponding to using a path frontwards (_P_2 = 0, for paths 1-3) or backwards (_P_2 = 1, for paths 4-6); and \(P\)3 at three levels, corresponding to the three paths used. The corresponding effects of \(P\)2, \(P\)3 and \(P\)2_P_3 are modeled by the parameters (_ph_2)_q_2, (_ph_3)_q_3, and (_ph_2_ph_3)_q_2\(q\)3, respectively. Likewise, the factor run order (_O_) has been represented by pseudofactors: \(O\)2 at two levels, corresponding to runs on day 1 (_O_2 = 0, for runs 1-3) or day 2 (_O_2 = 1, for runs 4-6); and \(O\)3 at three levels, corresponding to the three runs on a given day. The effects corresponding to \(O\)2, \(O\)3 and \(O\)2_O_3 are modeled by the parameters (_ph_2)_r_2, (_ph_3)_r_3, and (_ph_2_ph_3)_r_2\(r\)3, respectively.

Since each subject makes the first three runs on one day and the other three on a second day, one degree of freedom for run order corresponding to \(O\)2 is confounded with days (i.e. whole plots). Also, since paths 1-3 are always used on one day for each subject and paths 4-6 on the other day, the one degree of freedom for path direction corresponding to \(P\)2 is also confounded with days.

Consequently, the between-whole-plot comparisons consist of: main effects of display type \(A\), subject main effects, the path direction effect \(P\)2, and the run order effect \(O\)2. Within-whole-plot comparisons include: main effects of display format \(B\), _AB_ interaction effects, the path effects \(P\)3 and \(P\)2_P_3, and the run order effects \(O\)3 and \(O\)2_O_3.

#### Analysis of Variance

Recall, one observation is missing since one of the subjects traversed one of the paths in the wrong direction from what was intended. Consequently, the resulting 71-run experiment deviates modestly from the balanced 72-run experiment that was planned, complicating the data analysis, since the standard formulas for a balanced design are no longer applicable. Direct analysis of the 71 observations collected is an option, and it will be illustrated using the SAS and R software packages in Sects. 19.8.4

\begin{table}
\begin{tabular}{l|r r r r r r|r r r r r} \hline Subj & \multicolumn{6}{c|}{Day 1} & \multicolumn{6}{c}{Day 2} \\ \cline{2-11}  & \multicolumn{2}{c}{Run 1} & \multicolumn{2}{c}{Run 2} & \multicolumn{2}{c}{Run 3} & \multicolumn{2}{c}{Run 4} & \multicolumn{2}{c}{Run 5} & \multicolumn{2}{c}{Run 6} \\ \cline{2-11}  & \multicolumn{2}{c}{PAB} & \multicolumn{2}{c}{RMSE} & \multicolumn{2}{c}{PAB} & \multicolumn{2}{c}{RMSE} & \multicolumn{2}{c}{PAB} & \multicolumn{2}{c}{RMSE} & \multicolumn{2}{c}{PAB} & \multicolumn{2}{c}{RMSE} & \multicolumn{2}{c}{PAB} & \multicolumn{2}{c}{RMSE} \\ \hline
1 & 111 & 49.321 & 212 & 24.386 & 313 & 37.680 & 421 & 34.291 & 522 & 32.053 & 623 & 43.121 \\
2 & 213 & 45.469 & 311 & 24.224 & 112 & 29.063 & 523 & 32.020 & 621 & 33.478 & 422 & 36.942 \\
3 & 312 & 20.378 & 113 & 47.680 & 211 & 39.962 & 622 & 19.876 & 423 & 37.471 & 521 & 27.410 \\
4 & 121 & 50.088 & 222 & 19.010 & 323 & 28.749 & 411 & 41.306 & 512 & 21.924 & 613 & 41.469 \\
5 & 223 & 27.452 & 321 & 46.204 & 122 & 42.188 & 513 & 28.919 & 611 & 24.599 & 412 & 28.361 \\
6 & 322 & 73.913 & 123 & 59.856 & 221 & 73.709 & 612 & 32.315 & 413 & 80.809 & 511 & 36.911 \\
7 & 421 & 45.506 & 522 & 40.380 & 623 & 37.135 & 111 & 54.271 & 212 & 26.685 & 313 & 26.076 \\
8 & 523 & 29.368 & 621 & 34.627 & 422 & 27.021 & 213 & 33.799 & 311 & 43.408 & 112 & 40.724 \\
9 & 622 & 19.946 & 423 & 36.251 & 521 & 29.726 & 312 & 26.041 & 113 & 53.162 & 211 & 27.546 \\
10 & 411 & 77.787 & 512 & 66.956 & 613 & 51.114 & 121 & 67.176 & 222 & 38.774 & 323 & 48.602 \\
11 & 513 & 26.584 & 611 & 41.038 & 412 & 47.183 & 223 & 37.914 & 321 & 30.026 & 122 & 44.577 \\
12 & 612 & 31.994 & 413 & 35.671 & 511 & 30.146 & 322 &. & 123 & 58.481 & 221 & 62.659 \\ \hline \end{tabular} _Source_ Wesler (2001). Copyright © 2001 Mary Mc. Wesler. Research was performed under U.S. Army Research Laboratory, Federated Laboratory Research Consortium (DAAL01-96-0003) directed by Mr. Bernie Corona. Reprinted with permission

\end{table}
Table 19.11 Mobile computing field study: root mean square error (RMSE) data for each subject (Subj), day, run order, and path-treatment combination (PAB), with one observation missing and 19.9.4, respectively. Another option, illustrated here, is the following traditional remedy involving the estimation of missing values.

Given the missing observation, a standard approach is to fit the intended model using the 71 observations collected, estimate the missing value, then analyze the data as a 72-run experiment including the estimated value as if not missing, except making the following accommodation. With one observation missing, there is one fewer degrees of freedom for the analysis. In comparing the results when using software to fit model (19.7.18) with the 71 and 72 observations, respectively, the analysis of variance for the 71-run fit (not shown here) yields one fewer degrees of freedom for split-plot error--namely, 35 rather than 36. So, the same effects are estimable in each case, but the lost observation results in one fewer split-plot error degrees of freedom. Consequently, in analyzing the 72-run data set including the estimated missing value, the number of split-plot error degrees of freedom should be reduced by one. That said, the reduction from 36 to 35 split-plot error degrees of freedom has negligible impact on the analysis, as corresponding critical values are nearly the same with this many error degrees of freedom, so such an adjustment is not always made in the analyses presented here.

Recall, the experimental plan was a split-plot design, with a single response on each independent variable for each of the six treatment combinations per subject. The subjects served as blocks in the design, days as whole plots, and the 72 runs as split plots. The analysis of variance is given in Table 19.12 and is analogous to the one in Table 19.4 (p. 710) for the oats split-plot experiment.

The experimenter planned to test each treatment effect using a 5% significance level. As one can see from the _p_-values in Table 19.12, the interaction between display type and visual presentation format is not significant (\(p=0.4038\)) using \(\alpha=0.05\), nor is the main effect of display type (\(p=0.6311\)), but the main effect of visual presentation format is significant (\(p=0.0179\)) at the 5% level.

As one can also see from the _p_-values, there are significant effects of path (i.e. \(P_{3}\) and \(P_{2}\,P_{3}\) collectively) but not of \(P_{2}\), so the three paths used had significant differences either themselves or interacting with path direction, but the path direction was not significant. Also, the subject and day effects were modestly significant with \(p=0.0594\) and \(p=0.0483\), respectively, but order effects were not significant.

\begin{table}
\begin{tabular}{l c c c c c} \hline Source of variation & Degrees of freedom & Sum of square & Mean square & Ratio & _p_-value \\ \hline Subject & 11 & 6230.92 & 566.45 & 2.92 & 0.0594 \\ Order (\(O_{2}\)) & 1 & 30.48 & 30.48 & 0.16 & 0.7012 \\ Path (\(P_{2}\)) & 1 & 379.34 & 379.34 & 1.95 & 0.1957 \\ \(A\) (display) & 1 & 47.95 & 47.95 & 0.25 & 0.6311 \\ Whole-plot error (day) & 9 & 1747.52 & 194.17 & 2.17 & 0.0483 \\ \hline Whole-plot total & 23 & 8436.21 & & & \\ Order (\(O_{3}\), \(O_{2}\,O_{3}\)) & 4 & 56.56 & 14.14 & 0.16 & 0.9581 \\ Path (\(P_{3}\), \(P_{2}\,P_{3}\)) & 4 & 1941.84 & 485.46 & 5.42 & 0.0016 \\ \(B\) (VPF) & 2 & 806.44 & 403.22 & 4.51 & 0.0179 \\ _AB_ & 2 & 166.48 & 83.24 & 0.93 & 0.4038 \\ Split-plot error & 36 & 3222.00 & 89.50 & & \\ \hline Total & 71 & 14629.54 & & & \\ \hline \end{tabular}
\end{table}
Table 19.12: Analysis of variance for the mobile computing field study 

#### Multiple Comparisons

For each treatment effect found to be significant in the analysis of variance, the experimenter followed up with multiple comparisons using simultaneous 95% confidence intervals. Since only the main effect of visual presentation format was significant, Tukey's method was used to compare the three formats.

The estimated pairwise comparisons are:

\[\begin{array}{l}\hat{\beta}_{1}^{*}-\hat{\beta}_{2}^{*}=\overline{y}_{...1..}- \overline{y}_{...2..}=7.792\,,\\ \hat{\beta}_{3}^{*}-\hat{\beta}_{2}^{*}=\overline{y}_{...3..}-\overline{y}_{... 2..}=6.102\,,\\ \hat{\beta}_{1}^{*}-\hat{\beta}_{3}^{*}=\overline{y}_{...1..}-\overline{y}_{... 3..}=1.690\,.\end{array}\]

Since the corresponding \(F\)-test uses the split-plot mean squared error as the denominator and the 72-run design is balanced, the estimated standard error of each pairwise comparison also utilizes the split-plot mean squared error. Also, since each treatment sample mean is the average of 24 observations, the variance estimate of each pairwise contrast is \(2msE_{S}/24=89.5/12\approx 7.4583\). So, the minimum significant difference for each comparison is \((q_{3,35,0.05}/\sqrt{2})\sqrt{7.4583}\approx 6.69\), for \(q_{3,35,0.05}=3.465\), with the split-plot error degrees of freedom having been reduced by one to 35 because of the missing value. Hence, visual presentation format 1 (second person egocentric) has a significantly larger mean RMSE from the intended path than does visual presentation format 2 (birds' eye view egocentric), indicating that format 2 is preferable. The other two pairwise comparisons are not significantly different, though format 3 also does substantially worse than format 2. The reader may verify for example that the minimum significant difference would only be 5.89 for simultaneous 90% confidence intervals, in which case visual presentation format 2 would be significantly better than both of the other formats.

#### Analysis as a Split-Split-Plot Design

The original experimental plan was a split-plot design, with a single response on each independent variable for each of the six treatment combinations per subject. The subjects served as blocks in the design, days as whole plots, and the 72 runs as split plots. The split-plot analysis was provided in Sects. 19.7.1 and 19.7.2.

It subsequently became of interest to study whether the effectiveness of the display types (factor \(A\)) or visual presentation formats (factor \(B\)) depended on the direction being navigated. One could consider utilizing the data for this purpose because, as noted previously, each path was roughly square in shape with north, south, east, and west legs, (coded 1-4, respectively). Furthermore, data was available on the independent variables for each of the four legs of each run. It was ultimately decided to analyze the data as a split-split-plot design, including leg direction as a factor, treating each leg of a run as a split-split-plot. In that regard, one should note that leg order may also have an effect and may be confounded with leg direction. Nonetheless, it was decided to include leg direction rather than leg order as a factor, since previous studies indicate that leg direction is a stronger independent variable, noting for example that participants in another study had difficulty cognitively transposing information from a fixed north-up display while traversing a south-bound leg of a test course. For this reason, visual display format by leg direction interaction effects were also included in the model.

Adding leg direction factor \(D\) with effects \(\delta_{t}\) (\(t=1,\ldots,4\)), visual presentation format by leg direction interaction effects \((\beta\delta)_{jt}\), and split-split-plot errors \(\epsilon_{t(dhijqr)}^{\text{SS}}\) to the split-plot design model (19.7.18), the split-split-plot design model is as follows.

\[\begin{array}{l}Y_{dhijqrt}=\mu+\theta_{h}+\alpha_{i}+(\phi_{2})_{q_{2}}+(\rho_{ 2})_{r_{2}}+\epsilon_{d(h)}^{W}\\ \qquad\qquad\qquad\qquad\qquad\qquad+\beta_{j}+(\alpha\beta)_{ij}+(\phi_{3})_{q_ {3}}+(\phi_{2}\phi_{3})_{q_{2}q_{3}}\\ \qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad+(\rho_{3})_{r_{3}}+(\rho_{2} \rho_{3})_{r_{2}r_{3}}+\epsilon_{ijq_{3}r_{3}(dhu_{2}r_{2})}^{S}\\ \qquad\qquad\qquad\qquad\qquad+\delta_{t}+(\beta\delta)_{ji}+\epsilon_{t(dhijqr )}^{SS}\,,\\ \theta_{h}\sim N(0,\sigma_{\theta}^{2})\,,\quad\epsilon_{d(h)}^{W}\sim N(0, \sigma_{W}^{2})\,,\\ \epsilon_{ijq_{3}r_{3}(dhu_{2}r_{2})}^{S}\sim N(0,\sigma_{S}^{2})\,,\quad \epsilon_{t(dhijqr)}^{SS}\sim N(0,\sigma_{\text{SS}}^{2})\\ \theta_{h}\ \text{'s},\ \epsilon_{d(h)}^{W}\ \text{'s},\ \epsilon_{ijq_{3}r_{3}(dhu_{2}r_{2})}^{S}\ \text{'s},\ \epsilon_{t(dhijqr)}^{SS}\ \text{'s}\ \text{are all mutually independent,}\\ \qquad\qquad\qquad\qquad\qquad d=1,2;\ \ h=1,\ldots,12;\ \ i=1,2;\ \ j=1,2,\ 3;\\ q=3(q_{3}-1)+2(q_{2}-1)+1,\ \text{for}\ q_{2}=1,2,\ \ q_{3}=1,2,\ 3;\\ r=3(r_{3}-1)+2(r_{2}-1)+1,\ \text{for}\ r_{2}=1,2,\ \ r_{3}=1,2,\ 3;\\ t=1,2,3,4.\end{array}\]

The data for the split-split-plot design consist of the RMSE values for each of the four legs of each run. The data, shown in Table 19.13, now include four missing observations, since the one missing run of the split-plot design includes four legs. Estimating these four missing values, the analysis of variance is provided in Table 19.14. As the reader may verify, if the model is fit without the estimated missing values, one loses one degree of freedom for split-plot error and three for split-split-plot error, but adjusting the corresponding degrees of freedom from 36 to 35 and from 207 to 204, respectively, would have minimal impact on any analysis. The first two sections of Table 19.14 duplicate information given in Table 19.12 for the split-plot analysis--the degrees of freedom, ratio, and \(p\)-value is the same for each source so conclusions are unchanged, though the sum of squares and mean squares are different since the data are observations on legs of runs, not runs. The visual presentation format by leg direction interaction is not significant, but leg direction is significant with \(p=0.0117<0.05\). Hence, the experimenter compared the leg direction effects using simultaneous 95% confidence intervals obtained via Tukey's method.

The estimated pairwise comparisons are:

\[\begin{array}{l}\hat{\delta}_{2}^{*}-\hat{\delta}_{1}^{*}=\overline{y}_{. \ldots 2}-\overline{y}_{.\ldots 1}=2.8645\,,\quad\hat{\delta}_{4}^{*}-\hat{ \delta}_{1}^{*}=\overline{y}_{.\ldots.4}-\overline{y}_{.\ldots.1}=1.5666\,,\\ \hat{\delta}_{2}^{*}-\hat{\delta}_{3}^{*}=\overline{y}_{.\ldots.2}-\overline{y}_{.\ldots.3}=2.0217\,,\quad\hat{\delta}_{4}^{*}-\hat{\delta}_{3}^{*}=\overline{y}_{. \ldots.4}-\overline{y}_{.\ldots.3}=0.7239\,,\\ \hat{\delta}_{2}^{*}-\hat{\delta}_{4}^{*}=\overline{y}_{.\ldots.2}-\overline{y}_{.\ldots.4}=1.2979\,,\quad\hat{\delta}_{3}^{*}-\hat{\delta}_{1}^{*}=\overline{y}_{. \ldots.3}-\overline{y}_{.\ldots.1}=0.8427\,.\end{array}\]

Since the corresponding \(F\)-test uses the (split-split-plot) mean square error as the denominator and the 288-leg design is balanced, the estimated standard error of each pairwise comparison also utilizes the mean squared error. Also, since each treatment sample mean is the average of 72 of the 288 observations, the variance estimate of each pairwise contrast is \(2(\text{ms}E)/72=2(28.19)/72\approx 0.7831\). So, the minimum significant difference for each comparison is \((q_{4,204,0.05}/\sqrt{2})\sqrt{0.7831}\approx 2.27\), for \(q_{3,204,0.05}\approx q_{3,\infty,0.05}=3.63\), with the split-plot error degrees of freedom having been reduced by three to 204 because of the missing values. Hence, mean RMSEis significantly greater for leg direction 2 (south) than for leg direction 1 (north). This provides some credence to the observation in another study that participants had difficulty cognitively transposing information from a fixed north-up display while traversing a south-bound leg of a test course.

[MISSING_PAGE_FAIL:738]

#### Design Construction

In this section we discuss construction of the split-plot design used in the mobile computing field study. The design used (Table 19.11, p. 719) is a fractional factorial design with some day effects confounded with blocks (subjects). The design construction illustrated here utilizes the techniques of Chaps. 13 and 14, including the use of pseudofactors introduced in Sect. 14.3. The first step in the design construction is to determine an appropriate fraction of the non-blocking factors, then some effects (and their aliases)--some day effects in this case--are chosen to be confounded with blocks. Before constructing the fraction, here are some preliminary considerations.

Recall, the basic experiment was 2 x 3 in the treatment factors \(A\) (display type) and \(B\) (visual presentation format), the purpose being accurate comparison of the treatment effects. Multiple subjects were to be recruited for the study based on appropriate protocols. It was pragmatically reasonable to have each subject make three runs per day and to involve each subject for two days. This would allow each subject to be assigned each of the six treatment combinations once, providing a balanced design with treatment comparisons as within-subject comparisons, good for precision. Since day-to-day variation was anticipated to be relatively small and simplicity of the experimental design is desirable, it was decided to confound main effects of \(A\) with days. Viewing subjects as blocks, days as whole plots, and runs as split plots, levels of \(A\) would be assigned to whole plots and levels of \(B\) to split plots.

There remains the question of how many days 2\(h\) to include in the experiment, (or equivalently, how many subjects, _h_). Consider this question from the viewpoint of design construction rather than as a sample size question, to see how small an appropriate design can be given the circumstances. For a 2 x 3 experiment, standard confounding techniques can be applied if the number of subjects is a power of two times a power of three, \(h\) = 2\(m\)3_n_ say, so represent the subjects factor \(S\) by pseudofactors \(S\)2_i_ (_i_ = 1,..., _m_) each at two levels and pseudofactors \(S\)3_j_ (_j_ = 1,..., _n_) each at three levels, where the number of each remains to be determined. The other nuisance sources of variation are days \(D\), with two days for each subject, and run order \(O\) and path \(P\) each at six levels. Let \(O\)2, \(O\)3, \(P\)2 and \(P\)3 be pseudofactors for run order and path, with the subscript indicating the number of levels. Likewise,

\begin{table}
\begin{tabular}{c c c c c c} \hline Source of variation & Degrees offeredom & Sum ofsquare & Meansquare & Ratio & _p_-value \\ \hline Subject & 11 & 1557.78 & 141.62 & 2.92 & 0.0594 \\ O2 & 1 & 7.62 & 7.62 & 0.16 & 0.7011 \\ P2 & 1 & 94.84 & 94.84 & 1.95 & 0.1957 \\ Display & 1 & 11.99 & 11.99 & 0.25 & 0.6311 \\ Whole-plot error (day) & 9 & 436.86 & 48.54 & 2.17 & 0.0483 \\ \hline Whole-plot total & 23 & 2109.09 & & & \\ Order & 4 & 14.15 & 3.54 & 0.16 & 0.9581 \\ Path & 4 & 485.43 & 121.36 & 5.42 & 0.0016 \\ VPF & 2 & 201.60 & 100.80 & 4.51 & 0.0179 \\ VPF*Display & 2 & 41.62 & 20.81 & 0.93 & 0.4038 \\ Split-plot error & 36 & 805.47 & 22.37 & 0.79 & 0.7934 \\ \hline Split-plot total & 71 & 3657.36 & & & \\ LegDir & 3 & 317.98 & 105.99 & 3.76 & 0.0117 \\ VPF*LegDir & 6 & 34.85 & 5.81 & 0.21 & 0.9746 \\ Split-split-plot error & 207 & 5835.85 & 28.19 & & \\ \hline Total & 287 & 9846.03 & & & \\ \hline \end{tabular}
\end{table}
Table 19.14: Analysis of variance for the mobile computing field study

[MISSING_PAGE_FAIL:740]

\[\begin{array}{lcl}I_{3}&=&B_{3}D_{31}O_{3}^{2}&=&B_{3}^{2}D_{31}^{2}O_{3}\\ =&D_{31}O_{3}P_{3}^{2}&=&B_{3}D_{31}^{2}P_{3}^{2}&=&B_{3}^{2}O_{3}^{2}P_{3}^{2}\\ =&D_{31}^{2}O_{3}^{2}P_{3}&=&B_{3}O_{3}P_{3}&=&B_{3}^{2}D_{31}P_{3}\;,\end{array}\]

involving the contrasts \((B;B^{2}),(B_{3}D_{31}O_{3}^{2};B_{3}^{2}D_{31}^{2}O_{3}),(D_{31}O_{3}P_{3}^{2};D_{31}^{2}O_{3}^{2}P_{3}),(B_{3}D_{31}^{2}P_{3}^{2};B_{3}^{2}D_{31}P_{3})\), and \((B_{3}O_{3}P_{3};\,B_{3}^{2}O_{3}^{2}P_{3}^{2})\).

Since the effects of \(B_{3},\,O_{3}\) and \(P_{3}\) are not aliased with other main effects, and in particular not with day effects, they are estimable within-day comparisons under a main-effects model, free of day-to-day (i.e. whole-plot-to-whole-plot) variation, as desired.

With these choices used by the experimenter, using only one 3-level day pseudofactor \(D_{31}\), the fraction of the 3-level pseudofactors is a 1/9 resolution III fraction involving nine runs, including three days and three runs per day (corresponding to the nine combinations of the free variables \(D_{31}\) and \(O_{3}\)).

The 2-level and 3-level fractions are combined by pairing each of the eight 2-level pseudofactor combinations in the 2-level fraction with each of the nine 3-level pseudofactor combinations in the 3-level fraction, providing a _composite fractional factorial design_ with 72 pseudofactor combinations or runs, 24 days, six run orders, and six paths. The corresponding _composite defining relation_ includes 72 terms, including each product of one of the eight terms from the defining relation of the 2-level fraction with one of the nine terms from the defining relation of the 3-level fraction. In short, letting \(I_{6}=I_{2}\times I_{3}\), and treating \(I_{2}\) and \(I_{3}\) as multiplicative identities, the composite defining relation is as follows.

\[\begin{array}{c|c}\times&I_{2}&=D_{20}O_{2}&=\ldots=D_{20}D_{21}P_{2}\\ \hline I_{3}&I_{6}&=D_{20}O_{2}&=\ldots=D_{20}D_{21}P_{2}\\ =B_{3}D_{31}O_{3}^{2}&=B_{3}D_{31}O_{3}^{2}&=D_{20}O_{2}B_{3}D_{31}O_{3}^{2}&= \ldots=D_{20}D_{21}P_{2}B_{3}D_{31}O_{3}^{2}\\ =B_{3}^{2}D_{31}^{2}O_{3}&=B_{3}^{2}D_{31}^{2}O_{3}&=D_{20}O_{2}B_{3}^{2}D_{31}^{2}O_{3}&=\ldots=D_{20}D_{21}P_{2}B_{3}^{2}D_{31}^{2}O_{3}\\ =&\vdots&=&\vdots&=&\vdots\\ =B_{3}^{2}D_{31}P_{3}&=&B_{3}^{2}D_{31}P_{3}&=D_{20}O_{2}B_{3}^{2}D_{31}P_{3}&=\ldots=D_{20}D_{21}P_{2}B_{3}^{2}D_{31}P_{3}\end{array}\]

This composite defining relation includes each of the terms from the 2-level and 3-level defining relations, indicating for example that days are still aliased with the effects of \(A\), \(O_{2}\) and \(P_{2}\) in the composite fraction, as was the case in the 2-level fraction, so \(A\) and one degree of freedom for each of order and path remain between-day comparisons in the composite fraction. However, the remaining terms in the composite defining relation are the generalized interactions that include terms other than \(I_{2}\) and \(I_{3}\) from each of the 2-level and 3-level defining relations, so they tend to be of higher order. Consequently, one may observe for example that \(AB\) effects are _not_ aliased with day effects, so they are within-day (i.e. within-whole-plot) comparisons. The same is true of the order and path effects except \(O_{2}\) and \(P_{2}\), so order and path each have four degrees of freedom that are within-day comparisons, in addition to each having one degree of freedom that is a between-day (i.e. between-whole-plot) comparison.

Finally, the block design is obtained by confounding the day effects \(D_{21}\), \(D_{22}\) and \(D_{31}\) with subjects, which also confounds the corresponding generalized interactions \(D_{21}D_{22}\), \(D_{21}D_{31}\), \(D_{22}D_{31}\) and \(D_{21}D_{22}D_{31}\), confounding 11 degrees of freedom for days with subjects. The _composite design_ involves 12 subjects and 24 days, with three runs per day, so 72 runs in total. The resulting design is shown in Table 19.11, with factor levels in the table obtain as follows: \(D=D_{20}+1\) and \(\text{Subj}=6S_{21}+3S_{22}+S_{31}+1\).

In summary, 12 subjects is enough to design the experiment so treatment effects are not aliased with subject, path, or run order, though effects of \(A\) (display type) are aliased with days (whole plots), as is one degree of freedom each for order and path. One might say that the design is of resolution III in the fixed effects but of resolution II when random effects are considered.

The experimenter determined that this was a large enough experiment, with each pairwise comparison of visual presentation formats being estimable with variance \(\sigma_{S}^{2}/12\), and with the pairwise comparison of display types being estimable with variance \((3\sigma_{W}^{2}+\sigma_{S}^{2})/18\).

If a larger design was needed, one could be obtain by inclusion of additional free variables \(D_{2i}\) (\(i>2\)) or \(D_{3j}\) (\(j>1\)) and corresponding additional subject pseudofactors, coupled with an appropriate choice of defining relations to determine all non-free variables in terms of the free variables. For example, to have two replicates of the design obtained above, simply include the additional free variable \(D_{23}\) to double the number of days, include the pseudofactor \(S_{23}\) to double the number of subjects, impose the same constraints as above, and confound \(D_{23}\) with subjects. Alternatively, one could seek a better fraction--namely, either one of higher resolution or, short of that, a fraction with less aliasing together of lower order effects of interest--by inclusion of additional free variables \(D_{2i}\) or \(D_{3j}\) and corresponding subject pseudofactors, coupled with some better choice of defining relations that presumably would involve these additional free variables.

The approach used above to obtain a blocked fractional factorial experiment involved two steps: first obtaining a fraction of the non-blocking factors, then confounding some effects with blocks. Another equivalent approach is simply to obtain an appropriate fraction of all of the factor combinations, including the blocking factors as non-free variables. For example, one could obtain the same blocked fractional factorial design in one step by imposing the same defining relations as above plus the relations \(S_{21}=D_{21}\), \(S_{22}=D_{22}\), and \(S_{31}=D_{31}\).

### 19.8 Using SAS Software

In this section, we illustrate use of the SAS software for analyzing split-plot designs. The analysis of variance approach can be used for balanced data using PROC GLM or PROC MIXED, as illustrated for analysis of the oats experiment in Sect. 19.8.1. In Sect. 19.8.2, the UAV experiment is briefly revisited to illustrate the analysis of simple contrasts using the SLICE statement in PROC MIXED. In Sect. 19.8.3, we introduce a restricted maximum likelihood approach to analysis of split plot designs using PROC MIXED, comparing it to the analysis of variance approach and PROC GLM in the context of the UAV switch experiment--a new example involving a negative variance component estimate. In Sect. 19.8.4, using a subset of the oats data yielding a balanced incomplete block design for the whole-plots factor, PROC MIXED is used to illustrate the recovery of inter-block information. Finally, in Sect. 19.8.5, analysis of unbalanced data is illustrated using PROC MIXED and the restricted maximum likelihood approach for the mobile computing field study, excluding the missing observation from analysis of the split plot design.

#### The Analysis of Variance Approach

The _analysis of variance approach_ to the analysis of mixed models involves: (i) fitting the model by ordinary least squares, treating the random effects as fixed; and (ii) using the expected mean squares to determine unbiased estimates of the variance components. In analyzing a balanced split-plot design by the analysis of variance approach, care needs to be taken with PROC GLM or PROC MIXED in order to obtain the two separate parts of the analysis of variance table, corresponding to 

[MISSING_PAGE_EMPTY:8678]

the sources of variation need to be entered into the model in the same order as in model (19.2.2). The first three terms yield the whole-plot analysis. The whole-plot error term \(\epsilon^{W}_{i(h)}\) is represented by WP(BLOCK)--the nested effect of whole plots within blocks--since it accounts for any whole plot comparisons not yet modeled. The remaining terms provide the split-plot analysis. No term is needed to represent the split-plot error term \(\epsilon^{S}_{j(hi)}\), since this plays the role of the usual error variable, and the corresponding error sum of squares is automatically calculated by the SAS software. The type I analysis is necessary because, with inclusion of WP(BLOCK) in the model, the type III analysis would yield \(\mathit{SSA}=0\) with zero degrees of freedom for \(A\). Otherwise, the type I and type III sums of squares would be the same. Inclusion of the statement

\[\mathtt{RANDOM\ BLOCK\ WP(BLOCK)\ /\ TEST};\]

ensures that the correct denominators are used for all of the hypothesis tests.

The output is shown in Fig. 19.1. The type I sums of squares are listed, but the \(F\)-statistics and \(p\)-values are incorrect for testing the effects of blocks and \(A\), since SAS software uses the split-plot error mean square \(\mathit{MSE}\)throughout. The expected mean squares are listed, and the reader can verify that the error estimate for \(A\) differs from those of \(B\) and \(\mathit{AB}\). The correct hypothesis tests are listed in the bottom half of the output.

One would like to use the LSMEANS statement to obtain standard multiple comparisons procedures. For example, Dunnett's procedure for comparing each level of \(A\) with control level 0 and each level of \(B\) with control level 0 is requested via the LSMEANS statements shown in Table 19.15. Unfortunately, this generates no output for \(A\), because PROC GLM treats all effects as fixed, including the random effects, so concludes that main effects of \(A\) are not estimable. While we have generally avoided use of the MEANS statement for multiple comparisons, since it uses means rather than least squares means, the two are equivalent in this case, since both the whole-plot design and the split-plot design are randomized complete block designs. As such, the MEANS statement can be used to obtain standard multiple comparison procedures for \(A\), while the LSMEANS statement cannot. For example, Dunnett's procedure for comparing each level of \(A\) with control level 0 and each level of \(B\) with control level 0 are obtained via the MEANS statement and the second LSMEANS statement, respectively, shown in Table 19.15. For the MEANS statement, SAS software will use the split-plot term \(\mathit{MSE}\)to estimate standard errors unless told to do otherwise, which would be correct for the \(B\) contrasts but not for the \(A\) contrasts. To use the whole-plot error mean square for the \(A\) contrasts, we include the option \(\mathtt{E}=\mathtt{WP(BLOCK)}\). Partial output is shown in Fig. 19.2. For both factors, note that the SAS software has relabeled the levels starting at 1 rather than 0.

The first call of PROC MIXED in Table 19.15 would generate the same correct information, including only the correct \(F\)-tests for the analysis of variance, and automatically computing correct standard errors for contrasts. The option \(\mathtt{METHOD}=\mathtt{TYPE1}\) calls for a type I analysis. In PROC MIXED, all fixed effects are entered into the model before the random effects, but that is not problematic in this case.

#### Type III Analysis

The second approach to analysis of a split plot design is a _type III analysis_, utilizing the type III sums of squares and corresponding expected mean squares. This approach makes use of the fact that the whole-plot error sum of squares uses the same collective degrees of freedom as any block by whole-plot-treatment interactions deemed negligible. In the oats experiment, with only one whole-plot factor, \(A\), and with the block \(\times A\) interaction deemed negligible, the block \(\times A\) effect represents whole-plot error in the model. In the second call of PROC GLM in Table 19.15, the same sources of variation are entered into the SAS model as in model (19.2.2), but the whole plot error \(\epsilon^{W}_{i(h)}\) is replaced by BLOCK*A--the negligible block \(\times\) whole-plot-treatment interaction. For the type III analysis, the 

[MISSING_PAGE_EMPTY:8680]

order of entry of terms into the SAS model does not matter. The SAS output is not shown, but is identical to that in Fig. 19.1 with WP(BLOCK) replaced by BLOCK*A, and Type I Expected Mean Square replaced by Type III Expected Mean Square. The second call of PROC MIXED in Table 19.15 would generate the same information, but with only the correct \(F\)-tests for the analysis of variance, the option METHOD = TYPE3 calling for a type III analysis.

More generally, suppose the experiment included two whole-plot factors \(A\) and \(B\) and one split-plot factor \(C\), with the AB-combinations assigned to whole plots within blocks constituting a randomized complete block design, and with the levels of \(C\) assigned to split plots within whole plots constituting a randomized complete block design. Then, assuming all block by whole-plot-treatment interactions are negligible, the following SAS statements would provide the analogous type III analysis.

Figure 19.2: Multiple comparisons—the oats split-plot experiment

##### 19.8.2 Simple Contrasts

In this section, we briefly revisit the UAV experiment of Sect. 19.6 to illustrate the analysis of simple contrasts using the SLICE statement in PROC MIXED. The SAS program in Table 19.16 shows how either PROC MIXED or PROC GLM can be used to generate the analyses provided in Sect. 19.6. For example, both procedures generate the analysis of variance in Table 19.10, as well as the 99% confidence interval for the main effect of cue (_A_).

PROC MIXED generally provides more options and functionality for multiple comparisons. For example, the SLICE statement illustrated in the SAS program generates the output in Table 19.17, which includes the information on simple contrasts for cue that was provided in Sect. 19.6.2 (p. 717), comparing the effects of the two levels of cue (_A_) at each of the eight BC combinations. The standard

\begin{table}
\begin{tabular}{c} DATA UAV; \\ INPUT A W B C TIME; \\ LINES; \\
1 1 1 1 29 \\
1 1 1 2 28 \\
1 1 1 3 49 \\
1 1 1 4 46 \\
1 1 2 1 36 \\ : : : :: \\
2 8 2 4 22 \\ : \\ PROC MIXED METHOD = TYPE3; \\ CLASS A W B C; \\ MODEL TIME = A | B | C / DDFM = SAT; \\ RANDOM W(A); \\ LSMEANS A / CL DIFF ALPHA = 0.01; \\
* Compares levels of A at each B*C combination; \\ SLICE A*B*C / SLICEBY = B*C CL DIFF ALPHA = 0.01; \\ ; \\ PROC GLM; \\ CLASS A W B C; \\ MODEL TIME = A | B | C W(A); \\ RANDOM W(A) / TEST; \\ MEANS A / T CLDIFF E = W(A) ALPHA = 0.01; \\
* need PDIFF, else E = mse erroneously; \\ LSMEANS A / CL PDIFF E = W(A) ALPHA = 0.01; \\ \end{tabular}
\end{table}
Table 19.16: SAS program illustrating analysis of simple contrasts—UAV experiment

[MISSING_PAGE_FAIL:748]

as a boundary condition--so these asymptotic properties do not apply for example to a variance component estimator when the estimate is constrained to be zero because the solution to the likelihood equations is negative. Likewise, given a factor with random effects but with few levels observed in an experiment, one should be skeptical of the asymptotic properties of the corresponding variance component estimate. That said, the asymptotic properties of MLEs should usually be reasonably applicable for the analysis of fixed effects unless an experiment is quite small. We will utilize restricted maximum likelihood estimation--a special case of maximum likelihood estimation.

The _restricted maximum likelihood approach_ to fitting a mixed model involves two steps: (i) estimating the variance components by restricted maximum likelihood; then (ii) estimating the fixed effects by _estimated generalized least squares_--namely, treating the variance component estimates as true values, then computing the maximum likelihood estimates of the fixed effects, or equivalently, the _generalized least squares estimates_. To compute restricted maximum likelihood (ReML) estimates of the variance components, the original data is essentially replaced by a maximal set of linearly independent contrasts in the data each with mean zero (i.e. data contrasts the distributions of which do not involve the fixed effects), then the likelihood function of the contrasts is maximized. (Equivalently, one can estimate the fixed effects by ordinary least squares, then maximize the likelihood function of the residuals, the joint distribution of which does not involve the fixed effects. Hence, the restricted maximum likelihood approach is also known as _residual maximum likelihood_.) The ReML estimates of the variance components may be preferable to the usual maximum likelihood estimates, because the ReML estimates are the same as the ANOVA-based estimates if the data are balanced and all variance component estimates are positive. Also, restricted maximum likelihood adjusts in some sense for fixed effects, so often provides unbiased estimates of variance components. A new experiment will be introduced to illustrate the restricted maximum likelihood approach to analysis of split plot designs.

### UAV Switch Experiment

Mahadevan (2009) conducted three experiments to evaluate the performance of a semi-automated computer display system designed to support a human operator's ability to monitor and control the complex dynamic operation of multiple unmanned aerial vehicles (UAVs) when the UAVs are involved in multiple combat-related tasks. His third experiment involved: 16 subjects (factor \(W\)); two alert techniques--a visual alert (\(A=1\)) and an audio-visual alert (\(A=2\)); and two levels of task complexity--a simple primary task coupled with a simple secondary task (\(B=1\)), and a complex primary task coupled with a simple secondary task (\(B=2\)). The experiment was a \(2\times 2\) split-plot design, with subjects as whole plots and two trials per subject as split-plots, with each level of \(A\) assigned to half of the subjects, and with both levels of \(B\) observed once on each subject. Hence, subject is nested within alert type. For each trial, each subject, while working on the primary task, was warned of the secondary task using one of the two alert techniques. One of the response variables measured was the time taken to switch to the secondary task following the alert, and the experimenter was interested in the effect of the nature of the alert (\(A\)) on the mean time to switch from the primary to the secondary task. The data are shown in Table 19.18. The model used by the experimenter is as follows.

\[\begin{array}{c}Y_{luj}=\mu+\alpha_{i}+\epsilon_{iu}^{W}\\ \qquad\qquad\qquad\qquad+\beta_{j}+(\alpha\beta_{ij})+\epsilon_{j(iu)}^{S}\,, \end{array} \tag{19.8.20}\]

\[\begin{array}{c}\epsilon_{iu}^{W}\sim N(0,\sigma_{W}^{2})\,,\;\;\;\;\epsilon _{j(iu)}^{S}\sim N(0,\sigma_{S}^{2})\,,\end{array}\]

\(\epsilon_{iu}^{W}\)'s and \(\epsilon_{j(iu)}^{S}\)'s are all mutually independent,

\[i=1,2;\;\;\;u=1,\ldots,8;\;\;\;j=1,2.\]The SAS program for the UAV switch experiment is shown in Table 19.19. The first calls of PROC GLM and PROC MIXED each fit model (19.8.20), and some of the corresponding output is shown in Fig. 19.3. The random effects term \(W(\texttt{A})\) in each SAS model represents the whole plot errors \(\epsilon_{iu}^{W}\) in model (19.8.20), so \(\sigma_{W(\texttt{A})}^{2}\) in the SAS output corresponds to \(\sigma_{W}^{2}\) in our model. Also, msE in SAS output corresponds to msE\({}_{S}\) in our formulae. PROC MIXED is by default fitting the model by ReML but, because of the NOBOUND option, the variance component estimates are not constrained to be positive. In fact, the whole-plots variance component estimate, \(\hat{\sigma}_{W(\texttt{A})}^{2}=-0.03571\), is negative, matching the estimate one could compute by hand from the PROC GLM output--namely, \(\hat{\sigma}_{W(\texttt{A})}^{2}=[\texttt{ms}(W(\texttt{A}))-\texttt{msE}]/2 \approx-0.036\). Because the data are balanced and the ReML estimates are allowed to be negative, the two procedures provide the same estimates of fixed effects and variance components, the same test results for fixed effects, and the same results for multiple comparisons (not shown).

Consider in comparison the output generated by the second calls of these procedures, shown in Fig. 19.4. PROC MIXED is still fitting model (19.8.20), but the restricted maximum likelihood estimate of \(\sigma_{W(\texttt{A})}^{2}\), now bounded, is zero. Correspondingly, the whole-plots term is effectively removed from the model, with the 14 degrees of freedom associated with it essentially pooled with the 14 degrees of freedom for error. Hence, there are now 28 degrees of freedom for error in the analysis, the (residual) error variance estimate of 3.1205 being the average of ms(W(A)) and msE generated by the first call of PROC GLM. These results match those at the bottom of Fig. 19.4, generated by the second call of PROC GLM, for which the whole-plots term has been removed from the model for sake of illustration. While the multiple comparisons output generated by these procedure calls is not shown, the reader may confirm that the results would also match, as they do for the \(F\)-tests, with both procedures using 28 error degrees of freedom for all contrast standard errors.

The above information begs the question, "What is the correct analysis?" The analyses provided by the first calls of PROC GLM and PROC MIXED are arguably correct, except one should use the multiple comparisons results from PROC MIXED in any instances where PROC GLM uses incorrect standard errors. Otherwise, the SAS procedures correctly implement the planned statistical analyses using the proposed model. If the model is reasonable and appropriate, then the statistical results are valid, even if a simpler model with \(\sigma_{W(\texttt{A})}^{2}=0\) suggested by the data would also be correct.

It is an open problem whether the analyses generated by the second calls of PROC MIXED or PROC GLM are correct--namely, whether they control error rates for any preplanned analysis, assuming the originally posed model (19.8.20) is correct. It seems _improper_ for example to fit the first model using PROC GLM, see that the estimate \(\hat{\sigma}_{W(\texttt{A})}^{2}\) is negative, so change the model by removing the whole-plots term from the model, then fit the reduced model as in the second call of PROC GLM and use these results for the analysis. Control of error rates is an open problem when one uses the data to determine the model then uses the model to analyze the same data. Still, it is interesting that the second call of PROC MIXED fits and conducts the analysis under the assumption that model (19.8.20) is correct and, while it so happens that \(\hat{\sigma}_{W(\texttt{A})}^{2}=0\), the originally postulated model is used for the analysis. If this approach could be shown to control error rates, then this would be the preferred analysis, since there are

\begin{table}
\begin{tabular}{c c|c c c c c c c c} \hline \(A\) (Alert Type) & \(B\) (Complexity) & \multicolumn{8}{c}{\(W\) (Subject)} \\ \cline{3-10}  & & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 \\ \hline
1 & 1 & 6 & 5 & 5 & 5 & 5 & 7 & 5 & 6 \\  & 2 & 16 & 22 & 16 & 20 & 12 & 18 & 16 & 14 \\ \hline
2 & 1 & 7 & 6 & 5 & 6 & 5 & 6 & 4 & 4 \\  & 2 & 6 & 7 & 6 & 8 & 6 & 6 & 7benefits associated with essentially pooling ms(W(A)) and msE, including for example increased power for some tests, as well as the availability of a common variance estimator for multiple comparisons of _AB_-treatment combinations.

Given any uncertainty regarding whether the latter approach (corresponding to the second calls) controls error rates, our formal (rather than exploratory) approach to data analysis is to advocate that the experimenter use the analyses generated by the first calls of the procedures, since this approach is known to control error rates for any preplanned analyses if the proposed model (19.8.20) is correct.

#### Recovery of Inter-block Information

The oats experiment, introduced in Sect. 19.3.4, involves a split-plot design with complete blocks at both the whole- and split-plots levels--namely, the levels of \(A\) assigned to whole plots within blocks

\begin{table}
\begin{tabular}{r} DATA UAV3; \\ INPUT A W B TIME; \\ LINES; \\
1 1 1 6 \\
1 1 2 16 \\
1 2 1 5 \\
1 2 2 22 \\
1 3 1 5 \\ : : : \\
2 8 2 6 \\ _;_ PROC GLM; \\ TITLE ’Proc GLM: full model’; \\ CLASS A W B; \\ MODEL TIME = A | B W(A); \\ RANDOM W(A) / TEST; \\ LSMEANS A / CL PDIFF E = W(A); * need PDIFF, else E = mse; \\ LSMEANS A*B; * SAS would erroneously use MSE for CLs; \\ PROC MIXED NOBOUND; \\ TITLE ’Proc Mixed NoBound’; \\ CLASS A W B; \\ MODEL TIME = A | B / DDFM = SAT; \\ RANDOM W(A); \\ LSMEANS A A*B / CL DIFF; \\ PROC MIXED; \\ TITLE ’Proc Mixed (Bounded)’; \\ CLASS A W B; \\ MODEL TIME = A | B / DDFM = SAT; \\ RANDOM W(A); \\ LSMEANS A A*B / CL DIFF; \\ * Dropping W(A) from the Proc GLM model; \\ PROC GLM; \\ TITLE ’Proc GLM: W(A) dropped from model’; \\ CLASS A B; \\ MODEL TIME = A | B; \\ LSMEANS A A*B / CL PDIFF; \\ \end{tabular}
\end{table}
Table 19: SAS program for the UAV switch experiment constitute a randomized complete block design, and the levels of \(B\) assigned to split plots within whole plots constitute a randomized complete block design. With this dual complete block structure, the data analysis is the same whether the block effects are modeled as fixed (as in Sect. 19.3.4) or random (as in Sect. 19.8.4). Such would not be the case if for example the split-plot design involves incomplete blocks at the whole-plots level, as illustrated in this section.

Consider again the oats experiment and corresponding data in Table 19.3 (p. 710), but suppose one only has the data for levels 1 and 2 of \(A\) in blocks 3 and 5, for levels 0 and 2 of \(A\) in blocks 1 and 4, and for levels 0 and 1 of \(A\) in blocks 2 and 6. For this subset of the data, the levels of \(A\) assigned to whole plots in blocks constitute a balanced incomplete block design with blocks of size 2. The SAS program in Table 19.20 provides several approaches to the analysis of these data.

Figure 19.3: Output for the UAV switch experiment: Procs GLM and Mixed, First Calls

In the first call of PROC MIXED, the ANOVA approach is used to conduct a type 3 analysis, and block effects are modeled as fixed. Figure 19.5 contains the corresponding output. Because the block effects are modeled as fixed, the estimates of main-effect-of-_A_ contrasts are _intra-block estimates_--namely, each is composed (by summing over blocks) of within-block contrasts of observations--as is necessary for the fixed block effects to cancel out to yield unbiased estimates. Analogously, for testing for main effects of \(A\), the numerator of the _F_-statistic is the mean square for \(A\) adjusted for block effects, which can be computed from the sum of squares of an appropriate set of such intra-block estimates of main-effect-of-_A_ contrasts. The corresponding data analysis is called the _intra-block analysis_. The second call of PROC MIXED uses the restricted maximum likelihood approach but provides the same intra-block analysis, since the block effects are again modeled as fixed. The output (not shown) would include the same Type 3 Tests of Fixed Effects and Differences of Least Squares Means as in Fig. 19.5. For sake of comparison with subsequent analyses, note that the pairwise comparisons with the control for \(A\) each have estimated standard error 11.2883 with 4 degrees of freedom.

Figure 19.4: Output for the UAV switch experiment: Procs GLM and Mixed, Second Calls

In the third call of PROC MIXED, the ANOVA approach is used to conduct a type 3 analysis, but the block effects are modeled as independent random effects with mean zero and variance \(\sigma_{\theta}^{2}\). With random block effects, one can obtain unbiased ordinary least squares estimates of main-effect-of-\(A\) contrasts using contrasts of block totals (the sum total of the observations in each block), and these so-called _inter-block estimates_ are in addition to and independent of the intra-block estimates. So, for any main-effect-of-\(A\) contrast, any fixed weighted average of the corresponding intra- and inter-block estimates provides an unbiased estimate of the contrast, and the best (minimum variance) estimate would be obtained when each weight is inversely proportional to the variance of the corresponding estimate. Unfortunately, this best weighting is unknown, because the variance of the intra-block estimate is a

\begin{table}
\begin{tabular}{c c} DATA DATABIBD; & \\ INPUT BLOCK WP A B Y; & \\ IF A = 0 AND (BLOCK = 3 OR BLOCK = 5) THEN DELETE; & \\ IF A = 1 AND (BLOCK = 1 OR BLOCK = 4) THEN DELETE; & \\ IF A = 2 AND (BLOCK = 2 OR BLOCK = 6) THEN DELETE; & \\ LINES; & \\
1 1 2 3 156 \\
1 1 2 2 118 \\
1 1 2 1 140 \\
1 1 2 0 105 \\
1 2 0 0 111 \\ : : : : \\
6 3 2 3 121 \\ ; \\ *** Intra-block analyses; & \\ PROC MIXED METHOD = TYPE3; & \\ TITLE ’ANOVA Approach, Type 3, Fixed Block Effects’; & \\ CLASS BLOCK A B; & \\ MODEL Y = BLOCK A B A*B / DDFM = SAT; & \\ RANDOM WP(BLOCK); & \\ LSMEANS A / DDIFF = CONTROL(’0’) CL DIFF ADJUST = DUNNETT ALPHA = 0.01; \\ *** Analyses recovering inter-block information; & \\ PROC MIXED METHOD = TYPE3; & \\ TITLE ’ANOVA Approach, Type 3, Random Block Effects’; & \\ CLASS BLOCK A B; & \\ MODEL Y = A B A*B / DDFM = SAT; & \\ RANDOM BLOCK A*BLOCK; & \\ LSMEANS A / DDIFF = CONTROL(’0’) CL DIFF ADJUST = DUNNETT ALPHA = 0.01; \\ *** \\ *** \\ \end{tabular}
\end{table}
Table 19.20: SAS program illustrating the intra-block analysis and also the recovery of inter-block information—the oats split-plot experiment multiple of \(\sigma^{2}+4\sigma_{W}^{2}\), the variance of the inter-block estimate is a multiple of \(\sigma^{2}+4\sigma_{W}^{2}+8\sigma_{\theta}^{2}\), and these variances are unknown. A common approach is to use the estimated variances to determine the weights, but random weights would make the resulting analyses approximate. If the weights are well chosen, the resulting combined estimate is better (has smaller variance) than the intra-block estimate, due to recovery of inter-block information.

The output corresponding to the third call of PROC MIXED is in Fig. 19.6. Because a type 3 analysis is requested, the model is initially fit by ordinary least squares, providing a corresponding Type 3 Analysis of Variance identical to that generated by the first call of PROC MIXED, again with effects of \(A\) adjusted for block effects. However, this ANOVA information is then used to estimate the variance components, then the variance component estimates are in turn used to re-estimate the fixed

Figure 19.5: SAS output illustrating the intra-block analysis—the oats split-plot experiment

effects by estimated generalized least squares. Using this revised information, SAS software provides updated Type 3 Tests of Fixed Effects, including an approximate \(F\) test for \(A\) with 5 rather than 4 denominator degrees of freedom, and revised estimates of the pairwise comparisons with the control for \(A\), each now with estimated standard error 10.6837 with 5 degrees of freedom. The smaller standard error and increased number of degrees of freedom are both helpful consequences of the recovered inter-block information, increasing test power and decreasing confidence interval width.

In the fourth call of PROC MIXED, the restricted maximum likelihood approach is used for the analysis, with the block effects again modeled as independent random effects with mean zero and variance \(\sigma_{\theta}^{2}\). The output corresponding to the third call of PROC MIXED is in Fig. 19.7. Under this approach, ReML estimates of the variance components are computed, then these are used to estimate the fixed effects by generalized least squares. Based on these estimates, SAS software provides Type 3 Tests of Fixed Effects, including an approximate \(F\) test for \(A\) with 4.95 denominator degrees of freedom, and estimates of the pairwise comparisons with the control for \(A\), each with estimated standard error 10.7095 with 4.95 degrees of freedom. These values are slightly worse than the results of the third call of PROC MIXED, but still much better than for the intra-block analysis generated by the first two calls. Clearly there is a helpful recovery of inter-block information.

Turning attention to the split-plot comparisons, note that the \(F\)-tests for \(B\), and likewise for \(AB\), are the same in each analysis. This is the case because a randomized complete block design was used for the assignment of levels of \(B\) to split plots in whole plots (serving as blocks). Consequently, for each main effect of \(B\) and \(AB\)-interaction contrast, the corresponding contrast in treatment means is a within-whole-plot contrast, free of whole-plot or block effects, so no adjustment is needed.

Figure 19.6: SAS output illustrating the recovery of inter-block information—the oats split-plot experiment; ANOVA approach

In the above example, recovery of the inter-block information provided better information for analysis of the whole-plots factor \(A\). For example, for each treatment-versus-control contrast estimate for \(A\), recovery of inter-block information provided a tighter confidence interval, due to both a smaller standard error and more error degrees of freedom. In planning such an experiment, the experimenter should determine in advance how the data will be analyzed. While one could plan on conducting the intra-block analysis, recovery of the inter-block information should usually be beneficial.

#### ReML and Unbalanced Data

In this section, we illustrate the restricted maximum likelihood approach using PROC MIXED for analysis of an unbalance split-plot design, revisiting the mobile computing field study experiment introduced in Sect. 19.7. Recall, while the planned experiment was nicely balanced, it was discovered prior to analysis of the data that one of the subjects traversed one of the paths in the reverse direction, making the corresponding observation inappropriate to use in the analysis. As such, one of the 72 planned observations (given in Table 19.11, p. 719) is listed as missing. In Sects. 19.7.1 and 19.7.2, an approximate analysis of the split-plot design was provided by estimating the missing value and treating it as observed, using standard formulas for analysis of the balanced design via the analysis of variance approach, but adjusting degrees of freedom appropriately. With one observation lost, the data are no longer balanced, making the data analysis conceptually and computationally more difficult. However, SAS PROC MIXED handles this situation nicely, as we shall illustrate.

Figure 19.7: SAS output illustrating the recovery of inter-block information—the oats split-plot experiment; ReML approach

The SAS program for analysis of the 71-observation split-plot design via the restricted maximum likelihood approach is shown in Table 19.21, with the corresponding output in Fig. 19.8. The mixed model for the analysis was provided in Eq. (19.7.18), p. 718. Using PROC MIXED, the three variance components are (by default) estimated by restricted maximum likelihood. In this case, the three estimates are all positive. Given these variance component estimates, the fixed effects are then estimated by generalized least squares.

PROC MIXED provides Type III \(F\)-tests for each fixed effect--Type III in the sense that the tests are based on estimates of effects and corresponding variability obtained by fitting the full model. The option DDFM = SAT in the MODEL statement causes use of a general Satterthwaite approximation for the denominator degrees of freedom, equivalent to Satterthwaite's approximation for a balanced design. Readers are referred to SAS documentation for details. Regarding the two treatment factors, only the effects of visual presentation format (\(B\)) are significant, with \(p=0.0166\). Concerning the nuisance factors path and order, these involved both within- and between-whole-plot comparisons before the lost observation caused design imbalance. For each of these factors, the first call of PROC MIXED provides tests of each of three pseudofactor components, including for example tests for \(P_{2}\), \(P_{3}\) and \(P_{2}\,P_{3}\) for path. The second call of PROC MIXED provides a consolidated test for each of these nuisance factors. It is not surprising that path has significant effects, and these are attributable to the three distinct paths used as distinguished by \(P_{3}\).

The LSMEANS statement generated the pairwise Differences of Least Squares Means output for each of factors \(A\) and \(B\), including individual \(t\)-tests and individual 95% confidence intervals for each pairwise comparison. These results are similar to those obtained in Sect. 19.7.2, where the approach used was to estimate the missing value and analyze the balanced design, though there Tukey's method was used. Based on the individual 95% confidence intervals provided here, level 2 of \(B\)--the

\begin{table}
\begin{tabular}{r} DATA MCFS71; \\ INPUT SUBJ DAY ORDER O2 O3 PATH P2 P3 A B Y; \\ LINES; \\
1 1 1 0 0 1 0 0 1 1 49.321 \\
1 1 2 0 1 2 0 1 1 2 24.386 \\
1 1 3 0 2 3 0 2 1 3 37.680 \\ : : : : : : : : : : : : : : : : \\
12 1 3 0 2 5 1 1 1 1 30.146 \\
12 2 4 1 0 3 0 2 2 2. \\
12 2 5 1 1 1 0 0 2 3 58.481 \\
12 2 6 1 2 2 0 1 2 1 62.659 \\ ; \\ PROC MIXED NOBOUND; \\ TITLE ‘Analysis of RMSE without missing value’; \\ CLASS SUBJ DAY O2 O3 P2 P3 A B; \\ MODEL Y = O2 P2 A O3 O2*O3 P3 P2*O3 B A*B / DDFM = SAT; \\ RANDOM SUBJ DAY(SUBJ); \\ LSMEANS A B / CL DIFF ALPHA = 0.05; \\ * To get consolidated tests for order and path; \\ PROC MIXED NOBOUND; \\ CLASS SUBJ DAY ORDER PATH A B; \\ MODEL Y = ORDER PATH A B A*B / DDFM = SAT; \\ RANDOM SUBJ DAY(SUBJ); \\ \end{tabular}
\end{table}
Table 19.21: SAS program for the mobile computing field study experiment birds' eye view egocentric visual presentation format--has a significantly smaller RMSE from the intended path than do the other two visual presentation formats. It is interesting that the denominator degrees of freedom is not constant for the factor \(B\) pairwise comparisons, due to the imbalance created by the lost observation. This indicates that the pairwise comparisons do not all utilize the same variance estimator. As a consequence, the Bonferroni method should be used if multiple comparisons for \(B\) are of interest. These comparisons could be generated by adding the option ADJUST = BON to the LSMEANS statement. Replacing the keyword BON by DUNNETT, SCHEFFE or TUKEY would yield the corresponding multiple comparisons method, though these latter methods assume availability of a common variance estimator so are not applicable here.

One could also generate pairwise comparisons for the AB combinations by including A*B in the list of effects in the LSMEANS statement. However, only the Bonferroni method of multiple comparisons would be applicable, since there would not be a common variance estimator for all of these pairwise

Figure 19: Output for the mobile computing field study experiment

comparisons. Also, the corresponding variance estimators would generally be composite variance estimators, in which case Satterthwaite's approximation would be used.

### 19.9 Using R Software

In this section, we illustrate use of the R software for analyzing split-plot designs. The analysis of variance approach can be used for balanced data using aov, as illustrated for analysis of the oats experiment in Sect. 19.9.1. In Sect. 19.9.2, the UAV experiment is briefly revisited to illustrate the analysis of simple contrasts by conditioning on other factor level combinations, given a model fit using the aov function. In Sect. 19.9.3, we introduce a restricted maximum likelihood approach to analysis of split plot designs using the lmer function of the lme4 package, comparing it to the analysis of variance approach using the aov function in the context of UAV switch experiment--a new example involving a negative variance component estimate. In Sect. 19.9.4, the recovery of inter-block information is illustrated, using a subset of the oats data yielding a balanced incomplete block design for the whole-plots factor, and using the lmer function to fit the mixed model by restricted maximum likelihood. Finally, in Sect. 19.9.5, analysis of unbalanced data is illustrated using the lmer function and restricted maximum likelihood estimation for the mobile computing field study, excluding the missing observation from analysis of the split plot design.

#### The Analysis of Variance Approach

The _analysis of variance approach_ to the analysis of mixed models involves: (i) fitting the model by ordinary least squares, treating the random effects as fixed; and (ii) using the expected mean squares to determine unbiased estimates of the variance components. In analyzing a balanced split-plot design by the analysis of variance approach, the aov function automatically provides correct \(F\) tests of fixed effects, taking into account the two separate parts of the analysis of variance table, corresponding to between-whole-plots and within-whole-plots comparisons. Table 19.22 contains R code and output, providing an analysis of variance table similar to the one in Table 19.4 (p. 710) presented for the oats experiment in Sect. 19.3.4.

The approach used by aov in this analysis of a split plot design is a _type III analysis_, utilizing the type III sums of squares and corresponding expected mean squares. In the call of aov in Table 19.22, the model explicitly includes all sources of variation as in model (19.2.2) except the split-plot error term \(\epsilon^{S}_{I(h)}\), which plays the role of the usual error variable. The whole-plot error term \(\epsilon^{W}_{i(h)}\) is represented by fWP:fBlock--the random effects of whole plots nested within blocks--entered into the model via the Error function used to designate random effects. The term fBlock is likewise included in the Error function to designate the block effects as random.

Table 19.23 continues the R program and output of Table 19.22, illustrating the use of lsmeans to implement standard multiple comparisons procedures. For example, Dunnett's procedure for comparing each level of \(A\) with control level 0 and each level of \(B\) with control level 0 is requested via the lsmeans and summary(contrast... statements shown in Table 19.23. The syntax ref=1 designates the first level of a factor as the reference level or control, 0 being the first level of both \(A\) and \(B\). R automatically uses the correct standard error estimates, using the split-plot term MSE to estimate standard errors for the \(B\) contrasts, while using the whole-plot error mean square represented by fBlock:fWP for the \(A\) contrasts.

[MISSING_PAGE_FAIL:761]

#### The Restricted Maximum Likelihood Approach

In this section, we introduce a restricted maximum likelihood (ReML) approach to analysis of split plot designs using the lmer function of the lme4 package, comparing the restricted maximum likelihood approach to the analysis of variance approach in the context of a new example--UAV switch experiment. The two approaches yield the same results if (i) the design is balanced and (ii) all variance component estimates are either positive or allowed to be negative, though the lmer function does not allow variance component estimates to be negative. The restricted maximum likelihood approach is generally preferable for (i) the estimation and testing of variance components and (ii) the analysis of fixed effects given sufficiently unbalanced data. The UAV switch experiment provides an interesting comparison of the approaches, because the design is balanced but a variance component estimate is negative if unconstrained.

The analysis of variance approach was illustrated in Sects. 17.11.2, 18.6, 19.9.1 and 19.9.2 for balanced data using the aov function. Indeed, the analysis of variance approach can be reasonable and appropriate for the analysis of balanced data, as the fixed effect estimates are then best linear unbiased estimates, and the variance component estimates are then minimum variance unbiased estimates under normality. That said, variance component estimates can be negative even for balanced data. This may be reasonable for analysis of fixed effects, but it seems problematic if one is interested in inferences

\begin{table}
\begin{tabular}{r} \hline \hline \(>\) \# Multiple comparisons: Dunnett’s method \\ \(>\) library(lsmeans) \\ \(>\) lsmA = lsmeans(model1, \^{}\) fA) \\ \(>\) set.seed(21531957) \\ \(>\) summary(contrast(lsmA, method=“trt.vs.ctrl”, adjust=“mvt”, ref=l), \\ \(+\) infer=c(T,T), level=0.99, side=“two-sided”) \\ \(\quad\) contrast estimate SE df lower.CL upper.CL t.ratio p.value \\ \(1\) - \(0\) \(6.875\) \(7.0789\)\(10\)\(-18.123\)\(31.873\)\(0.971\)\(0.5423\) \\ \(2\) - \(0\) \(12.167\)\(7.0789\)\(10\)\(-12.831\)\(37.164\)\(1.719\)\(0.1973\) \\ \(\quad\) Results are averaged over the levels of: fB \\ \(\quad\) Confidence level used: \(0.99\) \\ \(\quad\) Conf-level adjustment: mvt method for 2 estimates \\ \(\quad\) P value adjustment: mvt method for 3 tests \\ \hline \hline \end{tabular}
\end{table}
Table 19.23: Multiple comparisons—the oats split-plot experiment

[MISSING_PAGE_FAIL:763]

As an alternative to the analysis of variance approach, consider the use of maximum likelihood estimates, which generally have good large-sample properties. Under appropriate regularity conditions, the maximum likelihood estimator \(\hat{\theta}\) of an estimable parameter \(\theta\) is asymptotically \(N(\theta,\) CRLB\()\), where CRLB is the Cramer-Rao lower bound for the variance of an unbiased estimator. Mind you, for the regularity conditions to hold, the estimate must be a solution to the likelihood equations--not obtained as a boundary condition--so these asymptotic properties do not apply for example to a variance component estimator when the estimate is constrained to be zero because the solution to the likelihood equations is negative. Likewise, given a factor with random effects but with few levels observed in an experiment, one should be skeptical of the asymptotic properties of the corresponding variance component estimate. That said, the asymptotic properties of MLEs should usually be reasonably applicable for the analysis of fixed effects unless an experiment is quite small. We will utilize restricted maximum likelihood estimation--a special case of maximum likelihood estimation.

The _restricted maximum likelihood approach_ to fitting a mixed model involves two steps: (i) estimating the variance components by restricted maximum likelihood; then (ii) estimating the fixed effects by _estimated generalized least squares_--namely, treating the variance component estimates as true values, then computing the maximum likelihood estimates of the fixed effects, or equivalently, the _generalized least squares estimates_. To compute restricted maximum likelihood (ReML) estimates of the variance components, the original data is essentially replaced by a maximal set of linearly independent contrasts in the data each with mean zero (i.e. data contrasts the distributions of which do not involve the fixed effects), then the likelihood function of the contrasts is maximized. (Equivalently, one can estimate the fixed effects by ordinary least squares, then maximize the likelihood function of the residuals, the joint distribution of which does not involve the fixed effects. Hence, the restricted maximum likelihood approach is also known as _residual maximum likelihood_.) The ReML estimates of the variance components may be preferable to the usual maximum likelihood estimates, because the ReML estimates are the same as the ANOVA-based estimates if the data are balanced and all variance component estimates are positive. Also, restricted maximum likelihood adjusts in some sense for fixed effects, so often provides unbiased estimates of variance components. A new experiment will be introduced to illustrate the restricted maximum likelihood approach to analysis of split plot designs.

### UAV Switch Experiment

Mahadevan (2009) conducted three experiments to evaluate the performance of a semi-automated computer display system designed to support a human operator's ability to monitor and control the complex dynamic operation of multiple unmanned aerial vehicles (UAVs) when the UAVs are involved in multiple combat-related tasks. His third experiment involved: 16 subjects (factor \(W\)); two alert techniques--a visual alert (\(A=1\)) and an audio-visual alert (\(A=2\)); and two levels of task complexity--a simple primary task coupled with a simple secondary task (\(B=1\)), and a complex primary task coupled with a simple secondary task (\(B=2\)). The experiment was a \(2\times 2\) split-plot design, with subjects as whole plots and two trials per subject as split-plots, with each level of \(A\) assigned to half of the subjects, and with both levels of \(B\) observed once on each subject. Hence, subject is nested within alert type. For each trial, each subject, while working on the primary task, was warned of the secondary task using one of the two alert techniques. One of the response variables measured was the time taken to switch to the secondary task following the alert, and the experimenter was interested in the effect of the nature of the alert (\(A\)) on the mean time to switch from the primary to the secondary task. The data are shown in Table 19.25. The model used by the experimenter is as follows.

\[Y_{iuj} = \mu + \alpha_{i} + \epsilon_{iu}^{W} + \beta_{j} + (\alpha\beta)_{ij} + \epsilon_{j(iu)}^{S}\]

,

\[\epsilon_{iu}^{W} \sim N(0,\sigma_{W}^{2})\]

,

\[\epsilon_{iu}^{W}\]

's and

\[\epsilon_{j(iu)}^{S}\]

's are all mutually independent,

\[i = 1,2;\;\;u = 1,\ldots,8;\;\;j = 1,2.\]

The R program and selected output for the UAV switch experiment is shown in Tables 19.26 and 19.27. Table 19.26 illustrates the analysis of variance approach, which is recommended for analysis of fixed effects given a balanced design--the case here. The model term Error(fA:fW) in the aov function models the whole plot errors \(\epsilon_{iu}^{W}\) as random whole plots effects \(W(A)\), and the corresponding mean square provides the denominator for testing main effects of \(A\), as appropriate. R code for multiple comparisons is shown, but not the corresponding output.

For sake of comparison, the restricted maximum likelihood approach is illustrated in the top of Table 19.27. The lmer function fits a linear mixed effects model by restricted maximum likelihood. This function is part of the lme4 package, but loading it via the lmerTest package adds the _p_-values to the analysis of variance table. For the model specified in the lmer statement, the term (1|fA:fW) causes inclusion of random \(W(A)\) effects in the model, representing the whole plot errors \(\epsilon_{iu}^{W}\). The corresponding variance component estimate, bounded to be nonnegative, is essentially zero, (\(\hat{\sigma}_{W}^{2} = 3.88 \times 10^{- 19}\) per output from the summary command). Consequently, the restricted maximum likelihood approach effectively removes this term from the model, pooling its degrees of freedom with that for (split plot) error, yielding 28 error degrees of freedom rather than 14 each for \(W(A)\) and error as in the analysis of variance approach. This is confirmed by the analysis of variance provided at the bottom of Table 19.27, obtained by removing whole plot effects from the model. These two analyses provide exactly the same \(F\) tests for the fixed effects. They also generate the same multiple comparisons results (not shown), with both procedures using 28 error degrees of freedom for all contrast standard errors.

The analysis in Table 19.26 is correct and should be used. It correctly implements the planned statistical analyses using the proposed model. If the model is reasonable and appropriate, then the statistical results are valid, even if a simpler model with \(\sigma_{W}^{2} = 0\) suggested by the data would also be correct.

\begin{table}
\begin{tabular}{c c|c c c c c c c c} \hline \(A\) (Alert Type) & \(B\) (Complexity) & \multicolumn{8}{c}{\(W\) (Subject)} \\ \cline{3-10}  & & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 \\ \hline
1 & 1 & 6 & 5 & 5 & 5 & 5 & 7 & 5 & 6 \\  & 2 & 16 & 22 & 16 & 20 & 12 & 18 & 16 & 14 \\ \hline
2 & 1 & 7 & 6 & 5 & 6 & 5 & 6 & 4 & 4 \\  & 2 & 6 & 7 & 6 & 8 & 6 & 6 & 7 & 6 \\ \hline \end{tabular}
\end{table}
Table 19.25: Time taken (in seconds) to switch to secondary task for the UAV switch experiment It is an open problem whether the analyses provided in Table 19.27 are strictly correct--namely, whether they control error rates for any preplanned analysis, assuming the originally posed model (19.9.21) is correct. It seems _improper_ for example if one were to fit the original full model by least squares, see that the estimate \(\hat{\sigma}^{2}_{W}\) is negative, so change the model by removing the whole-plots term from the model, then fit the reduced model and use these results for the analysis. Control of error rates is an open problem when one uses the data to determine the model then uses the model to analyze the same data. Still, it is interesting that the restricted maximum likelihood approach fits and conducts the analysis under the assumption that model (19.9.21) is correct and, while it so happens that \(\hat{\sigma}^{2}_{W}=0\), the originally postulated model is used for the analysis. If this approach could be shown to control error rates, then this would seem to be the preferred analysis, since effectively setting \(\hat{\sigma}^{2}_{W}=0\)

\begin{table}
\begin{tabular}{r} \hline \hline \(>\) uav3.data = read.table(‘data/uav3.txt’’, header=T) \\ \(>\) uav3.data = within(uav3.data, \\ \(+\) \{fA = factor(A); fW = factor(W); fB = factor(B) \}) \\ \(>\) head(uav3.data, 3) \\ \end{tabular}
\end{table}
Table 19.26: R program and selected output for the UAV switch experiment: analysis of variance approach 

[MISSING_PAGE_FAIL:767]

causes pooling of _ms_(_W_(_A_)) and _msE_ (i.e. _msE__W_ and _msE__S_) to estimate \(\sigma_{S}^{2}\) with more degrees of freedom. One benefit should be increased power for some tests--especially tests of effects compared between whole plots. It would also provide a common variance estimator for multiple comparisons of _AB_-treatment combinations, making most if not all methods of multiple comparisons applicable. Moreover, the restricted maximum likelihood approach becomes preferable to the analysis of variance approach for unbalanced designs.

#### Recovery of Inter-block Information

The oats experiment, introduced in Sect. 19.3.4, involves a split-plot design with complete blocks at both the whole- and split-plots levels--namely, the levels of \(A\) assigned to whole plots within blocks constitute a randomized complete block design, and the levels of \(B\) assigned to split plots within whole plots constitute a randomized complete block design. With this dual complete block structure, the data analysis is the same whether the block effects are modeled as fixed (as in Sect. 19.3.4) or random (as in Sect. 19.9.4). Such would not be the case if for example the split-plot design involves incomplete blocks at the whole-plots level, as illustrated in this section.

Consider again the oats experiment and corresponding data in Table 19.3 (p. 710), but suppose one only has the data for levels 1 and 2 of \(A\) in blocks 3 and 5, for levels 0 and 2 of \(A\) in blocks 1 and 4, and for levels 0 and 1 of \(A\) in blocks 2 and 6. For this subset of the data, the levels of \(A\) assigned to whole plots in blocks constitute a balanced incomplete block design with blocks of size 2. The R program and output in Tables 19.28 and 19.29 provides two approaches to the analysis of these data.

In Table 19.28, the analysis of variance approach is used and block effects are modeled as fixed. This is a Type I analysis. Since block effects are modeled as fixed, unbiased estimates of main-effect-of-_A_ contrasts must be _intra-block estimates_--namely, each is composed (by summing over blocks) of within-block contrasts of observations--as is necessary for the fixed block effects to cancel out to yield unbiased estimates. Analogously, for testing for main effects of \(A\), the numerator of the _F_-statistic is the mean square for \(A\) adjusted for block effects, which can be computed from the sum of squares of an appropriate set of such intra-block estimates of main-effect-of-_A_ contrasts. The corresponding data analysis is called the _intra-block analysis_. For sake of comparison with subsequent analyses, note that the pairwise comparisons with the control for \(A\) each have estimated standard error 11.288 with 4 degrees of freedom. The same results would be obtained by the restricted maximum likelihood approach using the following R code, except Type III tests would be provided, so the sum of squares for blocks would be adjusted for \(A\).

library(lmerTest)  model2 = lmer(y ~ fBlock + fA + fB + fA:fB + (l|fWP:fBlock),  data=oats2.data)  anova(model2)

The program and output are continued in Table 19.29, where the restricted maximum likelihood approach is used, but this time block effects are modeled as random. With random block effects, one can obtain unbiased estimates of main-effect-of-_A_ contrasts using contrasts of block totals (the sum total of the observations in each block), and these so-called _inter-block estimates_ are in addition to and independent of the intra-block estimates used in the first analysis. So, for any main-effect-of-_A_ contrast, any fixed weighted average of the corresponding intra- and inter-block estimates provides an unbiased estimate of the contrast, and the best (minimum variance) estimate would be obtained when each weight is inversely proportional to the variance of the corresponding estimate. Unfortunately, this best weighting is unknown because, for any main-effect-of-_A_ contrast, the variances of the intra- and inter-block estimates are different and depend on the unknown variance components. A common 

[MISSING_PAGE_FAIL:769]

[MISSING_PAGE_FAIL:770]

a smaller standard error and more error degrees of freedom. In planning such an experiment, the experimenter should determine in advance how the data will be analyzed. While one could plan on conducting the intra-block analysis, recovery of the inter-block information should usually be beneficial.

#### ReML and Unbalanced Data

In this section, we illustrate the restricted maximum likelihood approach using the linear mixed effects function lmer for analysis of an unbalance split-plot design, revisiting the mobile computing field study experiment introduced in Sect. 19.7. Recall, while the planned experiment was nicely balanced, it was discovered prior to analysis of the data that one of the subjects traversed one of the paths in the reverse direction, making the corresponding observation inappropriate to use in the analysis. As such, one of the 72 planned observations (given in Table 19.11, p. 719) is listed as missing. In Sects. 19.7.1 and 19.7.2, an approximate analysis of the split-plot design was provided by estimating the missing value and treating it as observed, using standard formulas for analysis of the balanced design via the analysis of variance approach, but adjusting degrees of freedom appropriately. With one observation lost, the data are no longer balanced, making the data analysis conceptually and computationally more difficult. However, the R function lmer handles this situation nicely, as we shall illustrate.

The R program and output for analysis of the 71-observation split-plot design via the restricted maximum likelihood approach is shown in Tables 19.30 and 19.31. The mixed model for the analysis, provided in Eq. (19.7.18), p. 718, was fit in Table 19.30 using the lmer function of the lme4 (and lmerTest) package. The three variance components are estimated by restricted maximum likelihood. In this case, the three estimates are all positive, as shown in selected output from the summary command. Given these variance component estimates, the fixed effects are then estimated by generalized least squares.

The anova function then provides Type III \(F\)-tests for each fixed effect--Type III in the sense that the tests are based on estimates of effects and corresponding variability obtained by fitting the full model. By default, Satterthwaite's approximation is used to compute the denominator degrees of freedom for each \(F\) test, analogous to Satterthwaite's approximation for a balanced design. Regarding the two treatment factors, only the effects of visual presentation format (\(B\)) are significant, with \(p=0.01660\). Concerning the nuisance factors path and order, these involved both within- and between-whole-plot comparisons before the lost observation caused design imbalance. For each of these factors, tests are provided for each of three pseudofactor components, including for example tests for \(P_{2}\), \(P_{3}\) and \(P_{2}P_{3}\) for path. At the top of Table 19.31, a second call of the lmer and anova functions fits a model using factors rather than pseudo-factors for order and path, providing a consolidated \(F\)-test for each of these nuisance factors. It is not surprising that path has significant effects, and these are attributable to the three distinct paths used as distinguished by \(P_{3}\).

At the bottom of Table 19.31, the lsameans function has generated the pairwise comparisons for each of factors \(A\) and \(B\), including individual \(t\)-tests and individual 95% confidence intervals for each pairwise comparison. These results are similar to those obtained in Sect. 19.7.2, where the approach used was to estimate the missing value and analyze the balanced design, though there Tukey's method was used. Based on the individual 95% confidence intervals provided here, level 2 of \(B\)--the birds' eye view egocentric visual presentation format--has a significantly smaller RMSE from the intended path than do the other two visual presentation formats. It is interesting that the denominator degrees of freedom is not constant for the factor \(B\) pairwise comparisons, due to the imbalance created by the lost observation. This indicates that the pairwise comparisons do not all utilize the same variance estimator, though presumably nearly so. As a consequence, the Bonferroni method should perhaps be used if multiple comparisons for \(B\) are of interest.

#### Using R Software

##### The R program and output for the mobile computing field study experiment

> MCFS71.data = read.table("data/MCFS71.txt", header=T) > head(MCFS71.data, 3)

Subj Day Order O2 O3 Path P2 P3 A B Y
1 1 1 1 0 0 1 0 0 1 1 49.321
2 1 1 2 0 1 2 0 1 1 2 24.386
3 1 1 3 0 2 3 0 2 1 3 37.680

> MCFS71.data = within(MCFS71.data, {fSubj = factor(Subj); + fDay = factor(Day); forder = factor(Order); fO2 = factor(O2); + fO3 = factor(O3); fPath = factor(Path); fP2 = factor(P2); + fP3 = factor(P3); fA = factor(A); fB = factor(B) ))

> # ReML > library(lmerTest) > model1 = lmer(y ~ fO2 + fP2 + fA + fO3 + fO2:fO3 + fP3 + fP2:fP3 + fB + fA:fB + (1|fSubj) + (1|fSubj:fDay), + data=MCFS71.data) > summary(model1)

... Random effects:  Groups Name Variance Std.Dev.  fSubj:fDay (Intercept) 28.2 5.31  fSubj (Intercept) 64.0 8.00  Residual 93.0 9.64...

> anova(model1)

Analysis of Variance Table of type III with Satterthwaite approximation for degrees of freedom  Sum Sq Mean Sq NunDF DenDF F.value Pr(>F)  fO2 23 23 1 8.5 0.25 0.63172  fp2 174 174 1 8.5 1.87 0.20643  fA 17 17 1 8.5 0.19 0.67688  fO3 8 4 2 34.6 0.04 0.95807  fp3 1976 988 2 34.6 10.63 0.00025  fB 860 430 2 34.6 4.62 0.01660  fO2:fO3 69 35 2 34.6 0.37 0.69270  fp2:fP3 26 13 2 34.6 0.14 0.87176  fA:fB 146 73 2 34.6 0.79 0.46336

One could also generate pairwise comparisons for the AB combinations by using A:B as the effect in an lsmeans statement, as follows.

\begin{table}
\begin{tabular}{r} \hline \hline \(>\) MCFS71.data = read.table("data/MCFS71.txt", header=T) \\ \(>\) head(MCFS71.data, 3) \\ \hline Subj Day Order O2 O3 Path P2 P3 A B Y 1 1 1 1 0 0 1 0 0 1 1 49.321 2 1 1 2 0 1 2 0 1 1 2 24.386 3 1 1 3 0 2 3 0 2 1 3 37.680 \\ \(>\) MCFS71.data = within(MCFS71.data, {fSubj = factor(Subj); + fDay = factor(Day); forder = factor(Order); fO2 = factor(O2); + fO3 = factor(O3); fPath = factor(Path); fP2 = factor(P2); + fP3 = factor(P3); fA = factor(A); fB = factor(B) )) \\ \(>\) # ReML \(>\) library(lmerTest) \(>\) model1 = lmer(y ~ fO2 + fP2 + fA + fO3 + fO2:fO3 + fP3 + fP2:fP3 + + fB + fA:fB + (1|fSubj) + (1|fSubj:fDay), + data=MCFS71.data) \(>\) summary(model1)

... Random effects:  Groups Name Variance Std.Dev.  fSubj:fDay (Intercept) 28.2 5.31  fSubj (Intercept) 64.0 8.00  Residual 93.0 9.64... \\ \(>\) anova(model1) \\ \(\;\) Analysis of Variance Table of type III with Satterthwaite approximation for degrees of freedom \\ \(\;\) Sum Sq Mean Sq NunDF DenDF F.value Pr(>F) \\ \(\;\) fO2 23 23 1 8.5 0.25 0.63172  fp2 174 174 1 8.5 1.87 0.20643  fA 17 17 1 8.5 0.19 0.67688  fO3 8 4 2 34.6 0.04 0.95807  fp3 1976 988 2 34.6 10.63 0.00025  fB 860 430 2 34.6 4.62 0.01660  fO2:fO3 69 35 2 34.6 0.37 0.69270  fp2:fP3 26 13 2 34.6 0.14 0.87176  fA:fB 146 73 2 34.6 0.79 0.46336 \\ \hline \hline \end{tabular}
\end{table}
Table 19.30: R program and output for the mobile computing field study experiment

[MISSING_PAGE_FAIL:773]

experimental units used in the study were \(n=64\) rats. The response was the amount of fluid (in milliliters) measured in the pleural cavity of an animal after having been administered a particular treatment combination. In many pharmacological studies, time of day has an effect on the response due to changing laboratory conditions, etc. Consequently, the experiment was divided into blocks, whole plots and split plots. The blocks were of size 32, each set of 32 observations being measured on a single day. Each treatment combination was measured once per day. Each day was then subdivided into 4 whole plots of size 8, where the eight measurements within a whole plot were taken fairly close together in time. Since the effect of the drug (_A_) was of primary importance, and since the effects of \(B\) and \(C\) were of interest only in the form of an interaction with \(A\), the main effects of \(B\) and \(C\) and the _BC_ interaction were confounded with the whole plots. The data are shown in Table 19.32, and the experimenter used the logarithms of the data in his analysis. Notice that the design for \(A\) on the split plots is a randomized block design, and the design for the _BC_ combinations on the whole plots is also a randomized block design. 1. Write out a model for this experiment. 2. Calculate an analysis of variance table using the logarithms of the data. Distinguish between the effects measured on the whole plots and those measured on the split plots. Identify the whole-plot error and split-plot error. 3. Test any hypotheses of interest and state your conclusions clearly. 4. Examine interaction plots of any important interactions. Calculate a set of 95% confidence intervals for the differences between pairs of drugs. State your conclusions.
2. **Fishing line experiment** The fishing line experiment was run by C. Reynolds, B. Grunden, and K. Taylor in 1996 in order to compare the strengths of two brands of fishing line exposed to two different levels of stress. Two different reels of fishing line were purchased for each of the two brands, and sections of line were cut from each reel. Thus the reels were automatically assigned to the levels of factor \(A\) (Brand), and constituted the four whole plots. There were no blocks in this experiment. The split plots constituted sixteen sections of line, four cut from each of the four reels (that is, 16 split plots in total, 4 per whole plot). The split plots were randomly assigned to two different stress levels (stressed, "S";

\begin{table}
\begin{tabular}{c c c c c c c c c c c} \hline  & \multicolumn{3}{c}{Block I} & & & & & & & & & \\ Whole & Dose & Time & & & & & & Drug A & & & \\ Plot & \(B\) & \(C\) & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 \\ \hline
1 & 1 & 1 & 5.7 & 8.6 & 6.9 & 6.6 & 6.7 & 7.4 & 5.7 & 6.7 \\
2 & 1 & 2 & 8.4 & 9.6 & 9.3 & 11.1 & 12.5 & 8.7 & 9.3 & 9.5 \\
3 & 2 & 1 & 5.1 & 7.2 & 6.8 & 6.4 & 6.6 & 8.7 & 6.7 & 7.0 \\
4 & 2 & 2 & 7.3 & 8.7 & 7.9 & 6.9 & 8.9 & 9.5 & 8.3 & 11.3 \\ \hline \multicolumn{3}{c}{Block II} & & & & & & & & & \\ Whole & Dose & Time & & & & & & & & & \\ Plot & \(B\) & \(C\) & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 \\ \hline
5 & 1 & 1 & 5.8 & 6.8 & 7.0 & 8.5 & 7.8 & 7.3 & 6.4 & 8.5 \\
6 & 1 & 2 & 9.1 & 10.8 & 6.9 & 12.2 & 9.9 & 10.4 & 10.6 & 10.5 \\
7 & 2 & 1 & 5.4 & 7.9 & 8.0 & 6.4 & 8.4 & 7.1 & 6.4 & 7.2 \\
8 & 2 & 2 & 5.3 & 10.4 & 8.2 & 8.1 & 10.9 & 9.8 & 8.4 & 14.6 \\ \hline \end{tabular} _Source_ Wooding (1973). Reprinted with Permission from Journal of Quality Technology © 1973 ASQ, www.asq.org

\end{table}
Table 19.32: Fluid (milliliters) in pleural cavity for the drug experiment 

[MISSING_PAGE_FAIL:775]

[MISSING_PAGE_FAIL:776]

5. **UAV experiment, continued** The UAV experiment, introduced in Sect. 19.6, was run using a 2\({}^{2}\)\(\times\) 4 split-plot design with 16 subjects (\(W\)) as whole plots, with two levels of cue condition (\(A\)) assigned to whole-plots, and with 2 \(\times\) 4 combinations of levels of task similarity (\(B\)) and task complexity (\(C\)) assigned to split plots. Another response variable measured by the experimenter was the time taken to perform situation awareness comprehension tasks in the primary task, yielding the data shown in Table 19.36. Using model (19.6.16), p. 715, conduct the following analyses. 1. Construct an analysis of variance table. For each main effect and interaction in the treatment factors, determining which effects are significant at the 1% level. 2. Construct a 95% confidence interval for the main effect of cue, and interpret the results. 3. If the three-factor interaction is significant, then compare the effect of cue at each combination of the other two factors. Otherwise, if the factor cue interacts significantly with either of the other treatment factors, then compare the effect of cue at each level of each factor with which cue interacts significantly. Use individual 99% confidence intervals.
6. **UAV switch experiment, continued** The UAV switch experiment, introduced in Sect. 19.8.3, was run using a 2 \(\times\) 2 split-plot design with 16 subjects as whole plots, with two levels of alert type (\(A\)) assigned to whole-plots, and with two levels of complexity (\(B\)) assigned to split plots. Main effects and interactions for \(A\) and \(B\) were all significant, but the primary interest is in comparing the effects of the levels of \(A\). Use the approach analogous to the first call of PROC GLM in Table 19.19 to do the following. 1. Construct a 95% confidence interval for the main effect of alert type, and interpret the results. 2. For each level of complexity, estimate the difference in effects of the two levels of alert type. Determine the variance of each of the two corresponding pairwise comparison estimators,

\begin{table}
\begin{tabular}{c c c c c c|c c c} \hline \multicolumn{2}{c|}{\(B\) (Similarity)} & \multicolumn{2}{c|}{1} & \multicolumn{2}{c|}{2} & \multicolumn{2}{c}{2} \\ \cline{3-10} \multicolumn{2}{c|}{\(C\) (Complexity)} & \multicolumn{1}{c}{1} & 2 & 3 & 4 & 1 & 2 & 3 & 4 \\ \hline \(A\) (Cue) & \(W\) (Subject) & & & & & & & & \\ \hline
1 & 1 & 20 & 21 & 27 & 32 & 23 & 21 & 30 & 28 \\  & 2 & 24 & 19 & 33 & 35 & 24 & 23 & 32 & 30 \\  & 3 & 19 & 22 & 28 & 33 & 21 & 20 & 34 & 31 \\  & 4 & 30 & 27 & 37 & 30 & 26 & 24 & 31 & 33 \\  & 5 & 25 & 24 & 35 & 38 & 28 & 27 & 33 & 30 \\  & 6 & 22 & 20 & 40 & 41 & 26 & 25 & 29 & 37 \\  & 7 & 28 & 23 & 34 & 36 & 28 & 26 & 37 & 34 \\  & 8 & 21 & 26 & 33 & 34 & 24 & 28 & 34 & 40 \\
2 & 1 & 8 & 9 & 11 & 9 & 7 & 7 & 8 & 8 \\  & 2 & 10 & 8 & 13 & 13 & 12 & 8 & 18 & 10 \\  & 3 & 11 & 9 & 15 & 14 & 9 & 10 & 15 & 18 \\  & 4 & 8 & 9 & 12 & 18 & 8 & 12 & 8 & 9 \\  & 5 & 7 & 10 & 17 & 13 & 12 & 12 & 12 & 17 \\  & 6 & 9 & 7 & 13 & 12 & 10 & 7 & 12 & 10 \\  & 7 & 11 & 12 & 10 & 11 & 13 & 8 & 10 & 8 \\  & 8 & 10 & 11 & 15 & 13 & 7 & 13 & 9 & 8 \\ \hline \end{tabular} _Source_ Mahadevan (2009). Copyright © 2009 Sriram Mahadevan. Reprinted with permission

\end{table}
Table 19.36: Split-plot design and times (in seconds) for the UAV experiment: situation awareness comprehension compute the corresponding estimated standard errors, and use Satterthwaite's approximation to compute the approximate number of degrees of freedom associated with each estimated standard error. 3. Using the results of part (b), construct individual 99% confidence intervals for the difference in effects of the two levels of alert type for each level of complexity. Interpret the results.
7. **UAV switch experiment, continued** The UAV switch experiment, introduced in Sect. 19.8.3, was run using a 2 x 2 split-plot design with 16 subjects as whole plots, with two levels of alert type (\(A\)) assigned to whole-plots, and with two levels of complexity (\(B\)) assigned to split plots. Another response variable measured by the experimenter was the alert detection time (in seconds), yielding the data shown in Table 19.37. Using model (19.8.20), p. 734, conduct the following analyses. 1. Construct an analysis of variance table. For each main effect and interaction in the treatment factors, determining which effects are significant at the 1% level. 2. Construct a 95% confidence interval for the main effect of alert type, and interpret the results. 3. For each level of complexity, compare the effects of the two levels of alert type, using individual 99% confidence intervals.
8. **Mobile Computing Field Study, continued** The Mobile Computing Field Study, introduced in Sect. 19.7, was run using a 2 x 3 split-plot design with 12 subjects as blocks, 24 days as whole plots, three runs per day as split plots, two display types (\(A\)) assigned to whole-plots, three visual presentation formats (\(B\)) assigned to split-plots, six runs per subject, and utilizing six paths. Another response variable measured by the experimenter was the time (in minutes) to navigate the path, yielding the data shown in Table 19.38. Using model (19.7.18), p. 718, conduct the following analyses, estimating the missing value and utilizing it in the analysis. 1. Estimate the missing value. 2. Construct an analysis of variance table analogous to Table 19.12. For each main effect and interaction in the treatment factors, determining which effects are significant at the 1% level. 3. Compare the visual presentation formats using simultaneous 99% confidence intervals and Tukey's method. Interpret the results.

\begin{table}
\begin{tabular}{c c|c c c c c c c c} \hline \(A\) (Alert type) & \(B\) (Complexity) & \multicolumn{8}{c}{\(W\) (Subject)} \\ \cline{3-10}  & & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 \\ \hline
1 & 1 & 5 & 6 & 4 & 6 & 5 & 5 & 5 & 6 \\  & 2 & 10 & 10 & 6 & 8 & 6 & 6 & 6 & 6 \\ \hline
2 & 1 & 6 & 5 & 4 & 5 & 5 & 4 & 6 & 6 \\  & 2 & 5 & 6 & 4 & 5 & 5 & 4 & 6 & 5 \\ \hline _Source_ Mahadevan (2009). Copyright (c) 2009 Sriram Mahadevan. Reprinted with permission \\ \hline \end{tabular}
\end{table}
Table 19.37: Alert detection times (in seconds) for UAV switch experiment 
## 9 Mobile Computing Field Study, continued

The Mobile Computing Field Study was introduced in Sect. 19.7, and data on an additional response variable, time, was provided in Exercise 8. Using model (19.7.18), p. 718, conduct the following analyses of the response variable time, using only the 71 observations available--namely, without estimating and using the missing value. If using SAS software, you may adapt the program in Table 19.21; if using R, you may adapt the program in Tables 19.30 and 19.31.

1. Provide the resulting variance component estimates.
2. Test for significance of each treatment factor main effect and interaction. Report the observed significance level of each test, and interpret the results.
3. Using an appropriate method of multiple comparisons, construct simultaneous 99% confidence intervals for pairwise comparison of the visual presentation formats (_B_). Interpret the results.

\begin{table}
\begin{tabular}{c|c c c c c|c c c c c c} \hline Subj & \multicolumn{6}{c|}{Day 1} & \multicolumn{6}{c}{Day 2} \\ \cline{2-13}  & \multicolumn{2}{c}{Run 1} & \multicolumn{2}{c}{Run 2} & \multicolumn{2}{c}{Run 3} & \multicolumn{2}{c}{Run 4} & \multicolumn{2}{c}{Run 5} & \multicolumn{2}{c}{Run 6} \\ \cline{2-13}  & \multicolumn{2}{c}{PAB} & \multicolumn{2}{c}{Time} & \multicolumn{2}{c}{PAB} & \multicolumn{2}{c}{Time} & \multicolumn{2}{c}{PAB} & \multicolumn{2}{c}{Time} & \multicolumn{2}{c}{PAB} & \multicolumn{2}{c}{Time} & \multicolumn{2}{c}{PAB} & \multicolumn{2}{c}{Time} & \multicolumn{2}{c}{PAB} & \multicolumn{2}{c}{Time} \\ \hline
1 & 111 & 15.633 & 212 & 11.717 & 313 & 13.550 & 421 & 11.900 & 522 & 11.817 & 623 & 16.517 \\
2 & 213 & 13.767 & 311 & 13.867 & 112 & 11.233 & 523 & 10.533 & 621 & 11.966 & 422 & 10.633 \\
3 & 312 & 11.150 & 113 & 13.167 & 211 & 12.633 & 622 & 9.367 & 423 & 10.350 & 521 & 9.750 \\
4 & 121 & 11.867 & 222 & 8.600 & 323 & 8.700 & 411 & 10.400 & 512 & 9.117 & 613 & 10.067 \\
5 & 223 & 10.183 & 321 & 11.600 & 122 & 8.350 & 513 & 16.667 & 611 & 9.783 & 412 & 7.600 \\
6 & 322 & 7.650 & 123 & 9.667 & 221 & 12.417 & 612 & 11.400 & 413 & 14.900 & 511 & 10.350 \\
7 & 421 & 9.233 & 522 & 8.700 & 623 & 12.083 & 111 & 10.700 & 212 & 7.833 & 313 & 9.050 \\
8 & 523 & 11.130 & 621 & 8.717 & 422 & 7.967 & 213 & 8.867 & 311 & 8.917 & 112 & 6.667 \\
9 & 622 & 12.133 & 423 & 12.800 & 521 & 12.433 & 312 & 11.767 & 113 & 12.367 & 211 & 12.983 \\
10 & 411 & 18.150 & 512 & 10.483 & 613 & 13.370 & 121 & 14.100 & 222 & 10.217 & 323 & 11.583 \\
11 & 513 & 10.883 & 611 & 15.117 & 412 & 10.833 & 223 & 16.783 & 321 & 15.333 & 122 & 12.483 \\
12 & 612 & 9.567 & 413 & 16.450 & 511 & 11.217 & 322 &. & 123 & 10.567 & 221 & 10.517 \\ \hline \end{tabular} _Source_ Wesler (2001). Copyright © 2001 Mary Mc. Wesler. Research was performed under U.S. Army Research Laboratory, Federated Laboratory Research Consortium (DAAL01-96-0003) directed by Mr. Bernie Corona. Reprinted with permission

\end{table}
Table 19.38: Mobile computing field study: time (in minutes) for each subject (Subj), day, run order, and path-treatment combination (PAB), with one observation missing 

### 20.1 Introduction

All of the experiments described in the previous chapters are _physical experiments_ where the experimenter can work directly with the treatments and experimental material. The experimenter makes an assignment of experimental units to the levels of the treatment factors, possibly including blocks, and then measures the corresponding responses. Since it is not possible to control every single variable that influences the scientific process under consideration, all measurements necessarily include random variability. Statisticians have developed numerous methods to mitigate the effects of uncontrolled variation on the study conclusions. For example, Chap. 1 introduced replication, blocking, and randomization. These standard techniques of physical experiments allow an experimenter to increase precision and decrease bias.

In some situations, however, it is economically, ethically, or temporally not possible to run a statistically appropriate physical experiment. Instead, the following scenario might be feasible. Suppose that

1. the physical process can be described by a mathematical model (for example, a system of differential equations),
2. computer code (called a _simulator_) can be written to compute the response from the mathematical model, and
3. computational methods exist for working with this model (for example, solving differential equations) within a reasonable timeframe.

In this scenario, a researcher can conduct a _computer experiment_ by running the computer code, which serves as a proxy for the physical process, to compute a "response" at any combination of values of the treatment factors, which are now called _input combinations_, or _input points_, or sometimes shortened to _inputs_. We use \(\boldsymbol{x}\) to represent an input combination.

_Example 20.1.1_ A Real Experiment-Prosthetic Elbow Experiment

Many biomedical engineers use computer experiments to help with the engineering design of prosthetic devices. For example, Hayeck (2009) studied the effects of four implant position variables on the functioning of a total elbow replacement prosthetic device. One of the responses of interest was a measure of principal compressive strain in the bone.

The input variables were the tip displacement (\(x_{1}\)), the rotation of the implant axis about the lateral axis at the tip (\(x_{2}\)), the rotation of the implant axis about the anterior axis at the tip (\(x_{3}\)), and the rotation about the implant axis (\(x_{4}\)). The variable \(x_{1}\) was measured in millimeters, while \(x_{2}\), \(x_{3}\), and \(x_{4}\) were measured in degrees. To conduct an experiment, one would need to observe the response \(y\) at various combinations \(\boldsymbol{x}=(x_{1},\ldots,x_{4})\) of the input variables. It would be ethically questionable to carry out this experiment on patients, since some input combinations of interest may prove harmful. However, as described by Hayeck (2009), the influence of these four variables on the functioning of the prosthetic device could be described by a mathematical model and could be implemented in computer code, and so a computer experiment could be conducted. 

A key difference between computer experiments and physical experiments is that many computer experiments are "deterministic". In other words, if an experimenter runs the computer code twice at the same input combination \(\boldsymbol{x}\), the same response \(y\) will be observed both times. A deterministic computer code has no random variability, and may exhibit an unknown, and/or highly complex, functional relationship, \(y=f(\boldsymbol{x})\). The lack of variability eliminates any benefit of replication and, further, since _all_ the input variables to the code are known and can be controlled, randomization and blocking are likewise unnecessary.

Some deterministic computer codes are very computationally intensive--perhaps requiring hours or days for a computer to solve the underlying mathematical model to produce each response value--so time constraints limit the number of runs or observations that can be taken. Given outputs \(y_{1}\), \(y_{2}\),..., \(y_{n}\) from a limited number of runs of the computer code (taken at input combinations \(\boldsymbol{x}_{1}\), \(\boldsymbol{x}_{2}\),..., \(\boldsymbol{x}_{n}\), respectively), a goal of a computer experiment is to fit a model that can generate good response predictions relatively rapidly throughout the set of possible input combinations. The set of possible input combinations is called the _input space_ or _design space_. If the fitted model, \(\hat{f}(\boldsymbol{x})\) say, provides a good approximation to the computer code function \(f(\boldsymbol{x})\) throughout the design space, and if \(\hat{f}(\boldsymbol{x})\) can be computed quickly as compared to running the cumbersome computer code, then the fitted model \(\hat{f}(\boldsymbol{x})\) can be used to investigate the behavior of the computer function \(f(\boldsymbol{x})\) over the input space. The fitted model is called an _emulator_ since it "emulates" the output of the computer code.

In the prosthetic elbow experiment in Example 20.1.1, it would be possible to use the fitted model \(\hat{f}(\boldsymbol{x})\) to find a region of inputs \(\boldsymbol{x}\) that yield relatively low estimates \(\hat{f}(\boldsymbol{x})\) of principal compressive strains in the bone, and finding this good region with respect to \(\hat{f}(\boldsymbol{x})\) may be the end of the study. That said, having pinned down this good region of inputs \(\boldsymbol{x}\) with respect to \(\hat{f}(\boldsymbol{x})\), but knowing that \(\hat{f}(\boldsymbol{x})\) merely approximates the computer code function \(f(\boldsymbol{x})\), one might make some additional runs of the computer code using input combinations \(\boldsymbol{x}\) in or around this good region. With this additional data, a refitted model \(\hat{f}(\boldsymbol{x})\) should better approximate the computer code function \(f(\boldsymbol{x})\) in the previously identified good region of inputs, allowing one to re-examine the effects of the inputs in this region. Better yet, since the computer code function \(y=f(\boldsymbol{x})\) is only a proxy for the true physical situation, having pinned down a good region of inputs with respect to either \(f(\boldsymbol{x})\) or \(\hat{f}(\boldsymbol{x})\), it may then be feasible, both morally and practically, to run a physical experiment with variable settings \(\boldsymbol{x}\) in this good region to study the effects of the input variables on principal compressive strains in the bone directly. This would be done using methods of physical experiments presented in earlier chapters.

For computer experiments, statisticians have developed highly flexible statistical models to emulate simulator output. These are typically smooth "interpolators", in the sense that they provide a fitted model \(\hat{f}(\boldsymbol{x})\) which is relatively smooth (no sudden jumps) and, since the observed data are deterministic, \(\hat{f}(\boldsymbol{x})\) passes through, or interpolates, the \(n\) observed data points (\(\boldsymbol{x}_{i}\), \(y_{i}\)); in other words, \(\hat{f}(\boldsymbol{x}_{i})=f(\boldsymbol{x}_{i})\) for the \(n\) observed input combinations \(\boldsymbol{x}_{1}\),..., \(\boldsymbol{x}_{n}\).

### Models for Computer Experiments

Since the precise functional relationship \(y=f(\boldsymbol{x})\) between the inputs and the response in a deterministic computer experiment is usually unknown a priori, and is potentially highly non-linear, we require the model for the outputs to be very flexible as well as to interpolate the data. While the complete treatment of the technical details behind the statistical models of computer experiment data is beyond the scope of this book, the intuition behind them is quite appealing and is explained in the following example.

#### 20.2.1 One Predictor

Suppose \(n=7\) runs of a computer code yield the following data points, written as the pairs \((x_{i},\,y_{i})\), \(i=1,\ldots,7\): \((0.06,0.33)\), \((0.18,-0.47)\), \((0.35,\,0.23)\), \((0.52,-0.12)\), \((0.69,\,0.06)\), \((0.74,\,0.01)\), \((0.95,\,0.01)\). These seven points are plotted in Fig. 20.1 as dark circles. While the relationship \(y=f(x)\) intrinsic in the computer code would be unknown to us, for sake of illustration, let it be \(y=e^{-4x}\cos(6\pi x)\). The solid curve in Fig. 20.1 represents this true but unknown relationship between \(x\) and \(y\), and we want to estimate it based on the seven data points. Suppose we could use the seven data points to somehow obtain a fitted model (emulator), \(\hat{y}=\hat{f}(x)\), which we could compute for any value of \(x\) in the input space. Then to "estimate" this unknown relationship \(y=f(x)\), we could use the fitted model to make predictions \(\hat{f}(x)\) at a grid of \(x\) values, such as \(x=0,0.01,0.02,\,\ldots,1\). Plotting these points (\(x\), \(\hat{f}(x)\)) would approximate the unknown solid curve.

To fit a model with the desired characteristics, consider how we might predict \(y\) at any unobserved input point \(x\). We want the fitted model to be an interpolator--namely, for any of the observed points \((x,\,y)\), we want the model prediction \(\hat{y}=\hat{f}(x)\) to match the observed value \(y=f(x)\) of the computer code. We also want the fitted model to be relatively smooth. Consider obtaining a prediction \(\hat{y}_{a}\) at, say, the unobserved input point \(x_{a}=0.36\). In the absence of knowing the nature of the true relationship, the model will "look around" in the \(x\) space and it will notice that \(x_{a}=0.36\) is very close to the observed input point \(x_{3}=0.35\), and is between \(x_{3}\) and \(x_{4}=0.52\). Since \(x_{a}\) is very close to \(x_{3}\), \(y_{a}\) should be very close to the observed value \(y_{3}\) if the response is smooth and without "spikes". Hence, the model will estimate \(y_{a}\) by a value \(\hat{y}_{a}\) that is close to \(y_{3}=0.23\), and perhaps a little smaller to fall between \(y_{3}\) and \(y_{4}=-0.12\).

Consider now calculating \(\hat{y}\) at a different input point \(x_{a}=0.45\). The two input points closest to \(x_{a}=0.45\) for which the computer code was observed are again \(x_{3}=0.35\) and \(x_{4}=0.52\). Since \(x_{a}\) is approximately halfway between \(x_{4}\) and \(x_{3}\), the model could assign roughly the average of \(y_{3}\) and

Figure 20.1: True unknown relationship between \(x\) and \(y\), including seven observed pointsas a value for \(\hat{y}(x_{a})\). Or, since \(x_{a}\) is not too close to either \(x_{3}\) or \(x_{4}\), \(\bar{y}\) might be a reasonable prediction of \(y_{a}\). Consider this latter notion further.

To formulate a simple predictor, we might consider \(\bar{y}\) and the deviations \(y_{i}-\bar{y}\), \(i=1,2,\,\ldots,n\). For example, to make a prediction for a particular input \(x_{a}\), suppose we use

\[\hat{y}(x_{a})=\bar{y}+\sum_{i=1}^{n}w_{i}(y_{i}-\bar{y}),\]

where \(\sum_{i=1}^{n}w_{i}(y_{i}-\bar{y})\) represents a weighted average of the deviations from the mean. The weight \(w_{i}\) should depend on the relative distance between \(x_{a}\) and \(x_{i}\), with more weight associated with the inputs \(x_{i}\) that are closer to \(x_{a}\). If only one input point, say \(x_{p}\), is very close to \(x_{a}\), this could result in \(w_{p}\approx 1\) with the rest of the weights negligible, in which case one would obtain \(\hat{y}_{a}\approx\bar{y}+(y_{p}-\bar{y})=y_{p}\). For an input \(x_{a}\) sufficiently far away from all of the \(x_{i}\), all weights \(w_{i}\) could be very small, in which case one would obtain \(\hat{y}(x_{a})\approx\bar{y}+0=\bar{y}\). The model described in Sect. 20.3 has features similar to these. 

### Gaussian Stochastic Process Model

The model most commonly employed in the analysis of computer experiments is called the _Gaussian Stochastic Process model_ (GaSP). The model specifies the deterministic computer code function \(y=f(\boldsymbol{x})\) as the realization of a "Gaussian stochastic process". Although the code is deterministic, this statistical model provides a probabilistic framework for the response at unobserved input combinations while modeling the unknown output surface as being relatively smooth and responses at nearby inputs as being highly correlated. The GaSP model takes the form

\[Y(\boldsymbol{x})=\beta_{0}+Z(\boldsymbol{x}), \tag{20.3.1}\]

which is similar to a regression model in Chap. 8 but with a different type of error variable. Here, \(Y(\boldsymbol{x})\) denotes the response at input combination \(\boldsymbol{x}=(x_{1},\,x_{2},\,\ldots,\,x_{d})\), and \(\beta_{0}\) is an unknown constant. \(Z(\boldsymbol{x})\) is assumed to be a _Gaussian stochastic process_, which means that, for any choice of \(\ell\) input combinations, \(\boldsymbol{x}_{1}\), \(\boldsymbol{x}_{2}\),..., \(\boldsymbol{x}_{\ell}\), the random variables \(Z(\boldsymbol{x}_{1})\), \(Z(\boldsymbol{x}_{2})\),..., \(Z(\boldsymbol{x}_{\ell})\) have a multivariate normal distribution (so, in particular, they are generally not independent). The assumptions on the model are as follows:

1. \(Z(\boldsymbol{x})\) has mean zero and constant variance \(\sigma^{2}\) for any input combination \(\boldsymbol{x}\), so \(Z(\boldsymbol{x})\sim N(0,\,\sigma^{2})\) and \[Y(\boldsymbol{x})\sim N(\beta_{0},\,\sigma^{2}).\]
2. For any two inputs \(\boldsymbol{x}_{i}\) and \(\boldsymbol{x}_{j}\), the correlation between the responses \(Y(\boldsymbol{x}_{i})\) and \(Y(\boldsymbol{x}_{j})\) is denoted by \(R(\boldsymbol{x}_{i}-\boldsymbol{x}_{j}|\boldsymbol{\xi})\), where \(R(\boldsymbol{x}_{i}-\boldsymbol{x}_{j}|\boldsymbol{\xi})\) is a function of the distance between the inputs \(\boldsymbol{x}_{i}\) and \(\boldsymbol{x}_{j}\) (in d-dimensional space), and depends on a set of unknown parameters which, for simplicity, we write as \(\boldsymbol{\xi}\).

Thus,

\[Cov(Y(\boldsymbol{x}_{i}),\,Y(\boldsymbol{x}_{j}))=Cov(Z(\boldsymbol{x}_{i}),\,Z(\boldsymbol{x}_{j}))=\sigma^{2}R(\boldsymbol{x}_{i}-\boldsymbol{x}_{j}| \boldsymbol{\xi}). \tag{20.3.2}\]Quantifying the correlation between \(Y(\mathbf{x}_{i})\) and \(Y(\mathbf{x}_{j})\) by taking into account the distance between \(\mathbf{x}_{i}\) and \(\mathbf{x}_{j}\) is a non-trivial problem. One possible structure that one might use is the "Gaussian correlation function", which is given by

\[R(\mathbf{x}_{i}-\mathbf{x}_{j}|\mathbf{\xi}) = \prod_{k=1}^{d}e^{-\theta_{k}(x_{ik}-x_{jk})^{2}}\] \[= e^{-[\theta_{1}(x_{11}-x_{j1})^{2}+\theta_{2}(x_{i2}-x_{j2})^{2} +\cdots+\theta_{d}(x_{id}-x_{jd})^{2}]},\]

where all \(\theta_{k}>0\), and where \(\mathbf{\xi}\) is the set of parameters \((\theta_{1},\theta_{2},\ldots,\theta_{d})\) that need to be estimated from the data. This correlation structure yields a relatively smooth model. Replacing the exponent 2 in \((x_{i1}-x_{j1})^{2}\) by some positive number \(p\) smaller than 2, would result in a less smooth model.

Consider the case of one predictor (\(d=1\)). Then the notation simplifies, and the correlation function (20.3.3) reduces to \(R(x_{i}-x_{j}|\theta)=e^{-\theta(x_{i}-x_{j})^{2}}\). For any fixed value of \(\theta>0\), the correlation \(e^{-\theta(x_{i}-x_{j})^{2}}\) starts to approach zero as the absolute value \(|x_{i}-x_{j}|\) of the distance between \(x_{i}\) and \(x_{j}\) gets very large, indicating that \(Y(x_{i})\) and \(Y(x_{j})\) are essentially independent so need not be similar. On the other hand, as the distance between \(x_{i}\) and \(x_{j}\) gets very small, the correlation starts to approach 1, indicating that \(Y(x_{i})\) and \(Y(x_{j})\) are strongly correlated and so should be similar. Taken to the extreme, if \(x_{i}=x_{j}\), the correlation between \(Y(x_{i})\) and \(Y(x_{j})\) is 1, so \(Y(x_{i})=Y(x_{j})\), i.e. two responses at the same input yield the same value, as desired. Exercise 1 asks the reader to investigate the effect of \(\theta\) and the absolute distance \(|x_{i}-x_{j}|\) on the size of the correlation between two responses while using the Gaussian correlation function. Exercises 2-4 show some alternatives to the Gaussian correlation function which are sometimes used in practice.

Under model (20.3.1) and assumption (i), the mean response is simply a constant, \(\beta_{0}\). While \(\beta_{0}\) could be replaced with a more complicated regression model as in Chap. 8 or 16, doing so typically does not improve the predictive performance of the model for reasonably smooth surfaces (For further reading, see Sacks et al. 1989). Using appropriate methods of prediction, the correlation structure of the Gaussian stochastic process model with constant mean apparently provides adequate model flexibility for reasonably smooth surfaces such as that of Fig. 20.1.

The parameters \((\beta_{0},\sigma^{2},\theta_{1},\ldots,\theta_{d})\) in (20.3.1)-(20.3.3) are unknown so need to be estimated. There are a few different ways to estimate these, but we shall use the most common one--maximum likelihood estimation, since such estimators have excellent statistical properties. An in-depth discussion of maximum likelihood estimation is beyond the scope of this book, but maximum likelihood estimates can be computed using appropriate statistical software, and we will rely on software for the computations (as in Sects. 20.6 and 20.7).

For the interested reader, here is the idea of maximum likelihood estimation. Under model (20.3.1), the response variables \(Y(\mathbf{x}_{1})\),..., \(Y(\mathbf{x}_{n})\) follow a multivariate normal distribution which depends on the values of the parameters \(\beta_{0}\), \(\sigma^{2}\), \(\theta_{1}\),..., \(\theta_{d}\). For given values of these parameters, the probability density function (pdf) is a function of the possible data (output) points \(y(\mathbf{x}_{1})\),..., \(y(\mathbf{x}_{n})\). One is more likely to observe data values where the pdf is larger, and most likely to get data where the pdf is at or near its maximum. Conversely, if we have the data \(\mathbf{y}=(y(\mathbf{x}_{1})\),..., \(y(\mathbf{x}_{n}))\) but the parameters are unknown, it seems reasonable to estimate the parameters by values that would correspond to the observed data being as likely as possible. If we estimate the parameters by values that maximize the likelihood of the observed data, these are _maximum likelihood estimates_, and this is _maximum likelihood estimation_.

Once estimates of the model parameters have been obtained, the next step is to construct a predictor \(\hat{Y}(\mathbf{x}_{a})\) of a response \(Y(\mathbf{x}_{a})\) at any new unobserved input point \(\mathbf{x}_{a}\) (cf. Chap. 8). The predictor should be easily computable but sufficiently sophisticated to utilize the observed data \(\boldsymbol{y}=(y(\boldsymbol{x}_{1}),\,y(\boldsymbol{x}_{2}),\,\ldots,\,y( \boldsymbol{x}_{n}))\). The predictor \(\hat{Y}(\boldsymbol{x}_{a})=\hat{\beta}_{0}\), for example, would be too simplistic. If the correlation parameters \(\theta_{k}\) were known, we could compute and use the _best linear unbiased predictor_--namely, the unbiased predictor that minimizes the mean squared error of prediction. Since the correlation parameters \(\theta_{k}\) are unknown, what we can do is compute their maximum likelihood estimates, then use what would be the best linear unbiased predictor if the estimated correlations \(\theta_{k}\) were the true values. The resulting predictor is called the _empirical best linear unbiased predictor_ (eBLUP).

It can be shown that the eBLUP of \(Y(\boldsymbol{x}_{a})\) is \(\hat{Y}(\boldsymbol{x}_{a})=E[Y(\boldsymbol{x}_{a})|\boldsymbol{y}]\), which is the mean of \(Y(\boldsymbol{x}_{a})\) conditional on the observed data \(\boldsymbol{y}\) at the observed input combinations \(\boldsymbol{x}_{1},\,\ldots,\,\boldsymbol{x}_{n}\). For model (20.3.1), the formula for the eBLUP of \(Y(\boldsymbol{x}_{a})\) is most easily written in terms of vectors and matrices. Readers who do not have an algebra background can jump to (20.3.6) and leave it to computer software to do the needed calculations. The formula for the eBLUP is

\[\hat{Y}(\boldsymbol{x}_{a})=\hat{\beta}_{0}+\hat{\boldsymbol{r}}^{\prime}\hat{ \boldsymbol{R}}^{-1}(\boldsymbol{y}-\boldsymbol{1}\hat{\beta}_{0}), \tag{20.3.4}\]

where \(\hat{\boldsymbol{r}}\) is an \(n\times 1\) vector whose \(i\)th element \(\hat{r}_{i}=R(\boldsymbol{x}_{a}-\boldsymbol{x}_{i}|\hat{\boldsymbol{\xi}})\) is the estimated correlation between the response \(Y(\boldsymbol{x}_{a})\) at a new input combination \(\boldsymbol{x}_{a}\) and the \(i\)th previous response \(Y(\boldsymbol{x}_{i})\), \(\hat{\boldsymbol{R}}\) is a \(n\times n\) matrix whose \(i\)th element \(\hat{R}_{ij}=R(\boldsymbol{x}_{i}-\boldsymbol{x}_{j}|\hat{\boldsymbol{\xi}})\) is the estimated correlation between observed responses \(Y(\boldsymbol{x}_{i})\) and \(Y(\boldsymbol{x}_{j})\), \(\boldsymbol{1}\) is \(n\times 1\) vector of \(1\)'s, and \(\hat{\beta}_{0}=(\boldsymbol{1}^{\prime}\hat{\boldsymbol{R}}^{-1}\boldsymbol{ 1})^{-1}\boldsymbol{1}^{\prime}\hat{\boldsymbol{R}}^{-1}\boldsymbol{y}\) is the generalized least squares estimate of \(\beta_{0}\).

Under model (20.3.1), the uncertainty about the predicted value can be estimated via the estimated variance of the eBLUP given by

\[\hat{s}^{2}(\boldsymbol{x}_{a})=\hat{\sigma}^{2}\left[1-\hat{\boldsymbol{r}}^ {\prime}\hat{\boldsymbol{R}}^{-1}\hat{\boldsymbol{r}}+\frac{(1-\boldsymbol{1} ^{\prime}\hat{\boldsymbol{R}}^{-1}\boldsymbol{1})^{2}}{\boldsymbol{1}^{ \prime}\hat{\boldsymbol{R}}^{-1}\boldsymbol{1}}\right]. \tag{20.3.5}\]

It can be shown algebraically that \(s^{2}(\boldsymbol{x})=0\) for any \(\boldsymbol{x}\) for which the response \(Y(\boldsymbol{x})\) was already observed, i.e. the model will interpolate the data.

For each possible unobserved input combination \(\boldsymbol{x}_{a}\), the \(100(1-\alpha)\)% prediction interval can be calculated as

\[\hat{Y}(\boldsymbol{x}_{a})\pm z_{\alpha/2}\hat{s}(\boldsymbol{x}_{a})\,. \tag{20.3.6}\]

There are two key observations to be made about the predictor \(\hat{Y}(\boldsymbol{x}_{a})\), whose form is shown in (20.3.4). First, the predicted value at a new input site \(\boldsymbol{x}_{a}\) is the sum of two parts. The first part is the estimated overall mean \(\hat{\beta}_{0}\). The second part is a weighted average of the differences \(y(\boldsymbol{x}_{i})-\hat{\beta}_{0}\) between each observed response \(y(\boldsymbol{x}_{i})\) and the estimated overall mean \(\hat{\beta}_{0}\). In general, the largest weight that would be calculated in (20.3.4) is associated with the term \(y(\boldsymbol{x}_{i})-\hat{\beta}_{0}\) corresponding to the \(\boldsymbol{x}_{i}\) that is closest to \(\boldsymbol{x}_{a}\); the second largest weight is associated with the term corresponding to \(\boldsymbol{x}_{i}\) that is second closest to \(\boldsymbol{x}_{a}\), etc. So, similar to Example 20.2.1, the quality of the prediction at \(\boldsymbol{x}_{a}\) is a function of the distances between \(\boldsymbol{x}_{a}\) and the \(n\) points \(\boldsymbol{x}_{i}\) for which we have already observed the response. If we have not observed any responses in the vicinity of an input combination \(\boldsymbol{x}_{a}\), then our prediction \(\hat{Y}(\boldsymbol{x}_{a})\) will default to a value close to \(\hat{\beta}_{0}\) and may be a poor estimate of \(Y(\boldsymbol{x}_{a})\). On the other hand, if we have collected quite a few observations in a particular region of the input space, we can expect to predict the unknown surface quite well in that region.

The second important observation is that the predictor \(\hat{Y}(\mathbf{x}_{a})\) shown in (20.3.4) is an _interpolating_ predictor. In other words, suppose that \(\mathbf{x}_{a}\) is one of the inputs for which we have observed the response, say \(\mathbf{x}_{a}=\mathbf{x}_{p}\). Then our predictor will return the observed value \(y(\mathbf{x}_{p})\); that is,

\[\hat{Y}(\mathbf{x}_{p})=y(\mathbf{x}_{p})\,.\]

This behavior from our predictor is desirable because of the deterministic nature of the computer code. If we know that we have observed a response without an error and that we will observe the same response every time we run the computer code for the same input \(\mathbf{x}_{i}\), then we would like our predictor to predict the same value for the response.

#### 20.3.1 One Predictor, continued

As in Example 20.2.1, suppose the true but unknown input-output relationship is described by a dampened cosine curve, \(y=f(x)=e^{-4x}\cos(6\pi x)\), for \(0\leq x\leq 1\), as shown in Fig. 20.1. This relationship is shown again as the solid line in Fig. 20.2. Suppose we try to estimate the unknown relationship based on the seven observations \((x_{i},\,y_{i})\) that were considered in Example 20.2.1--namely, (0.06, 0.33), (0.18, \(-\)0.47), (0.35, 0.23), (0.52, \(-\)0.12), (0.69, 0.06), (0.74, 0.01), (0.95, 0.01). These seven data points are shown as the solid dots in Fig. 20.2(a). Using software (see Sects. 20.6 and 20.7) to fit the GaSP model from (20.3.1) with the Gaussian correlation function (20.3.3) and \(d=1\), we obtain the maximum likelihood estimates \(\hat{\sigma}=0.0582\), \(\hat{\beta}_{0}=0.0047\), and \(\hat{\theta}=271.95\). Using (20.3.4)-(20.3.6), the predictions and 95% prediction intervals can then be calculated for \(x=0.01,\,0.02,\,\ldots,\,1\). The three dashed lines in Fig. 20.2(a) show the predicted curve (the darker middle curve) and the prediction intervals. We can see that our model does a particularly poor job of predicting the true relationship for \(x\) values roughly between 0.8 and 0.9. Since there are no observations in this area, the prediction tends to regress to (i.e. predict values closer to) the estimated mean \(\hat{\beta}_{0}=0.0047\).

Figure 20.2(b) shows the same information as Fig. 20.2(a), but having fit the model using a set of \(n=10\) different observations. The maximum likelihood estimates are now \(\hat{\sigma}=0.0942\), \(\hat{\beta}_{0}=0.0551\), and \(\hat{\theta}=196.17\). Figure 20.2(b) indicates a dramatic improvement in the model's prediction performance. Thus, we see that good design of the computer experiment can be crucial to good prediction.

Figure 20.2: True unknown, observed, and predicted relationships between \(x\) and \(y\) for Example 20.3.1

### Design

For a computer experiment involving \(n\) runs and \(d\) input variables, a _design_ consists of the \(n\) input combinations \(\boldsymbol{x}_{1},\ldots,\boldsymbol{x}_{n}\) to be run, where \(\boldsymbol{x}_{i}=(x_{i1},\,x_{i2},\ldots,x_{id})\), \(i=1,\ldots,n\). It is customary to collect these input combinations into an \(n\times d\) array or "matrix" \(\boldsymbol{X}\), where the \(k\)th row of \(\boldsymbol{X}\) shows the \(k\)th input combination, and we refer to such an array as an \(n\times d\)_design_\(\boldsymbol{X}\), or an \(n\times d\)_design matrix_\(\boldsymbol{X}\).

The interpretation of the magnitude of the parameters \(\theta_{k}\) in (20.3.3) is related to the scale of the input \(x_{k}\). More importantly, assessing the sensitivity of the response to the changes in inputs \(x_{k}\) and \(x_{j}\) by comparing the magnitudes of \(\theta_{k}\) and \(\theta_{j}\) associated with those inputs \(x_{k}\) and \(x_{j}\) can be deceiving if those inputs are defined on vastly different scales. To avoid the potential pitfalls it is common to transform the range of each input variable to become [0,1]. This is done by subtracting the minimum and then dividing by maximum\(-\)minimum. For example, if \(x_{1}\) has an original range of possible values 3.5 to 9.6, we subtract 3.5 from every value of \(x_{1}\) and divide by \((9.6-3.5)=6.1\). From now on, we will assume that this transformation has been done and that every input variable now has values in the range [0,1].

#### Space-Filling and Non-collapsing Designs

The design of a computer experiment--namely, the choice of input combinations \(\boldsymbol{x}_{1},\ldots,\boldsymbol{x}_{n}\) for the computer code--is guided by the deterministic nature of a computer experiment and by the particular characteristics of the predictor discussed in Sect. 20.3. We expect to predict the unknown surface well in the regions of input space where we have observed some nearby responses. Therefore, we would like our initial design to explore the input space "evenly", so we would like our design to be _space-filling_. Designs that are not space-filling will neglect one or more regions of the input space, and we can anticipate poor prediction of the response in such regions.

For example, consider a computer experiment involving \(d=2\) input variables and input combinations \(\boldsymbol{x}_{i}=(x_{i1},\,x_{i2})\), with \(0<x_{ik}<1\) for \(i=1,\ldots,n;\,k=1,\,2\), listed as the rows of the design \(\boldsymbol{X}\). Such input combinations correspond to points in a unit square, where a response can be observed. Consider the two 20-run experimental designs \(\boldsymbol{X}_{1}\) and \(\boldsymbol{X}_{2}\) whose design points \((x_{i1},\,x_{i2})\) are plotted in Fig. 20.3. Although we have not yet quantified the space-filling idea, the design \(\boldsymbol{X}_{1}\) seems to do a much better job of exploring the two-dimensional input space than \(\boldsymbol{X}_{2}\). In particular, \(\boldsymbol{X}_{2}\) does not contain any points \((x_{i1},\,x_{i2})\) such that \(x_{i2}>x_{i1}+0.4\) leaving the upper left region of the input space unexplored. Hence, based on our previous discussion, the predictor based on \(\boldsymbol{X}_{1}\) should do a better job of predicting the unknown surface in the upper left region of the input space than the predictor based on \(\boldsymbol{X}_{2}\).

As previously noted, multiple runs of the computer code at the same input combination \(\boldsymbol{x}=(x_{1},\,x_{i},\,\ldots,\,x_{d})\) will yield the same output \(y(\boldsymbol{x})\) due to the deterministic nature of the computer code, so replicating input points is wasteful. Moreover, when one or more input variables has no effect on the response, it is beneficial to avoid replicating any input combination for _any subset_ of the input variables (as explained below). One way to avoid this replication is to ensure that, for each column (i.e. input variable) of such a design \(\boldsymbol{X}\), the \(n\) input values are distinct. Such a design is called a _noncollapsing design_. To illustrate this notion, consider the following two design matrices, each for four runs (rows) with two inputs (columns):\[\mathbf{X}_{3}=\left[\begin{array}{ccc}0.2&0.2\\ 0.2&0.8\\ 0.8&0.2\\ 0.8&0.8\end{array}\right]\text{ and }\mathbf{X}_{4}=\left[\begin{array}{ccc}0.2&0.8\\ 0.4&0.2\\ 0.6&0.6\\ 0.8&0.4\end{array}\right].\]

These designs are depicted in Fig. 20.4. We can see that \(\mathbf{X}_{3}\) is a collapsing design since both of its columns contain replicated values, i.e. if we collapse the design points onto either the \(x_{1}\)- or \(x_{2}\)-axis, we obtain only two distinct values from the four distinct points. \(\mathbf{X}_{4}\) is a noncollapsing design since neither \(x_{1}\) nor \(x_{2}\) values are replicated. Without any further considerations, one might wonder what possible problem a collapsing design could cause. Suppose the true, but unknown, response function is given by \(y(x_{1},x_{2})=\exp(-2x_{2})\cos(3\pi x_{2})\). We see that the response does not depend on the input \(x_{1}\); a fact not known to a researcher before the experiment. Based on the designs \(\mathbf{X}_{3}\) and \(\mathbf{X}_{4}\), the set of four corresponding observed values are given by \(\mathbf{y}_{3}=(0.21,0.06,0.21,0.06)\) and \(\mathbf{y}_{4}=(0.06,0.21,-0.24,-0.36)\), respectively. The design \(\mathbf{X}_{3}\) did not contain any replicated input combinations--no two rows were the same. Still, due to replication of values of \(x_{2}\) and the inactivity of \(x_{1}\), we ended up with undesirable replicated responses. One might argue that half of our computational resources were wasted, since two of the four runs of the computer code did not add any new information, except perhaps to notice that \(x_{1}\) may not affect the response. To prevent potential computational wastefulness, and in the light of the fact that we have other tools to identify inactive inputs, we prefer the design \(\mathbf{X}_{4}\).

Figure 20.4: A collapsing (\(\mathbf{X}_{3}\)) and a noncollapsing (\(\mathbf{X}_{4}\)) design

Figure 20.3: Two potential \(20\)-run designs for a computer experiment with \(2\) input variables

There are several strategies for constructing designs for computer experiments that are noncollapsing and/or space-filling. The most commonly used approach is that of Latin Hypercube designs, which are inherently noncollapsing and many are also space-filling. We illustrate these designs below.

#### Construction of Latin Hypercube Designs

To construct an \(n\times d\) Latin Hypercube design (LHD), we start by dividing the range \([0,1]\) of each input variable into \(n\) equal-length "bins", with divisions at

\[0,\,1/n,\,2/n,\,\ldots,\,(n-1)/n,\,1\,.\]

These bins have midpoints at \((2k-1)/2n\) for \(k=1,2,\ldots,n\) and, for simplicity, we can use the midpoints to label the bins. For example, in each of Fig. 20.5(a)-(c), we have \(n=5\) input points, and so the bin mid-points for each of \(x_{1}\) and \(x_{2}\) are at

\[\frac{2-1}{10}=0.1,\;\;\frac{4-1}{10}=0.3,\;\;\frac{6-1}{10}=0.5,\;\;\frac{8-1 }{10}=0.7,\;\;\frac{10-1}{10}=0.9\,. \tag{20.4.7}\]

In total, there are \(5^{2}\) two-dimensional cells which can be labeled by the pairs of midpoints of the \((x_{1},\,x_{2})\) bins. Similarly, in general, dividing the ranges of each of \(d\) input variables \(x_{1},\,\ldots,\,x_{d}\) into \(n\) bins leads to \(n^{d}\) possible d-dimensional cells; these are called _hypercubes_ and can be labeled using the sets of bin midpoints for the \(d\) input variables.

Next, we want to choose \(n\) of these \(n^{d}\) cells (hypercubes) to contain a design point in such a way that there is only one design point in each bin for each individual input variable. The design is then non-collapsing. For example, if the 5 input points in each of the designs depicted in Figs. 20.5(a)-(c) are projected onto each axis, it can be seen that they rest on the midpoints (20.4.7) of the 5 bins for both \(x_{1}\) and \(x_{2}\). One way of achieving such a choice is as follows.

1. Start with an array \(\boldsymbol{X}\) with \(n\) rows and \(d\) columns where each column contains the integers \(1,\,2,\,\ldots,\,n\).
2. For each column separately, randomly order the integers.
3. Replace each integer \(k\) by the corresponding bin midpoint \((2k-1)/2n\).

Figure 20.5: Latin hypercube designs

* The \(i\)th row of of the randomly ordered \(\mathbf{X}\) then determines the \(i\)th input combination for the experiment.

#### 20.4.1 \(5\times 2\) Latin hypercube designs

Suppose that a design is required with \(n=5\) input points for a computer experiment where the simulator has \(d=2\) input variables. Following the above procedure, each of the \(d\) columns of \(\mathbf{X}\) starts with the values 1, 2, 3, 4, 5 in order. Each column is randomly ordered and the integers \(k\) are replaced by the bin midpoints \((2k-1)/2n=0.1\), \(0.3\), \(0.5\), \(0.7\), \(0.9\) to give the final design. Three possible designs are

\[\mathbf{X}_{1}=\left[\begin{array}{cc}0.1&0.1\\ 0.3&0.3\\ 0.5&0.5\\ 0.7&0.7\\ 0.9&0.9\end{array}\right],\ \ \mathbf{X}_{2}=\left[\begin{array}{cc}0.3&0.5\\ 0.5&0.1\\ 0.9&0.7\\ 0.1&0.9\\ 0.7&0.3\end{array}\right],\ \text{and}\ \mathbf{X}_{3}=\left[\begin{array}{cc}0.5&0.1 \\ 0.3&0.5\\ 0.1&0.9\\ 0.9&0.3\\ 0.7&0.7\end{array}\right],\]

where each row gives the coordinates of an input combination \(\mathbf{x}_{i}=(x_{i1},x_{i2})\). Designs \(\mathbf{X}_{1}\), \(\mathbf{X}_{2}\), and \(\mathbf{X}_{3}\) are the three designs depicted in Fig. 20.5a-c. Since all these designs are LHDs, they are noncollapsing.

By visual inspection, we notice that the design \(\mathbf{X}_{1}\) is the least space-filling and does the poorest job of exploring the input space. Although this design does a really good job of exploring the space along the main diagonal, that is all that it does well. Since no points are placed away from the main diagonal, there is no exploration of the input space towards the upper left and lower right corners of the space. If we use this design to run our experiment, we can expect very poor predictions the further we get away from the main diagonal. Even though \(\mathbf{X}_{1}\) is an LHD, it is clearly not space-filling, so is a poor design for a computer experiment. Both \(\mathbf{X}_{2}\) and \(\mathbf{X}_{3}\) do better at space filling, and which is the better of these two designs is less clear (although a preference will be expressed for \(\mathbf{X}_{3}\) in Example 20.4.2). 

To seek a design which is both noncollapsing and space-filling, experimenters often look for a Latin hypercube design that best satisfies some space-filling property. There is a vast literature describing many attempts to define what we mean by a "best" design with respect to space-fillingness. One of the most common approaches is to choose a design which maximizes the distance between the two closest points in the design. A common measure of distance is the familiar Euclidean distance between \(\mathbf{x}_{i}=(x_{i1},\ldots,x_{id})\) and \(\mathbf{x}_{j}=(x_{j1},\ldots,x_{jd})\); that is,

\[\sqrt{\sum_{\ell=1}^{d}(x_{i\ell}-x_{j\ell})^{2}}\,. \tag{20.4.8}\]

Suppose that we have two \(n\times d\) designs \(\mathbf{X}_{1}\) and \(\mathbf{X}_{2}\). For each design, we can determine the minimum distance between pairs of input points. The design with the larger value of this minimum distance is considered preferable, since choosing a design in this way forces the design points to be far away from each other and so tends to be more space-filling. Among all possible designs, any design that _maximizes this _min_imum interpoint distance is called a _maximin design_.

#### 20.4.2 \(5\times 2\) Latin hypercube designs, continued

One could compare the designs \(\mathbf{X}_{1}\), \(\mathbf{X}_{2}\), and \(\mathbf{X}_{3}\) of Fig. 20.5 based on the maximin criterion. The corresponding interpoint distances (rounded to two decimal places) are shown in Table 20.1. Notice that the smallest interpoint distance is \(0.28\) for both \(\mathbf{X}_{1}\) and \(\mathbf{X}_{2}\), compared with the minimum interpoint distance of \(0.45\) for \(\mathbf{X}_{3}\). Hence, among these three Latin hypercube designs, \(\mathbf{X}_{3}\) is the maximin design.

If we now look at \(\mathbf{X}_{1}\) in Fig. 20.5(b) again, we can see that the two points nearest the \(x_{1}\) axis are close together in the two-dimensional space, whereas all the points lie further apart in \(\mathbf{X}_{3}\) in Fig. 20.5(c), leading to a slightly better coverage of the design space. 

Exercises 7 and 8 show alternative measures of space-fillingness ("minimax" and "average reciprocal distance"). There are other measures, too, in the literature. But, in this chapter, we will concentrate on the most common measure of "maximin". (For further types of designs, see Santner et al. 2003, Chaps. 5 and 6).

In practice, to construct a space-filling, noncollapsing design, one would use the aid of a computer. For example, given the number of runs \(n\) and inputs \(d\), one could use the computer to generate lots (several hundred) Latin hypercube designs \(\mathbf{X}\), by using many random orderings of the columns, compute the minimum interpoint distance for each design, and keep the design with the largest minimum interpoint distance. Although this may not result in _the_ maximin design, it should result in one that is close to maximin and which has good space-filling properties. Sections 20.6.1 and 20.7.1 show how to generate maximin LHDs using the SAS and R software, respectively.

As a final note, design points do not necessarily need to be placed at the midpoint of the cell. One can place a design point in a randomly chosen location in the cell by adding a random number between \(-(2n)^{-1}\) and \(+(2n)^{-1}\) to every \(x_{ij}\) in \(\mathbf{X}\).

### A Real Experiment--Neuron Experiment

One of the authors (Danel Draguljic) was involved in a study aimed at modeling the performance of neurons. The study, which is described by Rumbell and coauthors in _Journal of Computational Neuroscience_ in 2016, aimed to improve the fits of conductance-based models to in vitro whole cell recordings from pyramidal neurons of layer 3 of the prefrontal cortex from young and aged rhesus monkeys. The neuron's performance was measured by its firing rate (response, \(Y\)) which was modeled with either 4 or 8 ion channels resulting in 10 or 23 explanatory variables, respectively, to be considered in the model.

Table 20.2 shows the data from a simplified model for the firing rates of a neuron at +380 pA current injection of a young monkey. The simplified model contained two input variables; \(x_{1}\) was the maximal conductance of the transient sodium, denoted \(g_{\text{NaF}}\), and \(x_{2}\) was the maximal conductance of the delayed-rectifier potassium, denoted \(g_{\text{KDR}}\). Both of these variables affect the neuron firing rate. Both maximal conductances had original ranges between 0.05 and 0.5 mS/cm\({}^{2}\), but the \(g_{\text{NaF}}\) and \(g_{\text{KDR}}\) values in Table 20.2 have been scaled to the [0, 1] range, as throughout this chapter. The design chosen for the input variables was a 30 \(\times\) 2 Latin hypercube design and is shown in Fig. 20.6(a).

Columns 1 and 2 of Table 20.2 show the first 15 values of the input variables, and columns 4 and 5 show the next 15 values. For a given value of \(g_{\text{NaF}}\) and \(g_{\text{KDR}}\) the computer simulator was run for 2

\begin{table}
\begin{tabular}{l|c c c c|c c c c|c c c c}  & \multicolumn{4}{c}{\(\mathbf{X}_{1}\)} & \multicolumn{4}{c}{\(\mathbf{X}_{2}\)} & \multicolumn{4}{c}{\(\mathbf{X}_{3}\)} \\  & \(\mathbf{x}_{1}\) & \(\mathbf{x}_{2}\) & \(\mathbf{x}_{3}\) & \(\mathbf{x}_{4}\) & \(\mathbf{x}_{1}\) & \(\mathbf{x}_{2}\) & \(\mathbf{x}_{3}\) & \(\mathbf{x}_{4}\) & \(\mathbf{x}_{1}\) & \(\mathbf{x}_{2}\) & \(\mathbf{x}_{3}\) & \(\mathbf{x}_{4}\) \\ \hline \(\mathbf{x}_{2}\) & 0.28 & & & & 0.45 & & & & 0.45 & & & & \\ \(\mathbf{x}_{3}\) & 0.57 & 0.28 & & & 0.63 & 0.72 & & & 0.89 & 0.45 & & & \\ \(\mathbf{x}_{4}\) & 0.85 & 0.57 & 0.28 & & 0.45 & 0.89 & 0.82 & & & 0.45 & 0.63 & 1.00 & \\ \(\mathbf{x}_{5}\) & 1.13 & 0.85 & 0.57 & 0.28 & 0.45 & 0.28 & 0.45 & 0.85 & 0.63 & 0.45 & 0.63 & 0.45 \\ \end{tabular}
\end{table}
Table 20.1: Interpoint distances for the designs of Fig. 20.5seconds and the number of spikes, \(y_{i}\), was recorded. These observed firing rates are shown in columns 3 and 6 of Table 20.2 and displayed in Fig. 20.6(b). We can observe that relatively low firing rates occur for large values of \(g_{\text{KDR}}\) and small values of \(g_{\text{NaF}}\). For example, if we are trying to maximize neuron's firing rate, it seems that our best chance lies with values in the upper ranges of both variables.

We would like to use our data to construct an estimator \(\hat{y}\) of \(Y=f(g_{\text{NaF}},g_{\text{KDR}})\). The estimator \(\hat{y}\) would then enable us to identify the regions in the \((g_{\text{NaF}},g_{\text{KDR}})\) space that are associated with either low or high neuron activity. After fitting the GaSP model (20.3.1) with Gaussian correlation function (20.3.3), we obtain the maximum likelihood estimates \(\hat{\sigma}=15.87\), \(\hat{\theta}_{1}=\hat{\theta}_{\text{NaF}}=5.03\), and

\begin{table}
\begin{tabular}{c c c c c c} \hline \(g_{\text{NaF}}\) & \(g_{\text{KDR}}\) & \(y_{i}\) & \(g_{\text{NaF}}\) & \(g_{\text{KDR}}\) & \(y_{i}\) \\ \hline
0.38594 & 0.21207 & 33 & 0.53994 & 0.83528 & 41 \\
0.04667 & 0.45947 & 0 & 0.13236 & 0.93565 & 1 \\
1.00000 & 0.44733 & 46 & 0.90811 & 0.58219 & 46 \\
0.95468 & 0.33514 & 44 & 0.88221 & 0.09805 & 39 \\
0.53335 & 0.79813 & 41 & 0.39918 & 0.55403 & 36 \\
0.59167 & 0.60427 & 41 & 0.22713 & 0.67680 & 34 \\
0.18570 & 0.37995 & 31 & 0.82599 & 0.00000 & 13 \\
0.49928 & 0.24442 & 36 & 0.69149 & 0.06387 & 36 \\
0.74609 & 0.39496 & 42 & 0.79710 & 0.01235 & 19 \\
0.07269 & 1.00000 & 0 & 0.31326 & 0.12559 & 30 \\
0.27908 & 0.27845 & 32 & 0.62431 & 0.63717 & 41 \\
0.34985 & 0.51466 & 35 & 0.97649 & 0.86049 & 48 \\
0.64658 & 0.89122 & 43 & 0.46554 & 0.76087 & 39 \\
0.20972 & 0.71452 & 34 & 0.11439 & 0.31166 & 34 \\
0.00000 & 0.95918 & 0 & 0.77811 & 0.15813 & 39 \\ \hline \end{tabular}
\end{table}
Table 20.2: The data for the neuron experiment

Figure 20.6: The design and the data for the neuron experiment

[MISSING_PAGE_FAIL:793]

#### 20.6.1 Maximin Latin Hypercube Designs

This section shows how to use SAS software to get an LHD that is approximately maximin. The idea behind constructing a maximin LHD (Mm LHD) is described in Sect. 20.4.2. First, we construct an \(n\times d\) LHD. Second, for the newly constructed LHD we calculate all \(\binom{n}{2}\) interpoint Euclidean distances and then find the smallest one, i.e. we identify the distance between two closest points. And third, we iterate this process many times and, among many created LHDs, we identify the one with largest minimum interpoint distance. It is worth noting that the "best" design obtained after running the SAS code from this section contains the maximum minimum interpoint distance among the number of designs examined by the code. Another run of the same code with the same inputs might produce a design with even larger maximum minimum interpoint distance.

The SAS programs shown here are in the form of SAS "macros". A macro is a piece of SAS code that can be stored separately and is extremely useful when SAS software has to repeat the same calculations many times, as it does in the search for the best LHD. Table 20.3 shows a SAS macro. A macro begins and ends with SAS statements %macro and %mend, respectively. The macro in Table 20.3 is called createLHD and it has two inputs \(n\) and \(d\), which will be provided when the macro is "called" (implemented). The body of a macro contains SAS statements that can be run many times by calling the macro which eliminates copying and pasting the statements themselves. Before being able to use a macro, we have to run the whole macro. Once this is done, the SAS software has this macro available for use. To then execute the SAS statements within the macro createLHD, we run for example %createLHD(n = 20, d = 2) where, here, values 20 and 2 have been selected for \(n\) and \(d\). These values can be changed to suit the user's needs.

Within this macro, the % symbol indicates to the SAS software that this is a segment of the program; here we have two (nested) loops starting at %do and ending at %end. The & symbol in front of the variables n, d, i and j indicates that, within the macro, the variables have been assigned specific values (the last two change as we proceed around the loops). Writing macros is beyond the scope of this book, but we note that SAS code that is inside of a macro can be taken out and be used with some necessary clean-up, such as removing the % and & symbols.

The SAS code to find an approximately maximin LHD is shown in the form of three macros in Tables 20.3, 20.4, and 20.5, respectively. The macro createLHD, shown in Table 20.3, constructs an LHD with \(n\) rows and \(d\) columns, where \(d\) is the number of inputs to the computer simulator and \(n\) is the required number of outputs. The LHD is constructed by filling each of the \(d\) columns with \((2k-1)/2n\) for \(k=1\), \(2\),..., \(n\) and then the rows of each column are randomly rearranged using the ranuni(0) command described in Sect. 3.8.1. To then construct, say, a 20 \(\times\) 2 LHD, one simply

Figure 20.8: Correlation as a function of distance \(\boldsymbol{h}\) between two input pointsruns %createLHD(n = 20, d = 2) line. A 20 x 2 LHD will then be created, printed out to the SAS \(Results\)\(Viewer\) window, and stored in the SAS data set called Lhd.

The macro shown in Table 20.4 is mipd. This macro calculates minimum interpoint distance for a user-provided LHD. For example, if we created an LHD using createLHD macro, we can then calculate this LHD's minimum interpoint distance by running %mipd(x = Lhd, d = 2) where input \(x\) is the SAS data set that contains the LHD and \(d\) is the number of columns in this LHD. The minimum interpoint distance will be printed to the \(Results\)\(Viewer\) window and it will be saved in the SAS data set Mindist.

In order to create a maximin LHD, we do not have to call the createLHD and mipd macros explicitly. Macro MmLHD shown in Table 20.5 does all the work for us. In addition to other SAS statements, MmLHD calls macros createLHD and mipd with the appropriate inputs for each. Even though we do not call createLHD and mipd directly, we do have to run them before we run and call MmLHD. The macro MmLHD requires three inputs itself: mrow and ncol define the size of the LHD (\(n\) and \(d\)) and the integer iter tells the SAS software how many LHDs we want the SAS software to create from which to choose the one with largest minimum interpoint distance. If we run %MmLHD(mrow = 30, ncol = 3, iter = 100) the SAS software will create one hundred 30 x 3 LHDs and it will find the one with the largest minimum interpoint distance. This design with largest minimum interpoint distance is stored in the SAS data set Best. To see the design Best's smallest interpoint distance, we can run %mipd(x = Best, d = 3).

All designs created by MmLHD have input points placed at random within the selected LHD cells. If we want points placed at the midpoints of the selected cells, we have to remove + (l/&n)*ranuni(-l) - l/(2*&n) from the fifth line in the macro createLHD.

After creating the approximate maximin LHD, the simulator can be run with input combinations **x** defined by the \(n\) rows of the design stored in Best.

\begin{table}
\begin{tabular}{c c} \%macro createLHD(n=, d=); & \%do i = 1 \%to \&d; \\  & data temp\&i; \\  & \%do j = 1 \%to \&n; \\  & x\&i = (2*\&j - 1)/(2*\&n) + (l/&n)*ranuni(-l) - 1/(2*\&n); \\  & ramno\&i = ranuni(0); \\  & output; \\  & \%end; \\  & run; \\  & proc sort data = temp\&i; by ranno\&i; run; \\  & data temp\&i; set temp\&i; drop ranno\&i; run; \\  & \%end; \\  & data lhd; merge temp1 - temp\&d; run; \\  & proc print data = Lhd; run; \\  & \%mend createLHD; \\ \end{tabular}
\end{table}
Table 20.3: A SAS program for construction of an LHD

#### Fitting the GaSP Model

To use the SAS software, we view GaSP model as a mixed model where all observations are taken on the same subject and are therefore correlated. This approach allows us to fit the GaSP model using PROC MIXED (cf. Sect. 17.10).

Table 20.6 shows a SAS program for the analysis of the neuron computer experiment data of Table 20.2, p. 777. The goal of the experiment was to quantify the effect of \(g_{\text{NaF}}\) and \(g_{\text{KDR}}\) on a neuron's firing rate.

The 30 sets of data values are read in line by line via the first set of DATA statements in Table 20.6. In the second set of DATA statements a 1012\(\times\) 3 data set PREDS is constructed, whose first two columns contain the values of \(g_{\text{NaF}}\) and \(g_{\text{KDR}}\) for which we would like to predict the firing rate once the model is fitted. These values consist of a 2-dimensional grid with "mesh size" of 0.01. The mesh size defines the spacing on the grid, so a grid with mesh size 0.01 has points (0, 0), (0, 0.01), (0, 0.02), \(\ldots\), (1, 0.99), (1, 1). The third column in PREDS is \(y\) and it has all values set to missing. The third DATA statement constructs the new data set FORANALYSIS by appending PREDS to the original data, so that the data set FORANALYSIS has \(30+101^{2}\) rows of data. The GaSP model (20.3.1) is fitted with PROC MIXED. When fitting the model, the SAS software will use only the observations whose \(y\) value is available. If the value for \(y\) is missing, the SAS software will use the fitted model to calculate \(\hat{y}\) for the observations with missing \(y\) values.

There are several options in PROC MIXED that require some clarification. By default, SAS software will choose the restricted maximum likelihood as the method of estimation (see Sect. 19.8.3). The METHOD = ML option instructs the SAS software to use maximum likelihood estimation (p. 769). By leaving the right side of the MODEL equation empty, we instruct the SAS software to fit an intercept only model, i.e. estimate only \(\beta_{0}\). If we assumed a richer mean structure, say \(E[Y]=\beta_{0}+\beta_{1}g_{\text{NaF}}\), the

\begin{table}
\begin{tabular}{l} \%macro mipd(x=, d=); \\ proc distance data = \& x out = dist method = Euclid nostd; \\ var interval(xl - xkd); run; \\ data dist; \\ set dist; \\ array var \_numeric\_; \\ do over var; \\ if var = 0 then var =.; \\ end; \\ run; \\ proc meansolabels data = dist min noprint; \\ output out = colmins; run; \\ data colmins; \\ set columns; \\ where \_STAT\_ = “MIN”; \\ drop \_TYPE\_ \_FREQ\_ \_STAT\_; \\ run; \\ proc transpose data = colmins out = colminslong; run; \\ proc meansolabels data = colminslong min; \\ var COL1; \\ output out = Mindist min = minimum; run; \\ \end{tabular}
\end{table}
Table 20.4: A SAS program for calculation of minimum interpoint distancestatement would have been MODEL = g_NaF. The option OUTP = PREDICTIONS will calculate predictions and save them in a data set called PREDICTIONS.

The REPEATED statement is used to specify the covariance structure. The SP(EXPA) choice in the TYPE option specifies the "anisotropic exponential spatial" covariance structure which has the structure of (20.3.2) with \(R(\boldsymbol{x}_{i}-\boldsymbol{x}_{j}|\boldsymbol{\xi})\) being the Power exponential correlation function introduced in Exercise 2. The Gaussian correlation function from (20.3.3) is a special case of the Power exponential correlation function where \(p_{k}=2\) for \(k=1,2,\ldots,d\), and will be specified below. The SP(EXPA) statement is followed by the list of the input variables (\(g_{NaF}\,g_{KDR}\)). Then SUBJECT = INTERCEPT identifies all data as coming from one subject and forces the SAS software to model the covariance between any two observations, so that no covariance is set to zero.

The PARMS statement specifies the initial values for the covariance parameters. We can request a grid of values for each parameter to initiate the optimization algorithm which then searches for the parameter values that maximize the likelihood function. For the Power exponential correlation function, the SAS software expects \(2d\) + 1 initial values (\(\theta_{1},\ldots,\theta_{d}\), \(p_{1},\ldots,\,p_{d}\), and \(\sigma^{2}\)). In this example, the covariance parameters to be estimated are \(\theta_{1}\)(\(=\theta_{\text{NaF}}\)), \(\theta_{2}\)(\(=\theta_{\text{KDR}}\)), \(p_{1}\), \(p_{2}\), and \(\sigma^{2}\). To select the Gaussian correlation function, we need to set \(p_{1}\) and \(p_{2}\) equal to 2. Following the PARMS statement are the initial values. We must specify the values in the order in which they appear in the SAS output Covariance Parameter Estimates table (see Fig. 20.9). The first set of initial values is a set for \(\theta_{1}\) and, here, we provided a grid of 10 initial values, \(\{1,2,\ldots,10\}\). For \(\theta_{2}\) we provided a grid of 41 initial

\begin{table}
\begin{tabular}{c c} \%macro MmLHD(nrow=, ncol=, iter=); & \\ \%createLHD(n = \&nrow, d = \&ncol) \\ \%let design= lhd; & \\ \%mipd(x = \&design, d = \&ncol) \\ data Best; set\&design; run; quit; & \\ data\_null\_; & \\ set mindist; & \\ if\_N\_ = 1 then call symput("mipd", minimum); & \\ else stop; & \\ run; quit; & \\ \end{tabular}
\end{table}
Table 20.5: A SAS program for construction of maximin LHD

[MISSING_PAGE_FAIL:798]

one in Fig. 20.7. The DATA statement creates a data set to be plotted by keeping only the predictions. The PROC G3D creates the 3D plot (the actual plot is not shown here).

### Using R Software

In this section, we illustrate use of the R software for creating Latin hypercube designs (LHDs) and for analyzing data obtained from computer experiments.

#### Maximin Latin Hypercube Designs

This section shows how to use R to get an LHD that is approximately maximin (denoted Mm LHD). The idea behind constructing an Mm LHD is described in Sects. 20.4.2 and 20.6.1. While it would have been fairly straight-forward to write our own R code similar to the SAS code shown in Sect. 20.6.1 to construct an approximate Mm LHD, we can use R's package lhs for this purpose. To construct an appropriate Mm LHD, we use lhs's function maximinLHS which has three inputs. These are \(n\), the planned number of outputs of the computer simulator, \(k\), the number of inputs to the computer simulator, and dup, an integer tuning parameter that determines the number of candidate points considered by maximinLHS while constructing an Mm LHD. Larger values of dup lead to more points considered but also increase the time needed to construct a design. dup = 5 is suggested as a reasonable choice.

For example, to construct an approximate 30 x 3 Mm LHD named Best, we run the R command Best <- maximinLHS(30, 3, 5). After creating the approximate Mm LHD, the simulator can be run with input combinations \(\boldsymbol{x}\) defined by the \(n=30\) rows of the design stored in Best. Currently, maximinLHS does not support construction of designs whose points are at the midpoint of the cells, so the points in Best will be randomly placed within the selected cells.

Figure 20.9: GaSP model estimates—the neuron experiment

#### Fitting the GaSP Model

In this section, we illustrate the analysis of computer experiment data with R software, using the neuron experiment data in Table 20.2, p. 777. The goal of the experiment was to quantify the effect of \(g_{\text{NaF}}\) and \(g_{\text{KDR}}\) on a neuron's firing rate.

Table 20.7 contains the R program and selected output illustrating the fitting of the GaSP model to the neuron experiment data. The first lines of Table 20.7 read the data from the file neuron.txt and print out the first three rows of the data. The model is then fit using the mlegp function from the R package mlegp, which computes maximum likelihood estimates (mle) for Gaussian (stochastic) processes (gp). To calculate the maximum likelihood estimates of the GaSP parameters, the mlegp function requires two inputs. The first one is the design matrix \(\boldsymbol{X}\) defined here by the first two columns of neuron data. The second one is the vector of the observed responses \(\boldsymbol{y}\) given here in the third column of the neuron data set. The mlegp function has the capability to fit noisy data, data with

\begin{table}
\begin{tabular}{l} \textgreater{} neuron \textless{}- read.table(*data/neuron.txt*, header = T) \\ \textgreater{} head(neuron, 3) \\ g\_NaF g\_KDR Y \\
[1,] 0.38594 0.21207 33 \\
[2,] 0.04667 0.45947 0 \\ [3,] 1.00000 0.44733 46 \\ \textgreater{} \# install.packages(*mlegp*) \\ \textgreater{} library(mlegp) \\ \textgreater{} gasp \textless{}- mlegp(neuron[, 1:2], neuron[, 3]) \\ \textgreater{} summary(gasp) \\ Total observations = 30 \\ Dimensions = 2 \\ mu = 27.6111 \\ sig2: 251.9121 \\ Correlation parameters: \\ beta \\
1 5.027256 2 \\
2 50.233487 2 \\ Log likelihood = -104.4487 \\ \textgreater{} predictedX \textless{}- expand.grid(g\_NaF = seq(0, 1, 0.01), \\ g\_KDR = seq(0, 1, 0.01)) \\ \textgreater{} yhats \textless{}- predict(gasp, predictedX) \\ \textgreater{} \# install.packages(*rgl*) \\ \textgreater{} library(rgl) \\ \textgreater{} plot3d(neuron[, 1], neuron[, 2], neuron[, 3], \\ col = "red", size = 3, type = "s", \\ + xlab = "g NaF (mS/cm^2)*, ylab = "g KDR (mS/cm^2)", \\ + zlab = "Firing rate (spikes per 2 s)") \\ \textgreater{} plot3d(predictedX[, 1], predictedX[, 2], yhats, col = "blue", \\ \textgreater{} size = 0.5, type = "s", add = TRUE) \\ \end{tabular}
\end{table}
Table 20.7: An R program and selected output for analysis of the neuron experimentmultiple responses, etc. For more information on the mlegp function see R's help file by typing?mlegp. The model details are stored in gasp.

The maximum likelihood parameter estimates can be viewed by invoking the summary command. In the resulting output, \(\hat{\beta}_{0}\approx 27.61\) is labeled as mu, and \(\hat{\sigma}^{2}\approx 251.91\) is labeled as sig2. The correlation parameters are given in a \(d\times 2\) array where the first and second columns correspond to \(\hat{\theta}_{k}\) and \(\hat{p}_{k}\) for \(k=1\), \(2\), \(\ldots\), \(d\) but are labeled beta and a, respectively. \(\hat{\theta}_{1}\approx 5.03\) and \(\hat{\theta}_{2}\approx 50.23\). Since we fitted a Gaussian correlation function, \(p_{1}=p_{2}=2\).

Having fitted the model, we would like to construct the estimated response surface by predicting the response at a dense grid over the [0, 1] \(\times\) [0, 1] experimental region. The function expand.grid takes two sequences {0, 0.01, 0.02, \(\ldots\), 1} of length 101 as inputs and creates a "data frame" whose \(101^{2}\) rows represent all combinations of the members of the two sequences (e.g. all combinations of two sequences {.3,.6} would be (.3,.3), (.3,.6), (.6,.3), (.6,.6)). The resulting grid is stored in predictedX. To make the predictions yhats, we use R's predict function, first specifying gasp as the object that holds the estimated parameters and then specifying predictedX as the object that holds the new prediction sites. Depending upon the computer being used, calculating the yhats could take some time. The plot3d function from the R graphics library package rgl is used to produce the plot shown in Fig. 20.7, p. 778.

## Exercises

1. **Gaussian correlation function** The Gaussian correlation function \(R(\boldsymbol{x}_{i}-\boldsymbol{x}_{j}|\boldsymbol{\xi})\) introduced in Sect. 20.3, p. 768, quantifies the correlation between outputs at two points \(\boldsymbol{x}_{i}\) and \(\boldsymbol{x}_{j}\) based on the distance between them. For parts (a) and (b) below, consider the case of \(d=1\) input variable. 1. To investigate the effect of the value of parameter \(\theta\) on the correlation between outputs at two points, calculate the twenty five correlations \(R(x_{i}-x_{j}|\theta)\) for \(\theta\in\{0.5,2,5,20,100\}\) and \(|x_{i}-x_{j}|\in\{0.1,0.2,0.4,0.6,0.7\}\), where \(|x_{i}-x_{j}|\) is the absolute value of the distance between \(x_{i}\) and \(x_{j}\). 2. Construct a plot with \(|x_{i}-x_{j}|\) on the \(x\)-axis and \(R(x_{i}-x_{j}|\theta)\) on the \(y\)-axis, plot \(R(x_{i}-x_{j}|\theta)\) for each value of \(\theta\) on the same plot, and comment on the relationship between \(\theta\) and \(R(x_{i}-x_{j}|\theta)\).
2. **Power exponential correlation function** The Gaussian correlation function (20.3.3) is a special case of a Power exponential correlation function. The latter is given by \[R(\boldsymbol{x}_{i}-\boldsymbol{x}_{j}|\boldsymbol{\xi})=\prod_{k=1}^{d}\exp( -\theta_{k}|x_{ik}-x_{jk}|^{p_{k}})\] where \(\boldsymbol{\xi}\) represents the parameters (\(\theta_{1}\), \(\ldots\), \(\theta_{d}\), \(p_{1}\), \(\ldots\), \(p_{d}\)), with all \(\theta_{k}\geq 0\), and \(0<p_{k}\leq 2\). 1. Suppose there is \(d=1\) input variable. To investigate the effect of \(\theta\) on the correlation between outputs at two points \(x_{i}\) and \(x_{j}\) for the Power exponential correlation function, calculate the nine 

[MISSING_PAGE_FAIL:802]

6. **Maximin Latin hypercube designs** Consider the three LHDs shown below. Note that the location of the points is not in the center of each cell but is randomly chosen. \[\boldsymbol{X}_{1}=\left[\begin{array}{ccc}0.66&0.65\\ 0.23&0.38\\ 0.78&0.21\\ 0.38&0.98\end{array}\right],\boldsymbol{X}_{2}=\left[\begin{array}{ccc}0.50&0. 68\\ 0.24&0.39\\ 0.89&0.19\\ 0.35&0.92\end{array}\right],\text{ and }\boldsymbol{X}_{3}=\left[\begin{array}{ccc}0.98&0.10\\ 0.39&0.54\\ 0.18&0.76\\ 0.57&0.39\end{array}\right]\] We can think of _maximin designs_ in the following way. Suppose we need to place \(n\) grocery stores (design points, corresponding to rows in \(\boldsymbol{X}\)) in a particular county, where the county is the experimental region, taken as a rectangle determined by the ranges of the input variables \(x_{i}\) and then scaled to \([0,1]^{2}\). We would like to choose the store locations in a way that prevents any two stores from being close together. In other words, we are maximizing the minimum distance between the stores and are constructing a maximin design. 1. For each design, calculate all \(\binom{4}{2}\) Euclidean interpoint distances (20.4.8), p. 775, i.e. calculate the distances between each pair of proposed store locations. 2. For each design, identify the two closest points and their distance. 3. Between \(\boldsymbol{X}_{1}\), \(\boldsymbol{X}_{2}\), and \(\boldsymbol{X}_{3}\) identify the design that maximizes the minimum interpoint distance; i.e. identify the maximin design.
7. **Minimax designs** Referring back to the intuitive explanation of the maximin designs in Exercise 6, consider now the distance between each customer and the location of the stores in a county. A reasonable placement of the stores could be such that no customer is too far from the closest store. In other words, we are minimizing the maximum distance of each customer to the closest store. When we are minimizing the maximum distance of any point in the experimental region (input space) from the closest design point, we are constructing a _minimax design_. Minimax designs are notoriously difficult to construct. When building a maximin design we have to calculate only the \(\binom{n}{2}\) distances among the design points but, when constructing a minimax design, we have to consider infinitely many distances (since there are infinitely many points in the experimental region). Consider the three LHDs from Exercise 6 (i.e. the potential grocery store locations) and suppose that we are interested in the points in the experimental region (i.e. the customer locations) given by \[\boldsymbol{C}=\left[\begin{array}{ccc}0.59&0.10\\ 0.89&0.55\\ 0.14&0.35\\ 0.38&0.90\\ 0.72&0.63\end{array}\right].\] 1. For each of five points (customer locations) in \(\boldsymbol{C}\), determine the closest of the four design points in \(\boldsymbol{X}_{1}\) by calculating four appropriate Euclidean distances (20.4.8), p. 775. Identify a point (customer) in \(\boldsymbol{C}\) with the largest distance to its closest point in \(\boldsymbol{X}_{1}\). 2. Repeat part (a) for \(\boldsymbol{X}_{2}\) and \(\boldsymbol{X}_{3}\). 3. Identify which of the three designs is minimax for this scenario. 4. For each design, calculate all \(\binom{4}{2}\) Euclidean interpoint distances (20.4.8), p. 775, i.e. calculate the distances between each pair of proposed store locations. 5. For each design, identify the two closest points and their distance. 6. Between \(\boldsymbol{X}_{1}\), \(\boldsymbol{X}_{2}\), and \(\boldsymbol{X}_{3}\) identify the design that maximizes the minimum interpoint distance; i.e. identify the maximin design.

8. **Minimum average reciprocal distance designs** An alternative measure of space-fillingness is that of _minimum average reciprocal distance_. If design points are spaced out, then the distance between any pair of points will not be small, and so their reciprocal distance will not be large. Thus an alternative to constructing a maximin design is to construct a design with smallest possible average reciprocal distance between pairs of design points. The Euclidean distances between the points are calculated as in (20.4.8), p. 775, and the average of their reciprocals is the measure of goodness of the design. 1. Of the three designs \(\boldsymbol{X}_{1}\), \(\boldsymbol{X}_{2}\), \(\boldsymbol{X}_{3}\) in Exercise 6, which has the minimum average reciprocal distance? Does this coincide with the maximin design? 2. Of the three designs \(\boldsymbol{X}_{1}\), \(\boldsymbol{X}_{2}\), \(\boldsymbol{X}_{3}\) in Example 20.4.2, p. 775, which has the minimum average reciprocal distance? Does this coincide with the maximin design?
9. **Prediction** Suppose that a computer simulator with one input variable was run at 3 input points and the GaSP model with Gaussian correlation function (20.3.3) was fitted to the data: 
 leading to parameter estimates \(\hat{\beta}_{0}=-0.2104\), \(\hat{\sigma}^{2}=0.0264\), and \(\hat{\theta}=4.9003\). Based on this information, we would like to predict \(Y\) at \(x_{a}=0.20\) using the predictor in (20.3.4), p. 770. 1. Calculate \(\hat{\boldsymbol{R}}\) (defined below (20.3.4)). 2. Calculate \(\hat{\boldsymbol{r}}\) (defined below (20.3.4)). 3. Calculate \(\hat{Y}(x_{a})\) in (20.3.4) at \(x_{a}=0.20\). Is this the answer you expected? Explain. 4. Calculate the estimated variance \(\hat{s}^{2}(x_{a})\) (20.3.5) of your prediction. Is this the answer you expected? Explain. 5. Repeat parts (b), (c), and (d) for \(x_{a}=0.49\) and \(x_{a}=0.65\).
10. **Tool coating experiment** D. Draguljic, S. Nekkanty, T. J. Santner, A. M. Dean, and R. Shivpuri, in _Quality Engineering_ in 2015, described a computer experiment used to develop multilayer coatings which are used to protect tools, drills, cutting blades, bearings, etc. The experiment consisted of modeling the effect of the number of coating layers and the thicknesses of those layers on the normalized measures of maximum normal radial stress, \(Y_{1}\), and the maximum shear stress, \(Y_{2}\). The two responses were modeled independently. Large values of either stress would lead to coating failures (either peeling of of the coating or occurrence of cracks in the coating). Here we will focus on coatings with only two layers. Therefore we have input variables \(x_{1}\) and \(x_{2}\) (both in \(\mu\)m), the thicknesses of the top and the bottom layer, respectively. The data for this experiment are given in Table 20.8. Note that \(x_{1}\) and \(x_{2}\), as shown in Table 20.8, are scaled from their original (0, 6) \(\mu\)m scale to (0, 1) \(\mu\)m scale. 1. Estimate \(\theta_{1}\) and \(\theta_{2}\) from the GaSP model that relates \(x_{1}\) and \(x_{2}\) to \(y_{1}\) using the data from Table 20.8.

2. For this experiment the total thickness of the coating was required to be between 1/3 and 1, i.e. \(1/3\leq x_{1}+x_{2}\leq 1\) while the thickness of any individual layer needed to be a multiple of 1/24. Construct a grid with mesh size of 1/24 that satisfies this constraint and predict the values of \(Y_{1}\) for this grid. 3. Based on your predictions, what pair of coating thicknesses (\(x_{1}\), \(x_{2}\)) seems to minimize \(Y_{1}\)? 4. Repeat parts (a)-(c) for \(Y_{2}\). 5. Based on your predictions for \(Y_{1}\) and \(Y_{2}\), what single pair of coating thicknesses (\(x_{1}\), \(x_{2}\)) would you suggest to try to minimize both \(Y_{1}\) and \(Y_{2}\) simultaneously (as well as you can)? It may help to make a plot of the predicted values of \(Y_{1}\) and \(Y_{2}\).
11. **Borehole function** A borehole is a narrow tunnel drilled in the ground. Boreholes serve numerous purposes, including extraction of water or gases, mineral exploration, temperature measurement, etc. The _borehole_ function (see Surjanovic and Bingham 2013) models water flow through a borehole and is given by \[y=\frac{2\pi T_{u}(H_{u}-H_{l})}{a\left(1++\frac{2LT_{u}}{ar_{w}^{2}K_{w}}+ \frac{T_{u}}{T_{l}}\right)}\] (20.7.9) where \(a=\ln(r/r_{w})\). The output \(y\) measures the water flow rate in m\({}^{3}\)/year. There are eight inputs to the borehole function. Their names and ranges are given in Table 20.9. 1. Construct an 80 x 8 maximin LHD, \(X\), where each element of \(X\) is in [0, 1]. Let the elements \(x_{i1}\) in the first column of \(X\) represent the scaled values of the first variable \(r_{w}\) for which we will "observe" (calculate) \(y\) from the simulator, the elements \(x_{i2}\) in the second column of \(X\) represent the scaled values of the second variable \(r\), and so on for all 8 columns. 2. To be able to calculate the simulator data \(y(\boldsymbol{x}_{i})\) using (20.7.9), where \(\boldsymbol{x}_{i}\) is the \(i^{th}\) row (input combination) of \(X\), we need to transform the value of each input variable in \(X\) (which has range [0, 1]) to the variables and matching ranges given in Table 20.9. This will allow the appropriate values to be entered into (20.7.9). For transforming \(x_{1}\) to \(r_{w}\) with range in Table 20.9, the scaling is done via \[r_{w}^{[0.05,0.15]}=(0.15-0.05)x_{1}^{[0,1]}+0.05\,.\]

\begin{table}
\begin{tabular}{c c c c} \hline \(x_{1}\) & \(x_{2}\) & \(y_{1}\) & \(y_{2}\) \\ \hline
0.6250 & 0.0833 & 0.87771 & 0.13567 \\
0.8750 & 0.1250 & 0.84920 & 0.12590 \\
0.2083 & 0.2083 & 0.53123 & 0.13394 \\
0.0417 & 0.4583 & 0.26112 & 0.15829 \\
0.3750 & 0.0833 & 0.75124 & 0.13708 \\
0.0417 & 0.8333 & 2.56179 & 0.15464 \\
0.1667 & 0.5417 & 1.09043 & 0.22275 \\
0.3750 & 0.5000 & 1.75458 & 0.19860 \\
0.6250 & 0.3750 & 1.40447 & 0.12491 \\
0.4167 & 0.2917 & 1.19420 & 0.13259 \\ \hline \end{tabular}
\end{table}
Table 20.8: Data for the tool coating experiment The superscripts represent the ranges for the input variable \(x_{1}\) and transformed variable \(r_{w}\). The scaling for other variables is done in a similar fashion. Scale each value in each row \(\boldsymbol{x}_{i}\) of \(\boldsymbol{X}\) to the appropriate range. Calculate the output \(y(\boldsymbol{x}_{i})\), \(i=1,2,\ldots,80\) using (20.7.9). 3. One of the simple ways to assess how sensitive \(Y\) is to the changes in a particular input \(x_{k}\) is to plot \(y\) versus the \(x_{ik}\)'s and examine the plot for any obvious patterns. Construct eight scatterplots, one for each input variable \(x_{1}\)-\(x_{8}\), and identify the variables that seem to influence the response the most. 4. Using \(\boldsymbol{X}\) and \(y(\boldsymbol{x}_{i})\), fit the GaSP model. What are the maximum likelihood estimates of the parameters? Do the values of \(\hat{\theta}_{k}\), \(k=1,2,\ldots,8\), support your conclusion from part (c)? 5. Construct a grid of mesh size roughly equal to 0.5 (i.e. \(x_{ik}\in\{0,0.5,1\}\)) and predict the outputs \(y(\boldsymbol{x}_{i})\) over the grid. Based on your predictions, what are the values of \(x_{1}\),..., \(x_{8}\) that result in the predicted maximal water flow? How about the minimal water flow? Using the ranges in Table 20.9, again, scale these values to show the values of the original variables that result in predicted maximal and minimal water flow.

\begin{table}
\begin{tabular}{c c c} Variable & Variable name & Range \\ \hline \(r_{w}\) & Radius of the borehole (m) & [0.05, 0.15] \\ \(r\) & Radius of influence (m) & [100, 50000] \\ \(T_{u}\) & Transmissivity of the upper aquifer (m\({}^{2}\)/yr) & [63070, 115600] \\ \(H_{u}\) & Potentiometric head of the upper aquifer (m) & [990, 1110] \\ \(T_{\ell}\) & Transmissivity of the lower aquifer (m\({}^{2}\)/yr) & [63.1, 116] \\ \(H_{\ell}\) & Potentiometric head of the lower aquifer (m) & [700, 820] \\ \(L\) & Length of the borehole (m) & [1120, 1680] \\ \(K_{w}\) & Hydraulic conductivity of the borehole (m/yr) & [9855, 12045] \\ \hline \end{tabular}
\end{table}
Table 20.9: Input variables for the borehole function Appendix A Tables

\begin{tabular}{l l r} \hline \hline Table & Contents & Page \\ \hline A.1 & Random numbers & 794 \\ A.2 & Orthogonal polynomial trend contrast coefficients & 800 \\ A.3 & Standard normal distribution & 801 \\ A.4 & Student's \(t\)-distribution & 802 \\ A.5 & Chi-squared distribution & 803 \\ A.6 & \(F\)-distribution & 804 \\ A.7 & Power of the \(F\)-test & 810 \\ A.8 & Studentized range distribution & 814 \\  & (Tukey's method) & \\ A.9 & Multivariate \(t\)-distribution maximum & 816 \\  & (Dunnett's one-sided method) & \\ A.10 & Multivariate \(t\)-distribution absolute maximum & 818 \\  & (Dunnett's two-sided method) & \\ A.11 & Critical coefficients for the Voss-Wang method & 820 \\ \hline \hline \end{tabular}

[MISSING_PAGE_EMPTY:8744]

[MISSING_PAGE_EMPTY:8745]

[MISSING_PAGE_EMPTY:8746]

[MISSING_PAGE_EMPTY:8748]

[MISSING_PAGE_EMPTY:8749]

[MISSING_PAGE_EMPTY:8750]

[MISSING_PAGE_EMPTY:8751]

[MISSING_PAGE_EMPTY:8752]

[MISSING_PAGE_EMPTY:8754]

[MISSING_PAGE_EMPTY:8755]

[MISSING_PAGE_EMPTY:8756]

[MISSING_PAGE_EMPTY:8757]

[MISSING_PAGE_EMPTY:8758]

[MISSING_PAGE_EMPTY:8759]

\begin{table}
\begin{tabular}{c c c c c c c c c c c c} \hline \multicolumn{11}{c}{\(v_{1}=4\), \(\alpha=0.05\)} & & & & & & & & & & & & \\ \cline{2-11} \multicolumn{1}{c}{\(v_{2}\)} & 1.00 & 1.25 & 1.50 & 1.75 & 2.00 & 2.25 & 2.50 & 2.75 & 3.00 & 3.25 & 3.50 \\ \cline{2-11} \multicolumn{1}{c}{\(v_{2}\)} & 1.00 & 1.25 & 1.50 & 1.75 & 2.00 & 2.25 & 2.50 & 2.75 & 3.00 & 3.25 & 3.50 \\ \hline
5 & 0.190 & 0.278 & 0.385 & 0.502 & 0.619 & 0.726 & 0.814 & 0.882 & 0.930 & 0.961 & 0.980 \\
6 & 0.209 & 0.311 &

[MISSING_PAGE_EMPTY:8761]

[MISSING_PAGE_FAIL:827]

[MISSING_PAGE_EMPTY:8764]

[MISSING_PAGE_EMPTY:8765]

[MISSING_PAGE_EMPTY:8766]

[MISSING_PAGE_EMPTY:8767]

[MISSING_PAGE_EMPTY:8768]

\begin{table}
\begin{tabular}{c c c c c c c c c c c c} \hline even & \multicolumn{6}{c}{\(\alpha\)} & odd & \multicolumn{6}{c}{\(\alpha\)} \\ \cline{2-13} \(m\) & \(d\) & 0.10 & 0.05 & 0.01 & 0.001 & \(m\) & \(d\) & 0.10 & 0.05 & 0.01 & 0.001 \\ \hline

[MISSING_PAGE_POST]

 \hline \end{tabular}
\end{table}
Table A.11: Voss–Wang method: upper \(\alpha\) critical coefficients \(w_{V}=v_{m,d,\alpha}\) for \(m\) orthogonal contrasts and \(d\) sums of squares pooled into each quasi mean squared error

## Bibliography

* Anderson & McLean (1974) Anderson, V. L., & McLean, R. A. (1974). _Design of experiments: a realistic approach_. New York: Marcel Dekker Inc.
* Bainbridge (1951) Bainbridge, J. R. (1951). Factorial experiments in pilot plant studies. _Industrial and Engineering Chemistry_, _43_, 1300-1306.
* Barnabas et al. (1995) Barnabas, I. J., Dean, J. R., Tomlinson, W. R., & Owen, S. P. (1995). Experimental design approach for the extraction of polycyclic aromatic hydrocarbons form soil using supercritical carbon dioxide. _Analytical Chemistry_, _67_, 2064-2069.
* Barnett & Mead (1956) Barnett, M. K., & Mead, F. C, Jr. (1956). A 2\({}^{4}\) factorial experiment in four blocks of eight: a study in radioactive decontamination. _Applied Statistics_, \(5\), 122-131.
* Baten (1956) Baten, W. D. (1956). An analysis of variance applied to screw machines. _Industrial Quality Control_, _12_, 8-9.
* Beckman et al. (1987) Beckman, R. J., Nachtsheim, C. J., & Cook, R. D. (1987). Diagnostics for mixed-model analysis of variance. _Technometrics_, _29_, 413-426.
* Blom (1958) Blom, G. (1958). _Statistical estimates and transformed beta variables_. New York: Wiley.
* Box & Behnken (1960) Box, G. E. P., & Behnken, D. W. (1960). Some new three level designs for the study of quantitative variables. _Technometrics_, \(2\), 455-475.
* Box & Cox (1964) Box, G. E. P., & Cox, D. R. (1964). An analysis of transformations. _Journal of the Royal Statistical Society, B_, _26_, 211-243.
* Box & Hunter (1957) Box, G. E. P., & Hunter, J. S. (1957). Multi-factor experimental designs for exploring response surfaces. _Annals of Mathematical Statistics_, _28_, 195-241.
* Box & Wilson (1951) Box, G. E. P., & Wilson, K. B. (1951). On the experimental attainment of optimum conditions. _Journal of the Royal Statistical Society, Series B_, _13_, 1-45.
* Brickell & Knox (1992) Brickell, J., & Knox, K. (1992). Designed experiments case history--environmental engineering operation of an activated sludge system. In S. R. Schmidt & R. G. Launsby (Eds.), _Understanding industrial designed experiments_ (3rd ed., pp. 8.187-8.194). Colorado: Air Academy Press.
* Bullough & Melby (1993) Bullough, R. C., & Melby, C. L. (1993). Effect of inpatient versus outpatient measurement protocol on resting metabolic rate and respiratory exchange ratio. _Annals of Nutrition and Metabolism_, _37_, 24-32.
* Cameron (1951) Cameron, J. M. (1951). The use of components of variance in preparing schedules for sampling of baled wool. _Biometrics_, \(7\), 83-96.
* Clatworthy (1973) Clatworthy, W. H. (1973). _Tables of two-associate-class partially balanced designs._, Applied Mathematics Series Washington: National Bureau of Standards. 63.
* Cochran & Cox (1957) Cochran, W. G., & Cox, G. M. (1957). _Experimental designs_ (2nd ed.). New York: Wiley.
* Corlett & Gregory (1960) Corlett, E. N., & Gregory, G. (1960). The consistency of setting of a machine tool handwheel. _Applied Statistics_, \(9\), 92-102.
* Cunningham & O'Connor (1968) Cunningham, A. C., & O'Connor, N. (1968). Consumer reaction to retail price and display changes. _European Journal of Marketing_, \(2\), 147-151.
* Cuq et al. (1995) Cuq, B., Aymard, C., Cuq, J.-L., & Guilbert, S. (1995). Edible packaging films based on fish myofibrillar proteins: formulation and functional purposes. _Journal of Food Science_, _60_, 1369-1373.
* Daniel (1976) Daniel, C. (1976). _Applications of statistics to industrial experimentation_. New York: Wiley.
* Davies (Ed.) (1963) Davies, O. L. (Ed.). (1963). _Design and analysis of industrial experiments_ (2nd ed.). London: Longman.
* Dean et al. (2017)* Dean & Draper (1999) Dean, A. M., & Draper, N. R. (1999). Saturated main-effect designs for factorial experiments. _Statistics and Computing_, 9, 179-185.
* Desmond (1954) Desmond, D. J. (1954). Quality control on the setting of voltage regulators. _Applied Statistics_, \(3\), 65-73.
* Draguljic et al. (2015) Draguljic, D., Nekkanty, S., Santner, T. J., Dean, A. M., & Shivpuri, R. (2015). Optimizing thin film tool coatings using a finite element computer simulator. _Quality Engineering_, _27_(4), 461-472.
* Draper (1982) Draper, N. R. (1982). Center points in second-order response surface designs. _Technometrics_, _24_, 127-133.
* Draper & Smith (1998) Draper, N. R., & Smith, H. (1998). _Applied regression analysis_ (3rd ed.). New York: Wiley.
* Dunnett (1955) Dunnett, C. W. (1955). A multiple comparisons procedure for comparing several treatments with a control. _Journal of the American Statistical Association_, _50_, 1096-1121.
* Dunnett (1980) Dunnett, C. W. (1980). Pairwise multiple comparisons in the unequal variance case. _Journal of the American Statistical Association_, _75_, 796-800.
* Durbin & Watson (1951) Durbin, J., & Watson, G. S. (1951). Testing for serial correlation in least squares regression II. _Biometrika_, _38_, 159-178.
* Eibl et al. (1992) Eibl, S., Kess, U., & Pukelsheim, F. (1992). Achieving a target value for a manufacturing process: a case study. _Journal of Quality Technology_, _24_, 22-26.
* Erler et al. (2013) Erler, A., Mas, N, de, Ramsey, P., & Henderson, G. (2013). Efficient biological process characterization by definitive-screening designs: the formaldehyde treatment of a therapeutic protein as a case study. _Biotechnology Letters_, _35_, 323-329.
* Finner & Strassburger (2002) Finner, H., & Strassburger, K. (2002). The partitioning principle: a powerful tool in multiple decision theory. _Annals of Statistics_, _30_, 1194-1213.
* Fisher & Yates (1973) Fisher, R. A., & Yates, F. (1973). _Statistical tables for biological, agricultural and medical research_. Edinburgh: Oliver and Boyd.
* Games & Howell (1976) Games, P. A., & Howell, J. F. (1976). Comparison procedure with unequal N's and/or variances: A Monte Carlo study. _Journal of Educational Statistics_, \(1\), 113-125.
* Graybill (1976) Graybill, F. A. (1976). _Theory and application of the linear model_. North Scituate: Duxbury Press.
* Gupte & Kulkarni (2003) Gupte, M., & Kulkarni, P. (2003). A study of antifungal antibiotic production by Thermomonospora sp MTCC 3340 using full factorial design. _Journal of Chemical Technology and Biotechnology_, 78, 605-610.
* Gutsell (1951) Gutsell, J. S. (1951). The effect of sulfamerazine on the erythrocyte and hemoglobin content of trout blood. _Biometrics_, \(7\), 171-179.
* Hare (1988) Hare, L. B. (1988). In the soup: a case study to identify contributors to filling variability. _Journal of Quality Technology_, _20_, 36-43.
* Hayeck (2009) Hayeck, G. T. (2009). The kinematics of the upper extremity and subsequent effects on joint loading and surgical treatment. Ph.D. thesis. Cornell University.
* Hayter (1984) Hayter, A. J. (1984). A proof of the conjecture that the Tukey-Kramer multiple comparisons procedure is conservative. _Annals of Statistics_, _12_, 61-75.
* Hicks (1956) Hicks, C. R. (1956). Fundamentals of analysis of variance, Part III-nested designs in analysis of variance. _Industrial Quality Control_, _13_(4), 13-16.
* Hicks (1965) Hicks, C. R. (1965). The analysis of covariance. _Industrial Quality Control_, _22_, 282-286.
* Hicks (1993) Hicks, C. R. (1993). _Fundamental concepts in the design of experiments_ (4th ed.). New York: Oxford University Press Inc.
* Hochberg & Tamhane (1987) Hochberg, Y., & Tamhane, A. C. (1987). _Multiple comparison procedures_. New York: Wiley.
* Hocking (1996) Hocking, R. R. (1996). _Methods and applications of linear models; regression and the analysis of variance_. New York: Wiley.
* Hoerl (1988) Hoerl, A. E. (1988). _The 3-7 phenomena_. January issue: Royal Statistical Society News and Notes.
* Hollander et al. (2013) Hollander, M., Wolfe, D. A., & Chicken, E. (2013). _Nonparametric statistical methods_. New York: Wiley.
* Hsu (1996) Hsu, J. C. (1996). _Multiple comparisons: theory and methods_. London: Chapman and Hall.
* Inman et al. (1992) Inman, J., Ledtler, J., Lenth, R. V., & Niemi, L. (1992). Two case studies involving an optical emission spectrometer. _Journal of Quality Technology_, _24_, 27-36.
* Jeffers (1987) Jeffers, J. N. R. (1987). Acid rain and tree roots: an analysis. In D. J. Hand & B. S. Everitt (Eds.), _The statistical consultant in action_. New York: Cambridge University Press.
* John (1981) John, J. A. (1981). Efficient cyclic designs. _Journal of the Royal Statistical Society, Series B_, _43_, 76-80.
* John et al. (1972) John, J. A., Wolock, F. W., & David, H. A. (1972). _Cyclic designs_., Applied Mathematics Series Washington: National Bureau of Standards. 62.
* John (1961) John, P. W. M. (1961). An application of a balanced incomplete design. _Technometrics_, \(3\), 51-54.
* John (1971) John, P. W. M. (1971). _Statistical design and analysis of experiments_. New York: Macmillan.
* Johnson & Leone (1977) Johnson, N. L., & Leone, F. C. (1977). _Statistics and experimental design in engineering and the physical sciences_ (2nd ed.). New York: Wiley.
* Jones & Kenward (2003) Jones, B., & Kenward, M. G. (2003). _Design and analysis of crossover trials_ (2nd ed.). Boca Raton: Chapman and Hall/CRC.
* Jones & Nachtsheim (2011) Jones, B., & Nachtsheim, C. J. (2011). A class of three-level designs for definitive screening in the presence of second-order effects. _Journal of Quality Technology_, _43_, 1-15.

* [Kackar and ShoemakerKackar and Shoemaker1986] Kackar, R. N., & Shoemaker, A. C. (1986). Robust design: a cost-effective method for improving manufacturing processes. _AT&T Technical Journal_, _65_(2), 39-50.
* [KempthorneKempthorne1976] Kempthorne, O. (1976). _Design and analysis of experiments_. New York: Krieger.
* [KempthorneKempthorne1977] Kempthorne, O. (1977). Why randomize? _Journal of Statistical Planning and Inference_, \(1\), 1-25.
* [Khuri and CornellKhuri and Cornell1987] Khuri, A. I., & Cornell, J. A. (1987). _Response surfaces: designs and analyses_. New York: Marcel Dekker.
* [Lamacraft and HallLamacraft and Hall1982] Lamacraft, R. R., & Hall, W. B. (1982). Tables of cyclic incomplete block designs: \(r=k\). _Australian Journal of Statistics_, _24_, 350-360.
* [Lewis and DeanLewis and Dean1980] Lewis, S. M., & Dean, A. M. (1980). Factorial experiments in resolvable generalized cyclic designs. _Bulletin in Applied Statistics_, \(7\), 159-167.
* [Lewis et al.1989] Lewis, S. M., Hodgson, B. A., New, R. E., & Sexton, C. J. (1989). The application of Taguchi methods at the design analysis stage. _Proceedings of the Institute of Mechanical Engineering, International Conference on Engineering Design_**1**, (pp. 283-294).
* [LinLin1993] Lin, D. K. J. (1993). A new class of supersaturated designs. _Technometrics_, _35_, 28-31.
* [Lorenz et al.1982] Lorenz, R. C., Hsu, J. C., & Tuovinen, O. H. (1982). Performance variability, ranking and selection analysis of membrane filters for enumerating coliform bacteria in river water. _Journal of the American Water Works Association_, _74_, 429-437.
* [MahadevanMahadevan2009] Mahadevan, S. (2009). Visualization methods and user interface design guidelines for rapid decision making in complex multi-task time-critical environments. Ph.D. Dissertation, Department of Biomedical, Industrial, and Human Factors Engineering, Wright State University.
* 10% \(Al_{2}O_{3}\) composite through factorial design of experiment. _Journal of Materials Science_, _36_, 1601-1607.
* [Moore and EppsMoore and Epps1992] Moore, M. A., & Epps, H. H. (1992). Accelerated weathering of marine fabrics. _Journal of Testing and Evaluation_, _20_, 139-143.
* [MunroMunro1986] Munro, K. J. (1986). Investigation of optokinetic nystagmus under different visual conditions. MSc Dissertation, Department of Audiology, University of Southampton.
* [Naveena et al.2005] Naveena, B. J., Altaf, M., Bhadriah, K., & Reddy, G. (2005). Selection of medium components by Plackett-Burman design for production of L(+) lactic acid by Lactobacillus amylophilus GV6 in SSF using wheat bran. _Bioresource Technology_, _96_, 485-490.
* [Neter et al.1996] Neter, J., Kutner, M. H., Nachtsheim, C. J., & Wasserman, W. (1996). _Applied linear statistical models_ (4th ed.). Chicago: Richard D. Irwin Inc.
* [Olsen et al.2014] Olsen, R. E., Bartholomew, C. H., Enfield, D. B., Lawson, J. S., Rohbock, N., Scott, B. S., & Woodfield, B. F. (2014). Optimizing the synthesis and properties of Al-modified anatase catalyst supports by statistical experimental design. _Journal of Porous Materials_, _21_, 827-837.
* [PeakePeake1953] Peake, R. E. (1953). Planning an experiment in a cotton spinning mill. _Applied Statistics_, \(2\), 184-192.
* [PeiserPeiser1943] Peiser, A. M. (1943). Asymptotic formulas for significance levels of a certain distributions. _Annals of Mathematical Statistics_, _14_, 56-62. (Correction 1949, _Annals of Mathematical Statistics_, _20_, 128-129).
* [Plackett and BurmanPlackett and Burman1946] Plackett, R. L., & Burman, J. P. (1946). The design of optimum multifactorial experiments. _Biometrika_, _33_, 305-325.
* [PoonGoal1995] Poon, G. K. K. (1995). Sequential experimental study and optimisation of an acid copper pattern plating process. _Circuit World_, _22_, 7-9.
* [PughPugh1953] Pugh, C. (1953). The evaluation of detergent performance in domestic dishwashing. _Applied Statistics_, \(2\), 172-179.
* [Ratkowsky et al.1993] Ratkowsky, D. A., Evans, M. A., & Alldredge, J. R. (1993). _Cross-over experiments: design, analysis and application._, Statistics Textbooks and Monographs, 135, New York: Marcel Dekker.
* [R Core TeamR Core Team2017] R Core Team (2017). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria, [http://www.R-project.org/](http://www.R-project.org/)
* [Rumbell et al.2016] Rumbell, T. H., Draguljic, D., Yadav, A., Hof, P. R., Luebke, J. I., & Weaver, C. M. (2016). Automated evolutionary optimization of ion channel conductances and kinetics in models of young and aged rhesus monkey pyramidal neurons. _Journal of Computational Neuroscience_, _41_(1), 65-90.
* [Sacks et al.1989] Sacks, J., Welch, W. J., Mitchell, T. J., & Wynn, H. P. (1989). Design and analysis of computer experiments. _Statistical Science_, \(4\), 409-435.
* [SalvadoriSalvadori1980] Salvadori, M. (1980). _Why buildings stand up: the strength of architecture_. New York: Norton.
* [Santner et al.2003] Santner, T. J., Williams, B. J., & Notz, W. I. (2003). _The design and analysis of computer experiments_. New York: Springer-Verlag.
* [Saravanan et al.2001] Saravanan, P., Selvarajan, V., Joshi, S. V., & Sundararajan, G. (2001). Experimental design and performance analysis of alumina coatings deposited by a detonation spray process. _Journal of Physics D: Applied Physics_, _34_(1), 131-140.
* [SAS Institute Inc.SAS/STAT. @ 9.1 _Users Guide_. Cary NC: SAS Institute Inc.
* [SatterthwaiteSatterthwaite1946] Satterthwaite, F. E. (1946). An approximate distribution of estimates of variance components. _Biometrics_, \(2\), 110-114.
* [ScheffeScheffe1959] Scheffe, H. (1959). _The analysis of variance_. New York: Wiley.
* [Schmidt and LounsbySchmidt and Lounsby1992] Schmidt, S. R., & Lounsby, R. G. (1992). _Experimental design on an injection molded plastic part_ (3rd ed.)., In Understanding Industrial Designed Experiments Colorado: Air Academy Press.
* [SterthwaiteSterthwaite1959]* Shahani (1970) Shahani, A. K. (1970). A saturated experiment in sequential determination of operating conditions. _The Statistician_, _19_, 403-408.
* Sinha (1991) Sinha, K. (1991). A list of new group divisible designs. _Journal of Research of the National Institute of Standards and Technology_, _96_, 613-615.
* Smith (1936) Smith, H. F. (1936). The problem of comparing the results of two experiments with unequal errors. _Journal of the Council of Scientific and Industrial Research_, \(9\), 211-212.
* Smith (1969) Smith, H, Jr. (1969). The analysis of data from a designed experiment. _Journal of Quality Technology_, \(1\), 259-263.
* Sosada (1993) Sosada, M. (1993). Optimal conditions for fractionation of rapeseed lecithin with alcohols. _Journal of the American Oil Chemists' Society_, _70_, 405-410.
* Stefansson et al. (1988) Stefansson, G., Kim, W.-C., & Hsu, J. C. (1988). On confidence sets in multiple comparisons. In S. S. Gupta & J. O. Berger, (Eds.), _Statistical Decision Theory, I. V. Related Topcis_ (2nd ed., pp. 89-104). New York: Academic Press.
* Surjanovic & Bingham (2013) Surjanovic, S., & Bingham, D. (2013). Virtual Library of Simulation Experiments: Test Functions and Datasets. Retrieved November 2, 2015, from [http://www.sfu.ca/~ssurjano](http://www.sfu.ca/~ssurjano).
* Thompson et al. (1963) Thompson, W. A, Jr., & Moore, J. R. (1963). Non-negative estimates of variance components. _Technometrics_, \(5\), 441-449.
* Tuck et al. (1993) Tuck, M. G., Lewis, S. M., & Cottrell, J. I. L. (1993). Response surface methodology and Taguchi: a quality improvement study from the milling industry. _Applied Statistics_, _42_, 671-681.
* Tukey (1953) Tukey, J. W. (1953). The problem of multiple comparisons. _Dittoed manuscript of 396 pages, Department of Statistics,_ Princeton University.
* Vance (1962) Vance, F. P. (1962). Optimization study of lube oil treatment by process 'X'. _Proceedings of the Symposium on Application of Statistics and Computers to Fuel Lubricant Research Problems_. Office of Chief Ordinance, U.S. Army, May 1962.
* Voss (2008) Voss, D. T. (2008). Partition testing: a generalization of hypothesis testing. _Statistics and Applications_, \(6\), 17-24.
* Voss (2010) Voss, D. T. (2010). Testing is confidence estimation: partition multiple testing. _Journal of Statistical Theory and Practice_, \(4\), 559-569.
* Voss & Wang (1999) Voss, D. T., & Wang, W. (1999). Exact simultaneous confidence intervals in the analysis of orthogonal saturated designs. _Journal of Statistical Planning and Inference_, _81_, 383-392.
* Welch (1938) Welch, B. L. (1938). The significance of the difference between two means when the population variances are unequal. _Biometrika_, _29_, 350-362.
* Wesler (2001) Wesler, M. Mc. (2001). The effects of display type and visual presentation format (frame of reference and perspective) on situation awareness and navigation performance in a mobile computing field study. M.S.Eg. thesis, Human Factors Engineering, Wright State University.
* Westlake (1974) Westlake, W. J. (1974). The use of balanced incomplete block designs in comparative bioavailability trials. _Biometrics_, _30_, 319-327.
* Wilkie (1962) Wilkie, D. (1962). A method of analysis of mixed level factorial experiments. _Applied Statistics_, _11_, 184-195.
* Wood & Hartvigsen (1964) Wood, S. R., & Hartvigsen, D. E. (1964). Statistical design and analysis of qualification test program for a small rocket engine. _Industrial Quality Control_, _20_, 14-18.
* Wooding (1973) Wooding, W. M. (1973). The split-plot design. _Journal of Quality Technology_, \(5\), 16-33.
* Wu (1964) Wu, S. M. (1964). Analysis of rail steel bar welds by two-level factorial design. _Welding Journal Research Supplement_, _43_, 179s-183s. (Reprinted University of Wisconsin Engineering Experiment Station, Reprint 684.)
* Xu et al. (2009) Xu, H., Phoa, F. K. H., & Wong, W. K. (2009). Recent developments in nonregular fractional factorial designs. _Statistics Surveys_, \(3\), 18-46.
* Yates (1935) Yates, F. (1935). Complex experiments. _Supplement to the Journal of the Royal Statistical Society_, \(2\), 181-247. (Reprinted in _Experimental Design_ (1970), Charles Griffin and Company, Ltd., London.

## Index of Authors

**A**

Alldredge, J.R., 402

Altaf, M., 531

Anderson, V.L., 194

Aymard, C., 610

Aymard, C., 610

**B**

Bainbridge, J.R., 469

Barnabas, I.J., 589

Barnett, M.K., 452, 466

Bartholomew, C.H., 554

Baten, W.D., 245

Beckman, R.J., 680

Behnken, D.W., 592

Bhadriah, K., 531

Bingham, D., 792

Blom, G., 117

Box, G.E.P., 198, 565, 578, 586, 588, 592

Brickell, J., 502

Bullough, R.C., 311

Burman, J.P., 530, 562

**C**

Cameron, J.M., 616

Chicken, E., 119

Clatworthy, W.H., 355

Cochran, W.G., 354, 392, 409, 437

Cook, R.D., 680

Corlett, E.N., 551

Cornell, J.A., 586

Cottrell, J.I.L., 513, 587, 589

Cox, D.R., 198

Cox, G.M., 354, 392, 409, 437

Cunningham, A., 427

Cug, B., 610

Cug, J.-L., 610

Cug, J.-L., 610

**D**

Daniel, C., 220

Das, S., 244

Dasgupta, R., 244

David, H.A., 356

Davies, O.L., 467, 478

De Mas, N., 538

Dean, A.M., 562, 791

Dean, J.R., 589

Desmond, D.J., 687, 692

Draguljic, D., 778, 791

Draper, N.R., 73, 562, 586

Dunnett, C.W., 90, 115

Durbin, J., 110

**E**

Eibl, S., 553, 569, 608

Enfield, D.B., 554

Epps, H.H., 238

Erler, A., 538

Evans, M.A., 402

**F**

Finner, H., 80

Fisher, R.A., 354, 402

**G**

Games, P.A., 115

Graybill, F.A., 75

Gregory, G., 551

Guilbert, S., 610

Gupte, M., 243

Gutsell, J.S., 67, 700

Gusell, J.S., 67, 700

**H**

Hall, W.B., 356

Hare, L.B., 499

Hartvigsen, D.E., 241

Hayeck, G.T., 767, 768

825* [19] Hayter, A.J., 89 Henderson, G., 538 Hicks, C.R., 302, 456, 672 Hochberg, Y., 90 Hocking, R.R., 649 Hodgson, B.A., 525 Hof, P.R., 778 Hollander, M., 119 Howell, J.F., 115 Hsu, J.C., 78, 80, 84, 92 Hunter, J.S., 586, 588
* [20] Hult, P.R., 778 Hoflander, M., 119 Howell, J.F., 115 Hsu, J.C., 78, 80, 84, 92 Hunter, J.S., 586, 588
* [21] Hult, P.R., 525 Inman, J., 242, 699
* [22] J Jeffers, J.N.R., 46 John, J.A., 356 John, P.W.M., 360, 507 Johnson, N.L., 465, 695, 698 Jones, Bradley, 537, 538 Jones, Byron, 402 Joshi, S.V., 240
* [23] Kackar, R.N., 519 Kempthorne, O., 447 Kenward, M.G., 402 Kess, U., 553, 569, 608 Khuri, A.I., 586 Kim, W.-C., 80 Knox, K., 502 Kulkarni, P., 243 Kutner, M.H., 110, 111
* [24] Lamacraft, R.R., 356 Launsby, R.G., 502 Lawson, J.S., 554 Ledolter, J., 242, 699 Lenth, R.V., 242, 699 Leone, F.C., 465, 695, 698 Lewis, S.M., 513, 525, 587, 589 Lin, D.K.J., 534 Lorenz, R.C., 78, 84 Luebke, J.I., 778
* [25] M Mahadevan, S., 713, 734, 749 McLean, R.A., 194 Mead, F.C.Jr., 452, 466 Melby, C.L., 311 Mitchell, T. J., 771 Modi, O.P., 244 Mondal, D.P., 244 Moore, J.R., 632 Moore, M.A., 238 Munro, K.J., 703 Nachtsheim, C.J., 110, 111, 537, 538, 680 Naveena, B.J., 531 Nekkanty, S., 791 Neter, J., 110, 111 New, R.E., 525 Niemi, L., 242, 699
* [26] O'Connor, N., 427 Olsen, R.E., 554 Owen, S.P., 589
* [27] P Peiser, A.M., 83 Phoa, F.K.H., 536 Plackett, R.L., 530, 562 Poon, G.K.K., 574, 594, 599 Pukelsheim, F., 553, 569, 608
* [28] R Ramsey, P., 538 Ratkowsky, D.A., 402 Reddy, G., 531 Rohbock, N., 554 Rumbell, T.H., 778
* [29] Sacks, J., 771 Santner, T.J., 778, 791 Saravanan, P., 240 Satterthwaite, F.E., 115, 627 Scheffe, H., 86, 627 Schmidt, S.R., 502 Scott, B.S., 554 Selvarajan, V., 240 Sexton, C.J., 525 Shahani, A.K., 505 Shivpari, R., 791 Shoemaker, A.C., 519 Sinha, K., 355 Smith, H., 73 Smith, H.F., 115 Smith, H.F., 134 Sosada, M., 609 Stefensson, G., 80 Strassburger, K., 80 Sundararajan, G., 240 Surjanovic, S., 792

**T**

Tamhane, A.C., 90

Thompson, W.A.Jr., 632

Tomlinson, W.R., 589

Tuck, M.G., 513, 587, 589

Tukey, J.W., 87, 175

Tuovinen, O.H., 78, 84

**V**

Vance, F.P., 507

Voss, D.T., 80, 224

**W**

Wang, W., 224

Wasserman, W., 110, 111

Watson, G.S., 110

Weaver, C.M., 778

Welch, B.L., 115

Welch, W.J., 771

Wesler, M.Mc., 717

Westlake, W.J., 393

Wilkie, D., 176

Wilson, K.B., 565, 578

Wolfe, D.A., 119

Wolock, F.W., 356

Wong, W.K., 536

Wood, S.R., 241

Woodfield, B.F., 554

Wooding, W.M., 758

Wu, S.M., 228, 234

Wynn, H.P., 771

**X**

Xu, H., 536

**Y**

Yadav, A., 778

Yadav, R.P., 244

Yates, F., 354, 402, 468, 492, 709

Yegneswaran, A.H., 244

[MISSING_PAGE_EMPTY:8777]

Handwheel, 551

Heart-lung pump, 37, 66, 73, 76, 77, 259, 284

I

Ice cream, 621, 624, 626, 627, 630, 657, 665, 666, 669

Ice melting, 246

Inclinometer, 525, 541, 546

Injection molding, 555, 761

Ink, 197

Insole cushion, 345

L

Lactic acid, 531

Length perception, 341

Light bulb, 337

Lithium bioavailability, 393

Load-carrying, 342

M

Machine head, 672, 683

Mangold, 447, 466, 550

Margarine, 133

Meat cooking, 67, 68, 100, 132, 198

Memory, 196

Memory recall, 339

Metal alloy, 350, 356

Mobile computing field study, 717, 742, 756, 763, 764

Mung bean, 120

N

Nail varnish, 162, 166, 167, 170

Neuron, 778, 783, 787

O

Oats, 709, 728, 736, 745, 753

Operator, 699

P

PAH recovery, 589, 597, 602

Paint, 553, 569, 571, 572, 576, 606, 608

Paint followup, 608

Paper towel absorbancy, 303

Paper towel strength, 240, 244

Peas, 468

Penicillin, 467

Perception, length, 341

Perception, quantity, 428

Plasma, 366, 380, 387, 394

Plastic, 678

Popcorn-microwave, 213, 238

Projectile, 465

Prosthetic elbow, 767

Q

Quantity perception, 428

R

Rail weld, 228, 234

Reaction time, 100, 133, 151, 153, 160, 177, 184, 341

Red blood cell, 700

Refinery, 507

Resin impurity, 612

Resin moisture, 613

Respiratory exchange ratio, 336

Resting metabolic rate, 311, 312, 336

Rocket, 241

Rust, 391

S
Sludge, 502, 538, 544

Soap, 49, 54, 60, 62, 91, 101, 132

Soil, 684

Soup, 499

Spaghetti sauce, 137

Spectrometer, 242, 556

Steel bar, 245

Step, 373, 392

Sugar beet, 492, 551

Survival, 198

Systolic blood pressure, 282

T

Temperature, 650, 654, 661, 669

Titanium alloy, 698, 699

Tool coating, 791

Trout, 67, 68, 101, 102, 105, 111, 116, 124, 130, 282

U

UAV experiment, 713, 732, 746, 762

UAV switch experiment, 734, 749, 762, 763

V

Vaccine, 538

Video game, 426, 427

Viscosity, 695

Viscosity, film, 610

Voltage, 687, 692, 695

W

Werfer, 519

Water boiling, 200

Water heating, 338

Weathering, 238, 239* [194] Weight lifting, 194
* [195] Weld strength, 194, 195
* [196] Welding, 505
* [197] Wildflower, 136

Y

Yeast, 346

## Index of Subjects

A Acid copper pattern plating, 599 Additive model, 143 Adjusted block sum of squares, 359 Adjusted means, 289 Adjusted treatment sum of squares, 358, 412 Adjusted treatment total, 358 Aliased effects, 495, 496 Aliasing scheme, 497 Analysis of covariance, 285, 289, 296, 299, 656 adjusted means, 289 assumption checking, 287 centered model, 286 confidence intervals, 294 least squares estimators, 288 model extensions, 287 multiple comparisons, 294 normal equations, 288 uncentered model, 286 Analysis of variance, 177, 186 balanced incomplete block designs, 358, 379, 385 confounding in factorial experiments, 435, 462, 464, 488, 489 crossed treatment factors, 159, 169, 177, 184, 211, 217 fixed effects, 41, 44, 54, 62 fractional factorial experiments, 538, 541, 544, 546 incomplete block designs, 358, 359, 380, 387 mixed effects, 648, 654, 661 nested factors, 676, 679, 683, 687, 691 one source of variation, 44, 623 one-way, 41, 44, 54, 62, 623 polynomial regression, 261, 273, 277 random effects, 623, 654 randomized complete block design, 311, 327, 331 response surface methods, 571, 581, 594, 597, 599, 603 row-column designs, 407, 408, 412, 416, 421 split-plot designs, 706, 709, 713, 715, 719, 729 split-split-plot designs, 712, 722 two-way, 159, 169, 177, 184 Assumption checking, 103, 104, 143 constant error variance, 110 independent errors, 108 lack of fit, 252 lack-of-fit test, 254, 276, 280 model fit, 106 normality of errors, 117 normality of random effects, 631 outliers, 107 random-effects model, 634 residual plots, 103 strategy, 103 Asymmetric factorial experiments, 433, 483, 511 Average reciprocal distance designs, 791 Axial points, 579 Axial-points block, 588

B Balanced incomplete block design, 352 analysis of variance, 358, 385 assumption checking, 356 confidence intervals, 379, 386 contrast estimators, 360 factorial experiments, 372, 459 inter-block estimates, 739, 753 intra-block analysis, 738, 753 intra-block estimates, 738, 753 multiple comparisons, 360, 379, 386 necessary conditions for existence, 354 plotting data adjusted for block effects, 362 randomization, 353 sample sizes, 371 Balanced incomplete block designs analysis of variance, 379 orthogonal contrasts, 360 Best linear unbiased predictor (BLUP), 772 Binary, 350 Block designs, 305, 349Blocking factors, 305, 306, 597

crossed, 399

Blocks, 306

Block sizes, 306, 349

Block-treatment model, 356, 434

Blom's normal scores, 117

Bonferroni method, 82, 83

Borelable function, 792

Box-Behnken designs, 592

orthogonal blocking, 592, 593

rotatable, 592, 593

Branching column, 534

C Canonical analysis, 583, 597, 604

Canonical axes, 585

Canonical coefficients, 583, 585

Canonical form, 583

Carryover effects, 402

Cell-means model, 142, 201

Center points, 568

Centered covariate, 286, 296, 299

Centered linear regression model, 264

Centered regressors, 264

Central composite designs, 578

orthogonal, 586

orthogonal blocking, 588

rotatable, 586

Checking model assumptions, 103, _see also_ Assumption checking

Coefficient list, 146, 207

Coefficient of determination, 262

Coefficient of multiple determination, 262

Complete block designs, 305, 307, _see also_ Randomized

complete block designs

Complete confounding, 451, 452, 459

Complete model, 142

Completely randomized designs, 31, 139, _see also_

Fractional factorial experiments; One source of variation; Several crossed treatment factors; Two crossed treatment factors

Composite design, 726

Computer simulator, 767

Confidence band, 258

Confidence bounds, 76

Confidence intervals, 74, 213, 223, 263, 276, 293, 638

Confidence region, 85

Confirmatory experiment, 451

Confounded, 434, 495

Confounding, 434, 713

complete, 451, 452, 459

partial, 451, 455

Confounding equations, 444

Confounding in factorial experiments, 433, 473

analysis of variance, 435, 462, 464, 488, 489

asymmetric factorial experiments, 483

block-treatment model, 434

complete confounding, 451, 459

confidence intervals, 462, 465, 489

confounding using contrasts, 435, 474

confounding using equations, 444, 475

four-level factors, 482

least squares estimators, 462, 465

partial confounding, 451, 460, 475

plans, 451, 481

pseudofactors, 482, 483

randomization, 436

three-level factors, 473, 475

two-level factors, 433

Confounding scheme, 443

Confounding using contrasts, 435, 474

Confounding using equations, 444, 475

Connected design, 352

Connectivity graph, 352

Contrast, 34, 69

coefficients, 70

difference of averages, 72

interaction, 144, 206

least squares estimator, 211

main-effect, 206

normalized, 70

pairwise comparison, 70

pairwise difference, 70

preplanned, 82

simple, 145

standard error, 70

sum of squares, 77, 212

three-factor interaction, 206

treatment, 69

treatment versus control, 71

trend, 72, 147, 266

two-factor interaction, 206

variance, 212

Control of noise variability, 523

Control treatment, 71

Covariates, 285, 305, 656

Critical coefficient, 83

Critical value, 597

Crossed array, 484

Crossed blocking factors, 399

Crossed treatment factors, 139

Crossover experiments, 401

Cubic correlation function, 789

Cyclic designs, 355

least squares estimators, 366

multiple comparisons, 366

randomization, 355

Cyclic Latin squares, 401

Cyclic row-column designs, 404, _see also_ Row-column designs

Cyclic Youden designs, 403

Cycling treatment labels, 355

D
Data adjusted for block effects, 362

Data snooping, 82Data transformation, 112 Decision rule, 77 Defining contrast, 496 Defining relation, 496 Definitive screening design, 537 Degrees of freedom, 209 Design, 31 Design matrix, 774 Design space, 768 Difference-of-averages contrast, 72 Difficult-to-change factors, 589, 703 Disconnected designs, 352, 355 Dunnett method, 82, 90

E

Effect sparsity, 172, 219, 222, 223, 533 Eigenvalues, 585, 597, 598, 604 Eigenvectors, 585, 597, 604 Empirical best linear unbiased predictor (eBLUP), 772 Empty cells, 228, 234 Emulator, 768 Error assumptions, 33, 104 constant variance, 110 independence, 108 normality, 117 Error sum of squares, 39, 210 Error variable, 32 Estimability of contrasts, 352 Estimable functions, 34 Estimated generalized least squares, 734, 749 Estimation rules, 209, _see also_ Rules for estimation and testing Euclidean distance, 789 Experimental design, 31, 350 Experimental plan, 350 Experimentwise error rate, 81, 152

F

Factorial experiments, 201, 324, 372, 416, 433 asymmetric, 433, 511 balanced incomplete block designs, 459 confounding, 433, 473 fractions, 495 incomplete block designs, 433, 473 single replicate, 433 symmetric, 433 three-level factors, 473 two-level factors, 433 Factorial points, 568 Factorial structure, 372 Factorial-points block, 588 First associates, 354 First-order designs, 568 orthogonal, 569 First-order response surface regression model, 567 Fixed effects, 615 Fixed-effects models, 615 Fractional factorial experiments, 495, 498, 724 analysis of variance, 538, 541, 544, 546 asymmetric fractions, 724 asymmetrical fractions, 511, 512 blocking, 513 composite defining relation, 726 composite design, 726 free variables, 725 hypothesis tests, 541, 546 least squares estimators, 538, 545 nonregular fraction, 530 orthogonal arrays, 516, 521, 522 orthogonal main effect plan, 529 pseudofactors, 511, 719, 724 randomization, 495 regular fraction, 530 saturated design, 529 Taguchi experiments, 523, 539, 546 three-level factors, 507 two-level factors, 495, 516 Full model, 41

G

Gauss-Markov Theorem, 37 Gaussian correlation function, 788 Gaussian stochastic process, 770 Gaussian stochastic process model, 770 General complete block designs, 307, 309 Generalized least squares estimates, 734, 749 Generator, 530 Group divisible designs, 354, _see also_ Incomplete block designs least squares estimators, 365 necessary conditions for existence, 355

H

Hadamard matrix, 534 Half-normal probability plots, 221, 225, 231 Half-normal scores, 221 Half-range, 568 Hypothesis testing rules, 209, _see also_ Rules for estimation and testing Hypothesis tests, 212

I

Incomplete block designs, 307, 349 analysis of variance, 358, 359, 380, 387 assumption checking, 356 balanced incomplete block designs, 352 block sizes, 349 block-treatment model, 356 cyclic designs, 355 estimability of contrasts, 352 factorial experiments, 372 group divisible designs, 354 least squares estimators, 357, 365multiple comparisons, 357, 380, 387 plotting data adjusted for block effects, 362, 381, 387 R design generation, 382 randomization, 350 sample sizes, 371 SAS design generation, 376 two-level factorial experiments, 433 Independent contrasts, 443 Initial block, 355 Input combinations, 767 Input points, 767 Input space, 768 Interaction contrasts, 144, 206 Interaction line graph, 205 Interaction plots, 140, 202, 217 Interactions, 139, 141 three-factor, 202 two-factor, 139

L

Lack of fit, 106, 252 Lack-of-fit sum of squares, 572 Lack-of-fit test, 254, 581, 597, 600 Latin hypercube design (LHD), 776, 781, 786, 790 maximin, 778, 781, 786 minimax, 790 minimum average reciprocal, 791 Latin square designs, 401, _see also_ Row-column designs analysis of variance, 407, 408 assumption checking, 414 confidence intervals, 410 least squares estimators, 408, 410 multiple comparisons, 410 randomization, 401 replication, 402 row-column-treatment model, 405 sample sizes, 411 Latin squares, 401 Least squares estimators, 36, 149, 161, 163, 164, 253, 264, 265, 288, 313 Line graph, 205 Linear effect, 568 Linear model, 33 Linear trend contrast, 264 Local experiment, 566 Local linear effect, 568 Loss of information, 451 Lower confidence bound, 76

M

Main effects, 141 Main-effect contrasts, 152, 206 Main-effects model, 143, 161, 202 Maximin Latin Hypercube designs, 790 Maximum likelihood estimation, 771 Maximum likelihood estimator, 733, 749 Mean square, 210 Mesh size, 783 Method of least squares, 35 Midrange, 568 Minimax designs, 790 Minimum significant difference, 83 Mixed arrays, 523 Mixed models, 615, 642, 673 analysis of variance, 648, 654, 661 confidence intervals, 647, 648, 655, 662 expected mean squares, 643, 648, 654 hypothesis tests, 643, 648, 654, 661 least squares estimators, 655, 662 test statistic denominator, 648 Mixed models analysis analysis of variance approach, 727, 745 restricted maximum likelihood approach, 734, 749 Mixed-models controversy, 648 Model building, 170 Modulo, 444, 476 Multiple comparisons, 81, 152, 166, 180, 187, 213, 294, 320, 321 Bonferroni method, 82, 83 combination of methods, 92 Dunnett method, 82, 90 Games-Howell method, 115 other methods, 92 Scheffe method, 82, 85 split-plot designs, 716, 721 split-split-plot designs, 722 summary of methods, 82 Tukey method, 82, 87

N

Nested blocking structure, 703 Nested factors, 671 analysis of variance, 676, 679, 683, 687, 691 assumption checking, 674 confidence intervals, 676, 678, 679, 682 expected mean squares, 679, 682, 687 fixed-effects model, 674 least squares estimators, 674 mixed effects, 682 rules for estimation and testing, 678, 679 test statistic denominator, 683 two-way nested models, 672, 673 Nested fixed effects, 674 Nested models, 671 Noise factors, 305, 513, 523, 541, 546 Noncollapsing design, 774 Normal equations, 35, 164, 253, 264, 265, 288, 412 Normal probability plots, 117 Normal scores, 117 Normalized contrasts, 70 Nuisance factors, 285, 305

O

One source of variation, 31, 41, 618fixed-effects model, 33, 265 analysis of variance, 41, 44, 54, 62 assumption checking, 103 confidence intervals, 74, 76, 94, 97 hypothesis tests, 77, 78, 94, 97 least squares estimates, 36 multiple comparisons, 81, 83, 86, 88, 90, 95, 99 normal equations, 35 randomization, 31, 52, 59 residual plots, 104 sample sizes, 45, 48, 92 random-effects model, 618 analysis of covariance, 656 analysis of variance, 623, 654 assumption checking, 631, 652, 659 confidence intervals, 625, 627 expected mean squares, 654 hypothesis tests, 654 least squares estimates, 36 normal equations, 35 randomization, 31, 52, 59 sample sizes, 628 variance-components estimators, 619, 621 One-way analysis of covariance, 289 One-way analysis of variance, 41, _see also_ One source of variation Orthogonal arrays, 436, 495, 516 asymmetrical, 521 three-level factors, 522 two-level factors, 516 Orthogonal blocking, 587, 588 Orthogonal central composite designs, 586 Orthogonal contrasts, 172, 360, 435 Orthogonal first-order designs, 569 Orthogonal main-effect plan, 529, 530 Orthogonal polynomials, 266 Orthogonal second-order designs, 586 Outliers, 107 Overall confidence level, 81 Overall significance level, 81 Overfit, 251

Pairwise comparisons, 70 Pairwise differences, 70 Partial confounding, 451, 455, 460, 475 Partitioning principle, 80 Path of steepest ascent, 566, 576 Pearson product-moment correlation, 262 Plackett-Burman design, 530 Polynomial regression, 249 analysis of variance, 261, 273, 277 assumption checking, 252 confidence intervals, 258, 263, 276 hypothesis testing, 274, 277 lack of fit, 252 lack-of-fit test, 254, 276, 280 least squares estimators, 251, 253, 254, 264, 265 model, 250, 567 normal equations, 253, 254, 264, 265 orthogonal polynomials, 266 prediction intervals, 258, 276 quadratic regression, 251, 265 simple linear regression, 250, 257, 263 Pooled sample variance, 255 Power, 47 Power exponential correlation function, 788 Prediction intervals, 258, 276 Preplanned contrasts, 82 Product arrays, 523, 589 Pseudofactors, 482, 511, 719 Pure error, 255, 572 P-value, 45

Quadratic regression, 251, 265 Quasi mean squared error, 223

Random block effects, 649, 739, 753 Random effects, 615, 618, 632, 679 Random numbers, 794, 796 Random two-way main-effects model, 632 Random-effects models, 615 Random-effects one-way model, 618 Random-effects two-way complete model, 632 Randomization, 31, 52, 59, 308, 350, 353 Randomized complete block designs, 305, 307, 308, 704 analysis of variance, 311, 318, 327, 331 assessment of blocking, 311 assumption checking, 323 block-treatment interaction model, 318, 325 block-treatment model, 310, 318, 325 factorial experiments, 324 least squares estimators, 313 multiple comparisons, 313, 320, 321 randomization, 308 sample sizes, 309, 322 Recovery of inter-block information, 736, 753 Reduced model, 41 Regression model, 249 Residual effects, 402 Residual maximum likelihood, 734, 749 Residual plots, 103, 104, 252, _see also_ Assumption checking Residuals, 39, 104 scaled, 104 standardized, 104 Studentized, 104 Resolution, 498 Response curve, 249 Response surface, 249 Response surface methods, 565 analysis of variance, 571, 581, 594, 597, 599, 603 analysis with blocking factors, 597assumption checking, 570

Box-Behnken designs, 592

canonical analysis, 583, 597, 604

central composite designs, 578

first-order designs, 568, 569

first-order model, 567

lack-of-fit test, 581, 597

orthogonal blocking, 587, 588

orthogonal designs, 586

path of steepest ascent, 576

rotatable designs, 585, 586

second-order designs, 578

second-order model, 573, 597, 602

Restricted maximum likelihood, 656, 664, 734, 743, 749, 756

Robust design, 523

Rotatable central composite designs, 586

Rotatable second-order designs, 585

Row-column designs, 399, 401, 403, 404

analysis of variance, 407, 416, 421

assumption checking, 414

confidence intervals, 417, 422

factorial experiments, 416

least squares estimators, 419, 425

multiple comparisons, 407

plotting data adjusted for block effects, 419, 425

randomization, 400

row-column-treatment model, 405

Row-column-treatment model, 405

R software, 57

analysis of covariance, 299

analysis of variance, 62

assumption checking, 125

confidence intervals, 97

data frame, 59

factor variable, 62

Games-Howell method, 130

hypothesis tests, 97

keyboard data entry, 61

least squares means, 62

library loading, 63

means, 128

mixed models, 661

multiple comparisons, 99

nested effects, 691

package installation, 63

plots, 60

plotting data, 61

regression, 276

residual plots, 125

Satterthwaite's method, 130

transforming data, 129

updating the software, 58

user-defined function, 130

working directory, 58

Rules for estimation and testing, 209, 637, 647, 678, 682,

683

analysis of variance, 211, 648, 678, 683

confidence intervals, 213, 648, 682

contrast sum of squares, 212

contrast variance, 212

degrees of freedom, 209, 678

error sum of squares, 210

expected mean squares, 637, 648, 679, 682

hypothesis tests, 212, 648

least squares estimators, 211

mean square, 210

multiple comparisons, 213

test statistic denominator, 648, 683

total sum of squares, 210

Run order, 110

Saddle point, 578

Sample correlation, 262

Sample sizes, 45, 92, 171, 309, 322, 371, 628, 642, 657,

664, 665

SAS software

analysis of covariance, 296

analysis of variance, 54

assumption checking, 119

classification variable, 55

confidence intervals, 94

data input, 53

Games-Howell method, 124

hypothesis tests, 94

least squares means, 56

means, 122

multiple comparisons, 95

nested effects, 687

pdf file output, 55

plotting data, 55

random effects, 654

regression, 273

residual plots, 119

Satterthwaite's method, 124

transforming data, 123

Satterthwaite's approximation, 115, 124, 130, 154, 168,

6555, 664, 691, 717, 733, 743, 746

Scaled residuals, 104

Scheffe method, 82, 85

Screening experiments, 497

Second associates, 354

Second-order designs, 578

orthogonal, 586

rotatable, 585

Second-order response surface regression model, 573,

597, 602

Separability of factorial effects, 205

Sequential sums of squares, 179, 273, 277

Several crossed treatment factors, 201

analysis of variance, 211, 217, 220

cell-means model, 201

confidence intervals, 213

hypothesis tests, 212

interaction plots, 202, 217

least squares estimators, 211main-effects model, 202 multiple comparisons, 213 rules for estimation and testing, 209 single replicate experiment, 219 three-way complete model, 202 Significance level, 43 Simple contrasts, 145, 732, 746 Simple linear regression, 250, 263 Simple pairwise differences, 145, 717 Simultaneous confidence intervals, 81, 223 Simultaneous hypothesis tests, 81 Single replicate experiments, 171, 183, 192, 219, 221, 223, 433 Split plots, 703 Split-plot designs, 703, 714, 718 analysis of variance, 706, 709, 713, 715, 719, 729 confidence intervals, 709 confounding, 724 expected mean squares, 728, 729, 745 least squares estimators, 708 models, 705, 718, 735, 750 multiple comparisons, 709, 716, 721, 729, 745 randomization, 703 split-plot analysis, 706 split-plot confounding, 713 type I analysis, 728 type III analysis, 729, 745 whole-plot analysis, 707 Split-split-plot designs, 711, 721 analysis of variance, 712, 722 model, 712, 722 multiple comparisons, 722 Standard error, 70 Standard first-order designs, 568 Standard Latin squares, 401 Star points, 579 Stationary point, 578 Studentized range distribution, 88 Studentized residuals, 104 Sum of products, 288 Sum of squares blocks adjusted for treatments, 359 contrast, 77 error, 39 lack of fit, 255, 572 pure error, 572 total, 44 treatments, 42 treatments adjusted for blocks, 358, 412 Type I, 178, 187, 273, 277 Type III, 178, 187 Supersaturated designs, 533 Symmetric factorial experiments, 433 Test power, 47 Three-factor interaction contrast, 206 Three-way complete model, 202 Total sum of squares, 44, 210 Transformation, 112 Treatment contrasts, 34, 69, 293, 435 Treatments adjusted for blocks, 358, 461, 463 Treatment sum of squares, 42 Treatment-versus-control contrast, 71 Trend contrasts, 72, 147, 266 Tukey method, 82, 87 Tukey's test for additivity, 175 Two crossed treatment factors, 139 analysis of variance, 155, 159, 168, 169, 177, 184, 186 assumption checking, 143, 182, 191 cell-means model, 142 complete model, 142 confidence intervals, 144, 152 interaction plots, 140 least squares estimators, 149, 161, 163, 164 main-effects model, 143, 161 multiple comparisons, 144, 152, 166, 180, 187 randomization, 139 residual plots, 182, 191 sample sizes, 171 single replicate experiment, 171, 183, 192 Two or more random effects, 632 analysis of variance, 648, 654 assumption checking, 634 confidence intervals, 638, 648 expected mean squares, 637, 648, 654 hypothesis tests, 640, 648, 654 intermediate random-effects model, 633 random-effects two-way complete model, 632 random two-way main-effects model, 632 sample sizes, 642 test statistic denominator, 648 variance-components estimators, 637 Two-factor interaction, 139 Two-factor interaction contrast, 206 Two-level factorial experiments, 433 Two-way analysis of variance, 159, _see also_ Two crossed treatment factors Two-way nested model, 672 Type I sums of squares, 178, 187 Type III sums of squares, 178, 187

**U**

U

Unaadjusted estimator, 356 Unadjusted mean, 289 Unconfounded, 307 Unequal variances, 154, 168 Upper confidence bound, 40, 76

**V**

Variance component estimation analysis of variance estimates, 620, 625, 635, 637, 655, 664, 682, 727, 745restricted maximum likelihood estimates, 656, 664, 695, 733, 742, 748, 755, 776
* Variance components, 618
* Voss-Wang method, 223, 227, 232
* Washout periods, 402
* Websites
* Dean Voss Draguljic, 54, 58
* R-project, 57
* RStudio, 57
* Whole plots, 703
* Words, 498
* Youden designs, 403, _see also_ Row-column designs analysis of variance, 407, 412 assumption checking, 414 confidence intervals, 413 least squares estimators, 412 multiple comparisons, 413 randomization, 403 replication, 403 row-column-treatment model, 405 sample sizes, 413
* Youden square, 403