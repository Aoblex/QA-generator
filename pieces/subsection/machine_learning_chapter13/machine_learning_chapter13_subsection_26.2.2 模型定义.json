[
    {
        "strategy": "subsection",
        "source": "machine_learning_chapter13",
        "title": "26.2.2 模型定义",
        "content_length": 2608,
        "content": "Title: 26.2.2 模型定义\nContent:\nRNN Search 模型对基本模型进行两个大的改动。用双向 LSTM 实现编码器, 用注意力实现从编码器到解码器的信息传递。\n\n编码器使用双向 LSTM。编码基于整个输入序列, 是非自回归过程。正向 LSTM 的状态是\n\n\n\\begin{equation*}\n\\boldsymbol{h}_{j}^{(1)}=a\\left(\\boldsymbol{x}_{j}, \\boldsymbol{h}_{j-1}^{(1)}\\right), \\quad j=1,2, \\cdots, m \\tag{26.13}\n\\end{equation*}\n\n\n这里 $\\boldsymbol{h}_{j}^{(1)}$ 是正向的当前位置的状态; $\\boldsymbol{h}_{j-1}^{(1)}$ 是前一个位置的状态; $\\boldsymbol{x}_{j}$ 是当前位置的输入单词的词向量; $a$ 是处理单元, 如 LSTM 单元; 假设 $\\boldsymbol{h}_{0}^{(1)}=\\boldsymbol{o}$ 。反向 LSTM 的状态是\n\n\n\\begin{equation*}\n\\boldsymbol{h}_{j}^{(2)}=a\\left(\\boldsymbol{x}_{j}, \\boldsymbol{h}_{j+1}^{(2)}\\right), \\quad j=m, m-1, \\cdots, 1 \\tag{26.14}\n\\end{equation*}\n\n\n这里 $\\boldsymbol{h}_{j}^{(2)}$ 是反向的当前位置的状态; $\\boldsymbol{h}_{j+1}^{(2)}$ 是前一个位置的状态; $\\boldsymbol{x}_{j}$ 是当前位置的输入单词的词向量; $a$ 是处理单元, 如 LSTM 单元; 假设 $\\boldsymbol{h}_{m+1}^{(2)}=\\boldsymbol{O}$ 。在各个位置对正向和反向状态进行拼接, 得到各个位置的状态，也就是中间表示。\n\n\n\\begin{equation*}\n\\boldsymbol{h}_{j}=\\left[\\boldsymbol{h}_{j}^{(1)} ; \\boldsymbol{h}_{j}^{(2)}\\right], \\quad j=1,2, \\cdots, m \\tag{26.15}\n\\end{equation*}\n\n\n这里 [;] 表示向量的拼接。\n\n解码器使用单向 LSTM, 解码基于已生成的输出序列, 是自回归过程。状态是\n\n\n\\begin{equation*}\ns_{i}=a\\left(\\boldsymbol{y}_{i-1}, s_{i-1}, c_{i}\\right), \\quad i=1,2, \\cdots, n \\tag{26.16}\n\\end{equation*}\n\n\n这里 $s_{i}$ 是当前位置的状态; $s_{i-1}$ 是前一个位置的状态; $\\boldsymbol{y}_{i-1}$ 是前一个位置的输出单词的词向量; $c_{i}$ 是当前位置的上下文向量 (context vector), 上下文向量表示在当前位置的注意力计算结果; $a$ 是处理单元, 如 LSTM 单元。假设 $s_{0}=\\boldsymbol{O}$ 。输出是\n\n\n\\begin{equation*}\n\\boldsymbol{p}_{i}=g\\left(\\boldsymbol{s}_{i}\\right), \\quad i=1,2, \\cdots, n \\tag{26.17}\n\\end{equation*}\n\n\n这里 $s_{i}$ 是当前位置的状态; $p_{i}$ 是当前位置的输出; $g$ 是输出层函数, 由线性变换和软最大化函数组成。 $p_{i}$ 表示的是下一个位置上单词出现的条件概率。\n\n在解码器的每一个位置, 通过加法注意力计算上下文向量。注意力的查询 (query) 是前一个位置的状态 $s_{i-1}$, 键和值相同, 是编码器的各个位置的状态 $h_{j}$ 。上下文向量是\n\n\n\\begin{equation*}\n\\boldsymbol{c}_{i}=\\sum_{j=1}^{m} \\alpha_{i j} \\boldsymbol{h}_{j}, \\quad i=1,2, \\cdots, n \\tag{26.18}\n\\end{equation*}\n\n\n其中, $\\alpha_{i j}$ 是注意力权重。\n\n\n\\begin{equation*}\n\\alpha_{i j}=\\frac{\\exp \\left(e_{i j}\\right)}{\\sum_{k=1}^{m} \\exp \\left(e_{i k}\\right)}, \\quad i=1,2, \\cdots, n, j=1,2, \\cdots, m \\tag{26.19}\n\\end{equation*}\n\n\n相似度 $e_{i j}$ 通过一层神经网络计算:\n\n\n\\begin{equation*}\ne_{i j}=\\sigma\\left(\\boldsymbol{w}^{\\mathrm{T}} \\cdot\\left[\\boldsymbol{s}_{i-1} ; \\boldsymbol{h}_{j}\\right]+b\\right), \\quad i=1,2, \\cdots, n, j=1,2, \\cdots, m \\tag{26.20}\n\\end{equation*}\n\n\n在解码 (生成) 的过程中, 将编码器得到的状态序列或中间表示序列通过注意力有选择地传递到解码器, 决定解码器的状态序列, 以及输出的单词序列。传递的上下文向量实际是从输出序列的当前位置看到的输入序列的相关内容。\n\n图 26.5 是 RNN Search 的架构图, 图中矩形表示函数及其输出。\n\n\\begin{center}\n\\includegraphics[max width=\\textwidth]{2024_03_13_5ec6446031f017adfacbg-18}\n\\end{center}\n\n图 26.5 RNN Search 模型"
    },
    {
        "id": "chatcmpl-93wKulWjVsSxZyqugNNpWrt6putDl",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "logprobs": null,
                "message": {
                    "content": "{\n    \"问题1\": \"RNN Search 模型中的编码器采用了什么样的结构？\",\n    \"回答1\": \"RNN Search 模型中的编码器采用双向 LSTM 结构。正向 LSTM 的状态和反向 LSTM 的状态分别基于输入序列的前向和后向信息，通过拼接得到各个位置的状态，形成中间表示。\",\n    \"问题2\": \"解码器在 RNN Search 模型中是如何实现信息传递的？\",\n    \"回答2\": \"解码器使用注意力机制实现从编码器到解码器的信息传递。在解码器的每一个位置，通过加法注意力计算上下文向量，决定解码器的状态序列以及输出的单词序列。\",\n    \"问题3\": \"RNN Search 模型中解码器的状态是如何计算得到的？\",\n    \"回答3\": \"解码器使用单向 LSTM，解码基于已生成的输出序列，是自回归过程。解码器的状态是通过单向 LSTM 计算得到的，其中包括当前位置的状态、前一个位置的状态和当前位置的上下文向量。\",\n    \"问题4\": \"RNN Search 模型中输出层函数 $g$ 的作用是什么？\",\n    \"回答4\": \"在 RNN Search 模型中，输出层函数 $g$ 由线性变换和软最大化函数组成，用于计算当前位置的输出。它表示下一个位置上单词出现的条件概率。\",\n    \"问题5\": \"RNN Search 模型中如何计算注意力权重 $\\boldsymbol{alpha}_{ij}$？\",\n    \"回答5\": \"在 RNN Search 模型中，注意力权重 $\\boldsymbol{alpha}_{ij}$ 通过相似度 $e_{ij}$ 的计算得到。相似度 $e_{ij}$ 通过一层神经网络计算，并经过 softmax 函数归一化得到注意力权重。\",\n    \"问题6\": \"RNN Search 模型中相似度 $e_{ij}$ 的计算公式是怎样的？\",\n    \"回答6\": \"在 RNN Search 模型中，相似度 $e_{ij}$ 通过一层神经网络计算得到，公式为 $e_{ij}=\\text{sigmoid}(\\boldsymbol{w}^{\\top} \\big[\\boldsymbol{s}_{i-1} ; \\boldsymbol{h}_{j}\\big]+b)$。\",\n    \"问题7\": \"RNN Search 模型中如何实现上下文向量 $\\boldsymbol{c}_i$ 的计算？\",\n    \"回答7\": \"在 RNN Search 模型中，在解码器的每一个位置，通过加法注意力计算得到上下文向量 $\\boldsymbol{c}_i$。上下文向量表示在当前位置的注意力计算结果，是编码器各个位置状态的加权求和。\",\n    \"问题8\": \"RNN Search 模型中编码器和解码器之间是如何进行信息传递的？\",\n    \"回答8\": \"RNN Search 模型中，在解码（生成）的过程中，将编码器得到的状态序列或中间表示序列通过注意力有选择地传递到解码器，决定解码器的状态序列以及输出的单词序列。传递的上下文向量实际是从输出序列的当前位置看到的输入序列的相关内容。\",\n    \"问题9\": \"RNN Search 模型中为什么需要使用双向 LSTM 作为编码器？\",\n    \"回答9\": \"RNN Search 模型使用双向 LSTM 作为编码器，可以更好地捕捉输入序列中前向和后向信息，并结合两者形成更丰富和全面的表示。这有助于提高模型对输入序列信息的理解和表达能力。\",\n    \"问题10\": \"RNN Search 模型中注意力机制对模型性能有何影响？\",\n    \"回答10\": \"RNN Search 模型中注意力机制能够使模型有选择地关注输入序列不同位置的信息，并将相关信息传递到解码器，从而提高模型对输入输出序列之间复杂关系的建模能力。这有助于提高模型翻译等任务的性能和效果。\"\n}",
                    "role": "assistant",
                    "function_call": null,
                    "tool_calls": null
                }
            }
        ],
        "created": 1710726256,
        "model": "gpt-3.5-turbo-1106",
        "object": "chat.completion",
        "system_fingerprint": "fp_4aaaf0dc94",
        "usage": {
            "completion_tokens": 1140,
            "prompt_tokens": 4003,
            "total_tokens": 5143
        },
        "parameters": {
            "model": "gpt-3.5-turbo-1106",
            "temperature": 0.2,
            "frequency_penalty": 0.15,
            "presence_penalty": 0.15
        }
    }
]