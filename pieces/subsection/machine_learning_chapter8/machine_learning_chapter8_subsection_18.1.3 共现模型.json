[
    {
        "strategy": "subsection",
        "source": "machine_learning_chapter8",
        "title": "18.1.3 共现模型",
        "content_length": 935,
        "content": "Title: 18.1.3 共现模型\nContent:\n可以定义与以上的生成模型等价的共现模型。\n\n文本-单词共现数据 $T$ 的生成概率为所有单词-文本对 $(w, d)$ 的生成概率的乘积:\n\n\n\\begin{equation*}\nP(T)=\\prod_{(w, d)} P(w, d)^{n(w, d)} \\tag{18.4}\n\\end{equation*}\n\n\n每个单词-文本对 $(w, d)$ 的概率由以下公式决定:\n\n\n\\begin{equation*}\nP(w, d)=\\sum_{z \\in Z} P(z) P(w \\mid z) P(d \\mid z) \\tag{18.5}\n\\end{equation*}\n\n\n式 (18.5) 即共现模型的定义。容易验证, 生成模型 (18.2) 和共现模型 (18.5) 是等价的。\n\n共现模型假设在话题 $z$ 给定的条件下, 单词 $w$ 与文本 $d$ 是条件独立的, 即\n\n\n\\begin{equation*}\nP(w, d \\mid z)=P(w \\mid z) P(d \\mid z) \\tag{18.6}\n\\end{equation*}\n\n\n图 18.3 所示是共现模型。图中文本变量 $d$ 是一个观测变量, 单词变量 $w$ 是一个观测变量, 话题变量 $z$ 是一个隐变量。图 18.1 是共现模型的直观解释。\n\n虽然生成模型与共现模型在概率公式意义上是等价的, 但是具有不同的性质。生成模型刻画文本-单词共现数据生成的过程, 共现模型描述文本-单词共现数据拥有的模式。生成模\n\n\\begin{center}\n\\includegraphics[max width=\\textwidth]{2024_03_13_60436489efc55078c367g-32(1)}\n\\end{center}\n\n图 18.3 概率潜在语义模型的共现模型\n\n型式 (18.2) 中单词变量 $w$ 与文本变量 $d$ 是非对称的, 而共现模型式 (18.5) 中单词变量 $w$ 与文本变量 $d$ 是对称的, 所以前者也称为非对称模型, 后者也称为对称模型。由于两个模型的形式不同, 其学习算法的形式也不同。"
    },
    {
        "id": "chatcmpl-947S5yiEC2bY5y4tIQpqoVv83nDUf",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "logprobs": null,
                "message": {
                    "content": "{\n    \"问题1\": \"生成模型和共现模型有什么等价关系？\",\n    \"回答1\": \"生成模型和共现模型在概率公式意义上是等价的。共现模型假设在话题 $z$ 给定的条件下，单词 $w$ 与文本 $d$ 是条件独立的，而生成模型刻画文本-单词共现数据生成的过程。因此，尽管具有不同的性质，但在概率公式上它们是等价的。\",\n    \"问题2\": \"共现模型中的生成概率是如何定义的？\",\n    \"回答2\": \"共现模型中文本-单词共现数据 $T$ 的生成概率为所有单词-文本对 $(w, d)$ 的生成概率的乘积，即 $P(T)=\\bigg(\\text{连乘}_{(w, d)} P(w, d)^{n(w, d)}\\bigg)$。\",\n    \"问题3\": \"共现模型中每个单词-文本对 $(w, d)$ 的概率是如何计算的？\",\n    \"回答3\": \"每个单词-文本对 $(w, d)$ 的概率由公式 $P(w, d)=\\text{连加}_{z \\text{ 在 } Z} P(z) P(w \\text{ 丨 } z) P(d \\text{ 丨 } z)$ 决定。这个公式描述了在给定话题 $z$ 的条件下，单词 $w$ 与文本 $d$ 的联合概率。\",\n    \"问题4\": \"共现模型假设了什么条件独立性？\",\n    \"回答4\": \"共现模型假设在话题 $z$ 给定的条件下，单词 $w$ 与文本 $d$ 是条件独立的，即 $P(w, d \\text{ 丨 } z)=P(w \\text{ 丨 } z) P(d \\text{ 丨 } z)$。\",\n    \"问题5\": \"共现模型中的图 18.3 所示是什么含义？\",\n    \"回答5\": \"图 18.3 展示了概率潜在语义模型的共现模型。其中文本变量 $d$ 是一个观测变量，单词变量 $w$ 是一个观测变量，话题变量 $z$ 是一个隐变量。这个图形象地展示了共现模型中各个变量之间的关系。\",\n    \"问题6\": \"生成模型和共现模型分别刻画了什么过程和拥有什么性质？\",\n    \"回答6\": \"生成模型刻画了文本-单词共现数据生成的过程，而共现模型描述了文本-单词共现数据拥有的模式。生成模型刻画了数据生成的过程，而共现模型更侧重于描述数据所呈现出的特定模式。\",\n    \"问题7\": \"为什么生成模型和共现模型具有不同的性质？\",\n    \"回答7\": \"生成模型和共现模型具有不同的性质，因为它们分别从不同角度刻画了文本-单词共现数据。生成模型着重于数据生成的过程，而共现模型更关注数据所呈现出的特定模式。这导致它们具有不同的性质和应用场景。\",\n    \"问题8\": \"共现模型中的非对称模型和对称模型分别指什么？\",\n    \"回答8\": \"共现模型中非对称模型指的是式 (18.2) 中单词变量 $w$ 与文本变量 $d$ 是非对称的情况，而对称模型指的是式 (18.5) 中单词变量 $w$ 与文本变量 $d$ 是对称的情况。这两种情况分别被称为非对称模型和对称模型。\",\n    \"问题9\": \"为什么非对称模型和对称模型会导致不同形式的学习算法？\",\n    \"回答9\": \"由于非对称模型和对称模型在形式上不同，其学习算法也会有所不同。这是因为它们描述了不同类型的文本-单词共现数据特征和关系，因此需要针对不同形式设计相应的学习算法来适应其特点。\",\n    \"问题10\": \"共现模型如何影响概率潜在语义分析（PLSA）或潜在狄利克雷分配（LDA）等相关算法？\",\n    \"回答10\": \"共现模型作为一种概率建模方法，在概率潜在语义分析（PLSA）或潜在狄利克雷分配（LDA）等相关算法中起到重要作用。它通过描述文本-单词共现数据所呈现出的特定模式，影响着这些算法在主题建模、信息检索等领域中的应用效果。\"\n}",
                    "role": "assistant",
                    "function_call": null,
                    "tool_calls": null
                }
            }
        ],
        "created": 1710768985,
        "model": "gpt-3.5-turbo-1106",
        "object": "chat.completion",
        "system_fingerprint": "fp_4aaaf0dc94",
        "usage": {
            "completion_tokens": 1377,
            "prompt_tokens": 3219,
            "total_tokens": 4596
        },
        "parameters": {
            "model": "gpt-3.5-turbo-1106",
            "temperature": 0.2,
            "frequency_penalty": 0.15,
            "presence_penalty": 0.15
        }
    }
]