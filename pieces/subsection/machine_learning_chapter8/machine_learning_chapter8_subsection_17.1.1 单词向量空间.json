[
    {
        "strategy": "subsection",
        "source": "machine_learning_chapter8",
        "title": "17.1.1 单词向量空间",
        "content_length": 3433,
        "content": "Title: 17.1.1 单词向量空间\nContent:\n文本信息处理, 比如文本信息检索、文本数据挖掘的一个核心问题是对文本的语义内容进行表示, 并进行文本之间的语义相似度计算。最简单的方法是利用向量空间模型 (vector space model, VSM）, 也就是单词向量空间模型（word vector space model）。向量空间模型的基本想法是：给定一个文本，用一个向量表示该文本的 “语义”，向量的每一维对应一个单词, 其数值为该单词在该文本中出现的频数或权值; 基本假设是文本中所有单词的出现情况表示了文本的语义内容; 文本集合中的每个文本都表示为一个向量, 存在于一个向量空间;向量空间的度量, 如内积或标准化内积表示文本之间的“语义相似度”。\\\\\n例如, 文本信息检索的任务是用户提出查询时, 帮助用户找到与查询最相关的文本, 以排序的形式展示给用户。一个最简单的做法是采用单词向量空间模型, 将查询与文本表示为单词的向量, 计算查询向量与文本向量的内积, 作为语义相似度, 以这个相似度的高低对文本进行排序。在这里, 查询被看成是一个伪文本, 查询与文本的语义相似度表示查询与文本的相关性。\n\n下面给出严格定义。给定一个含有 $n$ 个文本的集合 $\\boldsymbol{D}=\\left\\{d_{1}, d_{2}, \\cdots, d_{n}\\right\\}$, 以及在所有文本中出现的 $m$ 个单词的集合 $\\boldsymbol{W}=\\left\\{w_{1}, w_{2}, \\cdots, w_{m}\\right\\}$ 。将单词在文本中出现的数据用一个单词-文本矩阵（word-document matrix）表示, 记作 $\\boldsymbol{X}$ :\n\n\\[\n\\boldsymbol{X}=\\left[\\begin{array}{cccc}\nx_{11} & x_{12} & \\cdots & x_{1 n}  \\tag{17.1}\\\\\nx_{21} & x_{22} & \\cdots & x_{2 n} \\\\\n\\vdots & \\vdots & & \\vdots \\\\\nx_{m 1} & x_{m 2} & \\cdots & x_{m n}\n\\end{array}\\right]\n\\]\n\n这是一个 $m \\times n$ 矩阵, 元素 $x_{i j}$ 表示单词 $w_{i}$ 在文本 $d_{j}$ 中出现的频数或权值。由于单词的种类很多, 而每个文本中出现单词的种类通常较少, 所以单词-文本矩阵是一个稀疏矩阵。\n\n权值通常用单词频率-逆文本频率 (term frequency-inverse document frequency, TFIDF）表示，其定义是\n\n\\begin{center}\n\\includegraphics[max width=\\textwidth]{2024_03_13_60436489efc55078c367g-15}\n\\end{center}\n\n式中 $\\mathrm{tf}_{i j}$ 是单词 $w_{i}$ 出现在文本 $d_{j}$ 中的频数, $\\mathrm{tf}_{\\cdot j}$ 是文本 $d_{j}$ 中出现的所有单词的频数之和, $\\mathrm{df}_{i}$ 是含有单词 $w_{i}$ 的文本数, $\\mathrm{df}$ 是文本集合 $D$ 的全部文本数。直观上, 一个单词在一个文本中出现的频数越高, 这个单词在这个文本中的重要度就越高; 一个单词在整个文本集合中出现的文本数越少, 这个单词就越能表示其所在文本的特点, 重要度就越高; 一个单词在一个文本的 TF-IDF 是两种重要度的积, 表示综合重要度。\n\n单词向量空间模型直接使用单词-文本矩阵的信息。单词-文本矩阵的第 $j$ 列向量 $\\boldsymbol{x}_{j}$ 表示文本 $d_{j}$ :\n\n\\[\n\\boldsymbol{x}_{j}=\\left[\\begin{array}{c}\nx_{1 j}  \\tag{17.3}\\\\\nx_{2 j} \\\\\n\\vdots \\\\\nx_{m j}\n\\end{array}\\right], \\quad j=1,2, \\cdots, n\n\\]\n\n其中, $x_{i j}$ 是单词 $w_{i}$ 在文本 $d_{j}$ 的权值, $i=1,2, \\cdots, m$, 权值越大, 该单词在该文本中的重要度就越高。这时矩阵 $\\boldsymbol{X}$ 也可以写作 $\\boldsymbol{X}=\\left[\\begin{array}{llll}x_{1} & \\boldsymbol{x}_{2} & \\cdots & \\boldsymbol{x}_{n}\\end{array}\\right]$ 。\n\n两个单词向量的内积或标准化内积（余弦）表示对应的文本之间的语义相似度。因此, 文本 $d_{i}$ 与 $d_{j}$ 之间的相似度为\n\n\n\\begin{equation*}\nx_{i} \\cdot x_{j}, \\quad \\frac{x_{i} \\cdot x_{j}}{\\left\\|x_{i}\\right\\|\\left\\|x_{j}\\right\\|} \\tag{17.4}\n\\end{equation*}\n\n\n式中 ・ 表示向量的内积, $\\|\\cdot\\|$ 表示向量的范数。\\\\\n直观上, 在两个文本中共同出现的单词越多, 其语义内容就越相近, 这时, 对应的单词向量同不为零的维度就越多, 内积就越大 (单词向量元素的值都是非负的), 表示两个文本在语义内容上越相似。这个模型虽然简单, 却能很好地表示文本之间的语义相似度, 与人们对语义相似度的判断接近, 在一定程度上能够满足应用的需求, 至今仍在文本信息检索、文本数据挖掘等领域被广泛使用, 可以认为是文本信息处理的一个基本原理。注意, 两个文本的语义相似度并不是由一两个单词是否在两个文本中出现决定, 而是由所有的单词在两个文本中共同出现的 “模式” 决定。\n\n单词向量空间模型的优点是模型简单, 计算效率高。因为单词向量通常是稀疏的, 两个向量的内积计算只需要在其同不为零的维度上进行即可, 需要的计算很少, 可以高效地完成。单词向量空间模型也有一定的局限性, 体现在内积相似度未必能够准确表达两个文本的语义相似度上。因为自然语言的单词具有一词多义性 (polysemy) 及多词一义性 (synonymy), 即同一个单词可以表示多个语义, 多个单词可以表示同一个语义, 所以基于单词向量的相似度计算存在不精确的问题。\n\n图 17.1 给出一个例子一一单词-文本矩阵, 每一行表示一个单词, 每一列表示一个文本,矩阵的每一个元素表示单词在文本中出现的频数, 频数 0 省略。单词向量空间模型中, 文本 $d_{1}$ 与 $d_{2}$ 相似度并不高, 尽管两个文本的内容相似, 这是因为同义词 “airplane” 与 “aircraft”被当作了两个独立的单词, 单词向量空间模型不考虑单词的同义性, 在此情况下无法进行准确的相似度计算。另一方面, 文本 $d_{3}$ 与 $d_{4}$ 有一定的相似度, 尽管两个文本的内容并不相似,这是因为单词 “apple” 具有多义, 可以表示 “apple computer” 和 “fruit”, 单词向量空间模型不考虑单词的多义性, 在此情况下也无法进行准确的相似度计算。\n\n\\begin{center}\n\\begin{tabular}{|l|cccc|}\n\\hline\n & $d_{1}$ & $d_{2}$ & $d_{3}$ & $d_{4}$ \\\\\n\\hline\nairplane & 2 &  &  &  \\\\\naircraft &  & 2 &  &  \\\\\ncomputer &  &  & 1 &  \\\\\napple &  &  & 2 & 3 \\\\\nfruit &  &  &  & 1 \\\\\nproduce & 1 & 2 & 2 & 1 \\\\\n\\hline\n\\end{tabular}\n\\end{center}\n\n图 17.1 单词-文本矩阵例"
    },
    {
        "id": "chatcmpl-947HZiD5ehDin4JbFzVf3EmhlL4dK",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "logprobs": null,
                "message": {
                    "content": "{\n    \"问题1\": \"向量空间模型的基本想法是什么？\",\n    \"回答1\": \"向量空间模型的基本想法是，给定一个文本，用一个向量表示该文本的“语义”，向量的每一维对应一个单词，其数值为该单词在该文本中出现的频数或权值。文本集合中的每个文本都表示为一个向量，存在于一个向量空间；向量空间的度量，如内积或标准化内积表示文本之间的“语义相似度”。\",\n    \"问题2\": \"单词-文本矩阵的作用是什么？\",\n    \"回答2\": \"单词-文本矩阵用于表示单词在文本中出现的频数或权值，是向量空间模型的基础。它将文本集合中的每个文本表示为一个向量，存储在一个稀疏矩阵中，通过这种方式实现了文本语义内容的表示和计算。\",\n    \"问题3\": \"单词频率-逆文本频率（TF-IDF）的定义是什么？\",\n    \"回答3\": \"单词频率-逆文本频率（TF-IDF）是一种用于表示单词在文本中重要性的方法。其定义为 $\\text{tf-idf}_{i j} = \\text{tf}_{i j} \\times \\text{idf}_{i}$，其中 $\\text{tf}_{i j}$ 是单词 $w_{i}$ 出现在文本 $d_{j}$ 中的频数，$\\text{idf}_{i}$ 是含有单词 $w_{i}$ 的文本数与整个文本集合 $D$ 的全部文本数之比的对数倒数。\",\n    \"问题4\": \"单词向量空间模型如何表示一个文本？\",\n    \"回答4\": \"单词向量空间模型直接使用单词-文本矩阵的信息。单词-文本矩阵的第 $j$ 列向量 $\\boldsymbol{x}_{j}$ 表示文本 $d_{j}$。其中，$x_{i j}$ 是单词 $w_{i}$ 在文本 $d_{j}$ 的权值，通过这种方式实现了对每个文本的语义内容进行向量化表示。\",\n    \"问题5\": \"内积或标准化内积（余弦）如何表示两个文本之间的语义相似度？\",\n    \"回答5\": \"两个单词向量的内积或标准化内积（余弦）表示对应的文本之间的语义相似度。具体而言，文本 $d_{i}$ 与 $d_{j}$ 之间的相似度可以表示为 $x_{i} \\boldsymbol{\\bullet} x_{j}$ 或 $\\frac{x_{i} \\boldsymbol{\\bullet} x_{j}}{\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big|x_{i}\\big| \\times \\big|x_{j}\\big|} $。\",\n    \"问题6\": \"单词向量空间模型在哪些领域被广泛使用？\",\n    \"回答6\": \"单词向量空间模型至今仍在文本信息检索、文本数据挖掘等领域被广泛使用。它能够很好地表示文本之间的语义相似度，与人们对语义相似度的判断接近，在一定程度上能够满足应用的需求。\",\n    \"问题7\": \"单词向量空间模型存在哪些局限性？\",\n    \"回答7\": \"单词向量空间模型存在一定局限性，体现在内积相似度未必能够准确表达两个文本的语义相似度上。因为自然语言的单词具有一词多义性（polysemy）及多词一义性（synonymy），即同一个单词可以表示多个语义，多个单词可以表示同一个语义，所以基于单词向量的相似度计算存在不精确的问题。\",\n    \"问题8\": \"为什么基于单词向量的相似度计算存在不精确的问题？\",\n    \"回答8\": \"基于单词向量的相似度计算存在不精确的问题主要是因为自然语言中存在一词多义性和多词一义性。同一个单词可以有多种不同的含义，而不同的单词也可能具有相同的含义，这使得基于简单单词频率或权值无法完全准确地捕捉到语义相似度。\",\n    \"问题9\": \"单词-文本矩阵如何体现了稀疏性？\",\n    \"回答9\": \"由于单词种类很多，而每个文本中出现单词的种类通常较少，所以单词-文本矩阵是一个稀疏矩阵。这意味着大部分元素为零，只有少数元素非零，从而体现了稀疏性。\",\n    \"问题10\": \"为什么单词向量空间模型具有计算效率高的优点？\",\n    \"回答10\": \"由于单词向量通常是稀疏的，两个向量的内积计算只需要在其非零维度上进行即可，需要的计算很少，因此具有计算效率高的优点。这使得单词向量空间模型能够高效地完成语义相似度计算和相关任务。\"\n}",
                    "role": "assistant",
                    "function_call": null,
                    "tool_calls": null
                }
            }
        ],
        "created": 1710768333,
        "model": "gpt-3.5-turbo-1106",
        "object": "chat.completion",
        "system_fingerprint": "fp_4aaaf0dc94",
        "usage": {
            "completion_tokens": 1572,
            "prompt_tokens": 5097,
            "total_tokens": 6669
        },
        "parameters": {
            "model": "gpt-3.5-turbo-1106",
            "temperature": 0.2,
            "frequency_penalty": 0.15,
            "presence_penalty": 0.15
        }
    }
]