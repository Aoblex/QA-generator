[
    {
        "strategy": "subsection",
        "source": "deeplearning",
        "title": "4.3.1 通用近似定理",
        "content_length": 1444,
        "content": "Title: 4.3.1 通用近似定理\nContent:\n前馈神经网络具有很强的拟合能力, 常见的连续非线性函数都可以用前馈神经网络来近似.\n\n定理 4.1 - 通用近似定理 (Universal Approximation Theorem ) [Cybenko, 1989; Hornik et al., 1989] : 令 $\\phi(\\cdot)$ 是一个非常数、有界、单调递增的连续函数, $\\mathcal{J}_{D}$ 是一个 $D$ 维的单位超立方体 $[0,1]^{D}, C\\left(\\mathcal{J}_{D}\\right)$ 是定义在 $\\mathcal{J}_{D}$ 上的连续函数集合. 对于任意给定的一个函数 $f \\in C\\left(\\mathcal{J}_{D}\\right)$, 存在一个整数 $M$,和一组实数 $v_{m}, b_{m} \\in \\mathbb{R}$ 以及实数向量 $\\boldsymbol{w}_{m} \\in \\mathbb{R}^{D}, m=1, \\cdots, M$, 以至于我们可以定义函数\n\n\n\\begin{equation*}\nF(\\boldsymbol{x})=\\sum_{m=1}^{M} v_{m} \\phi\\left(\\boldsymbol{w}_{m}^{\\top} \\boldsymbol{x}+b_{m}\\right) \\tag{4.37}\n\\end{equation*}\n\n\n作为函数 $f$ 的近似实现, 即\n\n\n\\begin{equation*}\n|F(\\boldsymbol{x})-f(\\boldsymbol{x})|<\\epsilon, \\forall \\boldsymbol{x} \\in \\mathcal{J}_{D}, \\tag{4.38}\n\\end{equation*}\n\n\n其中 $\\epsilon>0$ 是一个很小的正数.\n\n通用近似定理在实数空间 $\\mathbb{R}^{D}$ 中的有界闭集上依然成立.\n\n根据通用近似定理, 对于具有线性输出层和至少一个使用 “挤压” 性质的激活函数的隐藏层组成的前馈神经网络, 只要其隐藏层神经元的数量足够, 它可以以任意的精度来近似任何一个定义在实数空间 $\\mathbb{R}^{D}$ 中的有界闭集函数 [Funahashi et al., 1993; Hornik et al., 1989]. 所谓 “挤压” 性质的函数是指像 Sigmoid 函数的有界函数, 但神经网络的通用近似性质也被证明对于其他类型的激活函数, 比如 ReLU, 也都是适用的.\n\n通用近似定理只是说明了神经网络的计算能力可以去近似一个给定的连续函数, 但并没有给出如何找到这样一个网络, 以及是否是最优的. 此外, 当应用到 \\href{https://nndl.github.io/%E5%AE%9A%E4%B9%89%E5%9C%A8%E5%AE%9E%E6%95%B0%E7%A9%BA%E9%97%B4}{https://nndl.github.io/定义在实数空间} $\\mathbb{R}^{D}$ 中的有界闭集上的任意连续函数, 也称为 Borel 可测函数.\n\n参见习题4-6.\\\\\n机器学习时, 真实的映射函数并不知道, 一般是通过经验风险最小化和正则化来进行参数学习. 因为神经网络的强大能力, 反而容易在训练集上过拟合."
    },
    {
        "id": "chatcmpl-941U0obopASRuKjRKjEitiRrO1LAM",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "logprobs": null,
                "message": {
                    "content": "{\n    \"问题1\": \"前馈神经网络具有什么样的拟合能力？\",\n    \"回答1\": \"前馈神经网络具有很强的拟合能力，能够用来近似常见的连续非线性函数。\",\n    \"问题2\": \"通用近似定理是什么？\",\n    \"回答2\": \"通用近似定理指出，对于具有线性输出层和至少一个使用 “挤压” 性质的激活函数的隐藏层组成的前馈神经网络，只要其隐藏层神经元的数量足够，它可以以任意的精度来近似任何一个定义在实数空间 $\\boldsymbol{R}^{D}$ 中的有界闭集函数。\",\n    \"问题3\": \"通用近似定理中的 $\\boldsymbol{F}(\\boldsymbol{x})$ 是如何定义的？\",\n    \"回答3\": \"通用近似定理中，$\\boldsymbol{F}(\\boldsymbol{x})$ 被定义为 $\\boldsymbol{F}(\\boldsymbol{x})=\\text{∑}_{m=1}^{M} v_{m} \\text{ϕ}(\\boldsymbol{w}_{m}^{\\top} \\boldsymbol{x}+b_{m})$，其中 $v_{m}, b_{m} \\text{ 和 } \\boldsymbol{w}_{m}$ 是一组实数和实数向量。\",\n    \"问题4\": \"通用近似定理对于神经网络的隐藏层有什么要求？\",\n    \"回答4\": \"通用近似定理要求神经网络的隐藏层至少包含一个使用 “挤压” 性质的激活函数，并且隐藏层神经元的数量足够，以便可以以任意的精度来近似任何一个定义在实数空间 $\\boldsymbol{R}^{D}$ 中的有界闭集函数。\",\n    \"问题5\": \"通用近似定理适用于哪些类型的激活函数？\",\n    \"回答5\": \"通用近似定理适用于具有线性输出层和至少一个使用 “挤压” 性质的激活函数的隐藏层组成的前馈神经网络。所谓 “挤压” 性质的函数是指像 Sigmoid 函数的有界函数，但通用近似性质也被证明对于其他类型的激活函数，比如 ReLU，也都是适用的。\",\n    \"问题6\": \"通用近似定理说明了神经网络的计算能力可以做什么？\",\n    \"回答6\": \"通用近似定理说明了神经网络的计算能力可以去近似一个给定的连续函数，即对于任意给定的一个函数 $f \\text{ in } C\\big(\\boldsymbol{J}_{D}\\big)$，存在一个整数 $M$ 和一组实数 $v_{m}, b_{m} \\text{ 和 } \\boldsymbol{w}_{m}$ 以至于可以定义一个函数 $F(\\boldsymbol{x})$ 作为函数 $f$ 的近似实现。\",\n    \"问题7\": \"通用近似定理是否给出了如何找到最优神经网络以及最优参数？\",\n    \"回答7\": \"通用近似定理并没有给出如何找到最优神经网络以及最优参数。它只是说明了神经网络具有这样的计算能力，即可以以任意精度来近似一个给定的连续函数。\",\n    \"问题8\": \"在机器学习中，为什么需要通过经验风险最小化和正则化来进行参数学习？\",\n    \"回答8\": \"在机器学习中，真实的映射函数通常是未知的，一般是通过经验风险最小化和正则化来进行参数学习。因为神经网络具有强大能力，容易在训练集上过拟合。因此需要通过经验风险最小化和正则化来控制模型复杂度，提高模型泛化能力。\",\n    \"问题9\": \"过拟合是指什么？\",\n    \"回答9\": \"过拟合是指模型在训练集上表现很好，但在测试集或新数据上表现较差的现象。这意味着模型过度地学习了训练数据中的噪声或特定样本特征，而忽略了数据中真正的规律和普遍性。\",\n    \"问题10\": \"在机器学习中，为什么强大能力反而容易导致过拟合？\",\n    \"回答10\": \"在机器学习中，强大能力反而容易导致过拟合是因为强大能力的模型具有更多自由度和灵活性，可以更好地拟合训练数据中的复杂关系。然而，当模型过度拟合训练数据时，就会忽略数据中真正的规律和普遍性，导致在测试集或新数据上表现较差。\"\n}",
                    "role": "assistant",
                    "function_call": null,
                    "tool_calls": null
                }
            }
        ],
        "created": 1710746040,
        "model": "gpt-3.5-turbo-1106",
        "object": "chat.completion",
        "system_fingerprint": "fp_4aaaf0dc94",
        "usage": {
            "completion_tokens": 1396,
            "prompt_tokens": 3516,
            "total_tokens": 4912
        },
        "parameters": {
            "model": "gpt-3.5-turbo-1106",
            "temperature": 0.2,
            "frequency_penalty": 0.15,
            "presence_penalty": 0.15
        }
    }
]