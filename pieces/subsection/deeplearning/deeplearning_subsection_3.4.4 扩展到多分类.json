[
    {
        "strategy": "subsection",
        "source": "deeplearning",
        "title": "3.4.4 扩展到多分类",
        "content_length": 2180,
        "content": "Title: 3.4.4 扩展到多分类\nContent:\n原始的感知器是一种二分类模型, 但也可以很容易地扩展到多分类问题, 甚至是更一般的结构化学习问题 [Collins, 2002].\n\n之前介绍的分类模型中, 分类函数都是在输入 $\\boldsymbol{x}$ 的特征空间上. 为了使得感知器可以处理更复杂的输出, 我们引入一个构建在输入输出联合空间上的特征函数 $\\phi(x, y)$, 将样本对 $(x, y)$ 映射到一个特征向量空间.\n\n在联合特征空间中,我们可以建立一个广义的感知器模型,\n\n\n\\begin{equation*}\n\\hat{\\boldsymbol{y}}=\\underset{\\boldsymbol{y} \\in \\operatorname{Gen}(\\boldsymbol{x})}{\\arg \\max } \\boldsymbol{w}^{\\top} \\boldsymbol{\\phi}(\\boldsymbol{x}, \\boldsymbol{y}) \\tag{3.78}\n\\end{equation*}\n\n\n其中 $\\boldsymbol{w}$ 为权重向量, $\\operatorname{Gen}(\\boldsymbol{x})$ 表示输入 $\\boldsymbol{x}$ 所有的输出目标集合.\n\n广义感知器模型一般用来处理结构化学习问题. 当用广义感知器模型来处理 $C$ 分类问题时, $\\boldsymbol{y} \\in\\{0,1\\}^{C}$ 为类别的 one-hot 向量表示. 在 $C$ 分类问题中,一种常用的特征函数 $\\phi(x, y)$ 是 $x$ 和 $y$ 的外积, 即\n\n\n\\begin{equation*}\n\\phi(\\boldsymbol{x}, \\boldsymbol{y})=\\operatorname{vec}\\left(\\boldsymbol{x} \\boldsymbol{y}^{\\top}\\right) \\in \\mathbb{R}^{(D \\times C)} \\tag{3.79}\n\\end{equation*}\n\n\n其中 $\\operatorname{vec}(\\cdot)$ 是向量化算子, $\\phi(\\boldsymbol{x}, \\boldsymbol{y})$ 为 $(D \\times C)$ 维的向量.\n\n外积的定义参见公式(A.28).\n\n\\href{https://nndl.github.io/}{https://nndl.github.io/}\\\\\n给定样本 $(\\boldsymbol{x}, \\boldsymbol{y})$, 若 $\\boldsymbol{x} \\in \\mathbb{R}^{D}, \\boldsymbol{y}$ 为第 $c$ 维为 1 的 one-hot 向量, 则\n\n\\[\n\\phi(\\boldsymbol{x}, \\boldsymbol{y})=\\left[\\begin{array}{c}\n\\vdots  \\tag{3.80}\\\\\n0 \\\\\n\\vdots \\\\\nx_{D} \\\\\n0 \\\\\n\\vdots\n\\end{array}\\right] \\leftarrow \\text { 第 }(c-1) \\times D+1 \\text { 行 }\n\\]\n\n广义感知器算法的训练过程如算法3.3所示.\n\n算法 3.3 广义感知器参数学习算法\n\n输入: 训练集: $\\left\\{\\left(\\boldsymbol{x}^{(n)}, \\boldsymbol{y}^{(n)}\\right)\\right\\}_{n=1}^{N}$, 最大迭代次数 $T$\n\n1 初始化: $\\boldsymbol{w}_{0} \\leftarrow 0, k \\leftarrow 0, t \\leftarrow 0$;\n\n\\section*{repeat}\n对训练集 $\\mathcal{D}$ 中的样本随机排序;\n\nfor $n=1 \\cdots N$ do\n\n选取一个样本 $\\left(\\boldsymbol{x}^{(n)}, \\boldsymbol{y}^{(n)}\\right)$;\n\n用公式 (3.78) 计算预测类别 $\\hat{\\boldsymbol{y}}^{(n)}$;\n\nif $\\hat{\\boldsymbol{y}}^{(n)} \\neq \\boldsymbol{y}^{(n)}$ then\n\n$$\n\\boldsymbol{w}_{k+1} \\leftarrow \\boldsymbol{w}_{k}+\\left(\\phi\\left(\\boldsymbol{x}^{(n)}, \\boldsymbol{y}^{(n)}\\right)-\\phi\\left(\\boldsymbol{x}^{(n)}, \\hat{\\boldsymbol{y}}^{(n)}\\right)\\right)\n$$\n\n$$\nk=k+1\n$$\n\nend\n\n$t=t+1$\n\nif $t=T$ then break; // 达到最大迭代次数\n\nend\n\n4 until $t=T$;\n\n输出: $\\boldsymbol{w}_{k}$"
    },
    {
        "id": "chatcmpl-941DCERzt9P1OsEjOSaawz0mpci7J",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "logprobs": null,
                "message": {
                    "content": "{\n    \"问题1\": \"感知器模型如何扩展到处理多分类问题？\",\n    \"回答1\": \"感知器模型可以很容易地扩展到多分类问题，甚至是更一般的结构化学习问题。为了处理更复杂的输出，引入一个构建在输入输出联合空间上的特征函数 $\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{x}, \\boldsymbol{y})}$，将样本对 $(\\boldsymbol{x}, \\boldsymbol{y})$ 映射到一个特征向量空间。在联合特征空间中，建立一个广义的感知器模型来处理多分类问题。\",\n    \"问题2\": \"广义感知器模型中的 $\\boldsymbol{w}$ 和 $\\text{Gen}(\\boldsymbol{x})$ 分别代表什么？\",\n    \"回答2\": \"在广义感知器模型中，$\\boldsymbol{w}$ 为权重向量，用于计算特征函数 $\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{x}, \\boldsymbol{y})}$ 的线性组合以预测输出。$\\text{Gen}(\\boldsymbol{x})$ 表示输入 $\\boldsymbol{x}$ 所有的输出目标集合，即所有可能的输出类别。\",\n    \"问题3\": \"广义感知器模型是用来解决什么类型的问题？\",\n    \"回答3\": \"广义感知器模型一般用来处理结构化学习问题，其中输入和输出之间存在复杂的关联关系。它可以扩展到多分类问题，并且适用于更一般的结构化学习问题。\",\n    \"问题4\": \"在 $C$ 分类问题中，常用的特征函数 $\\text{phi}(x, y)$ 是如何定义的？\",\n    \"回答4\": \"在 $C$ 分类问题中，一种常用的特征函数 $\\text{phi}(x, y)$ 是 $x$ 和 $y$ 的外积，即 $\\text{phi}(\\boldsymbol{x}, \\boldsymbol{y})=\\text{vec}(\\boldsymbol{x} \\boldsymbol{y}^{\\top}) \\text{ 且 } \\text{phi}(\\boldsymbol{x}, \\boldsymbol{y}) \\text{ 为 } (D \\times C) \\text{ 维的向量}$。\",\n    \"问题5\": \"外积的定义是什么？\",\n    \"回答5\": \"外积是一种向量运算，对于两个向量 $\\boldsymbol{x}$ 和 $\\boldsymbol{y}$，其外积结果是一个矩阵。在这里，$x$ 和 $y$ 的外积被定义为 $\\text{phi}(\\boldsymbol{x}, \\boldsymbol{y})=\\text{vec}(\\boldsymbol{x} \\boldsymbol{y}^{\\top})$。\",\n    \"问题6\": \"给定样本 $(\\boldsymbol{x}, \\boldymbol{y})$，如果 $\\boldymbol{x} \\text{ 为 } \\textbf{R}^{D}, \\textbf{y}$ 为第 $c$ 维为 1 的 one-hot 向量，则特征函数 $\\text{phi}(\\textbf{x}, \\textbf{y})$ 的计算方法是什么？\",\n    \"回答6\": \"对于给定样本 $(\\textbf{x}, \\textbf{y})$，如果 $\\textbf{x}$ 为 $\\textbf{R}^{D}$，$\\textbf{y}$ 为第 $c$ 维为 1 的 one-hot 向量，则特征函数 $\\text{phi}(\\textbf{x}, \\textbf{y})$ 的计算方法是将 $\\textbf{x}$ 中第 $(c-1) \\times D+1$ 行设置为 $\\textbf{x}$ 的值，其余部分为零。\",\n    \"问题7\": \"广义感知器算法的训练过程是怎样的？\",\n    \"回答7\": \"广义感知器算法的训练过程包括对训练集中的样本进行迭代处理，并根据预测结果对权重向量进行更新。具体而言，通过随机选择样本并计算预测类别，若预测错误则更新权重向量。该过程重复进行直至达到最大迭代次数。\",\n    \"问题8\": \"广义感知器算法中的参数学习算法具体包括哪些步骤？\",\n    \"回答8\": \"广义感知器参数学习算法包括以下步骤：初始化权重向量和迭代次数；对训练集中的样本进行随机排序；选取样本并计算预测类别；若预测错误则更新权重向量；重复以上步骤直至达到最大迭代次数。\",\n    \"问题9\": \"广义感知器算法中的参数学习算法如何更新权重向量？\",\n    \"回答9\": \"在广义感知器算法中，若预测错误，则通过更新权重向量来调整模型。具体而言，在预测错误时，根据实际输出和预测输出之间的差异来更新权重向量。\",\n    \"问题10\": \"广义感知器模型适用于解决哪种类型的学习问题？\",\n    \"回答10\": \"广义感知器模型适用于解决结构化学习问题，其中输入和输出之间存在复杂的关联关系。它可以处理多分类问题，并且适用于更一般的结构化学习问题。\"\n}",
                    "role": "assistant",
                    "function_call": null,
                    "tool_calls": null
                }
            }
        ],
        "created": 1710744998,
        "model": "gpt-3.5-turbo-1106",
        "object": "chat.completion",
        "system_fingerprint": "fp_4aaaf0dc94",
        "usage": {
            "completion_tokens": 1524,
            "prompt_tokens": 3683,
            "total_tokens": 5207
        },
        "parameters": {
            "model": "gpt-3.5-turbo-1106",
            "temperature": 0.2,
            "frequency_penalty": 0.15,
            "presence_penalty": 0.15
        }
    }
]