[
    {
        "strategy": "subsection",
        "source": "deeplearning",
        "title": "14.1.1 典型例子",
        "content_length": 651,
        "content": "Title: 14.1.1 典型例子\nContent:\n强化学习广泛应用于很多领域, 比如电子游戏、棋类游戏、迷宫类游戏、控制系统、推荐等. 这里我们介绍几个比较典型的强化学习例子.\n\n多臂奢博机问题 给定 $K$ 个奢博机，拉动每个奢博机的拉杆 (Arm), 奢博机会按照一个事先设定的概率掉出一块钱或不掉钱. 每个奢博机掉钱的概率不一样.多臂奢博机问题 (Multi-Armed Bandit Problem) 是指, 给定有限的机会次数 $T$,如何玩这些奢博机才能使得期望累积收益最大化. 多臂奢博机问题在广告推荐、投资组合等领域有着非常重要的应用.\n\n悬崖行走问题 在一个网格世界 (Grid World) 中, 每个格子表示一个状态. 如图14.1所示的一个网格世界, 每个状态为 $(i, j), 1 \\leq i \\leq 7,1 \\leq j \\leq 3$, 其中格子 $(2,1)$ 到 $(6,1)$ 是悬崖 (Cliff). 有一个醉汉, 从左下角的开始位置 $S$, 走到右下角的目标位置 $E$. 如果走到悬崖, 醉汉会跌落悬崖并死去. 醉汉可以选择行走的路线, 即在每个状态时, 选择行走的方向: 上下左右. 动作空间 $\\mathcal{A}=\\{\\uparrow, \\downarrow, \\leftarrow, \\rightarrow\\}$. 但每走一步, 都有一定的概率滑落到周围其他格子. 醉汉的目标是如何安全地到达目标位置.\n\n\n\n图 14.1 悬崖行走问题"
    },
    {
        "id": "chatcmpl-945bgX3NTQqSwYmvMVCLB2FpQwrYT",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "logprobs": null,
                "message": {
                    "content": "{\n    \"问题1\": \"强化学习在哪些领域有广泛的应用？\",\n    \"回答1\": \"强化学习广泛应用于很多领域，比如电子游戏、棋类游戏、迷宫类游戏、控制系统、推荐等。\",\n    \"问题2\": \"多臂奢博机问题是什么？\",\n    \"回答2\": \"多臂奢博机问题是指给定 $K$ 个奢博机，拉动每个奢博机的拉杆，奢博机会按照一个事先设定的概率掉出一块钱或不掉钱。每个奢博机掉钱的概率不一样。在有限的机会次数 $T$ 内，如何玩这些奢博机才能使得期望累积收益最大化。\",\n    \"问题3\": \"多臂奢博机问题在哪些领域有着重要的应用？\",\n    \"回答3\": \"多臂奢博机问题在广告推荐、投资组合等领域有着非常重要的应用。\",\n    \"问题4\": \"悬崖行走问题中的动作空间是什么？\",\n    \"回答4\": \"悬崖行走问题中的动作空间 $\\text{A}=\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big\\big{\\text{A}=\\big{\\text{A}=\\big{\\text{A}=\\big{\\text{A}=\\big{\\text{A}=\\big{\\text{A}=\\big{\\text{A}=\\big{\\text{A}=\\big{\\text{A}=\\big{\\text{A}=\\big{\\text{A}=\\big{\\text{A}=\\big{\\text{A}=\\big{\\text{A}=\\big{\\text{A}=\\big{\\text{A}=\\big{\\text{A}=\\big{\\text{A}=\\big{\\text{A}=\\big{\\text{A}=\\big{\\text{A}=\\big{\\text{A}=\\big{\\text{A}=\\big{\\text{A}=\\big{\\text{A}=\\big{\\text{A}=\\big{\\text{A}=\\big{\\text{A}=\\big{\\text{A}=\\bigright}, \\rightarrow}$。\",\n    \"问题5\": \"悬崖行走问题中的目标是什么？\",\n    \"回答5\": \"悬崖行走问题中，醉汉的目标是如何安全地到达目标位置，即从左下角的开始位置 $S$ 走到右下角的目标位置 $E$。\",\n    \"问题6\": \"强化学习是如何定义的？\",\n    \"回答6\": \"强化学习是一种机器学习范式，其目标是通过观察环境、执行动作和获得奖励来学习最优的决策策略，以使累积奖励最大化。\",\n    \"问题7\": \"强化学习与监督学习有什么区别？\",\n    \"回答7\": \"强化学习与监督学习不同，监督学习是通过给定输入和对应的标签来训练模型，而强化学习则是通过与环境交互来学习最优的决策策略。\",\n    \"问题8\": \"强化学习中的探索-利用平衡是指什么？\",\n    \"回答8\": \"探索-利用平衡是指在强化学习中需要平衡尝试新动作（探索）和选择已知能够带来高奖励的动作（利用）之间的关系，以最大化长期累积奖励。\",\n    \"问题9\": \"强化学习中的马尔可夫决策过程（MDP）是什么？\",\n    \"回答9\": \"马尔可夫决策过程（MDP）是强化学习中描述环境状态、动作和奖励之间关系的数学框架，它满足马尔可夫性质，即未来状态只依赖于当前状态和执行的动作。\",\n    \"问题10\": \"强化学习算法中常用的价值函数有哪些？\",\n    \"回答10\": \"强化学习算法中常用的价值函数包括状态值函数 $V(s)$ 和动作值函数 $Q(s, a)$，它们分别表示在状态 $s$ 下采取最优策略所能获得的期望累积奖励和在状态 $s$ 下采取动作 $a$ 后所能获得的期望累积奖励。\"\n}",
                    "role": "assistant",
                    "function_call": null,
                    "tool_calls": null
                }
            }
        ],
        "created": 1710761892,
        "model": "gpt-3.5-turbo-1106",
        "object": "chat.completion",
        "system_fingerprint": "fp_4aaaf0dc94",
        "usage": {
            "completion_tokens": 1354,
            "prompt_tokens": 3147,
            "total_tokens": 4501
        },
        "parameters": {
            "model": "gpt-3.5-turbo-1106",
            "temperature": 0.2,
            "frequency_penalty": 0.15,
            "presence_penalty": 0.15
        }
    }
]