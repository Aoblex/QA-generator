[
    {
        "strategy": "subsection",
        "source": "deeplearning",
        "title": "15.6.1 基于循环神经网络的序列到序列模型",
        "content_length": 1701,
        "content": "Title: 15.6.1 基于循环神经网络的序列到序列模型\nContent:\n实现序列到序列的最直接方法是使用两个循环神经网络来分别进行编码和解码, 也称为编码器-解码器 ( Encoder-Decoder) 模型.\n\n编码器 首先使用一个循环神经网络 $f_{\\mathrm{enc}}$ 来编码输入序列 $\\boldsymbol{x}_{1: S}$ 得到一个固定维数的向量 $\\boldsymbol{u}, \\boldsymbol{u}$ 一般为编码循环神经网络最后时刻的隐状态.\n\n\n\\begin{equation*}\n\\boldsymbol{h}_{t}^{\\mathrm{enc}}=f_{\\mathrm{enc}}\\left(\\boldsymbol{h}_{t-1}^{\\mathrm{enc}}, \\boldsymbol{e}_{x_{t-1}}, \\theta_{\\mathrm{enc}}\\right), \\quad \\forall t \\in[1: S], \\tag{15.99}\n\\end{equation*}\n\n\n\\href{https://nndl.github.io/}{https://nndl.github.io/}\n\n\n\\begin{equation*}\n\\boldsymbol{u}=\\boldsymbol{h}_{S}^{\\mathrm{enc}} \\tag{15.100}\n\\end{equation*}\n\n\n其中 $f_{\\mathrm{enc}}(\\cdot)$ 为编码循环神经网络, 可以为 LSTM 或 GRU, 其参数为 $\\theta_{\\mathrm{enc}}, \\boldsymbol{e}_{x}$ 为词 $x$的词向量.\n\n解码器 在生成目标序列时, 使用另外一个循环神经网络 $f_{\\mathrm{dec}}$ 来进行解码. 在解码过程的第 $t$ 步时, 已生成前缀序列为 $\\boldsymbol{y}_{1:(t-1)}$. 令 $\\boldsymbol{h}_{t}^{\\mathrm{dec}}$ 表示在网络 $f_{\\mathrm{dec}}$ 的隐状态, $\\boldsymbol{o}_{t} \\in(0,1)^{|\\mathcal{V}|}$ 为词表中所有词的后验概率, 则\n\n\n\\begin{align*}\n\\boldsymbol{h}_{0}^{\\mathrm{dec}} & =\\boldsymbol{u},  \\tag{15.101}\\\\\n\\boldsymbol{h}_{t}^{\\mathrm{dec}} & =f_{\\mathrm{dec}}\\left(\\boldsymbol{h}_{t-1}^{\\mathrm{dec}}, \\boldsymbol{e}_{y_{t-1}}, \\theta_{\\mathrm{dec}}\\right),  \\tag{15.102}\\\\\n\\boldsymbol{o}_{t} & =g\\left(\\boldsymbol{h}_{t}^{\\mathrm{dec}}, \\theta_{o}\\right), \\tag{15.103}\n\\end{align*}\n\n\n其中 $f_{\\mathrm{dec}}(\\cdot)$ 为解码循环神经网络,$g(\\cdot)$ 为最后一层为 $\\operatorname{Softmax}$ 函数的前馈神经网络, $\\theta_{\\mathrm{dec}}$ 和 $\\theta_{0}$ 为网络参数, $\\boldsymbol{e}_{y}$ 为 $y$ 的词向量, $y_{0}$ 为一个特殊符号, 比如 $\\langle E O S\\rangle$.\n\n基于循环神经网络的序列到序列模型的缺点是: 1 ) 编码向量 $\\boldsymbol{u}$ 的容量问题,输入序列的信息很难全部保存在一个固定维度的向量中; 2 ) 当序列很长时, 由于循环神经网络的长程依赖问题, 容易丢失输入序列的信息.\n\n长程依赖问题参见第6.5节。"
    },
    {
        "id": "chatcmpl-946mLW6O1Atku49C2ZZwtfS3QOzCI",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "logprobs": null,
                "message": {
                    "content": "{\n    \"问题1\": \"什么是编码器-解码器模型中的编码器？\",\n    \"回答1\": \"编码器是使用循环神经网络 $f_{\\text{enc}}$ 对输入序列进行编码，得到一个固定维度的向量 $\\boldsymbol{u}$。这个向量通常是编码循环神经网络最后时刻的隐状态。\",\n    \"问题2\": \"解码器在生成目标序列时的作用是什么？\",\n    \"回答2\": \"解码器使用另一个循环神经网络 $f_{\\text{dec}}$ 来进行解码。在解码过程中，它根据已生成的前缀序列和编码器得到的向量 $\\boldsymbol{u}$，生成目标序列的后验概率 $\\boldsymbol{o}_{t}$。\",\n    \"问题3\": \"在基于循环神经网络的序列到序列模型中，编码器和解码器分别使用了哪种类型的循环神经网络？\",\n    \"回答3\": \"在基于循环神经网络的序列到序列模型中，编码器使用了循环神经网络 $f_{\\text{enc}}$，可以是 LSTM 或 GRU；而解码器使用了另一个循环神经网络 $f_{\\text{dec}}$ 进行解码。\",\n    \"问题4\": \"基于循环神经网络的序列到序列模型中，如何计算解码过程中的隐状态 $\\boldsymbol{h}_{t}^{\\text{dec}}$？\",\n    \"回答4\": \"在解码过程中，隐状态 $\\boldsymbol{h}_{t}^{\\text{dec}}$ 的计算公式为 $\\boldsymbol{h}_{t}^{\\text{dec}}=f_{\\text{dec}}\\big(\\boldsymbol{h}_{t-1}^{\\text{dec}}, \\boldsymbol{e}_{y_{t-1}}, \\theta_{\\text{dec}}\\big)$，其中 $f_{\\text{dec}}(\\bullet)$ 为解码循环神经网络的计算函数。\",\n    \"问题5\": \"基于循环神经网络的序列到序列模型中，为什么会出现编码向量 $\\boldsymbol{u}$ 的容量问题？\",\n    \"回答5\": \"基于循环神经网络的序列到序列模型中，编码向量 $\\boldsymbol{u}$ 的容量问题主要是因为输入序列的信息很难全部保存在一个固定维度的向量中。这可能导致部分信息丢失或无法充分表达输入序列的特征。\",\n    \"问题6\": \"基于循环神经网络的序列到序列模型中，长程依赖问题会导致什么情况？\",\n    \"回答6\": \"基于循环神经网络的序列到序列模型中，长程依赖问题会导致当输入序列很长时，由于循环神经网络的长程依赖问题，容易丢失输入序列的信息。这可能影响模型对长序列的建模能力和预测准确性。\",\n    \"问题7\": \"在基于循环神经网络的序列到序列模型中，如何计算目标词表中所有词的后验概率 $\\boldsymbol{o}_{t}$？\",\n    \"回答7\": \"在基于循环神经网络的序列到序列模型中，目标词表中所有词的后验概率 $\\boldsymbol{o}_{t}$ 的计算公式为 $\\boldsymbol{o}_{t}=g\\big(\\boldsymbol{h}_{t}^{\\text{dec}}, \\theta_{o}\\big)$，其中 $g(\\bullet)$ 为最后一层为 Softmax 函数的前馈神经网络。\",\n    \"问题8\": \"在基于循环神经网络的序列到序列模型中，如何表示已生成前缀序列为 $\\boldsymbol{y}_{1:(t-1)}$？\",\n    \"回答8\": \"在基于循环神经网络的序列到序列模型中，在解码过程第 $t$ 步时，已生成前缀序列为 $\\boldsymbol{y}_{1:(t-1)}$。这表示已生成了目标语言中从第 1 个词到第 $t-1$ 个词的部分序列。\",\n    \"问题9\": \"在基于循环神经网络的序列到序列模型中，如何初始化解码过程中的隐状态 $\\boldsymbol{h}_{0}^{\\text{dec}}$？\",\n    \"回答9\": \"在基于循环神经网络的序列到序列模型中，解码过程中隐状态 $\\boldsymbol{h}_{0}^{\\text{dec}}$ 的初始化为编码向量 $\\boldsymbol{u}$。这意味着初始时解码器隐状态直接使用了编码器得到的固定维度向量。\",\n    \"问题10\": \"基于循环神经网络的序列到序列模型相比其他方法有什么优势和劣势？\",\n    \"回答10\": \"基于循环神经网络的序列到序列模型优势在于能够处理变长输入和输出序列，并且能够捕捉上下文信息。然而，它也存在编码向量容量不足和长程依赖问题等缺点。\"\n}",
                    "role": "assistant",
                    "function_call": null,
                    "tool_calls": null
                }
            }
        ],
        "created": 1710766397,
        "model": "gpt-3.5-turbo-1106",
        "object": "chat.completion",
        "system_fingerprint": "fp_4aaaf0dc94",
        "usage": {
            "completion_tokens": 1441,
            "prompt_tokens": 3499,
            "total_tokens": 4940
        },
        "parameters": {
            "model": "gpt-3.5-turbo-1106",
            "temperature": 0.2,
            "frequency_penalty": 0.15,
            "presence_penalty": 0.15
        }
    }
]