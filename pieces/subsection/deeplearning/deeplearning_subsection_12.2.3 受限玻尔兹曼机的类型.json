[
    {
        "strategy": "subsection",
        "source": "deeplearning",
        "title": "12.2.3 受限玻尔兹曼机的类型",
        "content_length": 2862,
        "content": "Title: 12.2.3 受限玻尔兹曼机的类型\nContent:\n在具体的不同任务中, 需要处理的数据类型不一定都是二值的, 也可能是连续值. 为了能够处理这些数据, 就需要根据输入或输出的数据类型来设计新的能 \\href{https://nndl.github.io/}{https://nndl.github.io/}\n\n\\section*{量函数.}\n一般来说, 常见的受限玻尔兹曼机有以下三种:\n\n（1）“伯努利-伯努利” 受限玻尔兹曼机（Bernoulli-Bernoulli RBM, BB$\\mathrm{RBM})$ : 上面介绍的可观测变量和隐变量都为二值类型的受限玻尔兹曼机.\n\n（2 ）“高斯-伯努利”受限玻尔兹曼机 (Gaussian-Bernoulli RBM, GB-RBM ):可观测变量为高斯分布, 隐变量为伯努利分布, 其能量函数定义为\n\n\n\\begin{equation*}\nE(\\boldsymbol{v}, \\boldsymbol{h})=\\sum_{i} \\frac{\\left(v_{i}-\\mu_{i}\\right)^{2}}{2 \\sigma_{i}^{2}}-\\sum_{j} b_{j} h_{j}-\\sum_{i} \\sum_{j} \\frac{v_{i}}{\\sigma_{i}} w_{i j} h_{j} \\tag{12.57}\n\\end{equation*}\n\n\n其中每个可观测变量 $v_{i}$ 服从 $\\left(\\mu_{i}, \\sigma_{i}\\right)$ 的高斯分布.\n\n（3）“伯努利-高斯”受限玻尔兹曼机 ( Bernoulli-Gaussian RBM, BG-RBM ):可观测变量为伯努利分布, 隐变量为高斯分布, 其能量函数定义为\n\n\n\\begin{equation*}\nE(\\boldsymbol{v}, \\boldsymbol{h})=-\\sum_{i} a_{i} v_{i}+\\sum_{j} \\frac{\\left(h_{j}-\\mu_{j}\\right)^{2}}{2 \\sigma_{j}^{2}}-\\sum_{i} \\sum_{j} v_{i} w_{i j} \\frac{h_{j}}{\\sigma_{j}} \\tag{12.58}\n\\end{equation*}\n\n\n其中每个隐变量 $h_{j}$ 服从 $\\left(\\mu_{j}, \\sigma_{j}\\right)$ 的高斯分布.\n\n\\section*{12.3 深度信念网络}\n深度信念网络 (Deep Belief Network, DBN ) 是一种深层的概率有向图模型, 其图结构由多层的节点构成. 每层节点的内部没有连接, 相邻两层的节点之间为全连接. 网络的最底层为可观测变量, 其他层节点都为隐变量. 最顶部的两\n\n和全连接的前馈神经网络结构相同.层间的连接是无向的, 其他层之间的连接是有向的. 图12.5给出了一个深度信念网络的示例.\n\n\n\n图 12.5 一个有 4 层结构的深度信念网络\n\n对一个有 $L$ 层隐变量的深度信念网络, 令 $\\boldsymbol{v}=\\boldsymbol{h}^{(0)}$ 表示最底层 (第 0 层) 为可观测变量, $\\boldsymbol{h}^{(1)}, \\cdots, \\boldsymbol{h}^{(L)}$ 表示其余每层的变量. 顶部的两层是一个无向图,可以 \\href{https://nndl.github.io/}{https://nndl.github.io/}\\\\\n看作一个受限玻尔兹曼机, 用来产生 $p\\left(\\boldsymbol{h}^{(L-1)}\\right)$ 的先验分布. 除了最顶上两层外,每一层变量 $\\boldsymbol{h}^{(l)}$ 依赖于其上面一层 $\\boldsymbol{h}^{(l+1)}$, 即\n\n\n\\begin{equation*}\np\\left(\\boldsymbol{h}^{(l)} \\mid \\boldsymbol{h}^{(l+1)}, \\cdots, \\boldsymbol{h}^{(L)}\\right)=p\\left(\\boldsymbol{h}^{(l)} \\mid \\boldsymbol{h}^{(l+1)}\\right), \\tag{12.59}\n\\end{equation*}\n\n\n其中 $l=\\{0, \\cdots, L-2\\}$.\n\n深度信念网络中所有变量的联合概率可以分解为\n\n\n\\begin{align*}\np\\left(\\boldsymbol{v}, \\boldsymbol{h}^{(1)}, \\cdots, \\boldsymbol{h}^{(L)}\\right) & =p\\left(\\boldsymbol{v} \\mid \\boldsymbol{h}^{(1)}\\right)\\left(\\prod_{l=1}^{L-2} p\\left(\\boldsymbol{h}^{(l)} \\mid \\boldsymbol{h}^{(l+1)}\\right)\\right) p\\left(\\boldsymbol{h}^{(L-1)}, \\boldsymbol{h}^{(L)}\\right)  \\tag{12.60}\\\\\n& =\\left(\\prod_{l=0}^{L-1} p\\left(\\boldsymbol{h}^{(l)} \\mid \\boldsymbol{h}^{(l+1)}\\right)\\right) p\\left(\\boldsymbol{h}^{(L-1)}, \\boldsymbol{h}^{(L)}\\right) \\tag{12.61}\n\\end{align*}\n\n\n其中 $p\\left(\\boldsymbol{h}^{(l)} \\mid \\boldsymbol{h}^{(l+1)}\\right)$ 为 Sigmoid 型条件概率分布, 定义为\n\n\n\\begin{equation*}\np\\left(\\boldsymbol{h}^{(l)} \\mid \\boldsymbol{h}^{(l+1)}\\right)=\\sigma\\left(\\boldsymbol{a}^{(l)}+\\boldsymbol{W}^{(l+1)} \\boldsymbol{h}^{(l+1)}\\right), \\tag{12.62}\n\\end{equation*}\n\n\n其中 $\\sigma(\\cdot)$ 为按位计算的 Logistic 函数, $\\boldsymbol{a}^{(l)}$ 为偏置参数, $\\boldsymbol{W}^{(l+1)}$ 为权重参数. 这样,每一个层都可以看作一个 Sigmoid 信念网络.\n\nSigmoid 信念网络参见第11.1.2.1节。"
    },
    {
        "id": "chatcmpl-945N0yTkxwpwy9B0E617khAZ7Fgwt",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "logprobs": null,
                "message": {
                    "content": "{\n    \"问题1\": \"受限玻尔兹曼机的类型有哪些？它们分别适用于什么类型的数据？\",\n    \"回答1\": \"常见的受限玻尔兹曼机包括“伯努利-伯努利”受限玻尔兹曼机（BBRBM）、“高斯-伯努利”受限玻尔兹曼机（GB-RBM）和“伯努利-高斯”受限玻尔兹曼机（BG-RBM）。它们分别适用于不同类型的数据，BBRBM适用于可观测变量和隐变量都为二值类型的数据，GB-RBM适用于可观测变量为高斯分布、隐变量为伯努利分布的数据，而BG-RBM适用于可观测变量为伯努利分布、隐变量为高斯分布的数据。\",\n    \"问题2\": \"“高斯-伯努利”受限玻尔兹曼机的能量函数是如何定义的？\",\n    \"回答2\": \"“高斯-伯努利”受限玻尔兹曼机的能量函数定义为 $E(\\boldsymbol{v}, \\boldsymbol{h})=\\text{...}$，其中每个可观测变量 $v_{i}$ 服从 $\\big(\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}\\big)$ 的高斯分布。\",\n    \"问题3\": \"深度信念网络是什么结构？它由哪些节点构成？\",\n    \"回答3\": \"深度信念网络是一种深层的概率有向图模型，其图结构由多层的节点构成。每层节点的内部没有连接，相邻两层的节点之间为全连接。网络的最底层为可观测变量，其余每层节点都为隐变量。\",\n    \"问题4\": \"深度信念网络中顶部两层的连接是什么类型的？\",\n    \"回答4\": \"深度信念网络中顶部两层的连接是无向的，可以看作一个受限玻尔兹曼机，用来产生 $p\\big(\\boldsymbol{h}^{(L-1)}\\big)$ 的先验分布。\",\n    \"问题5\": \"深度信念网络中各层之间的连接是怎样的？\",\n    \"回答5\": \"除了最顶上两层外，每一层变量 $\\boldsymbol{h}^{(l)}$ 依赖于其上面一层 $\\boldsymbol{h}^{(l+1)}$，即 $p\\big(\\boldsymbol{h}^{(l)} \\big| \\boldsymbol{h}^{(l+1)}\\big)=p\\big(\\boldsymbol{h}^{(l)} \\big| \\boldsymbol{h}^{(l+1)}\\big)$。\",\n    \"问题6\": \"深度信念网络中所有变量的联合概率是如何分解的？\",\n    \"回答6\": \"深度信念网络中所有变量的联合概率可以分解为 $p\\big(\\boldsymbol{v}, \\boldsymbol{h}^{(1)}, \\text{...}, \\boldsymbol{h}^{(L)}\\big) = \\text{...}$。其中 $p\\big(\\boldsymbol{h}^{(l)} \\big| \\boldsymbol{h}^{(l+1)}\\big)$ 为 Sigmoid 型条件概率分布。\",\n    \"问题7\": \"Sigmoid 型条件概率分布在深度信念网络中起着什么作用？\",\n    \"回答7\": \"Sigmoid 型条件概率分布在深度信念网络中起着连接各层节点的作用，定义为 $p\\big(\\boldsymbol{h}^{(l)} \\big| \\boldsymbol{h}^{(l+1)}\\big)=\\text{...}$。这样，每一个层都可以看作一个 Sigmoid 信念网络。\",\n    \"问题8\": \"深度信念网络和全连接的前馈神经网络有何区别？\",\n    \"回答8\": \"深度信念网络和全连接的前馈神经网络结构不同。深度信念网络具有多层节点构成的概率有向图模型结构，而全连接的前馈神经网络结构是有向连接的。此外，深度信念网络中相邻两层节点之间为全连接，而全连接的前馈神经网络结构是全连接的前馈结构。\",\n    \"问题9\": \"深度信念网络和 Sigmoid 信念网络有何关联？\",\n    \"回答9\": \"每一个深度信念网络中的层都可以看作一个 Sigmoid 信念网络。Sigmoid 型条件概率分布在深度信念网络中起着连接各层节点的作用，使得整个深度信念网络具有更加复杂和灵活的信息处理和学习能力。\",\n    \"问题10\": \"受限玻尔兹曼机和深度信念网络在神经网络领域中有何应用？\",\n    \"回答10\": \"受限玻尔兹曼机和深度信念网络在神经网络领域中被广泛应用于表示学习、特征学习、生成模型等方面。它们能够有效地捕捉数据之间复杂的非线性关系，并在各种领域中取得了重要应用。\"\n}",
                    "role": "assistant",
                    "function_call": null,
                    "tool_calls": null
                }
            }
        ],
        "created": 1710760982,
        "model": "gpt-3.5-turbo-1106",
        "object": "chat.completion",
        "system_fingerprint": "fp_4aaaf0dc94",
        "usage": {
            "completion_tokens": 1633,
            "prompt_tokens": 4285,
            "total_tokens": 5918
        },
        "parameters": {
            "model": "gpt-3.5-turbo-1106",
            "temperature": 0.2,
            "frequency_penalty": 0.15,
            "presence_penalty": 0.15
        }
    }
]