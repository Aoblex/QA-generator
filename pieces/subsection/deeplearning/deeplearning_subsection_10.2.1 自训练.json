[
    {
        "strategy": "subsection",
        "source": "deeplearning",
        "title": "10.2.1 自训练",
        "content_length": 974,
        "content": "Title: 10.2.1 自训练\nContent:\n自训练（Self-Training，或 Self-Teaching），也叫自举法（Bootstrapping），是一种非常简单的半监督学习算法 [Scudder, 1965; Yarowsky, 1995].\n\n自训练是首先使用标注数据来训练一个模型, 并使用这个模型来预测无标注样本的标签, 把预测置信度比较高的样本及其预测的伪标签加入训练集, 然后重新训练新的模型, 并不断重复这个过程. 算法10.2 给出了自训练的训练过程.\n\n算法 10.2 自训练的训练过程\n\n输入: 标注数据集 $\\mathcal{L}=\\left\\{\\left(\\boldsymbol{x}^{(n)}, y^{(n)}\\right)\\right\\}_{n=1}^{N}$;\n\n无标注数据集 $\\mathcal{U}=\\left\\{\\boldsymbol{x}^{(m)}\\right\\}_{m=1}^{M}$ ；\n\n迭代次数 $T$;每次迭代增加样本数量 $P$;\n\n1 for $t=1 \\cdots T$ do\n\n2 根据训练集 $\\mathcal{L}$, 训练模型 $f$;\n\n3 使用模型 $f$ 对无标注数据集 $U$ 的样本进行预测, 选出预测置信度高的 $P$个样本 $\\mathcal{P}=\\left\\{\\left(\\boldsymbol{x}^{(p)}, f\\left(\\boldsymbol{x}^{(p)}\\right)\\right)\\right\\}_{p=1}^{P}$ ；\n\n4 更新训练集：\n\n$$\n\\mathcal{L} \\leftarrow \\mathcal{L} \\cup \\mathcal{P}, \\quad \\mathcal{U} \\leftarrow \\mathcal{U}-\\mathcal{P} .\n$$\n\n5 end\n\n输出: 模型 $f$\n\n自训练和密度估计中 EM 算法有一定的相似之处, 通过不断地迭代来提高 EM 算法参见第11.2.2.1节。模型能力. 但自训练的缺点是无法保证每次加入训练集的样本的伪标签是正确的. 如果选择样本的伪标签是错误的, 反而会损害模型的预测能力. 因此, 自训练参见习题10-3.最关键的步骤是如何设置挑选样本的标准."
    },
    {
        "id": "chatcmpl-92ykfCRMH3OAVpR2vBFvUn3EYwPBr",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "logprobs": null,
                "message": {
                    "content": "{\n    \"问题1\": \"什么是自训练（Self-Training）或自举法（Bootstrapping）？\",\n    \"回答1\": \"自训练（Self-Training）或自举法（Bootstrapping）是一种非常简单的半监督学习算法。它首先使用标注数据来训练一个模型，然后使用这个模型来预测无标注样本的标签，将预测置信度比较高的样本及其预测的伪标签加入训练集，然后重新训练新的模型，并不断重复这个过程。\",\n    \"问题2\": \"自训练的训练过程是怎样的？\",\n    \"回答2\": \"自训练的训练过程包括以下步骤：首先根据标注数据集训练模型，然后使用该模型对无标注数据集的样本进行预测，选出预测置信度高的一定数量的样本加入训练集，接着更新训练集并重新训练模型。这个过程会重复进行多次，直到达到设定的迭代次数。\",\n    \"问题3\": \"自训练算法中的关键步骤是什么？\",\n    \"回答3\": \"自训练算法中最关键的步骤是如何设置挑选样本的标准。由于自训练无法保证每次加入训练集的样本的伪标签是正确的，因此选择样本的伪标签是错误的话，反而会损害模型的预测能力。因此，挑选样本的标准对于自训练算法至关重要。\",\n    \"问题4\": \"自训练和密度估计中 EM 算法有何相似之处？\",\n    \"回答4\": \"自训练和密度估计中 EM 算法有一定的相似之处，都是通过不断地迭代来提高模型能力。EM 算法是一种迭代优化算法，用于含有隐变量的概率模型参数估计。而自训练也是通过迭代过程来逐步提升模型性能。\",\n    \"问题5\": \"自训练算法有哪些优点和缺点？\",\n    \"回答5\": \"自训练算法的优点在于简单易实现，并且能够利用无标注数据来提升模型性能。然而，其缺点在于无法保证每次加入训练集的样本的伪标签是正确的，如果选择样本的伪标签是错误的，反而会损害模型的预测能力。\",\n    \"问题6\": \"自训练算法如何利用无标注数据来提升模型性能？\",\n    \"回答6\": \"自训练算法利用无标注数据来提升模型性能的方式是通过预测置信度比较高的样本及其预测的伪标签加入训练集，并不断重复这个过程。这样可以逐步扩充训练集，提高模型对未标注数据的泛化能力。\",\n    \"问题7\": \"算法10.2给出了自训练的训练过程，它包括哪些关键步骤？\",\n    \"回答7\": \"算法10.2给出了自训练的训练过程，包括根据标注数据集训练模型、使用模型对无标注数据集的样本进行预测、选出预测置信度高的一定数量的样本加入训练集，并更新训练集。这些步骤会在每次迭代中重复执行。\",\n    \"问题8\": \"自训练算法如何处理无标注数据集中的样本？\",\n    \"回答8\": \"自训练算法会使用已经训练好的模型对无标注数据集中的样本进行预测，并选出预测置信度高的一定数量的样本加入到训练集中。这样可以逐步利用无标注数据来提升模型性能。\",\n    \"问题9\": \"如何确定哪些无标注数据样本应该加入到训练集中？\",\n    \"回答9\": \"确定哪些无标注数据样本应该加入到训练集中是自训练算法中一个关键问题。通常会选择预测置信度高的一定数量的样本加入到训练集中，但如何设置挑选样本的标准对于自训练算法至关重要。\",\n    \"问题10\": \"自训练算法与传统监督学习算法有何区别？\",\n    \"回答10\": \"自训练算法与传统监督学习算法最大的区别在于它利用了无标注数据来提升模型性能。传统监督学习算法仅使用标注数据进行模型训练，而自训练算法则通过不断迭代地利用无标注数据来扩充和优化模型。\"\n}",
                    "role": "assistant",
                    "function_call": null,
                    "tool_calls": null
                }
            }
        ],
        "created": 1710497213,
        "model": "gpt-3.5-turbo-1106",
        "object": "chat.completion",
        "system_fingerprint": "fp_4aaaf0dc94",
        "usage": {
            "completion_tokens": 1435,
            "prompt_tokens": 3185,
            "total_tokens": 4620
        },
        "parameters": {
            "model": "gpt-3.5-turbo-1106",
            "temperature": 0.2,
            "frequency_penalty": 0.1,
            "presence_penalty": 0.1
        }
    }
]