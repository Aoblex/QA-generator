[
    {
        "strategy": "subsection",
        "source": "deeplearning",
        "title": "10.2.1 自训练",
        "content_length": 974,
        "content": "Title: 10.2.1 自训练\nContent:\n自训练（Self-Training，或 Self-Teaching），也叫自举法（Bootstrapping），是一种非常简单的半监督学习算法 [Scudder, 1965; Yarowsky, 1995].\n\n自训练是首先使用标注数据来训练一个模型, 并使用这个模型来预测无标注样本的标签, 把预测置信度比较高的样本及其预测的伪标签加入训练集, 然后重新训练新的模型, 并不断重复这个过程. 算法10.2 给出了自训练的训练过程.\n\n算法 10.2 自训练的训练过程\n\n输入: 标注数据集 $\\mathcal{L}=\\left\\{\\left(\\boldsymbol{x}^{(n)}, y^{(n)}\\right)\\right\\}_{n=1}^{N}$;\n\n无标注数据集 $\\mathcal{U}=\\left\\{\\boldsymbol{x}^{(m)}\\right\\}_{m=1}^{M}$ ；\n\n迭代次数 $T$;每次迭代增加样本数量 $P$;\n\n1 for $t=1 \\cdots T$ do\n\n2 根据训练集 $\\mathcal{L}$, 训练模型 $f$;\n\n3 使用模型 $f$ 对无标注数据集 $U$ 的样本进行预测, 选出预测置信度高的 $P$个样本 $\\mathcal{P}=\\left\\{\\left(\\boldsymbol{x}^{(p)}, f\\left(\\boldsymbol{x}^{(p)}\\right)\\right)\\right\\}_{p=1}^{P}$ ；\n\n4 更新训练集：\n\n$$\n\\mathcal{L} \\leftarrow \\mathcal{L} \\cup \\mathcal{P}, \\quad \\mathcal{U} \\leftarrow \\mathcal{U}-\\mathcal{P} .\n$$\n\n5 end\n\n输出: 模型 $f$\n\n自训练和密度估计中 EM 算法有一定的相似之处, 通过不断地迭代来提高 EM 算法参见第11.2.2.1节。模型能力. 但自训练的缺点是无法保证每次加入训练集的样本的伪标签是正确的. 如果选择样本的伪标签是错误的, 反而会损害模型的预测能力. 因此, 自训练参见习题10-3.最关键的步骤是如何设置挑选样本的标准."
    },
    {
        "id": "chatcmpl-944rrPZthzplDB0ZVvoz2z3uDlTBB",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "logprobs": null,
                "message": {
                    "content": "{\n    \"问题1\": \"自训练算法是什么？\",\n    \"回答1\": \"自训练是一种半监督学习算法，首先使用标注数据来训练一个模型，然后使用这个模型来预测无标注样本的标签，将预测置信度高的样本及其预测的伪标签加入训练集，并不断重复这个过程。\",\n    \"问题2\": \"自训练算法的训练过程是怎样的？\",\n    \"回答2\": \"自训练算法的训练过程包括以下步骤：首先根据标注数据集训练模型；然后使用训练好的模型对无标注数据集的样本进行预测，选出预测置信度高的样本加入训练集；最后更新训练集，并不断重复这个过程。\",\n    \"问题3\": \"自训练算法中的迭代次数和每次迭代增加样本数量分别指什么？\",\n    \"回答3\": \"在自训练算法中，迭代次数表示进行整个自训练过程的次数，而每次迭代增加样本数量表示每次迭代中加入训练集的样本数量。\",\n    \"问题4\": \"自训练算法和EM算法有何相似之处？\",\n    \"回答4\": \"自训练算法和密度估计中的EM算法有一定的相似之处，都通过不断地迭代来提高模型能力。它们都涉及在每次迭代中更新模型或参数，以逐步提升模型性能。\",\n    \"问题5\": \"自训练算法的缺点是什么？\",\n    \"回答5\": \"自训练算法的缺点是无法保证每次加入训练集的样本的伪标签是正确的。如果选择样本的伪标签是错误的，反而会损害模型的预测能力。\",\n    \"问题6\": \"自训练算法中最关键的步骤是什么？\",\n    \"回答6\": \"自训练算法中最关键的步骤是如何设置挑选样本的标准。即在每次迭代中，如何确定哪些无标注样本可以被加入到训练集中，以保证伪标签的准确性和有效性。\",\n    \"问题7\": \"自训练算法如何处理无标注数据集中的样本？\",\n    \"回答7\": \"自训练算法使用已经训练好的模型对无标注数据集中的样本进行预测，并选出预测置信度高的样本及其预测的伪标签加入到训练集中。\",\n    \"问题8\": \"自训练算法如何更新训练集？\",\n    \"回答8\": \"在自训练算法中，更新训练集包括将预测置信度高的样本及其预测的伪标签加入到原有标注数据集中，并从无标注数据集中移除这些样本。\",\n    \"问题9\": \"自训练算法如何保证模型性能？\",\n    \"回答9\": \"自训练算法无法保证每次加入训练集的样本的伪标签是正确的。因此，为了保证模型性能，关键在于合理设置挑选样本的标准，以确保加入到训练集中的无标注样本具有准确有效的伪标签。\",\n    \"问题10\": \"自训练算法和传统监督学习有何区别？\",\n    \"回答10\": \"自训练算法与传统监督学习相比，主要区别在于利用了无标注数据来辅助模型训练。传统监督学习仅使用标注数据进行模型训练，而自训练算法通过利用无标注数据来扩充和改进模型。\"\n}",
                    "role": "assistant",
                    "function_call": null,
                    "tool_calls": null
                }
            }
        ],
        "created": 1710759051,
        "model": "gpt-3.5-turbo-1106",
        "object": "chat.completion",
        "system_fingerprint": "fp_4aaaf0dc94",
        "usage": {
            "completion_tokens": 1134,
            "prompt_tokens": 3247,
            "total_tokens": 4381
        },
        "parameters": {
            "model": "gpt-3.5-turbo-1106",
            "temperature": 0.2,
            "frequency_penalty": 0.15,
            "presence_penalty": 0.15
        }
    }
]