[
    {
        "strategy": "subsection",
        "source": "deeplearning",
        "title": "13.2.5 再参数化",
        "content_length": 1677,
        "content": "Title: 13.2.5 再参数化\nContent:\n再参数化 (Reparameterization) 是将一个函数 $f(\\theta)$ 的参数 $\\theta$ 用另外一组参数表示 $\\theta=g(\\vartheta)$, 这样函数 $f(\\theta)$ 就转换成参数为 $\\vartheta$ 的函数 $\\hat{f}(\\vartheta)=f(g(\\vartheta))$. 再参数化通常用来将原始参数转换为另外一组具有特殊属性的参数. 比如当 $\\theta$ 为一个很大的矩阵时, 可以使用两个低秩矩阵的乘积来再参数化, 从而减少参数量.\n\n在公式(13.21)中, 期望 $\\mathbb{E}_{\\boldsymbol{z} \\sim q(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\phi)}[\\log p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta)]$ 依赖于分布 $q$ 的参数 $\\boldsymbol{\\phi}$. 但是, 由于随机变量 $\\boldsymbol{z}$ 采样自后验分布 $q(z \\mid x ; \\phi)$, 它们之间不是确定性关系, 因此无法直接求解 $\\boldsymbol{z}$ 关于参数 $\\phi$ 的导数. 这时, 我们可以通过再参数化方法来将 $\\boldsymbol{z}$ 和 $\\phi$之间随机性的采样关系转变为确定性函数关系.\n\n我们引入一个分布为 $p(\\epsilon)$ 的随机变量 $\\epsilon$, 期望 $\\mathbb{E}_{\\boldsymbol{z} \\sim q(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\phi)}[\\log p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta)]$ 可以重写为\n\n\n\\begin{equation*}\n\\mathbb{E}_{\\boldsymbol{z} \\sim q(z \\mid \\boldsymbol{x} ; \\phi)}[\\log p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta)]=\\mathbb{E}_{\\epsilon \\sim p(\\epsilon)}[\\log p(\\boldsymbol{x} \\mid g(\\phi, \\epsilon) ; \\theta)] \\tag{13.25}\n\\end{equation*}\n\n\n其中 $\\boldsymbol{z} \\triangleq g(\\phi, \\epsilon)$ 为一个确定性函数.\n\n假设 $q(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\phi)$ 为正态分布 $N\\left(\\mu_{I}, \\sigma_{I}^{2} \\boldsymbol{I}\\right)$, 其中 $\\left\\{\\mu_{I}, \\sigma_{I}\\right\\}$ 是推断网络 $f_{I}(\\boldsymbol{x} ; \\phi)$ 的输出, 依赖于参数 $\\phi$, 我们可以通过下面方式来再参数化:\n\n\n\\begin{equation*}\nz=\\mu_{I}+\\sigma_{I} \\odot \\epsilon \\tag{13.26}\n\\end{equation*}\n\n\n其中 $\\epsilon \\sim \\mathcal{N}(0, I)$. 这样 $\\boldsymbol{z}$ 和参数 $\\phi$ 的关系从采样关系变为确定性关系, 使得 $\\boldsymbol{z} \\sim q(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\phi)$ 的随机性独立于参数 $\\phi$, 从而可以求 $\\boldsymbol{z}$ 关于 $\\phi$ 的导数."
    },
    {
        "id": "chatcmpl-945WcpH9saVcyve6ilUFjODcMHF4M",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "logprobs": null,
                "message": {
                    "content": "{\n    \"问题1\": \"再参数化的定义是什么？\",\n    \"回答1\": \"再参数化是将一个函数 $f(\\theta)$ 的参数 $\\theta$ 用另外一组参数表示 $\\theta=g(\\bar{\\theta})$，这样函数 $f(\\theta)$ 就转换成参数为 $\\bar{\\theta}$ 的函数 $\\bar{f}(\\bar{\\theta})=f(g(\\bar{\\theta}))$。再参数化通常用来将原始参数转换为另外一组具有特殊属性的参数。\",\n    \"问题2\": \"再参数化方法的作用是什么？\",\n    \"回答2\": \"再参数化方法的作用是将随机性的采样关系转变为确定性函数关系。通过引入一个分布为 $p(\\bar{\\theta})$ 的随机变量 $\\bar{\\theta}$，可以将依赖于分布 $q$ 的参数 $\\boldsymbol{\\theta}$ 的期望重写为确定性函数关系，从而使得随机性独立于参数，便于求解导数。\",\n    \"问题3\": \"在公式(13.25)中，$\\boldsymbol{z} \\triangleq g(\\boldsymbol{\\theta}, \\bar{\\theta})$ 的含义是什么？\",\n    \"回答3\": \"在公式(13.25)中，$\\boldsymbol{z} \\triangleq g(\\boldsymbol{\\theta}, \\bar{\\theta})$ 表示通过再参数化方法得到的确定性函数关系，其中 $\\boldsymbol{z}$ 是由原始参数 $\\boldsymbol{\\theta}$ 和随机变量 $\\bar{\\theta}$ 决定的确定性函数。\",\n    \"问题4\": \"再参数化方法如何将随机变量 $\\boldsymbol{z}$ 和参数 $\\boldsymbol{\\theta}$ 的随机性关系转变为确定性关系？\",\n    \"回答4\": \"再参数化方法通过引入一个分布为 $p(\\bar{\\theta})$ 的随机变量 $\\bar{\\theta}$，使得期望依赖于分布 $q$ 的参数 $\\boldsymbol{\\theta}$ 可以重写为确定性函数关系。这样，随机性独立于参数，便于求解导数。\",\n    \"问题5\": \"如何通过再参数化方法来表示正态分布 $N\\big(\\boldsymbol{\\bar{\\theta}}, \\boldsymbol{\\bar{\\theta}}^{2} \\boldsymbol{I}\\big)$？\",\n    \"回答5\": \"通过再参数化方法，可以表示正态分布 $N\\big(\\boldsymbol{\\bar{\\theta}}, \\boldsymbol{\\bar{\\theta}}^{2} \\boldsymbol{I}\\big)$为 $\\boldsymbol{z}=\\boldsymbol{\\bar{\\theta}}+\\boldsymbol{\\bar{\\theta}} \\bigodot \\bar{\\bar{\\theta}}$，其中 $\\bar{\\bar{\\theta}} \\text{ 采样自 } \\text{标准正态分布 } \\text{N}(0, I)$。\",\n    \"问题6\": \"再参数化方法对于处理大矩阵等情况有什么优势？\",\n    \"回答6\": \"当原始参数 $\\boldsymbol{\\theta}$ 为一个很大的矩阵时，可以使用两个低秩矩阵的乘积来再参数化，从而减少参数量。这种优势使得再参数化方法在处理大矩阵等情况时能够更加高效和有效。\",\n    \"问题7\": \"再参数化方法如何帮助求解随机变量 $\\boldsymbol{z}$ 关于参数 $\\boldsymbol{\\theta}$ 的导数？\",\n    \"回答7\": \"通过再参数化方法，将随机性的采样关系转变为确定性函数关系后，使得随机性独立于参数。这样就可以更容易地求解随机变量 $\\boldsymbol{z}$ 关于参数 $\\boldsymbol{\\theta}$ 的导数。\",\n    \"问题8\": \"在公式(13.26)中，$\\boldsymbol{z}=\\boldsymbol{\\bar{\\theta}}+\\boldsymbol{\\bar{\\theta}} \\bigodot \\bar{\\bar{\\theta}}$ 中的符号 $\\bigodot$ 代表什么意义？\",\n    \"回答8\": \"在公式(13.26)中，符号 $\\bigodot$ 表示逐元素相乘操作。即对应位置上的元素相乘，得到一个相同维度的新向量。\",\n    \"问题9\": \"再参数化方法如何影响随机变量和参数之间的关系？\",\n    \"回答9\": \"再参数化方法使得随机变量和参数之间的关系从采样关系变为确定性关系，从而使得随机性独立于参数。这种影响使得求解随机变量关于参数的导数更加方便和有效。\",\n    \"问题10\": \"再参数化方法如何帮助优化神经网络模型中的推断过程？\",\n    \"回答10\": \"再参数化方法通过将原始参数转换为另外一组具有特殊属性的参数，能够更好地优化神经网络模型中的推断过程。它将随机性的采样关系转变为确定性函数关系，使得推断过程更加高效和有效。\"\n}",
                    "role": "assistant",
                    "function_call": null,
                    "tool_calls": null
                }
            }
        ],
        "created": 1710761578,
        "model": "gpt-3.5-turbo-1106",
        "object": "chat.completion",
        "system_fingerprint": "fp_4aaaf0dc94",
        "usage": {
            "completion_tokens": 1352,
            "prompt_tokens": 3414,
            "total_tokens": 4766
        },
        "parameters": {
            "model": "gpt-3.5-turbo-1106",
            "temperature": 0.2,
            "frequency_penalty": 0.15,
            "presence_penalty": 0.15
        }
    }
]