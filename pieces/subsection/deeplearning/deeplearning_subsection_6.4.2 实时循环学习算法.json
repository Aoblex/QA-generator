[
    {
        "strategy": "subsection",
        "source": "deeplearning",
        "title": "6.4.2 实时循环学习算法",
        "content_length": 3745,
        "content": "Title: 6.4.2 实时循环学习算法\nContent:\n与反向传播的 BPTT 算法不同的是, 实时循环学习 ( Real-Time Recurrent Learning,RTRL ) 是通过前向传播的方式来计算梯度 [Williams et al., 1995].\n\n假设循环神经网络中第 $t+1$ 时刻的状态 $\\boldsymbol{h}_{t+1}$ 为\n\n梯度前向传播可以参考自动微分中的前向模式,参见第4.5.3节。\n\n\n\\begin{equation*}\n\\boldsymbol{h}_{t+1}=f\\left(\\boldsymbol{z}_{t+1}\\right)=f\\left(\\boldsymbol{U} \\boldsymbol{h}_{t}+\\boldsymbol{W} \\boldsymbol{x}_{t+1}+\\boldsymbol{b}\\right) \\tag{6.42}\n\\end{equation*}\n\n\n其关于参数 $u_{i j}$ 的偏导数为\n\n\n\\begin{align*}\n\\frac{\\partial \\boldsymbol{h}_{t+1}}{\\partial u_{i j}} & =\\left(\\frac{\\partial^{+} \\boldsymbol{z}_{t+1}}{\\partial u_{i j}}+\\frac{\\partial \\boldsymbol{h}_{t}}{\\partial u_{i j}} \\boldsymbol{U}^{\\top}\\right) \\frac{\\partial \\boldsymbol{h}_{t+1}}{\\partial \\boldsymbol{z}_{t+1}}  \\tag{6.43}\\\\\n& =\\left(\\square_{i}\\left(\\left[\\boldsymbol{h}_{t}\\right]_{j}\\right)+\\frac{\\partial \\boldsymbol{h}_{t}}{\\partial u_{i j}} \\boldsymbol{U}^{\\top}\\right) \\operatorname{diag}\\left(f^{\\prime}\\left(\\boldsymbol{z}_{t+1}\\right)\\right) \\tag{6.44}\n\\end{align*}\n\n\n\\href{https://nndl.github.io/}{https://nndl.github.io/}\n\n\n\\begin{equation*}\n=\\left(\\mathbb{\\square}_{i}\\left(\\left[\\boldsymbol{h}_{t}\\right]_{j}\\right)+\\frac{\\partial \\boldsymbol{h}_{t}}{\\partial u_{i j}} \\boldsymbol{U}^{\\top}\\right) \\odot\\left(f^{\\prime}\\left(\\boldsymbol{z}_{t+1}\\right)\\right)^{\\top} \\tag{6.45}\n\\end{equation*}\n\n\n其中 $\\mathbb{q}_{i}(x)$ 是除了第 $i$ 行值为 $x$ 外,其余都为 0 的行向量.\n\nRTRL 算法从第 1 个时刻开始, 除了计算循环神经网络的隐状态之外, 还利用公式 (6.45) 依次前向计算偏导数 $\\frac{\\partial \\boldsymbol{h}_{1}}{\\partial u_{i j}}, \\frac{\\partial \\boldsymbol{h}_{2}}{\\partial u_{i j}}, \\frac{\\partial \\boldsymbol{h}_{3}}{\\partial u_{i j}}, \\cdots$.\n\n这样, 假设第 $t$ 个时刻存在一个监督信息, 其损失函数为 $\\mathcal{L}_{t}$, 就可以同时计算损失函数对 $u_{i j}$ 的偏导数\n\n\n\\begin{equation*}\n\\frac{\\partial \\mathcal{L}_{t}}{\\partial u_{i j}}=\\frac{\\partial \\boldsymbol{h}_{t}}{\\partial u_{i j}} \\frac{\\partial \\mathcal{L}_{t}}{\\partial \\boldsymbol{h}_{t}} \\tag{6.46}\n\\end{equation*}\n\n\n这样在第 $t$ 时刻, 可以实时地计算损失 $\\mathcal{L}_{t}$ 关于参数 $\\boldsymbol{U}$ 的梯度, 并更新参数. 参数 $\\boldsymbol{W}$ 和 $\\boldsymbol{b}$ 的梯度也可以同样按上述方法实时计算.\n\n两种算法比较 RTRL 算法和 BPTT 算法都是基于梯度下降的算法, 分别通过前向模式和反向模式应用链式法则来计算梯度. 在循环神经网络中, 一般网络输出维度远低于输入维度, 因此 BPTT 算法的计算量会更小, 但是 BPTT 算法需要保存所有时刻的中间梯度, 空间复杂度较高. RTRL 算法不需要梯度回传, 因此非常适合用于需要在线学习或无限序列的任务中.\n\n\\section*{6.5 长程依赖问题}\n循环神经网络在学习过程中的主要问题是由于梯度消失或爆炸问题, 很难建模长时间间隔 ( Long Range ) 的状态之间的依赖关系.\n\n在 BPTT 算法中, 将公式 (6.36) 展开得到\n\n\n\\begin{equation*}\n\\delta_{t, k}=\\prod_{\\tau=k}^{t-1}\\left(\\operatorname{diag}\\left(f^{\\prime}\\left(\\boldsymbol{z}_{\\tau}\\right)\\right) \\boldsymbol{U}^{\\top}\\right) \\delta_{t, t} \\tag{6.47}\n\\end{equation*}\n\n\n如果定义 $\\gamma \\cong\\left\\|\\operatorname{diag}\\left(f^{\\prime}\\left(\\boldsymbol{z}_{\\tau}\\right)\\right) \\boldsymbol{U}^{\\top}\\right\\|$,则\n\n\n\\begin{equation*}\n\\delta_{t, k} \\cong \\gamma^{t-k} \\delta_{t, t} \\tag{6.48}\n\\end{equation*}\n\n\n若 $\\gamma>1$, 当 $t-k \\rightarrow \\infty$ 时, $\\gamma^{t-k} \\rightarrow \\infty$. 当间隔 $t-k$ 比较大时, 梯度也变得很大,会造成系统不稳定,称为梯度爆炸问题 (Gradient Exploding Problem ).\n\n相反, 若 $\\gamma<1$, 当 $t-k \\rightarrow \\infty$ 时, $\\gamma^{t-k} \\rightarrow 0$. 当间隔 $t-k$ 比较大时, 梯度也变得非常小, 会出现和深层前馈神经网络类似的梯度消失问题 (Vanishing Gradient Problem ).\\\\\n要注意的是, 在循环神经网络中的梯度消失不是说 $\\frac{\\partial \\mathcal{L}_{t}}{\\partial U}$ 的梯度消失了, 而是 $\\frac{\\partial \\mathcal{L}_{t}}{\\partial \\boldsymbol{h}_{k}}$ 的梯度消失了 (当间隔 $t-k$ 比较大时).也就是说, 参数 $\\boldsymbol{U}$ 的更新主要靠当前时刻 $t$ 的几个相邻状态 $\\boldsymbol{h}_{k}$ 来更新, 长距离的状态对参数 $\\boldsymbol{U}$ 没有影响.\n\n由于循环神经网络经常使用非线性激活函数为 Logistic 函数或 Tanh函数作为非线性激活函数, 其导数值都小于 1 , 并且权重矩阵 $\\|\\boldsymbol{U}\\|$ 也不会太大, 因此如果时间间隔 $t-k$ 过大, $\\delta_{t, k}$ 会趋向于 0 , 因而经常会出现梯度消失问题.\n\n虽然简单循环网络理论上可以建立长时间间隔的状态之间的依赖关系, 但是由于梯度爆炸或消失问题, 实际上只能学习到短期的依赖关系. 这样, 如果时刻 $t$ 的输出 $y_{t}$ 依赖于时刻 $k$ 的输入 $\\boldsymbol{x}_{k}$, 当间隔 $t-k$ 比较大时, 简单神经网络很难建模这种长距离的依赖关系, 称为长程依赖问题 (Long-Term Dependencies Problem )."
    },
    {
        "id": "chatcmpl-9422gSRD4gmyT1x2M8sEx0jRjfwW8",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "logprobs": null,
                "message": {
                    "content": "{\n    \"问题1\": \"实时循环学习算法 RTRL 与 BPTT 算法的计算方式有何不同？\",\n    \"回答1\": \"实时循环学习算法 RTRL 是通过前向传播的方式来计算梯度，而 BPTT 算法是通过反向传播的方式来计算梯度。这意味着它们在计算梯度时采用了不同的传播方式。\",\n    \"问题2\": \"在循环神经网络中，如何计算第 $t+1$ 时刻的状态 $\\boldsymbol{h}_{t+1}$？\",\n    \"回答2\": \"在循环神经网络中，第 $t+1$ 时刻的状态 $\\boldsymbol{h}_{t+1}$ 可以通过函数 $f$ 计算得到，具体表达式为 $\\boldsymbol{h}_{t+1}=f\\big(\\boldsymbol{z}_{t+1}\\big)=f\\big(\\boldsymbol{U} \\boldsymbol{h}_{t}+\\boldsymbol{W} \\boldsymbol{x}_{t+1}+\\boldsymbol{b}\\big)$。\",\n    \"问题3\": \"如何计算关于参数 $u_{i j}$ 的偏导数 $\\frac{\\boldsymbol{h}_{t+1}}{\\boldsymbol{u}_{i j}}$？\",\n    \"回答3\": \"关于参数 $u_{i j}$ 的偏导数 $\\frac{\\boldsymbol{h}_{t+1}}{\\boldsymbol{u}_{i j}}$ 可以通过公式 $\\frac{\\boldsymbol{h}_{t+1}}{\\boldsymbol{u}_{i j}}=\\big(\\frac{\\boldsymbol{z}_{t+1}}{\\boldsymbol{u}_{i j}}+\\frac{\\boldsymbol{h}_{t}}{\\boldsymbol{u}_{i j}} \\boldsymbol{U}^{\\top}\\big) \\frac{\\boldsymbol{h}_{t+1}}{\\boldsymbol{z}_{t+1}}$ 来计算。\",\n    \"问题4\": \"RTRL 算法是如何计算损失函数对参数 $\\boldsymbol{U}$ 的梯度的？\",\n    \"回答4\": \"RTRL 算法从第 1 个时刻开始，利用公式 (6.45) 依次前向计算偏导数 $\\frac{\\boldsymbol{h}_{1}}{\\boldsymbol{u}_{i j}}, \\frac{\\boldsymbol{h}_{2}}{\\boldsymbol{u}_{i j}}, \\frac{\\boldsymbol{h}_{3}}{\\boldsymbol{u}_{i j}}, \\text{...}$。这样，在第 $t$ 时刻，可以实时地计算损失 $\\text{L}_t$ 关于参数 $\\boldsymbol{U}$ 的梯度，并更新参数。\",\n    \"问题5\": \"BPTT 算法中的长程依赖问题指的是什么？\",\n    \"回答5\": \"BPTT 算法中的长程依赖问题指的是由于梯度消失或爆炸问题，很难建模长时间间隔（Long Range）的状态之间的依赖关系。这会导致系统不稳定或梯度消失，使得神经网络难以学习到长期的依赖关系。\",\n    \"问题6\": \"在 BPTT 算法中，梯度爆炸问题和梯度消失问题分别指什么？\",\n    \"回答6\": \"在 BPTT 算法中，如果定义 $\\text{γ} \\text{≈} \\big\\big\\big\\big|\\text{diag}\\big(f^{\\text{'}}\\big(\\boldsymbol{z}_τ\\big)\\big) \\boldsymbol{U}^{\\top}\\big\\big\\big\\big|$, 则当 $\\text{γ}>1$ 时，会出现梯度爆炸问题；而当 $\\text{γ}<1$ 时，会出现梯度消失问题。这两个问题分别指梯度变得非常大和梯度变得非常小，导致系统不稳定或无法有效学习长期依赖关系。\",\n    \"问题7\": \"为什么循环神经网络中的梯度消失问题会导致长程依赖问题？\",\n    \"回答7\": \"循环神经网络中常使用非线性激活函数为 Logistic 函数或 Tanh 函数，其导数值都小于 1。同时，权重矩阵 $\\big|\\big|\\boldsymbol{U}\\big|\\big|$ 也不会太大。因此，如果时间间隔 $t-k$ 过大，梯度会趋向于 0，导致系统难以学习到长期的依赖关系，即出现长程依赖问题。\",\n    \"问题8\": \"简单循环网络理论上能否建立长时间间隔的状态之间的依赖关系？\",\n    \"回答8\": \"简单循环网络理论上可以建立长时间间隔的状态之间的依赖关系。然而，由于梯度爆炸或消失问题，实际上只能学习到短期的依赖关系，难以有效地建模长距离的依赖关系。\",\n    \"问题9\": \"为什么 RTRL 算法适合用于需要在线学习或无限序列任务中？\",\n    \"回答9\": \"RTRL 算法不需要梯度回传，因此非常适合用于需要在线学习或无限序列任务中。它能够实时地计算损失函数对参数的梯度，并更新参数，适合处理需要实时学习和大量序列数据的任务。\",\n    \"问题10\": \"两种算法比较下来，RTRL 算法和 BPTT 算法各自的优势是什么？\",\n    \"回答10\": \"RTRL 算法不需要梯度回传，适合用于在线学习或无限序列任务中；而 BPTT 算法计算量较小但需要保存所有时刻的中间梯度，适合处理维度较低且空间复杂度较高的任务。因此，两种算法各有优势，在不同场景下可以选择合适的算法来应用。\"\n}",
                    "role": "assistant",
                    "function_call": null,
                    "tool_calls": null
                }
            }
        ],
        "created": 1710748190,
        "model": "gpt-3.5-turbo-1106",
        "object": "chat.completion",
        "system_fingerprint": "fp_4aaaf0dc94",
        "usage": {
            "completion_tokens": 1662,
            "prompt_tokens": 4659,
            "total_tokens": 6321
        },
        "parameters": {
            "model": "gpt-3.5-turbo-1106",
            "temperature": 0.2,
            "frequency_penalty": 0.15,
            "presence_penalty": 0.15
        }
    }
]