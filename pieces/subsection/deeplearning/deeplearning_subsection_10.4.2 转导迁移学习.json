[
    {
        "strategy": "subsection",
        "source": "deeplearning",
        "title": "10.4.2 转导迁移学习",
        "content_length": 11469,
        "content": "Title: 10.4.2 转导迁移学习\nContent:\n转导迁移学习是一种从样本到样本的迁移, 直接利用源领域和目标领域的样本进行迁移学习 [Arnold et al., 2007]. 转导迁移学习可以看作一种特殊的转导学习 (Transductive Learning) [Joachims, 1999]. 转导迁移学习通常假设源领域有大量的标注数据, 而目标领域没有 (或只有少量) 标注数据, 但是有大量的无标注数据. 目标领域的数据在训练阶段是可见的.\n\n转导迁移学习的一个常见子问题是领域适应 (Domain Adaptation ). 在领域适应问题中, 一般假设源领域和目标领域有相同的样本空间, 但是数据分布不同 $p_{S}(\\boldsymbol{x}, y) \\neq p_{T}(\\boldsymbol{x}, y)$.\n\n根据贝叶斯公式, $p(\\boldsymbol{x}, y)=p(\\boldsymbol{x} \\mid y) p(y)=p(y \\mid \\boldsymbol{x}) p(\\boldsymbol{x})$, 因此数据分布的不一致通常由三种情况造成:\n\n(1) 协变量偏移 (Covariate Shift): 源领域和目标领域的输入边际分布不同 $p_{S}(\\boldsymbol{x}) \\neq p_{T}(\\boldsymbol{x})$, 但后验分布相同 $p_{S}(y \\mid \\boldsymbol{x})=p_{T}(y \\mid \\boldsymbol{x})$, 即学习任务相同 $\\mathcal{J}_{S}=\\mathcal{T}_{T}$.\n\n(2) 概念偏移 (Concept Shift): 输入边际分布相同 $p_{S}(\\boldsymbol{x})=p_{T}(\\boldsymbol{x})$, 但后验分布不同 $p_{S}(y \\mid \\boldsymbol{x}) \\neq p_{T}(y \\mid \\boldsymbol{x})$,即学习任务不同 $\\mathcal{T}_{S} \\neq \\mathcal{T}_{T}$.\n\n(3) 先验偏移 (Prior Shift): 源领域和目标领域中的输出标签 $y$ 的先验分布不同 $p_{S}(y) \\neq p_{T}(y)$, 条件分布相同 $p_{S}(\\boldsymbol{x} \\mid y)=p_{T}(\\boldsymbol{x} \\mid y)$. 在这样情况下, 目标领域必须提供一定数量的标注样本.\n\n广义的领域适应问题可能包含上述一种或多种偏移情况. 目前, 大多数的领域适应问题主要关注协变量偏移, 这样领域适应问题的关键就在于如何学习领 \\href{https://nndl.github.io/}{https://nndl.github.io/}\n\n\\section*{机器学习小知识 $\\mid$ 协变量偏移}\n协变量是一个统计学概念, 是可能影响预测结果的统计变量. 在机器学习中, 协变量可以看作输入. 一般的机器学习算法都要求输入在训练集和测试集上的分布是相似的. 协变量偏移 (Covariate Shift) 一般指输入在训练集和测试集上的分布不同. 这样, 在训练集上学习到的模型在测试集上的表现会比较差.\n\n\n\n域无关 ( Domain-Invariant) 的表示. 假设 $p_{S}(y \\mid \\boldsymbol{x})=p_{T}(y \\mid \\boldsymbol{x})$, 领域适应的目标是学习一个模型 $f: x \\rightarrow y$ 使得\n\n\n\\begin{align*}\n\\mathcal{R}_{T}\\left(\\theta_{f}\\right) & =\\mathbb{E}_{(\\boldsymbol{x}, y) \\sim p_{T}(\\boldsymbol{x}, y)}\\left[\\mathcal{L}\\left(f\\left(\\boldsymbol{x} ; \\theta_{f}\\right), y\\right)\\right]  \\tag{10.26}\\\\\n& =\\mathbb{E}_{(\\boldsymbol{x}, y) \\sim p_{S}(\\boldsymbol{x}, y)} \\frac{p_{T}(\\boldsymbol{x}, y)}{p_{S}(\\boldsymbol{x}, y)}\\left[\\mathcal{L}\\left(f\\left(\\boldsymbol{x} ; \\theta_{f}\\right), y\\right)\\right]  \\tag{10.27}\\\\\n& =\\mathbb{E}_{(\\boldsymbol{x}, y) \\sim p_{S}(\\boldsymbol{x}, y)} \\frac{p_{T}(\\boldsymbol{x})}{p_{S}(\\boldsymbol{x})}\\left[\\mathcal{L}\\left(f\\left(\\boldsymbol{x} ; \\theta_{f}\\right), y\\right)\\right], \\tag{10.28}\n\\end{align*}\n\n\n其中 $\\mathcal{L}(\\cdot)$ 为损失函数, $\\theta_{f}$ 为模型参数.\n\n如果我们可以学习一个映射函数 $g: X \\rightarrow \\mathbb{R}^{d}$, 将 $\\boldsymbol{x}$ 映射到一个特征空间中, 并在这个特征空间中使得源领域和目标领域的边际分布相同 $p_{S}\\left(g\\left(\\boldsymbol{x} ; \\theta_{g}\\right)\\right)=$ $p_{T}\\left(g\\left(\\boldsymbol{x} ; \\theta_{g}\\right)\\right), \\forall \\boldsymbol{x} \\in X$, 其中 $\\theta_{g}$ 为映射函数的参数, 那么目标函数可以近似为\n\n\n\\begin{align*}\n\\mathcal{R}_{T}\\left(\\theta_{f}, \\theta_{g}\\right) & =\\mathbb{E}_{(\\boldsymbol{x}, y) \\sim p_{S}(\\boldsymbol{x}, y)}\\left[\\mathcal{L}\\left(f\\left(g\\left(\\boldsymbol{x} ; \\theta_{g}\\right) ; \\theta_{f}\\right), y\\right)\\right]+\\gamma d_{g}(S, T)  \\tag{10.29}\\\\\n& =\\mathcal{R}_{S}\\left(\\theta_{f}, \\theta_{g}\\right)+\\gamma d_{g}(S, T), \\tag{10.30}\n\\end{align*}\n\n\n其中 $\\mathcal{R}_{S}\\left(\\theta_{f}, \\theta_{g}\\right)$ 为源领域上的期望风险函数, $d_{g}(S, T)$ 是一个分布差异的度量函数, 用来计算在映射特征空间中源领域和目标领域的样本分布的距离, $\\gamma$ 为一个超参数, 用来平衡两个子目标的重要性比例. 这样, 学习的目标是优化参数 $\\theta_{f}, \\theta_{g}$使得提取的特征是领域无关的, 并且在源领域上损失最小.\n\n\n\\begin{align*}\n& \\mathcal{D}_{S}=\\left\\{\\left(\\boldsymbol{x}_{S}^{(n)}, y_{S}^{(n)}\\right)\\right\\}_{n=1}^{N} \\sim p_{S}(\\boldsymbol{x}, y),  \\tag{10.31}\\\\\n& \\mathcal{D}_{T}=\\left\\{\\boldsymbol{x}_{T}^{(m)}\\right\\}_{m=1}^{M} \\sim p_{T}(\\boldsymbol{x}, y), \\tag{10.32}\n\\end{align*}\n\n\n分别为源领域和目标领域的训练数据, 我们首先用映射函数 $g\\left(x, \\theta_{g}\\right)$ 将两个领域中训练样本的输入 $\\boldsymbol{x}$ 映射到特征空间, 并优化参数 $\\theta_{g}$ 使得映射后两个领域的输入分布差异最小. 分布差异一般可以通过一些度量函数来计算, 比如 MMD ( Maximum Mean Discrepancy) [Gretton et al., 2007] 、CMD ( Central Moment Discrepancy ) [Zellinger et al., 2017]等, 也可以通过领域对抗学习来得到领域无关的表示 [Bousmalis et al., 2016; Ganin et al., 2016].\n\n以对抗学习为例, 我们可以引入一个领域判别器 $c$ 来判断一个样本是来自于哪个领域. 如果领域判别器 $c$ 无法判断一个映射特征的领域信息, 就可以认为这个特征是一种领域无关的表示.\n\n对于训练集中的每一个样本 $\\boldsymbol{x}$, 我们都赋予 $z \\in\\{1,0\\}$ 表示它是来自于源领域还是目标领域, 领域判别器 $c\\left(\\boldsymbol{h}, \\theta_{c}\\right)$ 根据其映射特征 $\\boldsymbol{h}=g\\left(\\boldsymbol{x}, \\theta_{g}\\right)$ 来预测它来自于源领域的概率 $p(z=1 \\mid \\boldsymbol{x})$. 由于领域判别是一个两分类问题, $\\boldsymbol{h}$ 来自于目标领域的概率为 $1-c\\left(\\boldsymbol{h}, \\theta_{c}\\right)$.\n\n因此,领域判别器的损失函数为:\n\n\n\\begin{equation*}\n\\mathcal{L}_{c}\\left(\\theta_{g}, \\theta_{c}\\right)=\\frac{1}{N} \\sum_{n=1}^{N} \\log c\\left(\\boldsymbol{h}_{S}^{(n)}, \\theta_{c}\\right)+\\frac{1}{M} \\sum_{m=1}^{M} \\log \\left(1-c\\left(\\boldsymbol{h}_{D}^{(m)}, \\theta_{c}\\right)\\right) \\tag{10.33}\n\\end{equation*}\n\n\n其中 $\\boldsymbol{h}_{S}^{(n)}=g\\left(\\boldsymbol{x}_{S}^{(n)}, \\theta_{g}\\right), \\boldsymbol{h}_{D}^{(m)}=g\\left(\\boldsymbol{x}_{D}^{(m)}, \\theta_{g}\\right)$ 分别为样本 $\\boldsymbol{x}_{S}^{(n)}$ 和 $\\boldsymbol{x}_{D}^{(m)}$ 的特征向量.\n\n这样, 领域迁移的目标函数可以分解为两个对抗的目标. 一方面, 要学习参数 $\\theta_{c}$ 使得领域判别器 $c\\left(\\boldsymbol{h}, \\theta_{c}\\right)$ 尽可能区分出一个表示 $\\boldsymbol{h}=g\\left(\\boldsymbol{x}, \\theta_{g}\\right)$ 是来自于哪个领域; 另一方面, 要学习参数 $\\theta_{g}$ 使得提取的表示 $\\boldsymbol{h}$ 无法被领域判别器 $c\\left(\\boldsymbol{h}, \\theta_{c}\\right)$ 预测出来, 并同时学习参数 $\\theta_{f}$ 使得模型 $f\\left(\\boldsymbol{h} ; \\theta_{f}\\right)$ 在源领域的损失最小.\n\n\\[\n\\begin{array}{ll}\n\\min _{\\theta_{c}} & \\mathcal{L}_{c}\\left(\\theta_{f}, \\theta_{c}\\right), \\\\\n\\min _{\\theta_{f}, \\theta_{g}} & \\sum_{n=1}^{N} \\mathcal{L}\\left(f\\left(g\\left(\\boldsymbol{x}_{S}^{(n)} ; \\theta_{g}\\right) ; \\theta_{f}\\right), y_{S}^{(n)}\\right)-\\gamma \\mathcal{L}_{c}\\left(\\theta_{f}, \\theta_{c}\\right) . \\tag{10.35}\n\\end{array}\n\\]\n\n\\section*{10.5 终身学习}\n虽然深度学习在很多任务上取得了成功, 但是其前提是训练数据和测试数据的分布要相同, 一旦训练结束模型就保持固定, 不再进行迭代更新. 并且, 要想 \\href{https://nndl.github.io/}{https://nndl.github.io/}\\\\\n一个模型同时在很多不同任务上都取得成功依然是一件十分困难的事情. 比如在围棋任务上训练的 AlphaGo 只会下围棋, 对象棋一窍不通. 如果让 AlphaGo 去学习下象棋, 可能会损害其下围棋的能力, 这显然不符合人类的学习过程. 我们在学会了下围棋之后, 再去学下象棋, 并不会忘记下围棋的下法. 人类的学习是一直持续的, 人脑可以通过记忆不断地累积学习到的知识, 这些知识累积可以在不同的任务中持续进行. 在大脑的海马系统上, 新的知识在以往知识的基础上被快速建立起来; 之后经过长时间的处理,在大脑皮质区形成较难遗忘的长时记忆. 由于不断的知识累积, 人脑在学习新的任务时一般不需要太多的标注数据.\n\n终身学习 (Lifelong Learning), 也叫持续学习 (Continuous Learning),是指像人类一样具有持续不断的学习能力, 根据历史任务中学到的经验和知识来帮助学习不断出现的新任务, 并且这些经验和知识是持续累积的, 不会因为新的任务而忘记旧的知识 [Chen et al., 2016; Thrun, 1998].\n\n在终身学习中, 假设一个终身学习算法已经在历史任务 $\\mathcal{T}_{1}, \\mathcal{T}_{2}, \\cdots, \\mathcal{T}_{m}$ 上学习到一个模型, 当出现一个新任务 $\\mathcal{T}_{m+1}$ 时, 这个算法可以根据过去在 $m$ 个任务上学习的知识来帮助学习第 $m+1$ 个任务, 同时累积所有的 $m+1$ 个任务上的知识. 这个设定和归纳迁移学习十分类似, 但归纳迁移学习的目标是优化目标任务的性能, 而不关心知识的累积. 而终身学习的目标是持续的学习和知识累积. 另外, 终身学习和多任务学习也十分类似, 但不同之处在于终身学习并不在所有任务上同时学习. 多任务学习是在使用所有任务的数据进行联合学习, 并不是持续地一个一个的学习.\n\n在终身学习中, 一个关键的问题是如何避免灾难性遗忘 (Catastrophic Forgetting ), 即按照一定顺序学习多个任务时, 在学习新任务的同时不忘记先前学会的历史任务 [French, 1999; Kirkpatrick et al., 2017]. 比如在神经网络模型中,一些参数对任务 $\\mathcal{J}_{A}$ 非常重要, 如果在学习任务 $\\mathcal{J}_{B}$ 时被改变了, 就可能给任务 $\\mathcal{F}_{A}$造成不好的影响.\n\n在网络容量有限时, 学习一个新的任务一般需要遗忘一些历史任务的知识.而目前的神经网络往往都是过参数化的, 对于任务 $\\mathcal{F}_{A}$ 而言有很多参数组合都可以达到最好的性能. 这样, 在学习任务 $\\mathcal{T}_{B}$ 时, 可以找到一组不影响任务 $\\mathcal{F}_{A}$ 而又能使得任务 $\\mathcal{T}_{B}$ 最优的参数.\n\n解决灾难性遗忘的方法有很多. 我们这里介绍一种弹性权重巩固 (Elastic Weight Consolidation ) 方法 [Kirkpatrick et al., 2017].\n\n不失一般性, 以两个任务的持续学习为例, 假设任务 $\\mathcal{T}_{A}$ 和任务 $\\mathcal{T}_{B}$ 的数据集分别为 $\\mathcal{D}_{A}$ 和 $\\mathcal{D}_{B}$. 从贝叶斯的角度来看, 将模型参数 $\\theta$ 看作随机向量, 给定两个任务时 $\\theta$ 的后验分布为\n\n\n\\begin{equation*}\n\\log p(\\theta \\mid \\mathcal{D})=\\log p(\\mathcal{D} \\mid \\theta)+\\log p(\\theta)-\\log p(\\mathcal{D}) \\tag{10.36}\n\\end{equation*}\n\n\n\\href{https://nndl.github.io/}{https://nndl.github.io/}\\\\\n其中 $\\mathcal{D}=\\mathcal{D}_{A} \\cup \\mathcal{D}_{B}$. 根据独立同分布假设, 上式可以写为\n\n\n\\begin{align*}\n\\log p(\\theta \\mid \\mathcal{D}) & =\\underline{\\log p\\left(\\mathcal{D}_{A} \\mid \\theta\\right)}+\\log p\\left(\\mathcal{D}_{B} \\mid \\theta\\right)+\\underline{\\log p(\\theta)}-\\underline{\\log p\\left(\\mathcal{D}_{A}\\right)}-\\log p\\left(\\mathcal{D}_{B}\\right)  \\tag{10.37}\\\\\n& =\\log p\\left(\\mathcal{D}_{B} \\mid \\theta\\right)+\\underline{\\log p\\left(\\theta \\mid \\mathcal{D}_{A}\\right)-\\log p\\left(\\mathcal{D}_{B}\\right),} \\tag{10.38}\n\\end{align*}\n\n\n其中 $p\\left(\\theta \\mid \\mathcal{D}_{A}\\right)$ 包含了所有在任务 $\\mathcal{T}_{A}$ 上学习到的信息. 当顺序地学习任务 $\\mathcal{T}_{B}$ 时,参数在两个任务上的后验分布和其在任务 $\\mathcal{T}_{A}$ 的后验分布有关.\n\n由于后验分布比较难以建模, 我们可以通过一个近似的方法来估计. 假设 $p\\left(\\theta \\mid \\mathcal{D}_{A}\\right)$ 为高斯分布, 期望为在任务 $\\mathcal{T}_{A}$ 上学习到的参数 $\\theta_{A}^{*}$, 精度矩阵 (即协方差矩阵的逆) 可以用参数 $\\theta$ 在数据集 $\\mathcal{D}_{A}$ 上的 Fisher 信息矩阵来近似,即\n\n\n\\begin{equation*}\np\\left(\\theta \\mid \\mathcal{D}_{A}\\right)=\\mathcal{N}\\left(\\theta_{A}^{*}, F^{-1}\\right) \\tag{10.39}\n\\end{equation*}\n\n\n其中 $F$ 为 Fisher 信息矩阵. 为了提高计算效率, $F$ 可以简化为对角矩阵, 由 Fisher 信息矩阵对角线构成.\n\nFisher信息矩阵 Fisher信息矩阵 (Fisher Information Matrix) 是一种测量似然函数 $p(x ; \\theta)$ 携带的关于参数 $\\theta$ 的信息量的方法. 通常一个参数对分布的影响可以通过对数似然函数的梯度来衡量. 令打分函数 $s(\\theta)$ 为\n\n\n\\begin{equation*}\ns(\\theta)=\\nabla_{\\theta} \\log p(x ; \\theta), \\tag{10.40}\n\\end{equation*}\n\n\n则 $s(\\theta)$ 的期望为 0 .\n\n证明.\n\n\n\\begin{align*}\n\\mathbb{E}[s(\\theta)] & =\\int \\nabla_{\\theta} \\log p(x ; \\theta) p(x ; \\theta) \\mathrm{d} x  \\tag{10.41}\\\\\n& =\\int \\frac{\\nabla_{\\theta} p(x ; \\theta)}{p(x ; \\theta)} p(x ; \\theta) \\mathrm{d} x  \\tag{10.42}\\\\\n& =\\int \\nabla_{\\theta} p(x ; \\theta) \\mathrm{d} x  \\tag{10.43}\\\\\n& =\\nabla_{\\theta} \\int p(x ; \\theta) \\mathrm{d} x  \\tag{10.44}\\\\\n& =\\nabla_{\\theta} 1=0 . \\tag{10.45}\n\\end{align*}\n\n\n$s(\\theta)$ 的协方差矩阵称为Fisher 信息矩阵, 可以衡量参数 $\\theta$ 的估计的不确定性. Fisher 信息矩阵的定义为\n\n\n\\begin{align*}\nF(\\theta) & =\\mathbb{E}\\left[s(\\theta) s(\\theta)^{\\top}\\right]  \\tag{10.46}\\\\\n& =\\mathbb{E}\\left[\\nabla_{\\theta} \\log p(x ; \\theta)\\left(\\nabla_{\\theta} \\log p(x ; \\theta)\\right)^{\\top}\\right] . \\tag{10.47}\n\\end{align*}\n\n\n\\href{https://nndl.github.io/}{https://nndl.github.io/}\\\\\n由于我们不知道似然函数 $p(x ; \\theta)$ 的具体形式, Fisher 信息矩阵可以用经验分布来进行估计. 给定一个数据集 $\\left\\{x^{(1)}, \\cdots, x^{(N)}\\right\\}$, Fisher 信息矩阵可以近似为\n\n\n\\begin{equation*}\nF(\\theta)=\\frac{1}{N} \\sum_{n=1}^{N} \\nabla_{\\theta} \\log p\\left(x^{(n)} ; \\theta\\right)\\left(\\nabla_{\\theta} \\log p\\left(x^{(n)} ; \\theta\\right)\\right)^{\\top} \\tag{10.48}\n\\end{equation*}\n\n\nFisher 信息矩阵的对角线的值反映了对应参数在通过最大似然进行估计时的不确定性, 其值越大, 表示该参数估计值的方差越小, 估计更可靠性, 其携带的关于数据分布的信息越多.\n\n因此, 对于任务 $\\mathcal{T}_{A}$ 的数据集 $\\mathcal{D}_{A}$, 我们可以用 Fisher 信息矩阵来衡量一个参数携带的关于 $\\mathcal{D}_{A}$ 的信息量,即\n\n\n\\begin{equation*}\nF^{A}(\\theta)=\\frac{1}{N} \\sum_{(\\boldsymbol{x}, y) \\in \\mathcal{D}_{A}} \\nabla_{\\theta} \\log p(y \\mid \\boldsymbol{x} ; \\theta)\\left(\\nabla_{\\theta} \\log p(y \\mid \\boldsymbol{x} ; \\theta)\\right)^{\\top} \\tag{10.49}\n\\end{equation*}\n\n\n通过上面的近似,在训练任务 $\\mathcal{T}_{B}$ 时的损失函数为\n\n\n\\begin{equation*}\n\\mathcal{L}(\\theta)=\\mathcal{L}_{B}(\\theta)+\\sum_{i=1}^{N} \\frac{\\lambda}{2} F_{i}^{A} \\cdot\\left(\\theta_{i}-\\theta_{A, i}^{*}\\right)^{2} \\tag{10.50}\n\\end{equation*}\n\n\n参见习题10-4.\n\n其中 $\\mathcal{L}_{B}(\\theta)$ 为任务 $p\\left(\\theta \\mid \\mathcal{D}_{B}\\right)$ 的损失函数, $F_{i}{ }^{A}$ 为 Fisher 信息矩阵的第 $i$ 个对角线元素, $\\theta_{A}^{*}$ 为在任务 $\\mathcal{T}_{A}$ 上学习到的参数, $\\lambda$ 为平衡两个任务重要性的超参数, $N$ 为参数的总数量.\n\n\\section*{10.6 元学习}\n根据没有免费午餐定理, 没有一种通用的学习算法可以在所有任务上都有效. 因此, 当使用机器学习算法实现某个任务时, 我们通常需要 “就事论事”, 根据任务的特点来选择合适的模型、损失函数、优化算法以及超参数. 那么, 我们是否可以有一套自动方法, 根据不同任务来动态地选择合适的模型或动态地调整超参数呢? 事实上, 人脑中的学习机制就具备这种能力. 在面对不同的任务时, 人脑的学习机制并不相同. 即使面对一个新的任务, 人们往往也可以很快找到其学习方式. 这种可以动态调整学习方式的能力, 称为元学习 ( Meta-Learning), 也称为学习的学习 (Learning to Learn ) [Thrun et al., 2012].\n\n元学习的目的是从已有任务中学习一种学习方法或元知识, 可以加速新任务的学习. 从这个角度来说, 元学习十分类似于归纳迁移学习, 但元学习更侧重从多种不同 (甚至是不相关) 的任务中归纳出一种学习方法.\n\n和元学习比较相关的另一个机器学习问题是小样本学习 ( Few-shot Learning ), 即在小样本上的快速学习能力. 每个类只有 $K$ 个标注样本, $K$ 非常小. 如 \\href{https://nndl.github.io/}{https://nndl.github.io/}\\\\\n果 $K=1$, 称为单样本学习 (One-shot Learning) ; 如果 $K=0$, 称为零样本学习\n\n( Zero-shot Learning).\n\n这里我们主要介绍两种典型的元学习方法: 基于优化器的元学习和模型无关的元学习."
    },
    {}
]