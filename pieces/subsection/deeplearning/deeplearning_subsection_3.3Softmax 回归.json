[
    {
        "strategy": "subsection",
        "source": "deeplearning",
        "title": "3.3Softmax 回归",
        "content_length": 2187,
        "content": "Title: 3.3Softmax 回归\nContent:\nSoftmax 回归 (Softmax Regression)，也称为多项 (Multinomial) 或多类 (Multi-Class) 的 Logistic 回归, 是 Logistic 回归在多分类问题上的推广.\n\n对于多类问题, 类别标签 $y \\in\\{1,2, \\cdots, C\\}$ 可以有 $C$ 个取值. 给定一个样本 $\\boldsymbol{x}$, Softmax 回归预测的属于类别 $c$ 的条件概率为\n\n\n\\begin{align*}\np(y=c \\mid \\boldsymbol{x}) & =\\operatorname{softmax}\\left(\\boldsymbol{w}_{c}^{\\top} \\boldsymbol{x}\\right)  \\tag{3.28}\\\\\n& =\\frac{\\exp \\left(\\boldsymbol{w}_{c}^{\\top} \\boldsymbol{x}\\right)}{\\sum_{c^{\\prime}=1}^{C} \\exp \\left(\\boldsymbol{w}_{c^{\\prime}}^{\\top} \\boldsymbol{x}\\right)}, \\tag{3.29}\n\\end{align*}\n\n\n其中 $\\boldsymbol{w}_{c}$ 是第 $c$ 类的权重向量.\n\nSoftmax 回归的决策函数可以表示为\n\n\n\\begin{align*}\n\\hat{y} & =\\underset{c=1}{\\arg \\max } p(y=c \\mid \\boldsymbol{x})  \\tag{3.30}\\\\\n& =\\underset{c=1}{C} \\underset{c}{\\arg \\max } \\boldsymbol{w}_{c}^{\\top} \\boldsymbol{x} . \\tag{3.31}\n\\end{align*}\n\n\n\\href{https://nndl.github.io/}{https://nndl.github.io/}\n\nSoftmax 回归也可以看作一种条件最大熵模型, 参见第11.1.5.1节。\n\nSoftmax 函数参见第B.4.2.2节。 $\\hat{y}$ 为 Logistic 函数,因此有 $\\frac{\\partial \\hat{y}}{\\partial \\boldsymbol{w}^{\\top} \\boldsymbol{x}}=$ $\\hat{y}^{(n)}\\left(1-\\hat{y}^{(n)}\\right)$. 参见第B.4.2.1节。\\\\\n与 Logistic 回归的关系 当类别数 $C=2$ 时, Softmax 回归的决策函数为\n\n\n\\begin{align*}\n\\hat{y} & =\\underset{y \\in\\{0,1\\}}{\\arg \\max } \\boldsymbol{w}_{y}^{\\top} \\boldsymbol{x}  \\tag{3.32}\\\\\n& =I\\left(\\boldsymbol{w}_{1}^{\\top} \\boldsymbol{x}-\\boldsymbol{w}_{0}^{\\top} \\boldsymbol{x}>0\\right)  \\tag{3.33}\\\\\n& =I\\left(\\left(\\boldsymbol{w}_{1}-\\boldsymbol{w}_{0}\\right)^{\\top} \\boldsymbol{x}>0\\right), \\tag{3.34}\n\\end{align*}\n\n\n其中 $I(\\cdot)$ 是指示函数. 对比公式 (3.5) 中的二分类决策函数, 可以发现二分类中的权重向量 $\\boldsymbol{w}=\\boldsymbol{w}_{1}-\\boldsymbol{w}_{0}$.\n\n向量表示 公式(3.29)用向量形式可以写为\n\n\n\\begin{align*}\n\\hat{\\boldsymbol{y}} & =\\operatorname{softmax}\\left(\\boldsymbol{W}^{\\top} \\boldsymbol{x}\\right)  \\tag{3.35}\\\\\n& =\\frac{\\exp \\left(\\boldsymbol{W}^{\\top} \\boldsymbol{x}\\right)}{\\mathbf{1}_{C}^{\\top} \\exp \\left(\\boldsymbol{W}^{\\top} \\boldsymbol{x}\\right)}, \\tag{3.36}\n\\end{align*}\n\n\n其中 $\\boldsymbol{W}=\\left[\\boldsymbol{w}_{1}, \\cdots, \\boldsymbol{w}_{C}\\right]$ 是由 $C$ 个类的权重向量组成的矩阵, $\\boldsymbol{1}_{C}$ 为 $C$ 维的全 1 向量, $\\hat{\\boldsymbol{y}} \\in \\mathbb{R}^{C}$ 为所有类别的预测条件概率组成的向量, 第 $c$ 维的值是第 $c$ 类的预测条件概率."
    },
    {
        "id": "chatcmpl-9417oFBLxUwkeoHmMW7yyHkjd2h4G",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "logprobs": null,
                "message": {
                    "content": "{\n    \"问题1\": \"Softmax 回归和 Logistic 回归有何区别？\",\n    \"回答1\": \"Softmax 回归是 Logistic 回归在多分类问题上的推广。在多类问题中，Softmax 回归预测属于类别 $c$ 的条件概率，而 Logistic 回归通常用于二分类问题。\",\n    \"问题2\": \"Softmax 回归的决策函数是如何表示的？\",\n    \"回答2\": \"Softmax 回归的决策函数可以表示为 $\\text{argmax}_{c=1} p(y=c \\text{ 为 } \\boldsymbol{x}) = \\text{argmax}_{c=1}^C \\text{argmax}_c \\boldsymbol{w}_c^{\\top} \\boldsymbol{x}$。\",\n    \"问题3\": \"Softmax 回归的条件概率公式是什么？\",\n    \"回答3\": \"Softmax 回归预测的属于类别 $c$ 的条件概率为 $p(y=c \\text{ 为 } \\boldsymbol{x}) = \\text{softmax}(\\boldsymbol{w}_c^{\\top} \\boldsymbol{x}) = \\frac{\\text{exp}(\\boldsymbol{w}_c^{\\top} \\boldsymbol{x})}{\\text{sum}_{c'=1}^C \\text{exp}(\\boldsymbol{w}_{c'}^{\\top} \\boldsymbol{x})}$。\",\n    \"问题4\": \"Softmax 回归的决策函数与 Logistic 回归有何关系？\",\n    \"回答4\": \"当类别数 $C=2$ 时，Softmax 回归的决策函数可以表示为 $\\text{argmax}_{y \\text{ 在 } \\big\\brace{0,1}} \\boldsymbol{w}_y^{\\top} \\boldsymbol{x} = I(\\boldsymbol{w}_1^{\\top} \\boldsymbol{x}-\\boldsymbol{w}_0^{\\top} \\boldsymbol{x}>0) = I((\\boldsymbol{w}_1-\\boldsymbol{w}_0)^{\\top} \\boldsymbol{x}>0)$。这与 Logistic 回归的决策函数形式相似。\",\n    \"问题5\": \"Softmax 函数在 Softmax 回归中扮演着什么角色？\",\n    \"回答5\": \"Softmax 函数在 Softmax 回归中用于计算预测属于每个类别的条件概率。它将权重向量和输入向量的线性组合转化为各个类别的概率分布。\",\n    \"问题6\": \"Softmax 回归与最大熵模型有何关联？\",\n    \"回答6\": \"Softmax 回归也可以看作一种条件最大熵模型，这意味着它在多分类问题上具有类似于最大熵模型的建模特性。\",\n    \"问题7\": \"Softmax 函数的向量形式公式是什么？\",\n    \"回答7\": \"Softmax 函数的向量形式公式为 $\\text{softmax}(\\boldsymbol{W}^{\\top} \\boldsymbol{x}) = \\frac{\\text{exp}(\\boldsymbol{W}^{\\top} \\boldsymbol{x})}{\\textbf{1}_C^{\\top} \\text{exp}(\\boldsymbol{W}^{\\top} \\boldsymbol{x})}$，其中 $\\boldsymbol{W}$ 是由 $C$ 个类的权重向量组成的矩阵。\",\n    \"问题8\": \"Softmax 回归中的权重向量 $\\boldsymbol{w}_c$ 表示什么意义？\",\n    \"回答8\": \"$\\boldsymbol{w}_c$ 是第 $c$ 类的权重向量，它表示了在预测属于类别 $c$ 的条件概率时，输入特征与该类别之间的权重关系。\",\n    \"问题9\": \"Softmax 回归适用于哪种类型的分类问题？\",\n    \"回答9\": \"Softmax 回归适用于多分类问题，其中类别标签 $y$ 可以有 $C$ 个取值。它是 Logistic 回归在多分类问题上的推广。\",\n    \"问题10\": \"Softmax 回归中的指示函数 $I(\\bullet)$ 扮演着什么角色？\",\n    \"回答10\": \"$I(\\bullet)$ 是指示函数，在 Softmax 回归中用于表示决策函数。它将输入映射为一个二元输出，帮助确定样本属于哪个类别。\"\n}",
                    "role": "assistant",
                    "function_call": null,
                    "tool_calls": null
                }
            }
        ],
        "created": 1710744664,
        "model": "gpt-3.5-turbo-1106",
        "object": "chat.completion",
        "system_fingerprint": "fp_4aaaf0dc94",
        "usage": {
            "completion_tokens": 1168,
            "prompt_tokens": 3650,
            "total_tokens": 4818
        },
        "parameters": {
            "model": "gpt-3.5-turbo-1106",
            "temperature": 0.2,
            "frequency_penalty": 0.15,
            "presence_penalty": 0.15
        }
    }
]