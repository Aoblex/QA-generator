[
    {
        "strategy": "subsection",
        "source": "deeplearning",
        "title": "7.6.3 贝叶斯优化",
        "content_length": 2442,
        "content": "Title: 7.6.3 贝叶斯优化\nContent:\n贝叶斯优化 ( Bayesian optimization ) [Bergstra et al., 2011; Snoek et al., 2012] 是一种自适应的超参数优化方法, 根据当前已经试验的超参数组合, 来预测下一个可能带来最大收益的组合.\n\n一种比较常用的贝叶斯优化方法为时序模型优化 ( Sequential Model-Based Optimization,SMBO ) [Hutter et al., 2011]. 假设超参数优化的函数 $f(\\boldsymbol{x})$ 服从高斯过程, 则 $p(f(\\boldsymbol{x}) \\mid \\boldsymbol{x})$ 为一个正态分布. 贝叶斯优化过程是根据已有的 $N$ 组试验结果 $\\mathcal{H}=\\left\\{\\boldsymbol{x}_{n}, y_{n}\\right\\}_{n=1}^{N}$ ( $y_{n}$ 为 $f\\left(\\boldsymbol{x}_{n}\\right)$ 的观测值 ) 来建模高斯过程, 并计算 $f(\\boldsymbol{x})$ 的后验分布 $p_{\\mathcal{G P}}(f(\\boldsymbol{x}) \\mid \\boldsymbol{x}, \\mathcal{H})$.\n\n为了使得 $p_{\\mathcal{G} P}(f(\\boldsymbol{x}) \\mid \\boldsymbol{x}, \\mathcal{H})$ 接近其真实分布, 就需要对样本空间进行足够多的采样. 但是超参数优化中每一个样本的生成成本很高, 需要用尽可能少的样本来使得 $p_{\\theta}(f(\\boldsymbol{x}) \\mid \\boldsymbol{x}, \\mathcal{H})$ 接近于真实分布. 因此, 需要通过定义一个收益函数 (Acquisition Function ) $a(x, \\mathcal{H})$ 来判断一个样本是否能够给建模 $p_{\\theta}(f(\\boldsymbol{x}) \\mid \\boldsymbol{x}, \\mathcal{H})$ 提供更多的收益. 收益越大, 其修正的高斯过程会越接近目标函数的真实分布.\n\n收益函数的定义有很多种方式.一个常用的是期望改善 ( Expected Improvement, EI ) 函数. 假设 $y^{*}=\\min \\left\\{y_{n}, 1 \\leq n \\leq N\\right\\}$ 是当前已有样本中的最优值, 期望改善函数为，\n\n\n\\begin{equation*}\n\\mathbf{E I}(\\boldsymbol{x}, \\mathcal{H})=\\int_{-\\infty}^{\\infty} \\max \\left(y^{*}-y, 0\\right) p_{\\mathcal{G P}}(y \\mid \\boldsymbol{x}, \\mathcal{H}) \\mathrm{d} y \\tag{7.67}\n\\end{equation*}\n\n\n期望改善是定义一个样本 $\\boldsymbol{x}$ 在当前模型 $p_{\\mathcal{G P}}(f(\\boldsymbol{x}) \\mid \\boldsymbol{x}, \\mathcal{H})$ 下, $f(\\boldsymbol{x})$ 超过最好结果 $y^{*}$ 的期望. 除了期望改善函数之外，收益函数还有其他定义形式，比如改善概\\\\\n率 (Probability of Improvement) 、高斯过程置信上界 (GP Upper Confidence Bound, GP-UCB) 等.\n\n时序模型优化方法如算法7.1所示. 贝叶斯优化的一个缺点是高斯过程建模需要计算协方差矩阵的逆, 时间复杂度是 $O\\left(N^{3}\\right)$, 因此不能很好地处理高维情况. 深度神经网络的超参数一般比较多, 为了使用贝叶斯优化来搜索神经网络的超参数, 需要一些更高效的高斯过程建模. 也有一些方法可以将时间复杂度从 $O\\left(N^{3}\\right)$ 降低到 $O(N)$ [Snoek et al., 2015].\n\n算法 7.1 时序模型优化 (SMBO ) 方法\n\n输入: 优化目标函数 $f(\\boldsymbol{x})$, 迭代次数 $T$, 收益函数 $a(x, \\mathcal{H})$\n\n$1 \\mathcal{H} \\leftarrow \\varnothing ;$\n\n2 随机初始化高斯过程,并计算 $p_{\\mathcal{G P}}(f(\\boldsymbol{x}) \\mid \\boldsymbol{x}, \\mathcal{H})$;\n\n3 for $t \\leftarrow 1$ to $T$ do\n\n$4 \\quad x^{\\prime} \\leftarrow \\arg \\max _{x} a(x, \\mathcal{H}) ;$\n\n5 评价 $y^{\\prime}=f\\left(\\boldsymbol{x}^{\\prime}\\right)$;\n\n$6 \\quad \\mathcal{H} \\leftarrow \\mathcal{H} \\cup\\left(\\boldsymbol{x}^{\\prime}, y^{\\prime}\\right)$;\n\n$7 \\quad$ 根据 $\\mathcal{H}$ 重新建模高斯过程, 并计算 $p_{\\mathcal{G} P}(f(\\boldsymbol{x}) \\mid \\boldsymbol{x}, \\mathcal{H})$;\n\n8 end 输出: $\\mathcal{H}$"
    },
    {
        "id": "chatcmpl-944BdIu9JXtnVvk03x31ubWgZTSp3",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "logprobs": null,
                "message": {
                    "content": "{\n    \"问题1\": \"贝叶斯优化是什么？它的作用是什么？\",\n    \"回答1\": \"贝叶斯优化是一种自适应的超参数优化方法，根据当前已经试验的超参数组合，来预测下一个可能带来最大收益的组合。其作用在于通过建模高斯过程，并计算后验分布，来寻找使得目标函数收益最大的超参数组合。\",\n    \"问题2\": \"时序模型优化 (SMBO) 是什么？它与贝叶斯优化有何关联？\",\n    \"回答2\": \"时序模型优化 (SMBO) 是一种比较常用的贝叶斯优化方法，假设超参数优化的函数 $f(\\boldsymbol{x})$ 服从高斯过程，通过建模高斯过程和计算后验分布来寻找使得目标函数收益最大的超参数组合。\",\n    \"问题3\": \"为了使得后验分布接近其真实分布，贝叶斯优化中需要做什么？\",\n    \"回答3\": \"为了使得后验分布接近其真实分布，贝叶斯优化中需要对样本空间进行足够多的采样。然而，由于超参数优化中每一个样本的生成成本很高，需要用尽可能少的样本来使得后验分布接近于真实分布。\",\n    \"问题4\": \"在贝叶斯优化中，如何判断一个样本是否能够给建模后验分布提供更多的收益？\",\n    \"回答4\": \"在贝叶斯优化中，判断一个样本是否能够给建模后验分布提供更多的收益是通过定义一个收益函数（Acquisition Function）$a(x, \\boldsymbol{\\text{H}})$ 来实现的。收益越大，其修正的高斯过程会越接近目标函数的真实分布。\",\n    \"问题5\": \"期望改善 (EI) 函数在贝叶斯优化中起到什么作用？\",\n    \"回答5\": \"期望改善 (EI) 函数在贝叶斯优化中用于定义一个样本 $\\boldsymbol{x}$ 在当前模型下，超过最好结果的期望。它是一种常用的收益函数定义方式之一。\",\n    \"问题6\": \"除了期望改善函数之外，还有哪些其他形式的收益函数？\",\n    \"回答6\": \"除了期望改善函数之外，还有其他形式的收益函数，比如改善概率 (Probability of Improvement)、高斯过程置信上界 (GP Upper Confidence Bound, GP-UCB) 等。\",\n    \"问题7\": \"贝叶斯优化方法中高斯过程建模存在什么缺点？\",\n    \"回答7\": \"贝叶斯优化方法中高斯过程建模需要计算协方差矩阵的逆，时间复杂度是 $O(N^3)$，因此不能很好地处理高维情况。对于深度神经网络等超参数较多的情况，需要一些更高效的高斯过程建模方法。\",\n    \"问题8\": \"如何降低贝叶斯优化方法中高斯过程建模的时间复杂度？\",\n    \"回答8\": \"为了降低贝叶斯优化方法中高斯过程建模的时间复杂度，可以采用一些方法将时间复杂度从 $O(N^3)$ 降低到 $O(N)$。这些方法可以帮助处理深度神经网络等超参数较多、高维情况下的高效建模需求。\",\n    \"问题9\": \"时序模型优化 (SMBO) 方法的基本流程是什么？\",\n    \"回答9\": \"时序模型优化 (SMBO) 方法的基本流程包括随机初始化高斯过程并计算后验分布，然后通过迭代选择收益最大的样本进行评价，并根据评价结果重新建模高斯过程和计算后验分布。\",\n    \"问题10\": \"时序模型优化 (SMBO) 方法如何选择下一个要评价的样本？\",\n    \"回答10\": \"时序模型优化 (SMBO) 方法选择下一个要评价的样本是通过选择使得收益函数最大的样本 $\\boldsymbol{x}^{\\text{'}}$ 来实现的。\"\n}",
                    "role": "assistant",
                    "function_call": null,
                    "tool_calls": null
                }
            }
        ],
        "created": 1710756433,
        "model": "gpt-3.5-turbo-1106",
        "object": "chat.completion",
        "system_fingerprint": "fp_4aaaf0dc94",
        "usage": {
            "completion_tokens": 1253,
            "prompt_tokens": 3962,
            "total_tokens": 5215
        },
        "parameters": {
            "model": "gpt-3.5-turbo-1106",
            "temperature": 0.2,
            "frequency_penalty": 0.15,
            "presence_penalty": 0.15
        }
    }
]