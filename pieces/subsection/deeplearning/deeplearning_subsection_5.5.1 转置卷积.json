[
    {
        "strategy": "subsection",
        "source": "deeplearning",
        "title": "5.5.1 转置卷积",
        "content_length": 3232,
        "content": "Title: 5.5.1 转置卷积\nContent:\n我们一般可以通过卷积操作来实现高维特征到低维特征的转换. 比如在一维卷积中, 一个 5 维的输入特征, 经过一个大小为 3 的卷积核, 其输出为 3 维特征.如果设置步长大于 1 , 可以进一步降低输出特征的维数. 但在一些任务中, 我们需要将低维特征映射到高维特征,并且依然希望通过卷积操作来实现.\n\n假设有一个高维向量为 $\\boldsymbol{x} \\in \\mathbb{R}^{d}$ 和一个低维向量为 $\\boldsymbol{z} \\in \\mathbb{R}^{p}, p<d$. 如果用仿射变换 (Affine Transformation ) 来实现高维到低维的映射,\n\n\n\\begin{equation*}\nz=W x \\tag{5.42}\n\\end{equation*}\n\n\n其中 $\\boldsymbol{W} \\in \\mathbb{R}^{p \\times d}$ 为转换矩阵. 我们可以很容易地通过转置 $\\boldsymbol{W}$ 来实现低维到高维的反向映射, 即\n\n\n\\begin{equation*}\n\\boldsymbol{x}=\\boldsymbol{W}^{\\top} \\boldsymbol{z} \\tag{5.43}\n\\end{equation*}\n\n\n需要说明的是, 公式 (5.42) 和公式 (5.43) 并不是逆运算, 两个映射只是形式上的转置关系.\n\n在全连接网络中, 忽略激活函数, 前向计算和反向传播就是一种转置关系.比如前向计算时, 第 $l+1$ 层的净输入为 $\\boldsymbol{z}^{(l+1)}=\\boldsymbol{W}^{(l+1)} \\boldsymbol{z}^{(l)}$, 反向传播时, 第 $l$ 层的误差项为 $\\delta^{(l)}=\\left(\\boldsymbol{W}^{(l+1)}\\right)^{\\top} \\delta^{(l+1)}$.\n\n参见公式(4.63).\n\n卷积操作也可以写为仿射变换的形式. 假设一个 5 维向量 $\\boldsymbol{x}$, 经过大小为 3 的卷积核 $\\boldsymbol{w}=\\left[w_{1}, w_{2}, w_{3}\\right]^{\\top}$ 进行卷积, 得到 3 维向量 $\\boldsymbol{z}$. 卷积操作可以写为\n\n\n\\begin{align*}\n\\boldsymbol{z} & =\\boldsymbol{w} \\otimes \\boldsymbol{x}  \\tag{5.44}\\\\\n& =\\left[\\begin{array}{lllll}\nw_{1} & w_{2} & w_{3} & 0 & 0 \\\\\n0 & w_{1} & w_{2} & w_{3} & 0 \\\\\n0 & 0 & w_{1} & w_{2} & w_{3}\n\\end{array}\\right] \\boldsymbol{x}  \\tag{5.45}\\\\\n& =\\boldsymbol{C} \\boldsymbol{x} \\tag{5.46}\n\\end{align*}\n\n\n参见习题5-5.\n\n其中 $\\boldsymbol{C}$ 是一个稀疏矩阵,其非零元素来自于卷积核 $\\boldsymbol{w}$ 中的元素.\\\\\n如果要实现 3 维向量 $\\boldsymbol{z}$ 到 5 维向量 $\\boldsymbol{x}$ 的映射, 可以通过仿射矩阵的转置来实现, 即\n\n\n\\begin{align*}\n\\boldsymbol{x} & =\\boldsymbol{C}^{\\top} \\boldsymbol{z}  \\tag{5.47}\\\\\n& =\\left[\\begin{array}{ccc}\nw_{1} & 0 & 0 \\\\\nw_{2} & w_{1} & 0 \\\\\nw_{3} & w_{2} & w_{1} \\\\\n0 & w_{3} & w_{2} \\\\\n0 & 0 & w_{3}\n\\end{array}\\right] \\boldsymbol{z}  \\tag{5.48}\\\\\n& =\\operatorname{rot} 180(\\boldsymbol{w}) \\tilde{\\otimes} \\boldsymbol{z}, \\tag{5.49}\n\\end{align*}\n\n\n其中 $\\operatorname{rot} 180(\\cdot)$ 表示旋转 180 度.\n\n从公式 (5.45)和公式 (5.48) 可以看出, 从仿射变换的角度来看两个卷积操作 $\\boldsymbol{z}=\\boldsymbol{w} \\otimes \\boldsymbol{x}$ 和 $\\boldsymbol{x}=\\operatorname{rot} 180(\\boldsymbol{w}) \\tilde{\\otimes} \\boldsymbol{z}$ 也是形式上的转置关系. 因此, 我们将低维特征映射到高维特征的卷积操作称为转置卷积 (Transposed Convolution) [Dumoulin et al., 2016],也称为反卷积 ( Deconvolution ) [Zeiler et al., 2011].\n\n在卷积网络中,卷积层的前向计算和反向传播也是一种转置关系.\n\n对一个 $M$ 维的向量 $\\boldsymbol{z}$, 和大小为 $K$ 的卷积核, 如果希望通过卷积操作来映射到更高维的向量, 只需要对向量 $\\boldsymbol{z}$ 进行两端补零 $P=K-1$, 然后进行卷积, 可以将转置卷积称为反卷积 (Deconvolution)并不太恰当, 它不是指卷积的逆运算.参见习题5-7.\n\n即宽卷积.得到 $M+K-1$ 维的向量.\n\n转置卷积同样适用于二维卷积. 图5.16给出了一个步长 $S=1$, 无零填充 $P=0$ 的二维卷积和其对应的转置卷积.\n\n\n\n(a) 卷积, $S=1, P=0$\n\n\n\n(b) 转置卷积, $S=1, P=2$\n\n图 5.16 步长 $S=1$, 无零填充 $P=0$ 的二维卷积和其对应的转置卷积\\\\\n微步卷积 我们可以通过增加卷积操作的步长 $S>1$ 来实现对输入特征的下采样操作, 大幅降低特征维数. 同样, 我们也可以通过减少转置卷积的步长 $S<1$来实现上采样操作, 大幅提高特征维数. 步长 $S<1$ 的转置卷积也称为微步卷积 (Fractionally-Strided Convolution) [Long et al., 2015]. 为了实现微步卷积, 我们可以在输入特征之间插入 0 来间接地使得步长变小.\n\n如果卷积操作的步长为 $S>1$, 希望其对应的转置卷积的步长为 $\\frac{1}{S}$, 需要在输入特征之间插入 $S-1$ 个 0 来使得其移动的速度变慢.\n\n以一维转置卷积为例, 对一个 $M$ 维的向量 $\\boldsymbol{z}$, 和大小为 $K$ 的卷积核, 通过对向量 $\\boldsymbol{z}$ 进行两端补零 $P=K-1$, 并且在每两个向量元素之间插入 $D$ 个 0 , 然后进行步长为 1 的卷积, 可以得到 $(D+1) \\times(M-1)+K$ 维的向量.\n\n图5.17 给出了一个步长 $S=2$, 无零填充 $P=0$ 的二维卷积和其对应的转置卷积.\n\n\n\n(a) 卷积 $, S=2, P=0$\n\n\n\n(b) 转置卷积, $S=1, P=2, D=1$\n\n图 5.17 步长 $S=2$, 无零填充 $P=0$ 的二维卷积和其对应的转置卷积"
    },
    {
        "id": "chatcmpl-941vEPxBVMJD31saNjtRGrPteLlp8",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "logprobs": null,
                "message": {
                    "content": "{\n    \"问题1\": \"卷积操作和转置卷积的主要区别是什么？\",\n    \"回答1\": \"卷积操作通常实现高维特征到低维特征的转换，而转置卷积则实现低维特征到高维特征的映射。此外，转置卷积可以通过对输入特征之间插入 0 来实现上采样操作，大幅提高特征维数，这是与卷积操作的主要区别。\",\n    \"问题2\": \"如何通过仿射变换来实现高维到低维的映射？\",\n    \"回答2\": \"通过仿射变换 $z=Wx$ 可以实现高维向量 $\\boldsymbol{x} \\text{ 为 } \\boldsymbol{x} \\text{ 为 } \\boldsymbol{R}^{d}$ 到低维向量 $\\boldsymbol{z} \\text{ 为 } \\boldsymbol{R}^{p}, p<d$ 的映射，其中 $\\boldsymbol{W} \\text{ 为 } \\boldsymbol{R}^{p \\times d}$ 为转换矩阵。\",\n    \"问题3\": \"转置矩阵如何实现低维到高维的反向映射？\",\n    \"回答3\": \"通过转置矩阵 $\\boldsymbol{x}=\\boldsymbol{W}^{\\top} \\boldsymbol{z}$ 可以实现低维向量 $\\boldsymbol{z}$ 到高维向量 $\\boldsymbol{x}$ 的反向映射。\",\n    \"问题4\": \"在全连接网络中，前向计算和反向传播之间存在什么关系？\",\n    \"回答4\": \"在全连接网络中，忽略激活函数，前向计算和反向传播形成一种转置关系。具体来说，前向计算时，第 $l+1$ 层的净输入为 $\\boldsymbol{z}^{(l+1)}=\\boldsymbol{W}^{(l+1)} \\boldsymbol{z}^{(l)}$；反向传播时，第 $l$ 层的误差项为 $\\boldsymbol{\\text{delta}}^{(l)}=\\big(\\boldsymbol{W}^{(l+1)}\\big)^{\\top} \\boldsymbol{\\text{delta}}^{(l+1)}$。\",\n    \"问题5\": \"转置卷积在卷积网络中的作用是什么？\",\n    \"回答5\": \"转置卷积在卷积网络中用于实现对输入特征的上采样操作，从而提高特征维数。它也可以通过增加卷积操作的步长 $S>1$ 来实现下采样操作，大幅降低特征维数。\",\n    \"问题6\": \"如何通过卷积操作将低维特征映射到高维特征？\",\n    \"回答6\": \"通过对低维向量 $\\boldsymbol{z}$ 进行两端补零 $P=K-1$，然后进行卷积，可以将低维特征映射到更高维度的向量。这个过程也被称为宽卷积，得到 $M+K-1$ 维的向量。\",\n    \"问题7\": \"转置卷积和反卷积有何区别？\",\n    \"回答7\": \"将转置卷积称为反卷积并不太恰当，因为它并不是指卷积的逆运算。转置卷积主要用于实现上采样操作，而反卷积通常指的是还原由卷积操作引起的信息损失。\",\n    \"问题8\": \"如何实现微步卷积？\",\n    \"回答8\": \"要实现微步卷积，可以通过减少转置卷积的步长 $S<1$来实现上采样操作，大幅提高特征维数。此外，在输入特征之间插入 0 来间接地使得步长变小。\",\n    \"问题9\": \"如何通过转置卷积实现对输入特征的下采样操作？\",\n    \"回答9\": \"如果希望通过转置卷积来实现对输入特征的下采样操作，需要在输入特征之间插入 $S-1$ 个 0 来使得其移动的速度变慢。\",\n    \"问题10\": \"转置卷积和标准卷积之间有怎样的形式上关系？\",\n    \"回答10\": \"从仿射变换的角度来看，两个卷积操作 $\\boldsymbol{z}=\\boldsymbol{w} \\bigotimes \\boldsymbol{x}$ 和 $\\boldsymbol{x}=\\text{rot} 180(\\boldsymbol{w}) \\tilde{\\bigotimes} \\boldsymbol{z}$ 也是形式上的转置关系。因此，我们将低维特征映射到高维特征的卷积操作称为转置卷积（Transposed Convolution），也称为反卷积（Deconvolution）。\"\n}",
                    "role": "assistant",
                    "function_call": null,
                    "tool_calls": null
                }
            }
        ],
        "created": 1710747728,
        "model": "gpt-3.5-turbo-1106",
        "object": "chat.completion",
        "system_fingerprint": "fp_4aaaf0dc94",
        "usage": {
            "completion_tokens": 1389,
            "prompt_tokens": 4818,
            "total_tokens": 6207
        },
        "parameters": {
            "model": "gpt-3.5-turbo-1106",
            "temperature": 0.2,
            "frequency_penalty": 0.15,
            "presence_penalty": 0.15
        }
    }
]