[
    {
        "strategy": "subsection",
        "source": "deeplearning",
        "title": "13.3.5 模型分析",
        "content_length": 2157,
        "content": "Title: 13.3.5 模型分析\nContent:\n我们把判别网络和生成网络合并为一个整体, 将整个生成对抗网络的目标函数看作最小化最大化游戏 (Minimax Game ) :\n\n\n\\begin{align*}\n& \\min _{\\theta} \\max _{\\phi}\\left(\\mathbb{E}_{\\boldsymbol{x} \\sim p_{r}(\\boldsymbol{x})}[\\log D(\\boldsymbol{x} ; \\phi)]+\\mathbb{E}_{\\boldsymbol{x} \\sim p_{\\theta}(\\boldsymbol{x})}[\\log (1-D(\\boldsymbol{x} ; \\phi))]\\right)  \\tag{13.35}\\\\\n= & \\min _{\\theta} \\max _{\\phi}\\left(\\mathbb{E}_{\\boldsymbol{x} \\sim p_{r}(\\boldsymbol{x})}[\\log D(\\boldsymbol{x} ; \\boldsymbol{\\phi})]+\\mathbb{E}_{\\boldsymbol{z} \\sim p(\\boldsymbol{z})}[\\log (1-D(G(\\boldsymbol{z} ; \\theta) ; \\phi))]\\right) . \\tag{13.36}\n\\end{align*}\n\n\n因为之前提到的生成网络梯度问题, 这个最小化最大化形式的目标函数一般用来进行理论分析,并不是实际训练时的目标函数.\\\\\n假设 $p_{r}(\\boldsymbol{x})$ 和 $p_{\\theta}(\\boldsymbol{x})$ 已知, 则最优的判别器为\n\n\n\\begin{equation*}\nD^{\\star}(\\boldsymbol{x})=\\frac{p_{r}(\\boldsymbol{x})}{p_{r}(\\boldsymbol{x})+p_{\\theta}(\\boldsymbol{x})} . \\tag{13.37}\n\\end{equation*}\n\n\n将最优的判别器 $D^{\\star}(\\boldsymbol{x})$ 代入公式(13.35), 其目标函数变为\n\n\n\\begin{align*}\n\\mathcal{L}\\left(G \\mid D^{\\star}\\right) & =\\mathbb{E}_{\\boldsymbol{x} \\sim p_{r}(\\boldsymbol{x})}\\left[\\log D^{\\star}(\\boldsymbol{x})\\right]+\\mathbb{E}_{\\boldsymbol{x} \\sim p_{\\theta}(\\boldsymbol{x})}\\left[\\log \\left(1-D^{\\star}(\\boldsymbol{x})\\right)\\right]  \\tag{13.38}\\\\\n& =\\mathbb{E}_{\\boldsymbol{x} \\sim p_{r}(\\boldsymbol{x})}\\left[\\log \\frac{p_{r}(\\boldsymbol{x})}{p_{r}(\\boldsymbol{x})+p_{\\theta}(\\boldsymbol{x})}\\right]+\\mathbb{E}_{\\boldsymbol{x} \\sim p_{\\theta}(\\boldsymbol{x})}\\left[\\log \\frac{p_{\\theta}(\\boldsymbol{x})}{p_{r}(\\boldsymbol{x})+p_{\\theta}(\\boldsymbol{x})}\\right]  \\tag{13.39}\\\\\n& =\\mathrm{KL}\\left(p_{r}, p_{a}\\right)+\\operatorname{KL}\\left(p_{\\theta}, p_{a}\\right)-2 \\log 2  \\tag{13.40}\\\\\n& =2 \\mathrm{JS}\\left(p_{r}, p_{\\theta}\\right)-2 \\log 2, \\tag{13.41}\n\\end{align*}\n\n\n其中 $\\mathrm{JS}(\\cdot)$ 为 $\\mathrm{JS}$ 散度, $p_{a}(\\boldsymbol{x})=\\frac{1}{2}\\left(p_{r}(\\boldsymbol{x})+p_{\\theta}(\\boldsymbol{x})\\right)$ 为一个“平均”分布.\n\nJS 散度参见第E.3.3节。\n\n在生成对抗网络中, 当判别网络为最优时, 生成网络的优化目标是最小化真实分布 $p_{r}$ 和模型分布 $p_{\\theta}$ 之间的 $\\mathrm{JS}$ 散度. 当两个分布相同时, $\\mathrm{JS}$ 散度为 0 , 最优生成网络 $G^{\\star}$ 对应的损失为 $\\mathcal{L}\\left(G^{\\star} \\mid D^{\\star}\\right)=-2 \\log 2$."
    },
    {
        "id": "chatcmpl-945aTeBe13lqcv68gbJbD6v0nAkmq",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "logprobs": null,
                "message": {
                    "content": "{\n    \"问题1\": \"生成对抗网络的目标函数采用了怎样的最小化最大化形式？\",\n    \"回答1\": \"生成对抗网络的目标函数采用了最小化最大化游戏（Minimax Game）形式，即 $\\text{min}_{\\theta} \\text{max}_{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\theta}}}}}}}}}}}}}}}}}}}\\big(\\text{E}_{\\boldsymbol{x} \\text{ 从 } p_{r}(\\boldsymbol{x})}[\\text{log} D(\\boldsymbol{x} ; \\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{x}}}}}}}}}}}}}})]+\\text{E}_{\\boldsymbol{x} \\text{ 从 } p_{\\theta}(\\boldsymbol{x})}[\\text{log} (1-D(\\boldsymbol{x} ; \\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\theta}}}}}}}))]\\big)$。\",\n    \"问题2\": \"生成对抗网络中的最优判别器 $D^{\\bigstar}(\\boldsymbol{x})$ 是如何定义的？\",\n    \"回答2\": \"在生成对抗网络中，假设 $p_{r}(\\boldsymbol{x})$ 和 $p_{\\theta}(\\boldsymbol{x})$ 已知，则最优的判别器 $D^{\\bigstar}(\\boldsymbol{x})$ 定义为 $D^{\\bigstar}(\\boldsymbol{x})=\\frac{p_{r}(\\boldsymbol{x})}{p_{r}(\\boldsymbol{x})+p_{\\theta}(\\boldsymbol{x})}$。\",\n    \"问题3\": \"将最优的判别器代入生成对抗网络的目标函数后，其形式变为什么？\",\n    \"回答3\": \"将最优的判别器 $D^{\\bigstar}(\\boldsymbol{x})$ 代入生成对抗网络的目标函数后，其形式变为 $\\text{L}\\big(G \\big| D^{\\bigstar}\\big)=\\text{E}_{\\boldsymbol{x} \\text{ 从 } p_{r}(\\boldsymbol{x})}\\big[\\text{log} D^{\\bigstar}(\\boldsymbol{x})\\big]+\\text{E}_{\\boldsymbol{x} \\text{ 从 } p_{\\theta}(\\boldsymbol{x})}\\big[\\text{log} \\big(1-D^{\\bigstar}(\\boldsymbol{x})\\big)\\big]$。\",\n    \"问题4\": \"生成对抗网络中的损失函数 $\\text{L}\\big(G \\big| D^{\\bigstar}\\big)$ 可以表示为哪些统计量之间的关系？\",\n    \"回答4\": \"生成对抗网络中的损失函数 $\\text{L}\\big(G \\big| D^{\\bigstar}\\big)$ 可以表示为真实分布 $p_{r}$ 和模型分布 $p_{\\theta}$ 之间的 Kullback-Leibler 散度（KL 散度）和 Jensen-Shannon 散度（JS 散度）之间的关系。\",\n    \"问题5\": \"在生成对抗网络中，当判别网络为最优时，生成网络的优化目标是什么？\",\n    \"回答5\": \"在生成对抗网络中，当判别网络为最优时，生成网络的优化目标是最小化真实分布 $p_{r}$ 和模型分布 $p_{\\theta}$ 之间的 Jensen-Shannon 散度（JS 散度），即使两个分布相同时，JS 散度为 0，最优生成网络 $G^{\\bigstar}$ 对应的损失为 $\\text{L}\\big(G^{\\bigstar} \\big| D^{\\bigstar}\\big)=-2 \\text{log} 2$。\",\n    \"问题6\": \"在生成对抗网络中，什么情况下两个分布的 Jensen-Shannon 散度为 0？\",\n    \"回答6\": \"在生成对抗网络中，当真实分布 $p_{r}$ 和模型分布 $p_{\\theta}$ 相同时，它们之间的 Jensen-Shannon 散度为 0。\",\n    \"问题7\": \"在生成对抗网络中，平均分布 $p_{a}(\\boldsymbol{x})$ 是如何定义的？\",\n    \"回答7\": \"在生成对抗网络中，平均分布 $p_{a}(\\boldsymbol{x})$ 定义为 $p_{a}(\\boldsymbol{x})=\\frac{1}{2}\\big(p_{r}(\\boldsymbol{x})+p_{\\theta}(\\boldsymbol{x})\\big)$。\",\n    \"问题8\": \"在生成对抗网络中，损失函数 $\\text{L}\\big(G \\big| D^{\\bigstar}\\big)$ 可以通过哪些统计量进行简化表示？\",\n    \"回答8\": \"在生成对抗网络中，损失函数 $\\text{L}\\big(G \\big| D^{\\bigstar}\\big)$ 可以通过 Kullback-Leibler 散度（KL 散度）和 Jensen-Shannon 散度（JS 散度）进行简化表示为 $2 \\text{JS}\\big(p_{r}, p_{\\theta}\\big)-2 \\text{log} 2$。\",\n    \"问题9\": \"在生成对抗网络中，JS 散度和 KL 散度之间有怎样的关系？\",\n    \"回答9\": \"在生成对抗网络中，JS 散度和 KL 散度之间有关系：$\\text{KL}\\big(p_{r}, p_{a}\\big)+\\text{KL}\\big(p_{\\theta}, p_{a}\\big)-2 \\text{log} 2 = 2 \\text{JS}\\big(p_{r}, p_{\\theta}\\big)-2 \\text{log} 2$。\",\n    \"问题10\": \"为什么生成对抗网络中使用平均分布 $p_{a}$ 进行损失函数计算？\",\n    \"回答10\": \"在生成对抗网络中使用平均分布 $p_{a}$ 进行损失函数计算是因为平均分布能够更好地衡量真实分布和模型分布之间的差异，从而更准确地评估模型训练的效果。\"\n}",
                    "role": "assistant",
                    "function_call": null,
                    "tool_calls": null
                }
            }
        ],
        "created": 1710761817,
        "model": "gpt-3.5-turbo-1106",
        "object": "chat.completion",
        "system_fingerprint": "fp_4aaaf0dc94",
        "usage": {
            "completion_tokens": 1643,
            "prompt_tokens": 3597,
            "total_tokens": 5240
        },
        "parameters": {
            "model": "gpt-3.5-turbo-1106",
            "temperature": 0.2,
            "frequency_penalty": 0.15,
            "presence_penalty": 0.15
        }
    }
]