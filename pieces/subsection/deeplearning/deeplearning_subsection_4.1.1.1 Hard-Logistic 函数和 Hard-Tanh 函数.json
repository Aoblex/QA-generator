[
    {
        "strategy": "subsection",
        "source": "deeplearning",
        "title": "4.1.1.1 Hard-Logistic 函数和 Hard-Tanh 函数",
        "content_length": 1250,
        "content": "Title: 4.1.1.1 Hard-Logistic 函数和 Hard-Tanh 函数\nContent:\nLogistic 函数和 Tanh 函数都是 Sigmoid 型函数, 具有饱和性, 但是计算开销较大. 因为这两个函数都是在中间 (0 附近) 近似线性, 两端饱和. 因此, 这两个函数可以通过分段函数来近似.\n\n\\href{https://nndl.github.io/}{https://nndl.github.io/}\\\\\n以 Logistic 函数 $\\sigma(x)$ 为例, 其导数为 $\\sigma^{\\prime}(x)=\\sigma(x)(1-\\sigma(x))$. Logistic 函数在 0 附近的一阶泰勒展开 (Taylor expansion) 为\n\n\n\\begin{align*}\ng_{l}(x) & \\approx \\sigma(0)+x \\times \\sigma^{\\prime}(0)  \\tag{4.7}\\\\\n& =0.25 x+0.5 . \\tag{4.8}\n\\end{align*}\n\n\n这样 Logistic 函数可以用分段函数 hard-logistic $(x)$ 来近似.\n\n\n\\begin{align*}\n\\operatorname{hard-\\operatorname {logistic}(x)} & = \\begin{cases}1 & g_{l}(x) \\geq 1 \\\\\ng_{l} & 0<g_{l}(x)<1 \\\\\n0 & g_{l}(x) \\leq 0\\end{cases}  \\tag{4.9}\\\\\n& =\\max \\left(\\min \\left(g_{l}(x), 1\\right), 0\\right)  \\tag{4.10}\\\\\n& =\\max (\\min (0.25 x+0.5,1), 0) . \\tag{4.11}\n\\end{align*}\n\n\n同样, Tanh 函数在 0 附近的一阶泰勒展开为\n\n\n\\begin{align*}\ng_{t}(x) & \\approx \\tanh (0)+x \\times \\tanh ^{\\prime}(0)  \\tag{4.12}\\\\\n& =x \\tag{4.13}\n\\end{align*}\n\n\n\n\n\n\\begin{align*}\n\\operatorname{hard}-\\tanh (x) & =\\max \\left(\\min \\left(g_{t}(x), 1\\right),-1\\right)  \\tag{4.14}\\\\\n& =\\max (\\min (x, 1),-1) . \\tag{4.15}\n\\end{align*}\n\n\n图4.3给出了 Hard-Logistic 函数和 Hard-Tanh 函数的形状.\n\n\n\n(a) Hard Logistic 函数\n\n\n\n(b) Hard Tanh 函数\n\n图 4.3 Hard Sigmoid 型激活函数"
    },
    {
        "id": "chatcmpl-941Gq8L811QOQEoP02SjabvljHLTd",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "logprobs": null,
                "message": {
                    "content": "{\n    \"问题1\": \"Logistic 函数和 Tanh 函数的特点是什么？\",\n    \"回答1\": \"Logistic 函数和 Tanh 函数都是 Sigmoid 型函数，具有饱和性，但是计算开销较大。它们在中间（0 附近）近似线性，两端饱和。因此，这两个函数可以通过分段函数来近似。\",\n    \"问题2\": \"Logistic 函数的一阶泰勒展开形式是怎样的？\",\n    \"回答2\": \"以 Logistic 函数 $\\text{为例，其导数为 }\\boldsymbol{\\text{σ}}^{\\boldsymbol{\\text{prime}}}(x)=\\boldsymbol{\\text{σ}}(x)(1-\\boldsymbol{\\text{σ}}(x))$。Logistic 函数在 0 附近的一阶泰勒展开为 $g_{l}(x) \\text{约等于} \\boldsymbol{\\text{σ}}(0)+x \\times \\boldsymbol{\\text{σ}}^{\\boldsymbol{\\text{prime}}}(0) =0.25 x+0.5$。\",\n    \"问题3\": \"Hard-Logistic 函数是如何定义的？\",\n    \"回答3\": \"Hard-Logistic 函数定义为 $\\text{hard-}\\boldsymbol{\\text{logistic}}(x) = \\begin{cases}1 & g_{l}(x) \\text{大于等于} 1 \\\\ g_{l} & 0<g_{l}(x)<1 \\\\ 0 & g_{l}(x) \\text{小于等于} 0\\big\\rbrace =\\text{max}\\big(\\text{min}\\big(g_{l}(x), 1\\big), 0\\big) =\\text{max}\\big(\\text{min}\\big(0.25 x+0.5,1\\big), 0\\big)$。\",\n    \"问题4\": \"Tanh 函数的一阶泰勒展开形式是怎样的？\",\n    \"回答4\": \"Tanh 函数在 0 附近的一阶泰勒展开为 $g_{t}(x) \\text{约等于} \\tanh (0)+x \\times \\tanh ^{\\boldsymbol{\\text{prime}}}(0) =x$。\",\n    \"问题5\": \"Hard-Tanh 函数是如何定义的？\",\n    \"回答5\": \"Hard-Tanh 函数定义为 $\\text{hard-}\\tanh (x) =\\text{max}\\big(\\text{min}\\big(g_{t}(x), 1\\big),-1\\big) =\\text{max}\\big(\\text{min}\\big(x, 1\\big),-1\\big)$。\",\n    \"问题6\": \"Hard-Logistic 函数和 Hard-Tanh 函数分别对应于什么形状？\",\n    \"回答6\": \"(a) Hard Logistic 函数对应图4.3中的 Hard Logistic 函数形状；(b) Hard Tanh 函数对应图4.3中的 Hard Tanh 函数形状。\",\n    \"问题7\": \"Hard-Logistic 函数和 Hard-Tanh 函数的分段特性有什么作用？\",\n    \"回答7\": \"Hard-Logistic 函数和 Hard-Tanh 函数通过分段函数来近似 Logistic 函数和 Tanh 函数，从而减少计算开销。它们在输入较大或较小时能够保持输出的稳定性，同时具有一定程度的非线性特性。\",\n    \"问题8\": \"Hard-Logistic 函数和 Hard-Tanh 函数相比原始函数有何优势？\",\n    \"回答8\": \"Hard-Logistic 函数和 Hard-Tanh 函数相比原始函数具有更低的计算开销，并且在输入较大或较小时能够保持输出的稳定性。它们通过分段函数的方式来近似原始函数，能够更有效地应用于神经网络模型中。\",\n    \"问题9\": \"Sigmoid 型函数为什么需要通过分段函数来近似？\",\n    \"回答9\": \"Sigmoid 型函数（如 Logistic 函数和 Tanh 函数）在中间（0 附近）近似线性，两端饱和，因此可以通过分段函数来近似。这样可以减少计算开销，并且在神经网络中更加高效地应用这些激活函数。\",\n    \"问题10\": \"Hard-Logistic 函数和 Hard-Tanh 函数如何影响神经网络模型的性能？\",\n    \"回答10\": \"Hard-Logistic 函数和 Hard-Tanh 函数能够减少计算开销，并且在输入较大或较小时能够保持输出的稳定性。它们通过分段函数的方式来近似原始函数，从而提高了神经网络模型的计算效率和稳定性，对模型性能有积极影响。\"\n}",
                    "role": "assistant",
                    "function_call": null,
                    "tool_calls": null
                }
            }
        ],
        "created": 1710745224,
        "model": "gpt-3.5-turbo-1106",
        "object": "chat.completion",
        "system_fingerprint": "fp_4aaaf0dc94",
        "usage": {
            "completion_tokens": 1255,
            "prompt_tokens": 3210,
            "total_tokens": 4465
        },
        "parameters": {
            "model": "gpt-3.5-turbo-1106",
            "temperature": 0.2,
            "frequency_penalty": 0.15,
            "presence_penalty": 0.15
        }
    }
]