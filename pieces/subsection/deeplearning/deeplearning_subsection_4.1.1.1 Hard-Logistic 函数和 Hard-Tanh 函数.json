[
    {
        "strategy": "subsection",
        "source": "deeplearning",
        "title": "4.1.1.1 Hard-Logistic 函数和 Hard-Tanh 函数",
        "content_length": 1568,
        "content": "Title: 4.1.1.1 Hard-Logistic 函数和 Hard-Tanh 函数\nContent:\nLogistic 函数和 Tanh 函数都是 Sigmoid 型函数, 具有饱和性, 但是计算开销较大. 因为这两个函数都是在中间 (0 附近) 近似线性, 两端饱和. 因此, 这两个函数可以通过分段函数来近似.\n\n\\href{https://nndl.github.io/}{https://nndl.github.io/}\\\\\n以 Logistic 函数 $\\sigma(x)$ 为例, 其导数为 $\\sigma^{\\prime}(x)=\\sigma(x)(1-\\sigma(x))$. Logistic 函数在 0 附近的一阶泰勒展开 (Taylor expansion) 为\n\n\n\\begin{align*}\ng_{l}(x) & \\approx \\sigma(0)+x \\times \\sigma^{\\prime}(0)  \\tag{4.7}\\\\\n& =0.25 x+0.5 . \\tag{4.8}\n\\end{align*}\n\n\n这样 Logistic 函数可以用分段函数 hard-logistic $(x)$ 来近似.\n\n\n\\begin{align*}\n\\operatorname{hard-\\operatorname {logistic}(x)} & = \\begin{cases}1 & g_{l}(x) \\geq 1 \\\\\ng_{l} & 0<g_{l}(x)<1 \\\\\n0 & g_{l}(x) \\leq 0\\end{cases}  \\tag{4.9}\\\\\n& =\\max \\left(\\min \\left(g_{l}(x), 1\\right), 0\\right)  \\tag{4.10}\\\\\n& =\\max (\\min (0.25 x+0.5,1), 0) . \\tag{4.11}\n\\end{align*}\n\n\n同样, Tanh 函数在 0 附近的一阶泰勒展开为\n\n\n\\begin{align*}\ng_{t}(x) & \\approx \\tanh (0)+x \\times \\tanh ^{\\prime}(0)  \\tag{4.12}\\\\\n& =x \\tag{4.13}\n\\end{align*}\n\n\n\\begin{center}\n\\includegraphics[max width=\\textwidth]{2024_03_13_b7f820bc184c7846d78fg-097(1)}\n\\end{center}\n\n\n\\begin{align*}\n\\operatorname{hard}-\\tanh (x) & =\\max \\left(\\min \\left(g_{t}(x), 1\\right),-1\\right)  \\tag{4.14}\\\\\n& =\\max (\\min (x, 1),-1) . \\tag{4.15}\n\\end{align*}\n\n\n图4.3给出了 Hard-Logistic 函数和 Hard-Tanh 函数的形状.\n\n\\begin{center}\n\\includegraphics[max width=\\textwidth]{2024_03_13_b7f820bc184c7846d78fg-097(2)}\n\\end{center}\n\n(a) Hard Logistic 函数\n\n\\begin{center}\n\\includegraphics[max width=\\textwidth]{2024_03_13_b7f820bc184c7846d78fg-097}\n\\end{center}\n\n(b) Hard Tanh 函数\n\n图 4.3 Hard Sigmoid 型激活函数"
    },
    {
        "id": "chatcmpl-92xeGgurOkpXemUpbVR1XTjADj4wj",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "logprobs": null,
                "message": {
                    "content": "{\n    \"问题1\": \"Logistic 函数和 Tanh 函数有什么特点？\",\n    \"回答1\": \"Logistic 函数和 Tanh 函数都属于 Sigmoid 型函数，具有饱和性，即在输入较大或较小时，函数的导数会趋于零。这两个函数在中间（0 附近）近似线性，而在两端则饱和。由于这些特点，它们的计算开销较大。\",\n    \"问题2\": \"Logistic 函数的导数是多少？\",\n    \"回答2\": \"Logistic 函数 $\\text{sigmoid}(x)$ 的导数是 $\\text{sigmoid}(x)(1-\\text{sigmoid}(x))$。\",\n    \"问题3\": \"Logistic 函数如何通过分段函数来近似？\",\n    \"回答3\": \"Logistic 函数可以通过分段函数 hard-logistic$(x)$ 来近似，其中 hard-logistic$(x)$ 的定义如下：$1$ 当 $g_{l}(x) \\textgreater= 1$，$g_{l}$ 当 $0 \\textless g_{l}(x) \\textless 1$，$0$ 当 $g_{l}(x) \\textless= 0$。进一步地，hard-logistic$(x)$ 可以表示为 $\\text{max}(\\text{min}(0.25x+0.5,1), 0)$。\",\n    \"问题4\": \"Tanh 函数的一阶泰勒展开是什么？\",\n    \"回答4\": \"Tanh 函数在 0 附近的一阶泰勒展开为 $g_{t}(x) \\textapprox \\tanh(0) + x \\times \\tanh^{\\text{'}}(0)$，即 $g_{t}(x) \\textapprox x$。\",\n    \"问题5\": \"Hard-Tanh 函数如何通过分段函数来近似？\",\n    \"回答5\": \"Hard-Tanh 函数可以通过分段函数 $\\text{hard}-\\tanh(x)$ 来近似，其中 $\\text{hard}-\\tanh(x)$ 的定义如下：$\\text{max}(\\text{min}(g_{t}(x), 1),-1)$，进一步地，$\\text{hard}-\\tanh(x)$ 可以表示为 $\\text{max}(\\text{min}(x, 1),-1)$。\",\n    \"问题6\": \"Hard-Logistic 函数和 Hard-Tanh 函数的形状是什么样子的？\",\n    \"回答6\": \"Hard-Logistic 函数和 Hard-Tanh 函数的形状可以在图4.3中看到。Hard-Logistic 函数的形状类似于一个分段线性函数，而 Hard-Tanh 函数的形状则类似于一个分段线性函数，但在两端被限制在了 $-1$ 和 $1$ 之间。\",\n    \"问题7\": \"Hard-Logistic 函数和 Hard-Tanh 函数的图形分别对应了什么？\",\n    \"回答7\": \"Hard-Logistic 函数的图形对应了图(a)，而 Hard-Tanh 函数的图形对应了图(b)。\",\n    \"问题8\": \"Hard-Logistic 函数和 Hard-Tanh 函数属于什么类型的激活函数？\",\n    \"回答8\": \"Hard-Logistic 函数和 Hard-Tanh 函数属于 Hard Sigmoid 型激活函数。\",\n    \"问题9\": \"Hard-Logistic 函数和 Hard-Tanh 函数的计算特点是什么？\",\n    \"回答9\": \"Hard-Logistic 函数和 Hard-Tanh 函数是 Sigmoid 型函数的分段函数近似，相比于原始的 Logistic 函数和 Tanh 函数，它们的计算开销较小。\",\n    \"问题10\": \"Hard-Logistic 函数和 Hard-Tanh 函数的分段函数近似有什么优势？\",\n    \"回答10\": \"Hard-Logistic 函数和 Hard-Tanh 函数的分段函数近似能够在保持一定的准确性的同时，降低了计算的复杂度，使得在实际应用中更加高效。\"\n}",
                    "role": "assistant",
                    "function_call": null,
                    "tool_calls": null
                }
            }
        ],
        "created": 1710492972,
        "model": "gpt-3.5-turbo-1106",
        "object": "chat.completion",
        "system_fingerprint": "fp_4aaaf0dc94",
        "usage": {
            "completion_tokens": 1055,
            "prompt_tokens": 3096,
            "total_tokens": 4151
        },
        "parameters": {
            "model": "gpt-3.5-turbo-1106",
            "temperature": 0.2,
            "frequency_penalty": 0.05,
            "presence_penalty": 0.05
        }
    }
]