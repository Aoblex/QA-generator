[
    {
        "strategy": "subsection",
        "source": "deeplearning",
        "title": "13.2.4 模型汇总",
        "content_length": 3612,
        "content": "Title: 13.2.4 模型汇总\nContent:\n结合公式(13.15)和公式(13.19), 推断网络和生成网络的目标都为最大化证据下界 $E L B O(q, x ; \\theta, \\phi)$. 因此, 变分自编码器的总目标函数为\n\n\n\\begin{equation*}\n\\max _{\\theta, \\phi} E L B O(q, \\boldsymbol{x} ; \\theta, \\phi)=\\max _{\\theta, \\phi} \\mathbb{E}_{\\boldsymbol{z} \\sim q(z ; \\phi)}\\left[\\log \\frac{p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta) p(\\boldsymbol{z} ; \\theta)}{q(\\boldsymbol{z} ; \\boldsymbol{\\phi})}\\right] \\tag{13.20}\n\\end{equation*}\n\n\n\\href{https://nndl.github.io/}{https://nndl.github.io/}\n\n\n\\begin{equation*}\n=\\max _{\\theta, \\phi} \\mathbb{E}_{\\boldsymbol{z} \\sim q(z \\mid x ; \\phi)}[\\log p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta)]-\\mathrm{KL}(q(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\phi), p(\\boldsymbol{z} ; \\theta)), \\tag{13.21}\n\\end{equation*}\n\n\n其中 $p(\\boldsymbol{z} ; \\theta)$ 为先验分布, $\\theta$ 和 $\\phi$ 分别表示生成网络和推断网络的参数.\n\n从 $\\mathrm{EM}$ 算法角度来看, 变分自编码器优化推断网络和生成网络的过程, 可以分别看作 EM 算法中的 E 步和 $\\mathrm{M}$ 步. 但在变分自编码器中, 这两步的目标合二为一, 都是最大化证据下界. 此外, 变分自编码器可以看作神经网络和贝叶斯网络的混合体. 贝叶斯网络中的所有节点都是随机变量. 在变分自编码器中, 我们仅仅将隐藏编码对应的节点看成是随机变量, 其他节点还是作为普通神经元. 这样, 编码器变成一个变分推断网络, 而解码器变成一个将隐变量映射到观测变量的生成网络.\n\n我们分别来看公式(13.21)中的两项.\n\n(1) 通常情况下, 公式(13.21)中第一项的期望 $\\mathbb{E}_{\\boldsymbol{z} \\sim q(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\phi)}[\\log p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta)]$ 可以通过采样的方式近似计算. 对于每个样本 $\\boldsymbol{x}$, 根据 $q(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\phi)$ 采集 $M$ 个 $\\boldsymbol{z}^{(m)}, 1 \\leq$ $m \\leq M$, 有\n\n\n\\begin{equation*}\n\\mathbb{E}_{\\boldsymbol{z} \\sim q(z \\mid x ; \\phi)}[\\log p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta)] \\approx \\frac{1}{M} \\sum_{m=1}^{M} \\log p\\left(\\boldsymbol{x} \\mid \\boldsymbol{z}^{(m)} ; \\theta\\right) \\tag{13.22}\n\\end{equation*}\n\n\n期望 $\\mathbb{E}_{z \\sim q(z \\mid x ; \\phi)}[\\log p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta)]$ 依赖于参数 $\\boldsymbol{\\phi}$. 但在上面的近似中, 这个期望变得和参数 $\\phi$ 无关. 当使用梯度下降法来学习参数时, 期望 $\\mathbb{E}_{\\boldsymbol{z} \\sim q(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\phi)}[\\log p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta)]$ 关于参数 $\\phi$ 的梯度为 0 . 这种情况是由于变量 $\\boldsymbol{z}$ 和参数 $\\phi$ 之间不是直接的确定性关系, 而是一种 “采样” 关系. 这种情况可以通过两种方法解决: 一种是再参数化, 我们在下一节具体介绍;另一种是梯度估计的方法,具体参考第14.3节.\n\n(2) 公式(13.21)中第二项的 KL 散度通常可以直接计算. 特别是当 $q(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\boldsymbol{\\phi})$和 $p(\\boldsymbol{z} ; \\theta)$ 都是正态分布时, 它们的 KL 散度可以直接计算出闭式解.\n\n给定 $D$ 维空间中的两个正态分布 $\\mathcal{N}\\left(\\mu_{1}, \\boldsymbol{\\Sigma}_{1}\\right)$ 和 $\\mathcal{N}\\left(\\mu_{2}, \\boldsymbol{\\Sigma}_{2}\\right)$, 其 KL 散度为\n\n\n\\begin{align*}\n& \\operatorname{KL}\\left(\\mathcal{N}\\left(\\mu_{1}, \\Sigma_{1}\\right), \\mathcal{N}\\left(\\mu_{2}, \\Sigma_{2}\\right)\\right) \\\\\n& =\\frac{1}{2}\\left(\\operatorname{tr}\\left(\\Sigma_{2}^{-1} \\Sigma_{1}\\right)+\\left(\\mu_{2}-\\mu_{1}\\right)^{\\top} \\Sigma_{2}^{-1}\\left(\\mu_{2}-\\mu_{1}\\right)-D+\\log \\frac{\\left|\\Sigma_{2}\\right|}{\\left|\\Sigma_{1}\\right|}\\right), \\tag{13.23}\n\\end{align*}\n\n\n其中 $\\operatorname{tr}(\\cdot)$ 表示矩阵的迹, $|\\cdot|$ 表示矩阵的行列式.\n\n这样, 当 $p(\\boldsymbol{z} ; \\theta)=\\mathcal{N}(\\boldsymbol{z} ; \\mathbf{0}, \\boldsymbol{I})$ 以及 $q(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\boldsymbol{\\phi})=\\mathcal{N}\\left(\\boldsymbol{z} ; \\boldsymbol{\\mu}_{I}, \\sigma_{I}^{2} \\boldsymbol{I}\\right)$ 时,\n\n\n\\begin{align*}\n& \\mathrm{KL}(q(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\boldsymbol{\\phi}), p(\\boldsymbol{z} ; \\theta)) \\\\\n& =\\frac{1}{2}\\left(\\operatorname{tr}\\left(\\sigma_{I}^{2} \\boldsymbol{I}\\right)+\\mu_{I}^{\\top} \\mu_{I}-d-\\log \\left(\\left|\\sigma_{I}^{2} \\boldsymbol{I}\\right|\\right)\\right) \\tag{13.24}\n\\end{align*}\n\n\n其中 $\\mu_{I}$ 和 $\\sigma_{I}$ 为推断网络 $f_{I}(\\boldsymbol{x} ; \\phi)$ 的输出.\n\\footnotetext{\\href{https://nndl.github.io/}{https://nndl.github.io/}\n}"
    },
    {
        "id": "chatcmpl-945U6qlWe7XYQuxHTxnK6o9Hkztpp",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "logprobs": null,
                "message": {
                    "content": "{\n    \"问题1\": \"变分自编码器的总目标函数是什么？\",\n    \"回答1\": \"变分自编码器的总目标函数为最大化证据下界 $ELBO(q, \\boldsymbol{x} ; \\theta, \\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\theta, \\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\theta, \\boldsymbol{\\boldsymbol{\\theta, \\theta) = \\text{max}_{\\theta, \\boldsymbol{\\theta} \\text{max}_{\\theta, \\theta} \\text{max}_{\\theta, \\theta} \\text{max}_{\\theta, \\theta} \\text{max}_{\\theta, \\theta} \\text{max}_{\\theta, \\theta} \\text{max}_{\\theta, \\theta} E}_{\\boldsymbol{z} \\text{max}_{\\theta, \\theta} E}_{\\boldsymbol{z} \\text{max}_{\\theta, \\theta} E}_{\\boldsymbol{z} \\text{max}_{\\theta, \\theta} E}_{\\boldsymbol{z} \\text{max}_{\\theta, \\theta} E}_{\\boldsymbol{z} \\text{max}_{\\theta, \\theta} E}_{\\boldsymbol{z} \\text{max}_{\\theta, \\theta} E}_{\\boldsymbol{z} \\text{max}_{\\theta, \\theta} E}_{\\boldsymbol{z} \\text{max}_{\\theta, \\theta} E}_{\\boldsymbol{z} \\text{max}_{\\theta, \\theta} E}_{\\boldsymbol{z}^{(m)} ; 1 \\text{leq m leq M}} log p(\\boldsymbol{x} | \\boldsymbol{z}^{(m)} ; \\theta)$.}\",\n    \"问题2\": \"变分自编码器中的推断网络和生成网络的优化过程分别对应于EM算法中的哪两个步骤？\",\n    \"回答2\": \"从EM算法角度来看，变分自编码器中的推断网络和生成网络的优化过程分别对应于EM算法中的E步和M步。在变分自编码器中，这两步的目标合二为一，都是最大化证据下界。\",\n    \"问题3\": \"变分自编码器可以被看作神经网络和什么混合体？\",\n    \"回答3\": \"变分自编码器可以被看作神经网络和贝叶斯网络的混合体。在贝叶斯网络中，所有节点都是随机变量。而在变分自编码器中，我们将隐藏编码对应的节点看成是随机变量，其他节点则作为普通神经元。\",\n    \"问题4\": \"公式(13.22)中的期望如何通过采样方式近似计算？\",\n    \"回答4\": \"公式(13.22)中的期望 $\\text{E}_{z \\text{sim } q(z | x ; \\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\bfphi}}}}}}}}}}}}[\\text{log } p(\\bf{x} | z ; \\bftheta)]$ 可以通过采样的方式近似计算。对于每个样本 $\\bf{x}$，根据 $q(z | x ; \\bfphi)$ 采集 $M$ 个 $z^{(m)}, 1 leq m leq M$，有 $\\text{E}_{z sim q(z | x ; phi)}[\\text{log } p(\\bf{x} | z ; theta)] approx frac{1}{M} sum_{m=1}^{M} log p(\\bf{x} | z^{(m)} ; theta)$。\",\n    \"问题5\": \"公式(13.23)中的KL散度如何计算？\",\n    \"回答5\": \"公式(13.23)中给出了两个正态分布 $\\bfN(\\bfmu_{1}, Sigma_{1})$ 和 $\\bfN(\\bfmu_{2}, Sigma_{2})$ 的KL散度计算公式。它由两部分组成：一部分是矩阵迹的计算，另一部分是关于均值和协方差矩阵的计算。当两个正态分布都是正态分布时，它们的KL散度可以直接计算出闭式解。\",\n    \"问题6\": \"在变分自编码器中，期望依赖于参数 $\\bfphi$ 的情况如何处理？\",\n    \"回答6\": \"在变分自编码器中，期望 $\\text{E}_{z sim q(z | x ; phi)}[\\text{log } p(\\bf{x} | z ; theta)]$ 依赖于参数 $\\bfphi$。但在近似计算中，这个期望变得和参数 $\\bfphi$ 无关。这种情况可以通过再参数化或梯度估计的方法来解决。\",\n    \"问题7\": \"当 $p(\\bfz ; theta)=N(\\bfz ; 0, I)$ 以及 $q(\\bfz | x ; phi)=N(\\bfz ; mu_{I}, sigma_{I}^{2} I)$ 时，公式(13.24)中的KL散度如何简化计算？\",\n    \"回答7\": \"当 $p(\\bfz ; theta)=N(\\bfz ; 0, I)$ 以及 $q(\\bfz | x ; phi)=N(\\bfz ; mu_{I}, sigma_{I}^{2} I)$ 时，公式(13.24)中的KL散度可以简化为一个闭式解的形式。具体计算过程包括矩阵迹、均值平方和行列式等操作。\",\n    \"问题8\": \"为什么需要将隐藏编码对应的节点看成是随机变量？\",\n    \"回答8\": \"在变分自编码器中，将隐藏编码对应的节点看成是随机变量是为了引入潜在变量，并通过生成网络将其映射到观测变量。这样可以更好地捕捉数据的潜在结构和特征，提高模型对数据的表达能力。\",\n    \"问题9\": \"如何处理公式(13.22)中期望依赖于参数 $\\bfphi$ 的情况？\",\n    \"回答9\": \"公式(13.22)中期望 $\\text{E}_{z sim q(z | x ; phi)}[\\text{log } p(\\bf{x} | z ; theta)]$ 依赖于参数 $\\bfphi$。但在近似计算中，这个期望变得和参数 $\\bfphi$ 无关。这种情况可以通过再参数化或梯度估计的方法来解决。\",\n    \"问题10\": \"变分自编码器与EM算法有怎样的相似之处？\",\n    \"回答10\": \"从EM算法角度来看，变分自编码器优化推断网络和生成网络的过程可以分别看作EM算法中的E步和M步。然而，在变分自编码器中，这两步的目标合二为一，都是最大化证据下界。因此，变分自编码器与EM算法在优化过程上有相似之处。\"\n}",
                    "role": "assistant",
                    "function_call": null,
                    "tool_calls": null
                }
            }
        ],
        "created": 1710761422,
        "model": "gpt-3.5-turbo-1106",
        "object": "chat.completion",
        "system_fingerprint": "fp_4aaaf0dc94",
        "usage": {
            "completion_tokens": 1898,
            "prompt_tokens": 4422,
            "total_tokens": 6320
        },
        "parameters": {
            "model": "gpt-3.5-turbo-1106",
            "temperature": 0.2,
            "frequency_penalty": 0.15,
            "presence_penalty": 0.15
        }
    }
]