[
    {
        "strategy": "subsection",
        "source": "machine_learning_chapter1",
        "title": "1.3.2 策略",
        "content_length": 3617,
        "content": "Title: 1.3.2 策略\nContent:\n有了模型的假设空间, 机器学习接着需要考虑的是按照什么样的准则学习或选择最优的模型。机器学习的目标在于从假设空间中选取最优模型。\n\n首先引入损失函数与风险函数的概念。损失函数度量模型一次预测的好坏, 风险函数度量平均意义下模型预测的好坏。\n\n\\section*{1. 损失函数和风险函数}\n监督学习问题是在假设空间 $\\mathcal{F}$ 中选取模型 $f$ 作为决策函数, 对于给定的输入 $X$, 由 $f(X)$ 给出相应的输出 $Y$, 这个输出的预测值 $f(X)$ 与真实值 $Y$ 可能一致也可能不一致, 用一个损失函数 (loss function) 或代价函数 (cost function) 来度量预测错误的程度。损失函数是 $f(X)$ 和 $Y$ 的非负实值函数, 记作 $L(Y, f(X))$ 。\n\n机器学习常用的损失函数有以下几种:\n\n(1) 0-1 损失函数 (0-1 loss function)\n\n\\[\nL(Y, f(X))= \\begin{cases}1, & Y \\neq f(X)  \\tag{1.9}\\\\ 0, & Y=f(X)\\end{cases}\n\\]\n\n(2) 平方损失函数 (quadratic loss function)\n\n\n\\begin{equation*}\nL(Y, f(X))=(Y-f(X))^{2} \\tag{1.10}\n\\end{equation*}\n\n\n(3) 绝对损失函数 (absolute loss function)\n\n\n\\begin{equation*}\nL(Y, f(X))=|Y-f(X)| \\tag{1.11}\n\\end{equation*}\n\n\n(4) 对数损失函数（logarithmic loss function）或对数似然损失函数（log-likelihood loss function)\n\n\n\\begin{equation*}\nL(Y, P(Y \\mid X))=-\\log P(Y \\mid X) \\tag{1.12}\n\\end{equation*}\n\n\n损失函数值越小, 模型就越好。由于模型的输入、输出 $(X, Y)$ 是随机变量, 遵循联合分布 $P(X, Y)$, 所以损失函数的期望是\n\n\n\\begin{align*}\nR_{\\exp }(f) & =E_{P}[L(Y, f(X))] \\\\\n& =\\int_{\\mathcal{X} \\times \\mathcal{Y}} L(y, f(x)) P(x, y) \\mathrm{d} x \\mathrm{~d} y \\tag{1.13}\n\\end{align*}\n\n\n这是理论上模型 $f(X)$ 关于联合分布 $P(X, Y)$ 的平均意义下的损失, 称为风险函数（risk function）或期望损失（expected loss）。\n\n学习的目标就是选择期望风险最小的模型。由于联合分布 $P(X, Y)$ 是未知的, $R_{\\exp }(f)$不能直接计算。实际上, 如果知道联合分布 $P(X, Y)$, 可以从联合分布直接求出条件概率分布 $P(Y \\mid X)$, 也就不需要学习了。正因为不知道联合概率分布, 所以才需要进行学习。这样一来, 一方面根据期望风险最小学习模型要用到联合分布, 另一方面联合分布又是未知的, 所以监督学习就成为一个病态问题（ill-formed problem）。\n\n给定一个训练数据集\n\n$$\nT=\\left\\{\\left(x_{1}, y_{1}\\right),\\left(x_{2}, y_{2}\\right), \\cdots,\\left(x_{N}, y_{N}\\right)\\right\\}\n$$\n\n模型 $f(X)$ 关于训练数据集的平均损失称为经验风险 (empirical risk) 或经验损失 (empirical loss ), 记作 $R_{\\text {emp }}$ :\n\n\n\\begin{equation*}\nR_{\\mathrm{emp}}(f)=\\frac{1}{N} \\sum_{i=1}^{N} L\\left(y_{i}, f\\left(x_{i}\\right)\\right) \\tag{1.14}\n\\end{equation*}\n\n\n期望风险 $R_{\\exp }(f)$ 是模型关于联合分布的期望损失, 经验风险 $R_{\\mathrm{emp}}(f)$ 是模型关于训练样本集的平均损失。根据大数定律, 当样本容量 $N$ 趋于无穷时, 经验风险 $R_{\\mathrm{emp}}(f)$ 趋于期望风险 $R_{\\exp }(f)$ 。所以一个很自然的想法是用经验风险估计期望风险。但是, 由于现实中训练样本数目有限, 甚至很小, 所以用经验风险估计期望风险常常并不理想, 要对经验风险进行一定的矫正。这就关系到监督学习的两个基本策略: 经验风险最小化和结构风险最小化。\n\n\\section*{2. 经验风险最小化与结构风险最小化}\n在假设空间、损失函数以及训练数据集确定的情况下，经验风险函数式 (1.14) 就可以确定。经验风险最小化 (empirical risk minimization, ERM) 的策略认为, 经验风险最小的模型是最优的模型。根据这一策略, 按照经验风险最小化求最优模型就是求解最优化问题:\n\n\n\\begin{equation*}\n\\min _{f \\in \\mathcal{F}} \\frac{1}{N} \\sum_{i=1}^{N} L\\left(y_{i}, f\\left(x_{i}\\right)\\right) \\tag{1.15}\n\\end{equation*}\n\n\n其中, $\\mathcal{F}$ 是假设空间。\n\n当样本容量足够大时, 经验风险最小化能保证有很好的学习效果, 在现实中被广泛采用。比如, 极大似然估计 (maximum likelihood estimation) 就是经验风险最小化的一个例子。当模型是条件概率分布、损失函数是对数损失函数时, 经验风险最小化就等价于极大似然估计。但是, 当样本容量很小时, 经验风险最小化学习的效果就未必很好, 会产生 “过拟合” (over-fitting) 现象。\n\n结构风险最小化 (structural risk minimization, SRM) 是为了防止过拟合而提出来的策略。结构风险最小化等价于正则化 (regularization)。结构风险在经验风险上加上表示模型复杂度的正则化项 (regularizer) 或罚项 (penalty term)。在假设空间、损失函数以及训练数据集确定的情况下，结构风险的定义是\n\n\n\\begin{equation*}\nR_{\\mathrm{srm}}(f)=\\frac{1}{N} \\sum_{i=1}^{N} L\\left(y_{i}, f\\left(x_{i}\\right)\\right)+\\lambda J(f) \\tag{1.16}\n\\end{equation*}\n\n\n其中, $J(f)$ 为模型的复杂度, 是定义在假设空间 $\\mathcal{F}$ 上的泛函。模型 $f$ 越复杂, 复杂度 $J(f)$就越大; 反之, 模型 $f$ 越简单, 复杂度 $J(f)$ 就越小。也就是说, 复杂度表示了对复杂模型的惩罚。 $\\lambda \\geqslant 0$ 是系数, 用以权衡经验风险和模型复杂度。结构风险小需要经验风险与模型复杂度同时小。结构风险小的模型往往对训练数据以及未知的测试数据都有较好的预测。\n\n比如, 贝叶斯估计中的最大后验概率估计 (maximum posterior probability estimation, MAP) 就是结构风险最小化的一个例子。当模型是条件概率分布、损失函数是对数损失函数、模型复杂度由模型的先验概率表示时, 结构风险最小化就等价于最大后验概率估计。\n\n结构风险最小化的策略认为结构风险最小的模型是最优的模型, 所以求最优模型就是求解最优化问题:\n\n\n\\begin{equation*}\n\\min _{f \\in \\mathcal{F}} \\frac{1}{N} \\sum_{i=1}^{N} L\\left(y_{i}, f\\left(x_{i}\\right)\\right)+\\lambda J(f) \\tag{1.17}\n\\end{equation*}\n\n\n这样, 监督学习问题就变成了经验风险或结构风险函数的最优化问题 (1.15) 和 (1.17)。这时经验或结构风险函数是最优化的目标函数。"
    },
    {
        "id": "chatcmpl-93zcAOzEi2ycr51QWaBJpN4hHkLfE",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "logprobs": null,
                "message": {
                    "content": "{\n    \"问题1\": \"损失函数和风险函数的概念分别是什么？\",\n    \"回答1\": \"损失函数度量模型一次预测的好坏，而风险函数度量平均意义下模型预测的好坏。损失函数是 $f(X)$ 和 $Y$ 的非负实值函数，记作 $L(Y, f(X))$。而风险函数是模型关于联合分布的期望损失，表示为 $R_{\\text{exp}}(f)$。\",\n    \"问题2\": \"损失函数的作用是什么？你能举例说明吗？\",\n    \"回答2\": \"损失函数度量模型一次预测的好坏，即衡量模型预测结果与真实值之间的差异。常见的损失函数包括 0-1 损失函数、平方损失函数、绝对损失函数和对数损失函数。例如，平方损失函数 $L(Y, f(X))=(Y-f(X))^{2}$ 衡量了预测值与真实值之间的差距的平方。\",\n    \"问题3\": \"什么是期望风险函数？\",\n    \"回答3\": \"期望风险函数是模型关于联合分布的期望损失，表示为 $R_{\\text{exp}}(f)$。它是理论上模型 $f(X)$ 关于联合分布 $P(X, Y)$ 的平均意义下的损失，用来衡量模型整体预测的好坏。\",\n    \"问题4\": \"经验风险和期望风险有何区别？\",\n    \"回答4\": \"经验风险 $R_{\\text{emp}}(f)$ 是模型关于训练样本集的平均损失，而期望风险 $R_{\\text{exp}}(f)$ 是模型关于联合分布的期望损失。经验风险是基于已知训练数据计算得到的，而期望风险是基于整体联合分布计算得到的。\",\n    \"问题5\": \"经验风险最小化和结构风险最小化分别是什么策略？\",\n    \"回答5\": \"经验风险最小化 (ERM) 的策略认为，经验风险最小的模型是最优的模型，其目标是求解最优化问题 $\\text{min}_{f \\text{ 在 } \\boldsymbol{F}} \\frac{1}{N} \\text{∑}_{i=1}^{N} L(y_{i}, f(x_{i}))$。而结构风险最小化 (SRM) 是为了防止过拟合而提出来的策略，其目标是求解最优化问题 $\\text{min}_{f \\text{ 在 } \\boldsymbol{F}} \\frac{1}{N} \\text{∑}_{i=1}^{N} L(y_{i}, f(x_{i}))+\\boldsymbol{\\text{λ}}J(f)$。\",\n    \"问题6\": \"为什么在样本容量较小时，经验风险最小化可能会产生过拟合现象？\",\n    \"回答6\": \"当样本容量很小时，经验风险最小化学习的效果未必很好，会产生 “过拟合” (over-fitting) 现象。这是因为在样本容量较小时，模型可能会过度地拟合训练数据，导致在未知数据上表现不佳。\",\n    \"问题7\": \"结构风险最小化中的正则化项有什么作用？\",\n    \"回答7\": \"结构风险最小化中的正则化项用于表示模型复杂度，并在经验风险上加上表示模型复杂度的正则化项或罚项。它可以对复杂模型进行惩罚，防止过拟合现象的发生。\",\n    \"问题8\": \"贝叶斯估计中的最大后验概率估计属于哪种策略？\",\n    \"回答8\": \"贝叶斯估计中的最大后验概率估计属于结构风险最小化的策略。当模型是条件概率分布、损失函数是对数损失函数、模型复杂度由模型的先验概率表示时，结构风险最小化就等价于最大后验概率估计。\",\n    \"问题9\": \"监督学习问题在经验或结构风险函数中转化为了什么类型的问题？\",\n    \"回答9\": \"监督学习问题在经验或结构风险函数中转化为了最优化问题。具体来说，监督学习问题变成了经验或结构风险函数的最优化问题。\",\n    \"问题10\": \"为什么在现实中经常需要对经验风险进行矫正？\",\n    \"回答10\": \"在现实中训练样本数目有限，甚至很小，所以用经验风险估计期望风险常常并不理想，需要对经验风险进行一定的矫正。这是因为有限的训练样本可能无法完全代表整体联合分布，因此需要对经验风险进行适当修正以更好地估计期望风险。\"\n}",
                    "role": "assistant",
                    "function_call": null,
                    "tool_calls": null
                }
            }
        ],
        "created": 1710738858,
        "model": "gpt-3.5-turbo-1106",
        "object": "chat.completion",
        "system_fingerprint": "fp_4aaaf0dc94",
        "usage": {
            "completion_tokens": 1507,
            "prompt_tokens": 5168,
            "total_tokens": 6675
        },
        "parameters": {
            "model": "gpt-3.5-turbo-1106",
            "temperature": 0.2,
            "frequency_penalty": 0.15,
            "presence_penalty": 0.15
        }
    }
]