[
    {
        "strategy": "subsection",
        "source": "machine_learning_chapter1",
        "title": "1.2.4 按技巧分类",
        "content_length": 2340,
        "content": "Title: 1.2.4 按技巧分类\nContent:\n机器学习方法可以根据其使用的技巧进行分类。\n\n\\section*{1. 贝叶斯学习}\n贝叶斯学习 (Bayesian learning) 又称为贝叶斯推理 (Bayesian inference), 是统计学、机器学习中重要的方法。其主要想法是: 在概率模型的学习和推理中, 利用贝叶斯定理, 计算在给定数据条件下模型的条件概率, 即后验概率, 并应用这个原理进行模型的估计, 以及对数据的预测。将模型、未观测要素及其参数用变量表示, 使用模型的先验分布是贝叶斯学习的特点。贝叶斯学习中也使用基本概率公式 (图 1.4)。\n\n本书介绍的朴素贝叶斯、潜在狄利克雷分配的学习属于贝叶斯学习。\n\n假设随机变量 $D$ 表示数据, 随机变量 $\\theta$ 表示模型参数。根据贝叶斯定理, 可以用以下公式计算后验概率 $P(\\theta \\mid D):$\n\n\n\\begin{equation*}\nP(\\theta \\mid D)=\\frac{P(\\theta) P(D \\mid \\theta)}{P(D)} \\tag{1.3}\n\\end{equation*}\n\n\n其中, $P(\\theta)$ 是先验概率, $P(D \\mid \\theta)$ 是似然函数。\n\n模型估计时, 估计整个后验概率分布 $P(\\theta \\mid D)$ 。如果需要给出一个模型, 通常取后验概率最大的模型。\n\n预测时，计算数据对后验概率分布的期望值:\n\n\n\\begin{equation*}\nP(x \\mid D)=\\int P(x \\mid \\theta, D) P(\\theta \\mid D) \\mathrm{d} \\theta \\tag{1.4}\n\\end{equation*}\n\n\n这里 $x$ 是新样本。\n\n贝叶斯估计与极大似然估计在思想上有很大的不同, 代表着统计学中贝叶斯学派和频率学派对统计的不同认识。其实, 可以简单地把两者联系起来, 假设先验分布是均匀分布, 取后验概率最大, 就能从贝叶斯估计得到极大似然估计。图 1.6 对贝叶斯估计和极大似然估计进行比较。\n\n$$\n\\begin{aligned}\n& D \\xrightarrow{\\text { 极大似然估计 }} \\hat{\\theta}=\\arg \\max _{\\theta} P(D \\mid \\theta) \\\\\n& D \\xrightarrow{\\text { 贝叶斯估计 }} \\hat{P}(\\theta \\mid D)=\\frac{P(\\theta) P(D \\mid \\theta)}{P(D)}\n\\end{aligned}\n$$\n\n\\begin{center}\n\\includegraphics[max width=\\textwidth]{2024_03_13_bea450f13c914fcf9c21g-35}\n\\end{center}\n\n图 1.6 贝叶斯估计与极大似然估计\n\n\\section*{2. 核方法}\n核方法 (kernel method) 是使用核函数表示和学习非线性模型的一种机器学习方法, 可以用于监督学习和无监督学习。有一些线性模型的学习方法基于相似度计算, 更具体地, 向量内积计算。核方法可以把它们扩展到非线性模型的学习, 使其应用范围更广泛。\n\n本书介绍的核函数支持向量机，以及核 PCA、核 $k$ 均值属于核方法。\n\n把线性模型扩展到非线性模型, 直接的做法是显式地定义从输入空间（低维空间）到特征空间（高维空间）的映射，在特征空间中进行内积计算。比如支持向量机，把输入空间的线性不可分问题转化为特征空问的线性可分问题，如图 1.7 所示。核方法的技巧在于不显式地定义这个映射, 而是直接定义核函数, 即映射之后在特征空间的内积。这样可以简化计算, 达到同样的效果。\n\n\\begin{center}\n\\includegraphics[max width=\\textwidth]{2024_03_13_bea450f13c914fcf9c21g-36(1)}\n\\end{center}\n\n图 1.7 输入空间到特征空间的映射\n\n假设 $x_{1}$ 和 $x_{2}$ 是输入空间的任意两个实例 (向量), 其内积是 $\\left\\langle x_{1}, x_{2}\\right\\rangle$ 。假设从输入空间到特征空间的映射是 $\\varphi$, 于是 $x_{1}$ 和 $x_{2}$ 在特征空间的映像是 $\\varphi\\left(x_{1}\\right)$ 和 $\\varphi\\left(x_{2}\\right)$, 其内积\n\n\\includegraphics[max width=\\textwidth, center]{2024_03_13_bea450f13c914fcf9c21g-36}\\\\\n$\\left\\langle\\varphi\\left(x_{1}\\right), \\varphi\\left(x_{2}\\right)\\right\\rangle$ 。表示定理给出核函数技巧成立的充要条件。\n\n\\section*{1.3 机器学习方法三要素}\n机器学习方法都是由模型、策略和算法构成的, 即机器学习方法由三要素构成, 可以简单地表示为\n\n$$\n\\text { 方法 }=\\text { 模型 }+ \\text { 策略 }+ \\text { 算法 }\n$$\n\n下面论述监督学习中的机器学习三要素。非监督学习也同样拥有这三要素。可以说构建一种机器学习方法就是确定具体的机器学习三要素。"
    },
    {
        "id": "chatcmpl-93zaeb1qzKLCMQlw4nAeZeTcqZJgu",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "logprobs": null,
                "message": {
                    "content": "{\n    \"问题1\": \"贝叶斯学习的主要想法是什么？\",\n    \"回答1\": \"贝叶斯学习的主要想法是在概率模型的学习和推理中，利用贝叶斯定理，计算在给定数据条件下模型的条件概率，即后验概率，并应用这个原理进行模型的估计，以及对数据的预测。将模型、未观测要素及其参数用变量表示，使用模型的先验分布是贝叶斯学习的特点。\",\n    \"问题2\": \"贝叶斯学习中的后验概率 $P(\\theta \\text{ ｜ } D)$ 是如何计算得到的？\",\n    \"回答2\": \"根据贝叶斯定理，可以用公式 $P(\\theta \\text{ ｜ } D)=\\frac{P(\\theta) P(D \\text{ ｜ } \\theta)}{P(D)}$ 计算后验概率 $P(\\theta \\text{ ｜ } D)$。其中，$P(\\theta)$ 是先验概率，$P(D \\text{ ｜ } \\theta)$ 是似然函数。\",\n    \"问题3\": \"贝叶斯学习中的模型估计时通常采取什么策略？\",\n    \"回答3\": \"在贝叶斯学习中，模型估计时通常采取估计整个后验概率分布 $P(\\theta \\text{ ｜ } D)$ 的策略。如果需要给出一个模型，通常取后验概率最大的模型。\",\n    \"问题4\": \"贝叶斯学习中的预测时采用什么方法？\",\n    \"回答4\": \"在贝叶斯学习中，预测时采用计算数据对后验概率分布的期望值的方法，即 $P(x \\text{ ｜ } D)=\\text{∫} P(x \\text{ ｜ } \\theta, D) P(\\theta \\text{ ｜ } D) \\text{d} \\theta$。这里 $x$ 是新样本。\",\n    \"问题5\": \"核方法是用来表示和学习什么类型的模型？\",\n    \"回答5\": \"核方法是使用核函数表示和学习非线性模型的一种机器学习方法。它可以用于监督学习和无监督学习，将一些线性模型扩展到非线性模型的学习，使其应用范围更广泛。\",\n    \"问题6\": \"核方法中的技巧在于什么？\",\n    \"回答6\": \"核方法的技巧在于不显式地定义从输入空间到特征空间的映射，而是直接定义核函数，即映射之后在特征空间的内积。这样可以简化计算，达到同样的效果。\",\n    \"问题7\": \"机器学习方法三要素包括哪些内容？\",\n    \"回答7\": \"机器学习方法三要素包括模型、策略和算法。构建一种机器学习方法就是确定具体的机器学习三要素。\",\n    \"问题8\": \"监督学习中的机器学习三要素是如何构成的？\",\n    \"回答8\": \"监督学习中的机器学习三要素由模型、策略和算法构成。这三要素共同决定了监督学习方法的具体实现和应用。\",\n    \"问题9\": \"核函数在核方法中起到什么作用？\",\n    \"回答9\": \"核函数在核方法中起到将输入空间映射到特征空间并进行内积计算的作用。它能够将一些线性模型扩展到非线性模型的学习，从而提高了模型的适应性和表达能力。\",\n    \"问题10\": \"贝叶斯估计与极大似然估计有何不同？\",\n    \"回答10\": \"贝叶斯估计与极大似然估计在思想上有很大的不同，代表着统计学中贝叶斯学派和频率学派对统计的不同认识。虽然两者有不同思想，但可以通过假设先验分布为均匀分布来联系起来，从而得到极大似然估计。\"\n}",
                    "role": "assistant",
                    "function_call": null,
                    "tool_calls": null
                }
            }
        ],
        "created": 1710738764,
        "model": "gpt-3.5-turbo-1106",
        "object": "chat.completion",
        "system_fingerprint": "fp_4aaaf0dc94",
        "usage": {
            "completion_tokens": 1234,
            "prompt_tokens": 4255,
            "total_tokens": 5489
        },
        "parameters": {
            "model": "gpt-3.5-turbo-1106",
            "temperature": 0.2,
            "frequency_penalty": 0.15,
            "presence_penalty": 0.15
        }
    }
]