[
    {
        "strategy": "subsection",
        "source": "machine_learning_chapter9",
        "title": "19.4.3 单分量 Metropolis-Hastings 算法",
        "content_length": 4808,
        "content": "Title: 19.4.3 单分量 Metropolis-Hastings 算法\nContent:\n在 Metropolis-Hastings 算法中, 通常需要对多元变量分布进行抽样。有时对多元变量分布的抽样是困难的, 可以对多元变量的每一变量的条件分布依次分别进行抽样, 从而实现对整个多元变量的一次抽样, 这就是单分量 Metropolis-Hastings (single-component Metropolis-Hastings）算法。\n\n假设马尔可夫链的状态由 $k$ 维随机变量表示:\n\n$$\nx=\\left(x_{1}, x_{2}, \\cdots, x_{k}\\right)^{\\mathrm{T}}\n$$\n\n其中, $x_{j}$ 表示随机变量 $x$ 的第 $j$ 个分量, $j=1,2, \\cdots, k$, 而 $x^{(i)}$ 表示马尔可夫链在时刻 $i$ 的状态\n\n$$\nx^{(i)}=\\left(x_{1}^{(i)}, x_{2}^{(i)}, \\cdots, x_{k}^{(i)}\\right)^{\\mathrm{T}}, \\quad i=1,2, \\cdots, n\n$$\n\n其中, $x_{j}^{(i)}$ 是随机变量 $x^{(i)}$ 的第 $j$ 个分量, $j=1,2, \\cdots, k$ 。\\\\\n为了生成容量为 $n$ 的样本集合 $\\left\\{x^{(1)}, x^{(2)}, \\cdots, x^{(n)}\\right\\}$, 单分量 Metropolis-Hastings 算法由下面的 $k$ 步迭代实现 Metropolis-Hastings 算法的一次迭代。\n\n设在第 $(i-1)$ 次迭代结束时分量 $x_{j}$ 的取值为 $x_{j}^{(i-1)}$, 在第 $i$ 次迭代的第 $j$ 步, 对分量 $x_{j}$根据 Metropolis-Hastings 算法更新, 得到其新的取值 $x_{j}^{(i)}$ 。首先, 由建议分布 $q\\left(x_{j}^{(i-1)}, x_{j} \\mid x_{-j}^{(i)}\\right)$抽样产生分量 $x_{j}$ 的候选值 $x_{j}^{\\prime(i)}$, 这里 $x_{-j}^{(i)}$ 表示在第 $i$ 次迭代的第 $(j-1)$ 步后的 $x^{(i)}$ 除去 $x_{j}^{(i-1)}$ 的所有值, 即\n\n$$\nx_{-j}^{(i)}=\\left(x_{1}^{(i)}, \\cdots, x_{j-1}^{(i)}, x_{j+1}^{(i-1)}, \\cdots, x_{k}^{(i-1)}\\right)^{\\mathrm{T}}\n$$\n\n其中分量 $1,2, \\cdots, j-1$ 已经更新。然后, 按照接受概率\n\n\\begin{center}\n\\includegraphics[max width=\\textwidth]{2024_03_13_f9cfd3d77aa90e83e0d5g-19}\n\\end{center}\n\n抽样决定是否接受候选值 $x^{\\prime}(i)$ 。如果 $x^{\\prime}{ }_{j}^{(i)}$ 被接受, 则令 $x_{j}^{(i)}={x^{\\prime}}_{j}^{(i)}$; 否则, 令 $x_{j}^{(i)}=x_{j}^{(i-1)}$ 。其余分量在第 $j$ 步不改变。马尔可夫链的转移概率为\n\n\n\\begin{equation*}\np\\left(x_{j}^{(i-1)},{x^{\\prime}}_{j}^{(i)} \\mid x_{-j}^{(i)}\\right)=\\alpha\\left(x_{j}^{(i-1)},{x^{\\prime}}_{j}^{(i)} \\mid x_{-j}^{(i)}\\right) q\\left(x_{j}^{(i-1)},{x^{\\prime}}_{j}^{(i)} \\mid x_{-j}^{(i)}\\right) \\tag{19.48}\n\\end{equation*}\n\n\n图 19.10 示意了单分量 Metropolis-Hastings 算法的迭代过程。目标是对含有两个变量的随机变量 $x$ 进行抽样。如果变量 $x_{1}$ 或 $x_{2}$ 更新, 那么在水平或垂直方向产生一个移动, 连续水平移动和垂直移动产生一个新的样本点。注意由于建议分布可能不被接受, Metropolis-Hastings 算法可能在一些相邻的时刻不产生移动。\n\n\\begin{center}\n\\includegraphics[max width=\\textwidth]{2024_03_13_f9cfd3d77aa90e83e0d5g-19(1)}\n\\end{center}\n\n图 19.10 单分量 Metropolis-Hastings 算法例\n\n\\section*{19.5 吉布斯抽样}\n本节叙述马尔可夫链蒙特卡罗法的常用算法吉布斯抽样, 可以认为是 MetropolisHastings 算法的特殊情况, 但是更容易实现, 因而被广泛使用。\n\n\\section*{19.5 .1 基本原理}\n吉布斯抽样 (Gibbs sampling) 用于多元变量联合分布的抽样和估计 (1)。其基本做法是:\n\\footnotetext{(1) 吉布斯抽样以统计力学奠基人吉布斯 (Josiah Willard Gibbs) 命名, 将该算法与统计力学进行类比。\n}\n从联合概率分布定义满条件概率分布, 依次对满条件概率分布进行抽样, 得到样本的序列。可以证明这样的抽样过程是在一个马尔可夫链上的随机游走, 每一个样本对应着马尔可夫链的状态, 平稳分布就是目标的联合分布。整体成为一个马尔可夫链蒙特卡罗法, 燃烧期之后的样本就是联合分布的随机样本。\n\n假设多元变量的联合概率分布为 $p(x)=p\\left(x_{1}, x_{2}, \\cdots, x_{k}\\right)$ 。吉布斯抽样从一个初始样本 $x^{(0)}=\\left(x_{1}^{(0)}, x_{2}^{(0)}, \\cdots, x_{k}^{(0)}\\right)^{\\mathrm{T}}$ 出发, 不断进行迭代, 每一次迭代得到联合分布的一个样本 $x^{(i)}=\\left(x_{1}^{(i)}, x_{2}^{(i)}, \\cdots, x_{k}^{(i)}\\right)^{\\mathrm{T}}$ 。最终得到样本序列 $\\left\\{x^{(0)}, x^{(1)}, \\cdots, x^{(n)}\\right\\}$ 。\n\n在每次迭代中, 依次对 $k$ 个随机变量中的一个变量进行随机抽样。如果在第 $i$ 次迭代中,对第 $j$ 个变量进行随机抽样, 那么抽样的分布是满条件概率分布 $p\\left(x_{j} \\mid x_{-j}^{(i)}\\right)$, 这里 $x_{-j}^{(i)}$ 表示第 $i$ 次迭代中变量 $j$ 以外的其他变量。\n\n设在第 $(i-1)$ 步得到样本 $\\left(x_{1}^{(i-1)}, x_{2}^{(i-1)}, \\cdots, x_{k}^{(i-1)}\\right)^{\\mathrm{T}}$, 在第 $i$ 步, 首先对第一个变量按照以下满条件概率分布随机抽样:\n\n$$\np\\left(x_{1} \\mid x_{2}^{(t-1)}, \\cdots, x_{k}^{(t-1)}\\right)\n$$\n\n得到 $x_{1}^{(i)}$, 之后依次对第 $j$ 个变量按照以下满条件概率分布随机抽样:\n\n$$\np\\left(x_{j} \\mid x_{1}^{(i)}, \\cdots, x_{j-1}^{(i)}, x_{j+1}^{(i-1)}, \\cdots, x_{k}^{(i-1)}\\right), \\quad j=2,3, \\cdots, k-1\n$$\n\n得到 $x_{j}^{(i)}$, 最后对第 $k$ 个变量按照以下满条件概率分布随机抽样:\n\n$$\np\\left(x_{k} \\mid x_{1}^{(i)}, \\cdots, x_{k-1}^{(i)}\\right)\n$$\n\n得到 $x_{k}^{(i)}$, 于是得到整体样本 $x^{(i)}=\\left(x_{1}^{(i)}, x_{2}^{(i)}, \\cdots, x_{k}^{(i)}\\right)^{\\mathrm{T}}$ 。\n\n吉布斯抽样是单分量 Metropolis-Hastings 算法的特殊情况。定义建议分布是当前变量 $x_{j}, j=1,2, \\cdots, k$ 的满条件概率分布:\n\n\n\\begin{equation*}\nq\\left(x, x^{\\prime}\\right)=p\\left(x_{j}^{\\prime} \\mid x_{-j}\\right) \\tag{19.49}\n\\end{equation*}\n\n\n这时, 接受概率 $\\alpha=1$,\n\n\n\\begin{align*}\n\\alpha\\left(x, x^{\\prime}\\right) & =\\min \\left\\{1, \\frac{p\\left(x^{\\prime}\\right) q\\left(x^{\\prime}, x\\right)}{p(x) q\\left(x, x^{\\prime}\\right)}\\right\\} \\\\\n& =\\min \\left\\{1, \\frac{p\\left(x^{\\prime}{ }_{-j}\\right) p\\left(x^{\\prime}{ }_{j} \\mid x^{\\prime}{ }_{-j}\\right) p\\left(x_{j} \\mid x^{\\prime}{ }_{-j}\\right)}{p\\left(x_{-j}\\right) p\\left(x_{j} \\mid x_{-j}\\right) p\\left(x^{\\prime}{ }_{j} \\mid x_{-j}\\right)}\\right\\}=1 \\tag{19.50}\n\\end{align*}\n\n\n这里用到 $p\\left(x_{-j}\\right)=p\\left(x^{\\prime}{ }_{-j}\\right)$ 和 $p\\left(\\cdot \\mid x_{-j}\\right)=p\\left(\\cdot \\mid x^{\\prime}{ }_{-j}\\right)$ 。\n\n转移核就是满条件概率分布:\n\n\n\\begin{equation*}\np\\left(x, x^{\\prime}\\right)=p\\left(x^{\\prime}{ }_{j} \\mid x_{-j}\\right) \\tag{19.51}\n\\end{equation*}\n\n\n也就是说依次按照单变量的满条件概率分布 $p\\left(x^{\\prime}{ }_{j} \\mid x_{-j}\\right)$ 进行随机抽样, 就能实现单分量 Metropolis-Hastings 算法。吉布斯抽样对每次抽样的结果都接受, 没有拒绝, 这一点和一般的 Metropolis-Hastings 算法不同。\n\n这里, 假设满条件概率分布 $p\\left(x^{\\prime}{ }_{j} \\mid x_{-j}\\right)$ 不为 0 , 即马尔可夫链是不可约的。"
    },
    {
        "id": "chatcmpl-948EVFbUJ8JWxmw7uFQDXgr8BYrCR",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "logprobs": null,
                "message": {
                    "content": "{\n    \"问题1\": \"单分量 Metropolis-Hastings 算法与普通 Metropolis-Hastings 算法有何区别？\",\n    \"回答1\": \"单分量 Metropolis-Hastings 算法是 Metropolis-Hastings 算法的一种特殊情况，用于对多元变量的联合分布进行抽样。它通过对多元变量的每一变量的条件分布依次分别进行抽样，从而实现对整个多元变量的一次抽样。相比之下，普通 Metropolis-Hastings 算法则直接对多元变量分布进行抽样。\",\n    \"问题2\": \"在单分量 Metropolis-Hastings 算法中，如何更新马尔可夫链的状态？\",\n    \"回答2\": \"在单分量 Metropolis-Hastings 算法中，对第 $j$ 个变量根据 Metropolis-Hastings 算法更新时，首先由建议分布 $q\\big(x_{j}^{(i-1)}, x_{j} \\big| x_{-j}^{(i)}\\big)$ 抽样产生分量 $x_{j}^{\\text{'}(i)}$。然后按照接受概率决定是否接受候选值 $x^{\\text{'}(i)}$，如果被接受，则更新 $x_{j}^{(i)}$ 为 $x_{j}^{\\text{'}(i)}$；否则保持不变。其余分量在该步不改变。\",\n    \"问题3\": \"单分量 Metropolis-Hastings 算法的转移概率是如何定义的？\",\n    \"回答3\": \"单分量 Metropolis-Hastings 算法的转移概率由满条件概率分布定义，即 $p\\big(x_{j}^{(i-1)},x_{j}^{\\text{'}(i)} \\big| x_{-j}^{(i)}\\big)=\\text{α}\\big(x_{j}^{(i-1)},x_{j}^{\\text{'}(i)} \\big| x_{-j}^{(i)}\\big)q\\big(x_{j}^{(i-1)},x_{j}^{\\text{'}(i)} \\big| x_{-j}^{(i)}\\big)$。\",\n    \"问题4\": \"吉布斯抽样与单分量 Metropolis-Hastings 算法有何联系？\",\n    \"回答4\": \"吉布斯抽样可以看作是单分量 Metropolis-Hastings 算法的特殊情况。吉布斯抽样是从联合概率分布定义满条件概率分布，依次对满条件概率分布进行抽样，得到样本的序列。而单分量 Metropolis-Hastings 算法则是通过对每个随机变量的满条件概率分布进行随机抽样，实现对整体多元变量的抽样。\",\n    \"问题5\": \"吉布斯抽样的基本原理是什么？\",\n    \"回答5\": \"吉布斯抽样的基本原理是从联合概率分布定义满条件概率分布，依次对满条件概率分布进行抽样，得到样本的序列。这样的抽样过程是在一个马尔可夫链上的随机游走，每一个样本对应着马尔可夫链的状态，平稳分布就是目标的联合分布。\",\n    \"问题6\": \"吉布斯抽样与统计力学有何类比？\",\n    \"回答6\": \"吉布斯抽样以统计力学奠基人吉布斯命名，并将该算法与统计力学进行类比。这种类比意味着吉布斯抽样在某种程度上类似于统计力学中随机系统状态的演化和平衡过程。\",\n    \"问题7\": \"吉布斯抽样和马尔可夫链蒙特卡罗法有何关系？\",\n    \"回答7\": \"吉布斯抽样是马尔可夫链蒙特卡罗法的一种特殊实现方式。它通过对满条件概率分布进行顺序抽样，得到联合分布的随机样本序列。这种方法在燃烧期之后得到的样本就是目标联合分布的随机样本。\",\n    \"问题8\": \"如何定义吉布斯抽样中的满条件概率分布？\",\n    \"回答8\": \"在吉布斯抽样中，满条件概率分布由联合概率分布定义，并依次对每个随机变量的满条件概率分布进行随机抽样。例如，在第 $i$ 步中，首先对第一个变量按照满条件概率分布 $p\\big(x_{1} \\big| x_{2}^{(t-1)}, \\text{...}, x_{k}^{(t-1)}\\big)$ 进行随机抽样。\",\n    \"问题9\": \"吉布斯抽样中是否存在拒绝操作？\",\n    \"回答9\": \"吉布斯抽样对每次抽样的结果都接受，没有拒绝操作。这一点和一般的 Metropolis-Hastings 算法不同。\",\n    \"问题10\": \"在吉布斯抽样中需要满足什么条件？\",\n    \"回答10\": \"在吉布斯抽样中，假设满条件概率分布不为 0 ，即马尔可夫链是不可约的。这是保证吉布斯抽样有效性的重要条件。\"\n}",
                    "role": "assistant",
                    "function_call": null,
                    "tool_calls": null
                }
            }
        ],
        "created": 1710771987,
        "model": "gpt-3.5-turbo-1106",
        "object": "chat.completion",
        "system_fingerprint": "fp_4aaaf0dc94",
        "usage": {
            "completion_tokens": 1542,
            "prompt_tokens": 5700,
            "total_tokens": 7242
        },
        "parameters": {
            "model": "gpt-3.5-turbo-1106",
            "temperature": 0.2,
            "frequency_penalty": 0.15,
            "presence_penalty": 0.15
        }
    }
]