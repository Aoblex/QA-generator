[
    {
        "strategy": "subsection",
        "source": "machine_learning_chapter3",
        "title": "6.1.2 二项逻辑斯谛回归模型",
        "content_length": 1721,
        "content": "Title: 6.1.2 二项逻辑斯谛回归模型\nContent:\n二项逻辑斯谛回归模型（binomial logistic regression model）是一种分类模型, 由条件概率分布 $P(Y \\mid X)$ 表示, 形式为参数化的逻辑斯谛分布。这里, 随机变量 $X$ 取值为实数, 随机变量 $Y$ 取值为 1 或 0 。我们通过监督学习的方法来估计模型参数。\n\n定义 6.2 (逻辑斯谛回归模型) 二项逻辑斯谛回归模型是如下的条件概率分布:\n\n\n\\begin{align*}\n& P(Y=1 \\mid x)=\\frac{\\exp (w \\cdot x+b)}{1+\\exp (w \\cdot x+b)}  \\tag{6.3}\\\\\n& P(Y=0 \\mid x)=\\frac{1}{1+\\exp (w \\cdot x+b)} \\tag{6.4}\n\\end{align*}\n\n\n这里, $x \\in \\boldsymbol{R}^{n}$ 是输入, $Y \\in\\{0,1\\}$ 是输出, $w \\in \\boldsymbol{R}^{n}$ 和 $b \\in \\boldsymbol{R}$ 是参数, $w$ 称为权值向量, $b$ 称为偏置, $w \\cdot x$ 为 $w$ 和 $x$ 的内积。\n\n对于给定的输入实例 $x$, 按照式 (6.3) 和式 (6.4) 可以求得 $P(Y=1 \\mid x)$ 和 $P(Y=0 \\mid x)$ 。逻辑斯谛回归比较两个条件概率值的大小, 将实例 $x$ 分到概率值较大的那一类。\n\n有时为了方便, 将权值向量和输入向量加以扩充, 仍记作 $w, x$, 即 $w=\\left(w^{(1)}\\right.$, $\\left.w^{(2)}, \\cdots, w^{(n)}, b\\right)^{\\mathrm{T}}, x=\\left(x^{(1)}, x^{(2)}, \\cdots, x^{(n)}, 1\\right)^{\\mathrm{T}}$ 。这时, 逻辑斯谛回归模型如下:\n\n\n\\begin{align*}\n& P(Y=1 \\mid x)=\\frac{\\exp (w \\cdot x)}{1+\\exp (w \\cdot x)}  \\tag{6.5}\\\\\n& P(Y=0 \\mid x)=\\frac{1}{1+\\exp (w \\cdot x)} \\tag{6.6}\n\\end{align*}\n\n\n现在考查逻辑斯谛回归模型的特点。一个事件的几率（odds）是指该事件发生的概率与该事件不发生的概率的比值。如果事件发生的概率是 $p$, 那么该事件的几率是 $\\frac{p}{1-p}$, 该事件的对数几率 ( $\\log$ odds) 或 logit 函数是\n\n$$\n\\operatorname{logit}(p)=\\log \\frac{p}{1-p}\n$$\n\n对逻辑斯谛回归而言, 由式 (6.5) 与式 (6.6) 得:\n\n$$\n\\log \\frac{P(Y=1 \\mid x)}{1-P(Y=1 \\mid x)}=w \\cdot x\n$$\n\n这就是说, 在逻辑斯谛回归模型中, 输出 $Y=1$ 的对数几率是输入 $x$ 的线性函数。或者说,输出 $Y=1$ 的对数几率是由输入 $x$ 的线性函数表示的模型, 即逻辑斯谛回归模型。\n\n换一个角度看, 考虑对输入 $x$ 进行分类的线性函数 $w \\cdot x$, 其值域为实数域。注意, 这里 $x \\in \\boldsymbol{R}^{n+1}, w \\in \\boldsymbol{R}^{n+1}$ 。通过逻辑斯谛回归模型定义式 (6.5) 可以将线性函数 $w \\cdot x$ 转换为概率:\n\n$$\nP(Y=1 \\mid x)=\\frac{\\exp (w \\cdot x)}{1+\\exp (w \\cdot x)}\n$$\n\n这时, 线性函数的值越接近正无穷, 概率值就越接近 1 ; 线性函数的值越接近负无穷, 概率值就越接近 0 (如图 6.1 所示)。这样的模型就是逻辑斯谛回归模型。"
    },
    {
        "id": "chatcmpl-93ymNXBsWA0yN2oh1KTtBQtlfeEex",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "logprobs": null,
                "message": {
                    "content": "{\n    \"问题1\": \"二项逻辑斯谛回归模型是用什么形式表示条件概率分布？\",\n    \"回答1\": \"二项逻辑斯谛回归模型是用参数化的逻辑斯谛分布来表示条件概率分布 $P(Y \\text{ 为 } 1 \\text{ 在 } x)$ 和 $P(Y \\text{ 为 } 0 \\text{ 在 } x)$。\",\n    \"问题2\": \"逻辑斯谛回归模型中的参数 $w$ 和 $b$ 分别代表什么意义？\",\n    \"回答2\": \"在逻辑斯谛回归模型中，$w$ 是权值向量，$b$ 是偏置。其中，$w$ 表示输入的权重，$b$ 表示偏置，$w \\text{ 和 } x$ 的内积 $w \\text{ 和 } x$ 表示线性函数的值。\",\n    \"问题3\": \"逻辑斯谛回归模型中的对数几率函数是如何定义的？\",\n    \"回答3\": \"对于逻辑斯谛回归模型，对数几率函数（logit 函数）定义为 $\\text{logit}(p)=\\text{log} \\frac{p}{1-p}$。在逻辑斯谛回归模型中，输出 $Y=1$ 的对数几率是输入 $x$ 的线性函数。\",\n    \"问题4\": \"逻辑斯谛回归模型是如何将线性函数转换为概率的？\",\n    \"回答4\": \"逻辑斯谛回归模型通过定义式将线性函数 $w \\text{ 和 } x$ 转换为概率：$P(Y=1 \\text{ 在 } x)=\\frac{\\text{exp}(w \\text{ 和 } x)}{1+\\text{exp}(w \\text{ 和 } x)}$。这样，线性函数的值越接近正无穷，概率值就越接近 1；线性函数的值越接近负无穷，概率值就越接近 0。\",\n    \"问题5\": \"逻辑斯谛回归模型是如何进行分类的？\",\n    \"回答5\": \"逻辑斯谛回归模型比较两个条件概率值的大小，并将实例 $x$ 分到概率值较大的那一类。通过计算 $P(Y=1 \\text{ 在 } x)$ 和 $P(Y=0 \\text{ 在 } x)$ ，逻辑斯谛回归模型实现了对输入实例的分类。\",\n    \"问题6\": \"为什么有时需要将权值向量和输入向量加以扩充？\",\n    \"回答6\": \"有时为了方便，将权值向量和输入向量加以扩充可以简化计算和表示。通过扩充后的形式，可以更方便地进行矩阵运算和参数表示，从而简化逻辑斯谛回归模型的表达和计算。\",\n    \"问题7\": \"逻辑斯谛回归模型中的几率是指什么？\",\n    \"回答7\": \"一个事件的几率（odds）是指该事件发生的概率与该事件不发生的概率的比值。如果事件发生的概率是 $p$，那么该事件的几率是 $\\frac{p}{1-p}$。在逻辑斯谛回归模型中，几率被用来表示事件发生和不发生之间的比值关系。\",\n    \"问题8\": \"逻辑斯谛回归模型中的 logit 函数有什么作用？\",\n    \"回答8\": \"在逻辑斯谛回归模型中，logit 函数用于表示输出 $Y=1$ 的对数几率与输入 $x$ 的线性函数之间的关系。它帮助描述了输出为 1 的对数几率与输入之间的线性关系。\",\n    \"问题9\": \"逻辑斯谛回归模型中的线性函数 $w \\text{ 和 } x$ 的值域是什么？\",\n    \"回答9\": \"在逻辑斯谛回归模型中，线性函数 $w \\text{ 和 } x$ 的值域为实数域。通过逻辑斯谛回归模型定义式可以将线性函数转换为概率，从而实现对输入实例进行分类。\",\n    \"问题10\": \"逻辑斯谛回归模型相比其他分类模型有哪些特点？\",\n    \"回答10\": \"相比其他分类模型，逻辑斯谛回归模型具有简单、直观、易于解释等特点。它能够通过线性函数和概率转换实现对输入实例的分类，并且具有较好的可解释性和可理解性。\"\n}",
                    "role": "assistant",
                    "function_call": null,
                    "tool_calls": null
                }
            }
        ],
        "created": 1710735647,
        "model": "gpt-3.5-turbo-1106",
        "object": "chat.completion",
        "system_fingerprint": "fp_4aaaf0dc94",
        "usage": {
            "completion_tokens": 1315,
            "prompt_tokens": 3759,
            "total_tokens": 5074
        },
        "parameters": {
            "model": "gpt-3.5-turbo-1106",
            "temperature": 0.2,
            "frequency_penalty": 0.15,
            "presence_penalty": 0.15
        }
    }
]