[
    {
        "strategy": "subsection",
        "source": "machine_learning_chapter3",
        "title": "7.1.1 线性可分支持向量机",
        "content_length": 3964,
        "content": "Title: 7.1.1 线性可分支持向量机\nContent:\n考虑一个二类分类问题。假设输入空间与特征空间为两个不同的空间。输入空间为欧氏空间或离散集合，特征空间为欧氏空间或希尔伯特空间。线性可分支持向量机、线性支\\\\\n持向量机假设这两个空间的元素一一对应, 并将输入空间中的输入映射为特征空间中的特征向量。非线性支持向量机利用一个从输入空间到特征空间的非线性映射将输入映射为特征向量。所以, 输入都由输入空间转换到特征空间, 支持向量机的学习是在特征空间进行的。\n\n假设给定一个特征空间上的训练数据集\n\n$$\nT=\\left\\{\\left(x_{1}, y_{1}\\right),\\left(x_{2}, y_{2}\\right), \\cdots,\\left(x_{N}, y_{N}\\right)\\right\\}\n$$\n\n其中, $x_{i} \\in \\mathcal{X}=\\boldsymbol{R}^{n}, y_{i} \\in \\mathcal{Y}=\\{+1,-1\\}, i=1,2, \\cdots, N \\circ x_{i}$ 为第 $i$ 个特征向量, 也称为实例, $y_{i}$ 为 $x_{i}$ 的类标记。当 $y_{i}=+1$ 时, 称 $x_{i}$ 为正例; 当 $y_{i}=-1$ 时, 称 $x_{i}$ 为负例。 $\\left(x_{i}, y_{i}\\right)$称为样本点。再假设训练数据集是线性可分的 (见定义 2.2 )。\n\n学习的目标是在特征空间中找到一个分离超平面, 能将实例分到不同的类。分离超平面对应于方程 $w \\cdot x+b=0$, 它由法向量 $w$ 和截距 $b$ 决定, 可用 $(w, b)$ 来表示。分离超平面将特征空间划分为两部分, 一部分是正类, 一部分是负类。法向量指向的一侧为正类, 另一侧为负类。\n\n一般地, 当训练数据集线性可分时, 存在无穷个分离超平面可将两类数据正确分开。感知机利用误分类最小的策略, 求得分离超平面, 不过这时的解有无穷多个。线性可分支持向量机利用间隔最大化求最优分离超平面, 这时, 解是唯一的。\n\n定义 7.1 (线性可分支持向量机) 给定线性可分训练数据集, 通过间隔最大化或等价地求解相应的凸二次规划问题学习得到的分离超平面为\n\n\n\\begin{equation*}\nw^{*} \\cdot x+b^{*}=0 \\tag{7.1}\n\\end{equation*}\n\n\n以及相应的分类决策函数\n\n\n\\begin{equation*}\nf(x)=\\operatorname{sign}\\left(w^{*} \\cdot x+b^{*}\\right) \\tag{7.2}\n\\end{equation*}\n\n\n称为线性可分支持向量机。\n\n考虑如图 7.1 所示的二维特征空间中的分类问题。图中 “○” 表示正例, “ ×” 表示负例。训练数据集线性可分, 这时有许多直线能将两类数据正确划分。线性可分支持向量机对应着将两类数据正确划分并且间隔最大的直线, 如图 7.1 所示。\n\n\\begin{center}\n\\includegraphics[max width=\\textwidth]{2024_03_13_aa878f82ee3a63be2358g-38}\n\\end{center}\n\n图 7.1 二类分类问题\n\n间隔最大及相应的约束最优化问题将在下面叙述。这里先介绍函数间隔和几何间隔的概念。\n\n\\section*{7.1 .2 函数间隔和几何间隔}\n在图 7.1 中, 有 $A, B, C$ 三个点, 表示 3 个实例, 均在分离超平面的正类一侧, 预测它们的类。点 $A$ 距分离超平面较远, 若预测该点为正类, 就比较确信预测是正确的; 点 $C$ 距分离超平面较近, 若预测该点为正类就不那么确信; 点 $B$ 介于点 $A$ 与点 $C$ 之间, 预测其为正类的确信度也在 $A$ 与 $C$ 之间。\n\n一般来说, 一个点距离分离超平面的远近可以表示分类预测的确信程度。在超平面 $w \\cdot x+b=0$ 确定的情况下, $|w \\cdot x+b|$ 能够相对地表示点 $x$ 距离超平面的远近。而 $w \\cdot x+b$的符号与类标记 $y$ 的符号是否一致能够表示分类是否正确, 所以可用量 $y(w \\cdot x+b)$ 来表示分类的正确性及确信度, 这就是函数间隔 (functional margin) 的概念。\n\n定义 7.2 (函数间隔) 对于给定的训练数据集 $T$ 和超平面 $(w, b)$, 定义超平面 $(w, b)$ 关于样本点 $\\left(x_{i}, y_{i}\\right)$ 的函数间隔为\n\n\n\\begin{equation*}\n\\hat{\\gamma}_{i}=y_{i}\\left(w \\cdot x_{i}+b\\right) \\tag{7.3}\n\\end{equation*}\n\n\n定义超平面 $(w, b)$ 关于训练数据集 $T$ 的函数间隔为超平面 $(w, b)$ 关于 $T$ 中所有样本点 $\\left(x_{i}, y_{i}\\right)$ 的函数间隔之最小值，即\n\n\n\\begin{equation*}\n\\hat{\\gamma}=\\min _{i=1,2, \\cdots, N} \\hat{\\gamma}_{i} \\tag{7.4}\n\\end{equation*}\n\n\n函数间隔可以表示分类预测的正确性及确信度。但是选择分离超平面时, 只有函数间隔还不够。因为只要成比例地改变 $w$ 和 $b$, 例如, 将它们改为 $2 w$ 和 $2 b$, 超平面并没有改变, 但函数间隔却成为原来的两倍。这一事实启示我们, 可以对分离超平面的法向量 $w$ 加某些约束,如规范化, $\\|w\\|=1$, 使得间隔是确定的。这时函数间隔成为几何间隔（geometric margin）。\n\n图 7.2 给出了超平面 $(w, b)$ 及其法向量 $w$ 。点 $A$ 表示某一实例 $x_{i}$, 其类标记为 $y_{i}=+1$ 。点 $A$ 与超平面 $(w, b)$ 的距离由线段 $A B$ 给出, 记作 $\\gamma_{i}$ 。\n\n$$\n\\gamma_{i}=\\frac{w}{\\|w\\|} \\cdot x_{i}+\\frac{b}{\\|w\\|}\n$$\n\n其中, $\\|w\\|$ 为 $w$ 的 $L_{2}$ 范数。这是点 $A$ 在超平面正的一侧的情形。如果点 $A$ 在超平面负的一侧, 即 $y_{i}=-1$, 那么点与超平面的距离为\n\n$$\n\\gamma_{i}=-\\left(\\frac{w}{\\|w\\|} \\cdot x_{i}+\\frac{b}{\\|w\\|}\\right)\n$$\n\n一般地, 当样本点 $\\left(x_{i}, y_{i}\\right)$ 被超平面 $(w, b)$ 正确分类时, 点 $x_{i}$ 与超平面 $(w, b)$ 的距离是\n\n\\begin{center}\n\\includegraphics[max width=\\textwidth]{2024_03_13_aa878f82ee3a63be2358g-39}\n\\end{center}\n\n图 7.2 几何间隔\n\n$$\n\\gamma_{i}=y_{i}\\left(\\frac{w}{\\|w\\|} \\cdot x_{i}+\\frac{b}{\\|w\\|}\\right)\n$$\n\n由这一事实导出几何间隔的概念。\n\n定义 7.3 (几何间隔) 对于给定的训练数据集 $T$ 和超平面 $(w, b)$, 定义超平面 $(w, b)$ 关于样本点 $\\left(x_{i}, y_{i}\\right)$ 的几何间隔为\n\n\n\\begin{equation*}\n\\gamma_{i}=y_{i}\\left(\\frac{w}{\\|w\\|} \\cdot x_{i}+\\frac{b}{\\|w\\|}\\right) \\tag{7.5}\n\\end{equation*}\n\n\n定义超平面 $(w, b)$ 关于训练数据集 $T$ 的几何间隔为超平面 $(w, b)$ 关于 $T$ 中所有样本点 $\\left(x_{i}, y_{i}\\right)$ 的几何间隔之最小值, 即\n\n\n\\begin{equation*}\n\\gamma=\\min _{i=1,2, \\cdots, N} \\gamma_{i} \\tag{7.6}\n\\end{equation*}\n\n\n超平面 $(w, b)$ 关于样本点 $\\left(x_{i}, y_{i}\\right)$ 的几何间隔一般是实例点到超平面的带符号的距离 (signed distance), 当样本点被超平面正确分类时就是实例点到超平面的距离。\n\n从函数间隔和几何间隔的定义 (式 (7.3) 式 (7.6)) 可知, 函数间隔和几何间隔有下面的关系:\n\n\n\\begin{align*}\n& \\gamma_{i}=\\frac{\\hat{\\gamma}_{i}}{\\|w\\|}  \\tag{7.7}\\\\\n& \\gamma=\\frac{\\hat{\\gamma}}{\\|w\\|} \\tag{7.8}\n\\end{align*}\n\n\n如果 $\\|w\\|=1$, 那么函数间隔和几何间隔相等。如果超平面参数 $w$ 和 $b$ 成比例地改变 (超平面没有改变), 函数间隔也按此比例改变, 而几何间隔不变。"
    },
    {
        "id": "chatcmpl-93ysNGRdh72ZIpAI3A2xlr4HWY1LJ",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "logprobs": null,
                "message": {
                    "content": "{\n    \"问题1\": \"线性可分支持向量机与非线性支持向量机的主要区别是什么？\",\n    \"回答1\": \"线性可分支持向量机假设输入空间与特征空间一一对应，并通过间隔最大化或等价地求解凸二次规划问题学习得到分离超平面。而非线性支持向量机利用一个从输入空间到特征空间的非线性映射将输入映射为特征向量，从而实现对非线性分类问题的处理。\",\n    \"问题2\": \"线性可分支持向量机的学习目标是什么？\",\n    \"回答2\": \"线性可分支持向量机的学习目标是在特征空间中找到一个分离超平面，能够将实例分到不同的类。这个分离超平面对应于方程 $w \\boldsymbol{\\bullet} x+b=0$，由法向量 $w$ 和截距 $b$ 决定，通过间隔最大化求最优分离超平面。\",\n    \"问题3\": \"如何定义函数间隔和几何间隔？\",\n    \"回答3\": \"对于给定的训练数据集 $T$ 和超平面 $(w, b)$，定义超平面 $(w, b)$ 关于样本点 $\\big(x_{i}, y_{i}\\big)$ 的函数间隔为 $\\tilde{\\text{γ}}_{i}=y_{i}\\big(w \\boldsymbol{\\bullet} x_{i}+b\\big)$，定义超平面 $(w, b)$ 关于训练数据集 $T$ 的函数间隔为超平面 $(w, b)$ 关于 $T$ 中所有样本点 $\\big(x_{i}, y_{i}\\big)$ 的函数间隔之最小值。而几何间隔则是函数间隔除以法向量 $w$ 的 $L_{2}$ 范数。\",\n    \"问题4\": \"函数间隔和几何间隔有什么关系？\",\n    \"回答4\": \"函数间隔和几何间隔之间的关系是，几何间隔等于函数间隔除以法向量 $w$ 的 $L_{2}$ 范数。如果法向量 $w$ 的 $L_{2}$ 范数为1，则函数间隔和几何间隔相等；而如果超平面参数 $w$ 和 $b$ 成比例地改变时，函数间隔也按此比例改变，而几何间隔不变。\",\n    \"问题5\": \"线性可分支持向量机的分类决策函数是如何定义的？\",\n    \"回筗5\": \"线性可分支持向量机的分类决策函数定义为 $f(x)=\\text{sign}\\big(w^{*} \\boldsymbol{\\bullet} x+b^{*}\\big)$，其中 $w^{*} \\boldsymbol{\\bullet} x+b^{*}=0$ 是通过学习得到的分离超平面方程。\",\n    \"问题6\": \"线性可分支持向量机与感知机在处理线性可分数据时有何不同？\",\n    \"回筗6\": \"当训练数据集线性可分时，感知机利用误分类最小的策略求得分离超平面，但这时的解有无穷多个。而线性可分支持向量机利用间隔最大化求最优分离超平面，这时解是唯一的。\",\n    \"问题7\": \"线性可分支持向量机在二维特征空间中的作用是什么？\",\n    \"回筗7\": \"在二维特征空间中，线性可分支持向量机对应着将两类数据正确划分并且间隔最大的直线。它能够有效地将正例和负例进行正确划分，并且在两类数据之间保持最大的距离，从而提高分类的准确性和鲁棒性。\",\n    \"问题8\": \"为什么选择几何间隔作为衡量分类预测确信度的指标？\",\n    \"回筗8\": \"选择几何间隔作为衡量分类预测确信度的指标是因为几何间隔能够表示点距离分离超平面的带符号距离，当样本点被超平面正确分类时就是实例点到超平面的距离。这种度量方式更加直观和具有实际意义，能够更好地反映分类预测的正确性和确信度。\",\n    \"问题9\": \"如何利用凸二次规划问题来学习得到线性可分支持向量机的分离超平面？\",\n    \"回筗9\": \"给定线性可分训练数据集，可以通过间隔最大化或等价地求解相应的凸二次规划问题来学习得到线性可分支持向量机的分离超平面。通过求解凸二次规划问题，可以得到唯一的最优分离超平面。\",\n    \"问题10\": \"线性可分支持向量机与非线性支持向量机在学习过程中有何不同之处？\",\n    \"回筗10\": \"线性可分支持向量机在学习过程中通过间隔最大化或等价地求解相应的凸二次规划问题来学习得到唯一的最优分离超平面。而非线性支持向量机则需要利用一个从输入空间到特征空间的非线性映射将输入映射为特征向量，并通过相应的核技巧来处理非线性分类问题。\"\n}",
                    "role": "assistant",
                    "function_call": null,
                    "tool_calls": null
                }
            }
        ],
        "created": 1710736019,
        "model": "gpt-3.5-turbo-1106",
        "object": "chat.completion",
        "system_fingerprint": "fp_4aaaf0dc94",
        "usage": {
            "completion_tokens": 1539,
            "prompt_tokens": 5456,
            "total_tokens": 6995
        },
        "parameters": {
            "model": "gpt-3.5-turbo-1106",
            "temperature": 0.2,
            "frequency_penalty": 0.15,
            "presence_penalty": 0.15
        }
    }
]