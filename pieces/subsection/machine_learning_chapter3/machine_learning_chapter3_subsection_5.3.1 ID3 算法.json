[
    {
        "strategy": "subsection",
        "source": "machine_learning_chapter3",
        "title": "5.3.1 ID3 算法",
        "content_length": 1899,
        "content": "Title: 5.3.1 ID3 算法\nContent:\nID3 算法的核心是在决策树各个结点上应用信息增益准则选择特征, 递归地构建决策树。具体方法是: 从根结点 (root node) 开始, 对结点计算所有可能的特征的信息增益, 选择信息增益最大的特征作为结点的特征, 由该特征的不同取值建立子结点; 再对子结点递归地调用以上方法, 构建决策树; 直到所有特征的信息增益均很小或没有特征可以选择为止, 最后得到一棵决策树。ID3 相当于用极大似然法进行概率模型的选择。\n\n\\section*{算法 5.2 (ID3 算法)}\n输入: 训练数据集 $D$, 特征集 $A$ 阈值 $\\varepsilon$ 。\n\n输出: 决策树 $T$ 。\n\n(1) 若 $D$ 中所有实例属于同一类 $C_{k}$, 则 $T$ 为单结点树, 并将类 $C_{k}$ 作为该结点的类标记，返回 $T$;\n\n(2) 若 $A=\\varnothing$, 则 $T$ 为单结点树, 并将 $D$ 中实例数最大的类 $C_{k}$ 作为该结点的类标记,返回 $T$;\n\n(3) 否则, 按算法 5.1 计算 $A$ 中各特征对 $D$ 的信息增益, 选择信息增益最大的特征 $A_{g}$;\n\n(4) 如果 $A_{g}$ 的信息增益小于阈值 $\\varepsilon$, 则置 $T$ 为单结点树, 并将 $D$ 中实例数最大的类 $C_{k}$作为该结点的类标记，返回 $T$;\n\n(5) 否则, 对 $A_{g}$ 的每一可能值 $a_{i}$, 依 $A_{g}=a_{i}$ 将 $D$ 分割为若干非空子集 $D_{i}$, 将 $D_{i}$ 中实例数最大的类作为标记, 构建子结点, 由结点及其子结点构成树 $T$, 返回 $T$;\n\n(6) 对第 $i$ 个子结点, 以 $D_{i}$ 为训练集, 以 $A-\\left\\{A_{g}\\right\\}$ 为特征集, 递归地调用步骤 (1) 步骤 (5), 得到子树 $T_{i}$, 返回 $T_{i}$ 。\n\n例 5.3 对表 5.1 的训练数据集, 利用 ID3 算法建立决策树。\n\n解 利用例 5.2 的结果, 由于特征 $A_{3}$ (有自己的房子) 的信息增益值最大, 所以选择特征 $A_{3}$ 作为根结点的特征。它将训练数据集 $D$ 划分为两个子集 $D_{1}$ ( $A_{3}$ 取值为 “是”) 和 $D_{2}$ ( $A_{3}$ 取值为 “否”)。由于 $D_{1}$ 只有同一类的样本点, 所以它成为一个叶结点, 结点的类标记为 “是”。\n\n对 $D_{2}$ 则需从特征 $A_{1}$ (年龄), $A_{2}$ (有工作) 和 $A_{4}$ (信贷情况) 中选择新的特征。计算各个特征的信息增益:\n\n$$\n\\begin{aligned}\n& g\\left(D_{2}, A_{1}\\right)=H\\left(D_{2}\\right)-H\\left(D_{2} \\mid A_{1}\\right)=0.918-0.667=0.251 \\\\\n& g\\left(D_{2}, A_{2}\\right)=H\\left(D_{2}\\right)-H\\left(D_{2} \\mid A_{2}\\right)=0.918 \\\\\n& g\\left(D_{2}, A_{4}\\right)=H\\left(D_{2}\\right)-H\\left(D_{2} \\mid A_{4}\\right)=0.474\n\\end{aligned}\n$$\n\n选择信息增益最大的特征 $A_{2}$ (有工作) 作为结点的特征。由于 $A_{2}$ 有两个可能取值, 从这一结点引出两个子结点: 一个对应 “是” (有工作) 的子结点, 包含 3 个样本, 它们属于同一类,所以这是一个叶结点, 类标记为 “是” ; 另一个是对应 “否” (无工作) 的子结点, 包含 6 个样本, 它们也属于同一类, 所以这也是一个叶结点, 类标记为 “否”。\n\n这样生成一棵如图 5.5 所示的决策树, 该决策树只用了两个特征（有两个内部结点）。\n\n\\begin{center}\n\\includegraphics[max width=\\textwidth]{2024_03_13_aa878f82ee3a63be2358g-09}\n\\end{center}\n\n图 5.5 决策树的生成\n\nID3 算法只有树的生成, 所以该算法生成的树容易产生过拟合。"
    },
    {
        "id": "chatcmpl-93ylXt0eWat1w3P1WqbPxPqsKT0Xp",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "logprobs": null,
                "message": {
                    "content": "{\n    \"问题1\": \"ID3 算法的核心是什么？\",\n    \"回答1\": \"ID3 算法的核心是在决策树各个结点上应用信息增益准则选择特征，递归地构建决策树。具体方法是从根结点开始，对结点计算所有可能的特征的信息增益，选择信息增益最大的特征作为结点的特征，由该特征的不同取值建立子结点，再对子结点递归地调用以上方法，构建决策树，直到所有特征的信息增益均很小或没有特征可以选择为止。\",\n    \"问题2\": \"ID3 算法的输入和输出是什么？\",\n    \"回答2\": \"ID3 算法的输入是训练数据集 $D$、特征集 $A$ 和阈值 $\\text{ε}$。输出是决策树 $T$。\",\n    \"问题3\": \"ID3 算法中如何选择根结点的特征？\",\n    \"回答3\": \"在 ID3 算法中，选择根结点的特征是通过计算所有可能特征的信息增益，选择信息增益最大的特征作为根结点的特征。\",\n    \"问题4\": \"ID3 算法中如何处理信息增益小于阈值的情况？\",\n    \"回答4\": \"如果某个特征的信息增益小于阈值 $\\text{ε}$，则将该结点置为单结点树，并将该结点的类标记为 $D$ 中实例数最大的类，返回该单结点树。\",\n    \"问题5\": \"ID3 算法如何构建子结点？\",\n    \"回答5\": \"在 ID3 算法中，对于选定的特征 $A_{g}$，对其每一可能值 $a_{i}$，依 $A_{g}=a_{i}$ 将 $D$ 分割为若干非空子集 $D_{i}$，将 $D_{i}$ 中实例数最大的类作为标记，构建子结点，由结点及其子结点构成树 $T$。\",\n    \"问题6\": \"ID3 算法生成的决策树容易产生什么问题？\",\n    \"回答6\": \"ID3 算法只有树的生成，容易产生过拟合问题。这意味着生成的决策树可能在训练数据上表现良好，但在未知数据上表现不佳。\",\n    \"问题7\": \"ID3 算法如何处理训练数据集中所有实例属于同一类的情况？\",\n    \"回答7\": \"如果训练数据集 $D$ 中所有实例属于同一类 $C_{k}$，则将该类作为单结点树的类标记，返回该单结点树。\",\n    \"问题8\": \"ID3 算法如何处理特征集为空集的情况？\",\n    \"回答8\": \"如果特征集 $A$ 为空集，则将训练数据集中实例数最大的类作为单结点树的类标记，返回该单结点树。\",\n    \"问题9\": \"ID3 算法如何处理信息增益最大的特征对应多个可能取值的情况？\",\n    \"回答9\": \"如果信息增益最大的特征有多个可能取值，则对每个可能取值构建相应子结点，并递归地调用 ID3 算法生成子树。\",\n    \"问题10\": \"ID3 算法如何选择新的特征进行递归调用？\",\n    \"回答10\": \"在 ID3 算法中，在生成每个子结点时，选择新的特征时会排除已经选择过的特征，以确保不会重复选择已经使用过的特征。\"\n}",
                    "role": "assistant",
                    "function_call": null,
                    "tool_calls": null
                }
            }
        ],
        "created": 1710735595,
        "model": "gpt-3.5-turbo-1106",
        "object": "chat.completion",
        "system_fingerprint": "fp_4aaaf0dc94",
        "usage": {
            "completion_tokens": 1071,
            "prompt_tokens": 4022,
            "total_tokens": 5093
        },
        "parameters": {
            "model": "gpt-3.5-turbo-1106",
            "temperature": 0.2,
            "frequency_penalty": 0.15,
            "presence_penalty": 0.15
        }
    }
]