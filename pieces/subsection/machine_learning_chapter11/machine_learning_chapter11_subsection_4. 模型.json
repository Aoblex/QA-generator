[
    {
        "strategy": "subsection",
        "source": "machine_learning_chapter11",
        "title": "4. 模型",
        "content_length": 4531,
        "content": "Title: 4. 模型\nContent:\n前馈神经网络可以作为机器学习模型用于不同任务, 有以下几种代表情况。\n\n(1) 严格意义上在 0 点并没有导数, 这里定义函数在该处的导数为 0 。\n\n(1) 用于回归。神经网络的输出层只有一个神经元, 其输出是一个实数值。神经网络表示为 $y=f(\\boldsymbol{x})$, 其中 $y \\in \\mathcal{R}$ 。预测时给定输入 $\\boldsymbol{x}$, 计算输出 $y$ 。\n\n(2) 用于二类分类。神经网络的输出层只有一个神经元, 其输出是一个概率值。神经网络表示为 $p=P(y=1 \\mid \\boldsymbol{x})=f(\\boldsymbol{x})$, 其中 $y \\in\\{0,1\\}$, 满足条件\n\n$$\n0<P(y=1 \\mid \\boldsymbol{x})<1, \\quad P(y=1 \\mid \\boldsymbol{x})+P(y=0 \\mid \\boldsymbol{x})=1\n$$\n\n预测时给定输入 $\\boldsymbol{x}$, 计算其属于类别 1 的概率。如果概率大于 0.5 , 则将输入分到类别 1 , 否则分到类别 0 。\n\n(3) 用于多类分类 (multi-class classification)。神经网络的输出层只有一个神经元, 神经元的输出是由 $l$ 个概率值组成的概率向量。神经网络表示为 $\\boldsymbol{p}=\\left[P\\left(y_{k}=1 \\mid \\boldsymbol{x}\\right)\\right]=f(\\boldsymbol{x})$, 其中 $y_{k} \\in\\{0,1\\}, k=1,2, \\cdots, l$, 满足条件\n\n$$\n\\sum_{k=1}^{l} y_{k}=1, \\quad 0<P\\left(y_{k}=1 \\mid x\\right)<1, \\quad \\sum_{k=1}^{l} P\\left(y_{k}=1 \\mid x\\right)=1, \\quad k=1,2, \\cdots, l\n$$\n\n也就是说 $\\left[y_{1}, y_{2}, \\cdots, y_{l}\\right]$ 是只有一个元素为 1 , 其他元素为 0 的向量, 这样的向量称为独热向量 (one-hot vector), $\\left[P\\left(y_{1}=1 \\mid \\boldsymbol{x}\\right), P\\left(y_{2}=1 \\mid \\boldsymbol{x}\\right), \\cdots, P\\left(y_{l}=1 \\mid \\boldsymbol{x}\\right)\\right]$ 是定义在独热向量上的概率分布, 表示输入 $\\boldsymbol{x}$ 属于 $l$ 个类别的概率。预测时给定输入 $\\boldsymbol{x}$, 计算其属于各个类别的概率。将输入分到概率最大的类别, 这时输入只可能被分到一个类别。\n\n(4) 用于多标签分类 (multi-label classification)。神经网络的输出层有 $l$ 个神经元,每个神经元的输出是一个概率值。神经网络表示为 $\\boldsymbol{p}=\\left[P\\left(y_{k}=1 \\mid \\boldsymbol{x}\\right)\\right]=f(\\boldsymbol{x})$, 其中 $y_{k} \\in\\{0,1\\}, k=1,2, \\cdots, l$, 满足条件\n\n$$\n0<P\\left(y_{k}=1 \\mid \\boldsymbol{x}\\right)<1, \\quad P\\left(y_{k}=1 \\mid \\boldsymbol{x}\\right)+P\\left(y_{k}=0 \\mid \\boldsymbol{x}\\right)=1, \\quad k=1,2, \\cdots, l\n$$\n\n$\\left[P\\left(y_{1}=1 \\mid \\boldsymbol{x}\\right), P\\left(y_{2}=1 \\mid \\boldsymbol{x}\\right), \\cdots, P\\left(y_{l}=1 \\mid \\boldsymbol{x}\\right)\\right]$ 表示输入 $\\boldsymbol{x}$ 分别属于 1 个类别的概率。预测时给定输入 $\\boldsymbol{x}$, 计算其属于各个类别的概率。将输入分到概率大于 0.5 的所有类别, 这时输入可以被分到多个类别 (赋予多个标签)。\n\n注意, 在回归中神经网络的输出和模型的输出是相同的, 都是实数值; 在分类中神经网络的输出和模型的输出是不同的, 前者是概率值, 后者是类别。现实中经常对神经网络及其表示的模型不严格区分, 这一点其他类型的神经网络也一样。\n\n\\section*{5. 输出层的神经元}\n输出层神经元函数由两部分组成: 仿射函数和激活函数。输出层激活函数通常使用恒等函数、 $\\mathrm{S}$ 型函数、软最大化函数。在回归、二类分类、多类分类、多标签分类中, 激活函数有不同的形式。\n\n回归时, 输出层只有一个神经元, 其激活函数是恒等函数, 神经元函数是\n\n\n\\begin{equation*}\ny=g(z)=z, z=\\boldsymbol{w}^{(s)^{\\mathrm{T}}} \\boldsymbol{h}^{(s-1)}+b^{(s)} \\tag{23.21}\n\\end{equation*}\n\n\n这里 $\\boldsymbol{w}^{(s)}$ 是权重向量, $b^{(s)}$ 是偏置, $g(\\cdot)$ 是恒等函数, $\\boldsymbol{h}^{(s-1)}$ 是第 $s-1$ 隐层的输出。称这样的输出层为线性输出层。\\\\\n二类分类时, 输出层只有一个神经元, 其激活函数是 $\\mathrm{S}$ 型函数, 神经元函数是\n\n\n\\begin{equation*}\nP(y=1 \\mid \\boldsymbol{x})=g(z)=\\frac{1}{1+\\mathrm{e}^{-z}}, z=\\boldsymbol{w}^{(s)^{\\mathrm{T}}} \\boldsymbol{h}^{(s-1)}+b^{(s)} \\tag{23.22}\n\\end{equation*}\n\n\n这里 $\\boldsymbol{w}^{(s)}$ 是权重向量, $b^{(s)}$ 是偏置, $g(\\cdot)$ 是 $\\mathrm{S}$ 型函数, $\\boldsymbol{h}^{(s-1)}$ 是第 $s-1$ 隐层的输出。\n\n多类分类时, 输出层只有一个神经元, 其激活函数是软最大化函数 (softmax function),神经元函数是\n\n\n\\begin{equation*}\nP\\left(y_{k}=1 \\mid \\boldsymbol{x}\\right)=g\\left(z_{k}\\right)=\\frac{\\mathrm{e}^{z_{k}}}{\\sum_{i=1}^{l} \\mathrm{e}^{z_{i}}}, z_{k}=\\boldsymbol{w}_{k}^{(s)^{\\mathrm{T}}} \\boldsymbol{h}^{(s-1)}+b_{k}^{(s)}, \\quad k=1,2, \\cdots, l \\tag{23.23}\n\\end{equation*}\n\n\n这里 $\\boldsymbol{w}_{k}^{(s)}$ 是权重向量, $b_{k}^{(s)}$ 是偏置, $g(\\cdot)$ 是软最大化函数, $\\boldsymbol{h}^{(s-1)}$ 是第 $s-1$ 隐层的输出。称这样的输出层为软最大化输出层。\n\n软最大化函数的名字来自它是最大化 ( $\\max$ ) 函数的近似这一事实。如果 $z_{k} \\gg z_{j}, j \\neq k$,那么 $p_{k}=P\\left(y_{k}=1\\right) \\approx 1, p_{j}=P\\left(y_{j}=1\\right) \\approx 0$ 。软最大化函数是 $l$ 维实数向量 $\\boldsymbol{z}$ 到 $l$ 维概率向量 $\\boldsymbol{p}$ 的映射。\n\n$$\n\\boldsymbol{z}=\\left[\\begin{array}{c}\nz_{1} \\\\\nz_{2} \\\\\n\\vdots \\\\\nz_{l}\n\\end{array}\\right] \\rightarrow \\boldsymbol{p}=\\left[\\begin{array}{c}\np_{1} \\\\\np_{2} \\\\\n\\vdots \\\\\np_{l}\n\\end{array}\\right]\n$$\n\n软最大化函数的偏导数或雅可比矩阵元素是 (推导见附录 $\\mathrm{F}$ )\n\n\\[\n\\frac{\\partial p_{k}}{\\partial z_{j}}=\\left\\{\\begin{array}{ll}\np_{k}\\left(1-p_{k}\\right), & j=k  \\tag{23.24}\\\\\n-p_{j} p_{k}, & j \\neq k\n\\end{array}, \\quad j, k=1,2, \\cdots, l\\right.\n\\]\n\n前馈神经网络用于多类分类时, 为了提高效率, 在预测时经常省去激活函数的计算, 选取仿射函数 (净输入) $z_{k}$ 值最大的类别。这样做, 分类结果是等价的, 因为软最大化函数的分母对各个类别是常量, 而分子的指数函数是单调递增函数。实数值 $z_{k}$ 又称为对数几率 (logit)。\n\n多标签分类时, 输出层有 $l$ 个神经元, 每个神经元的激活函数都是 $\\mathrm{S}$ 型函数, 神经元函数是\n\n\n\\begin{equation*}\nP\\left(y_{k}=1 \\mid \\boldsymbol{x}\\right)=g\\left(z_{k}\\right)=\\frac{1}{1+\\mathrm{e}^{-z_{k}}}, \\quad z_{k}=\\boldsymbol{w}_{k}^{(s)^{\\mathrm{T}}} \\boldsymbol{h}^{(s-1)}+b_{k}^{(s)}, \\quad k=1,2, \\cdots, l \\tag{23.25}\n\\end{equation*}\n\n\n这里 $\\boldsymbol{w}_{k}^{(s)}$ 是权重向量, $b_{k}^{(s)}$ 是偏置, $g(\\cdot)$ 是 $\\mathrm{S}$ 型函数, $\\boldsymbol{h}^{(s-1)}$ 是第 $s-1$ 隐层的输出。"
    },
    {
        "id": "chatcmpl-93z6z3CWA7SjQ24YmB6E1TKXP7UQX",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "logprobs": null,
                "message": {
                    "content": "{\n    \"问题1\": \"前馈神经网络用于回归任务时，输出层的神经元函数是怎样定义的？\",\n    \"回答1\": \"在回归任务中，前馈神经网络的输出层只有一个神经元，其激活函数是恒等函数，即 $y=g(z)=z$。其中 $z=\\boldsymbol{w}^{(s)^{\\top}} \\boldsymbol{h}^{(s-1)}+b^{(s)}$，$\\boldsymbol{w}^{(s)}$ 是权重向量，$b^{(s)}$ 是偏置，$g(\\boldsymbol{\\bullet})$ 是恒等函数，$\\boldsymbol{h}^{(s-1)}$ 是第 $s-1$ 隐层的输出。\",\n    \"问题2\": \"前馈神经网络用于二类分类任务时，输出层的神经元函数是怎样定义的？\",\n    \"回答2\": \"在二类分类任务中，前馈神经网络的输出层只有一个神经元，其激活函数是 $\\text{S}$ 型函数，即 $P(y=1 \\text{ 为 } \\boldsymbol{x})=g(z)=\\frac{1}{1+\\text{e}^{-z}}$。其中 $z=\\boldsymbol{w}^{(s)^{\\top}} \\boldsymbol{h}^{(s-1)}+b^{(s)}$，$\\boldsymbol{w}^{(s)}$ 是权重向量，$b^{(s)}$ 是偏置，$g(\\boldsymbol{\\bullet})$ 是 $\\text{S}$ 型函数，$\\boldsymbol{h}^{(s-1)}$ 是第 $s-1$ 隐层的输出。\",\n    \"问题3\": \"前馈神经网络用于多类分类任务时，输出层的神经元函数是怎样定义的？\",\n    \"回答3\": \"在多类分类任务中，前馈神经网络的输出层只有一个神经元，其激活函数是软最大化函数（softmax function），即 $P\\big(y_{k}=1 \\text{ 为 } \\boldsymbol{x}\\big)=g\\big(z_{k}\\big)=\\frac{\\text{e}^{z_{k}}}{\\text{∑}_{i=1}^{l} \\text{e}^{z_{i}}}$。其中 $z_{k}=\\boldsymbol{w}_{k}^{(s)^{\\top}} \\boldsymbol{h}^{(s-1)}+b_{k}^{(s)}$，$\\boldsymbol{w}_{k}^{(s)}$ 是权重向量，$b_{k}^{(s)}$ 是偏置，$g(\\boldsymbol{\\bullet})$ 是软最大化函数，$\\boldsymbol{h}^{(s-1)}$ 是第 $s-1$ 隐层的输出。\",\n    \"问题4\": \"软最大化函数在多类分类任务中起到什么作用？\",\n    \"回答4\": \"软最大化函数是将 $l$ 维实数向量 $\\boldsymbol{z}$ 映射为 $l$ 维概率向量 $\\boldsymbol{p}$ 的映射。它能够将神经网络的输出转化为表示输入 $\\boldsymbol{x}$ 属于 $l$ 个类别的概率分布。在预测时，可以根据概率最大的类别来确定输入的分类。\",\n    \"问题5\": \"在多标签分类任务中，前馈神经网络的输出层是如何定义的？\",\n    \"回答5\": \"在多标签分类任务中，前馈神经网络的输出层有 $l$ 个神经元，每个神经元的激活函数都是 $\\text{S}$ 型函数，即 $P\\big(y_{k}=1 \\text{ 为 } \\boldsymbol{x}\\big)=g\\big(z_{k}\\big)=\\frac{1}{1+\\text{e}^{-z_{k}}}$。其中 $z_{k}=\\boldsymbol{w}_{k}^{(s)^{\\top}} \\boldsymbol{h}^{(s-1)}+b_{k}^{(s)}$，$\\boldsymbol{w}_{k}^{(s)}$ 是权重向量，$b_{k}^{(s)}$ 是偏置，$g(\\boldsymbol{\\bullet})$ 是 $\\text{S}$ 型函数，$\\boldsymbol{h}^{(s-1)}$ 是第 $s-1$ 隐层的输出。\",\n    \"问题6\": \"为什么在多类分类任务中，在预测时通常省去激活函数的计算？\",\n    \"回答6\": \"在多类分类任务中，在预测时通常省去激活函数的计算是为了提高效率。通过选取仿射函数（净输入）值最大的类别来确定输入的分类。这样做是等价的，因为软最大化函数的分母对各个类别是常量，而分子的指数函数是单调递增函数。\",\n    \"问题7\": \"输出层激活函数在回归、二类分类、多类分类和多标签分类中有何不同形式？\",\n    \"回答7\": \"在回归中，输出层激活函数是恒等函数；在二类分类中，输出层激活函数是 $\\text{S}$ 型函数；在多类分类中，输出层激活函数是软最大化函数；在多标签分类中，每个神经元的激活函数都是 $\\text{S}$ 型函数。\",\n    \"问题8\": \"输出层神经元函数由哪两部分组成？\",\n    \"回答8\": \"输出层神经元函数由仿射函数和激活函数两部分组成。其中仿射函数用于计算净输入 $z_k$ 的值，而激活函数则将净输入转换为最终的输出结果。\",\n    \"问题9\": \"在多类分类任务中，软最大化函数的导数或雅可比矩阵元素是如何计算得到的？\",\n    \"回答9\": \"软最大化函数的导数或雅可比矩阵元素计算公式为 $\\frac{\\text{∂} p_k}{\\text{∂} z_j}=\\begin{cases} p_k\\big(1-p_k\\big), & j=k \\\\ -p_j p_k, & j \\neq k \\tag{23.24}\\big. \\right.$。其中 $j, k=1,2, \\text{...}, l$。\"\n}",
                    "role": "assistant",
                    "function_call": null,
                    "tool_calls": null
                }
            }
        ],
        "created": 1710736925,
        "model": "gpt-3.5-turbo-1106",
        "object": "chat.completion",
        "system_fingerprint": "fp_4aaaf0dc94",
        "usage": {
            "completion_tokens": 1678,
            "prompt_tokens": 5317,
            "total_tokens": 6995
        },
        "parameters": {
            "model": "gpt-3.5-turbo-1106",
            "temperature": 0.2,
            "frequency_penalty": 0.15,
            "presence_penalty": 0.15
        }
    }
]