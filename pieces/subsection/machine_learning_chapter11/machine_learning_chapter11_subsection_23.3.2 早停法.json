[
    {
        "strategy": "subsection",
        "source": "machine_learning_chapter11",
        "title": "23.3.2 早停法",
        "content_length": 1465,
        "content": "Title: 23.3.2 早停法\nContent:\n早停法 (early stopping) 在学习中使用验证集进行评估, 判断训练的终止点, 进行模型选择, 是隐式的正则化方法。\\\\\n早停法将数据分为训练集、验证集、测试集 (比如以 $1 / 2,1 / 4,1 / 4$ 的比例)。学习中, 持续训练模型, 得到训练误差 (训练集上的损失), 同时用验证集评估, 得到验证误差 (验证集上的损失)。图 23.28 示意训练过程。横轴表示训练步数, 纵轴表示误差。通常训练误差不断减小, 逐渐趋近于 0 , 而验证误差在某个点达到最小, 之后逐渐增加。\n\n\\begin{center}\n\\includegraphics[max width=\\textwidth]{2024_03_13_90c63935c3d97d7235e0g-30}\n\\end{center}\n\n图 23.28 训练过程与早停法\n\n如果选择训练误差很小而验证误差已经增大的点的模型, 很有可能这个模型的测试误差不是最小的, 即产生过拟合。早停法选择验证误差最小的点为训练终止点, 将这时的模型作为最终模型输出。有很大概率这个模型也是测试误差最小的模型, 即泛化最好的模型, 因为用验证集代替测试集进行了模型评估。因为没有等到训练误差降到很小, 甚至接近于 0 时结束训练, 所以训练是早停的。早停法的优点是简单有效, 缺点是需要将一部分标注数据用于训练评估而不是训练本身。算法 23.5 给出早停法的具体算法, 其中 $l_{\\operatorname{dev}}()$ 表示在验证集上的损失，即验证误差。\n\n\\section*{算法 23.5 (早停法)}\n输入: 神经网络结构 $f(\\boldsymbol{x} ; \\boldsymbol{\\theta})$, 训练集, 验证集。\n\n输出: 学习得到的神经网络参数向量 $\\hat{\\boldsymbol{\\theta}}$ 。\n\n参数: 评估间隔步数 $m$, 持续评估上限 $n$ 。\n\n\\{\n\n$$\n\\begin{gathered}\ni=0 \\\\\nj=0 \\\\\nl_{\\min }=\\infty\n\\end{gathered}\n$$\n\nwhile $(j<n)\\{$\n\n用训练集连续训练模型 $m$ 步, 得到参数向量 $\\boldsymbol{\\theta}_{i}$\n\n$$\ni \\leftarrow i+m\n$$\n\n用验证集评估模型的损失\n\n$$\nl=l_{\\operatorname{dev}}\\left(\\boldsymbol{\\theta}_{i}\\right)\n$$\n\n$$\n\\begin{array}{lc}\n\\text { if }\\left(l<l_{\\text {min }}\\right)\\{ & \\\\\n& l_{\\text {min }} \\leftarrow l \\\\\n& \\boldsymbol{\\theta}_{\\text {min }} \\leftarrow \\boldsymbol{\\theta}_{i} \\\\\n& j=0 \\\\\n\\} & \\\\\n\\text { else } & j \\leftarrow j+1 \\\\\n\\} & \\hat{\\boldsymbol{\\theta}}=\\boldsymbol{\\theta}_{\\text {min }}\n\\end{array}\n$$\n\n返回参数向量 $\\hat{\\boldsymbol{\\theta}}$\n\n\\}"
    },
    {
        "id": "chatcmpl-93zKfgYHMQNmtEJVo57F2ciAG2qXx",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "logprobs": null,
                "message": {
                    "content": "{\n    \"问题1\": \"早停法是如何使用验证集进行评估的？\",\n    \"回答1\": \"早停法将数据分为训练集、验证集、测试集，并持续训练模型，得到训练误差和验证误差。通过比较验证误差的变化趋势，选择验证误差最小的点作为训练终止点，将这时的模型作为最终模型输出。\",\n    \"问题2\": \"早停法中的训练误差和验证误差有何特点？\",\n    \"回答2\": \"通常情况下，训练误差不断减小，逐渐趋近于 0，而验证误差在某个点达到最小值后逐渐增加。这种趋势反映了模型在训练过程中的拟合情况和泛化能力。\",\n    \"问题3\": \"早停法选择验证误差最小的点作为训练终止点的原因是什么？\",\n    \"回答3\": \"选择验证误差最小的点作为训练终止点是为了避免过拟合。如果选择训练误差很小而验证误差已经增大的点的模型，很有可能这个模型的测试误差不是最小的，即产生过拟合。\",\n    \"问题4\": \"早停法对于模型泛化能力有何影响？\",\n    \"回答4\": \"早停法选择验证误差最小的点作为训练终止点，将这时的模型作为最终模型输出。有很大概率这个模型也是测试误差最小的模型，即泛化最好的模型，因为用验证集代替测试集进行了模型评估。\",\n    \"问题5\": \"早停法相比传统正则化方法有什么优势？\",\n    \"回答5\": \"早停法是一种隐式的正则化方法，相比传统正则化方法，它简单有效且易于实现。通过选择验证误差最小的点作为训练终止点，可以有效地避免过拟合，提高模型的泛化能力。\",\n    \"问题6\": \"早停法在算法中如何确定训练终止点？\",\n    \"回答6\": \"在早停法算法中，通过持续评估模型在验证集上的损失，并比较验证误差的变化趋势。选择验证误差最小的点作为训练终止点，并将这时的模型作为最终模型输出。\",\n    \"问题7\": \"早停法算法中参数 $m$ 和 $n$ 分别代表什么意义？\",\n    \"回答7\": \"参数 $m$ 表示评估间隔步数，即每隔 $m$ 步评估一次模型在验证集上的损失。参数 $n$ 表示持续评估上限，即评估模型损失的最大步数限制。\",\n    \"问题8\": \"早停法算法中如何确定最终的神经网络参数向量？\",\n    \"回答8\": \"在早停法算法中，通过持续评估模型在验证集上的损失，并选择验证误差最小的点作为训练终止点。将这时的参数向量作为最终学习得到的神经网络参数向量输出。\",\n    \"问题9\": \"早停法算法中如何处理训练误差和验证误差之间的关系？\",\n    \"回答9\": \"在早停法算法中，通过连续训练模型并得到训练误差和验证误差，在选择验证误差最小的点作为训练终止点时，会考虑训练误差很小而验证误差已经增大的情况，以避免过拟合。\",\n    \"问题10\": \"早停法相比其他模型选择方法有何特殊之处？\",\n    \"回答10\": \"早停法通过使用验证集进行评估来判断训练的终止点，并选择验证误差最小的点作为最终模型输出。这使得早停法能够更好地避免过拟合，并且通常能够得到泛化能力较好的模型。\"\n}",
                    "role": "assistant",
                    "function_call": null,
                    "tool_calls": null
                }
            }
        ],
        "created": 1710737773,
        "model": "gpt-3.5-turbo-1106",
        "object": "chat.completion",
        "system_fingerprint": "fp_4aaaf0dc94",
        "usage": {
            "completion_tokens": 1221,
            "prompt_tokens": 3539,
            "total_tokens": 4760
        },
        "parameters": {
            "model": "gpt-3.5-turbo-1106",
            "temperature": 0.2,
            "frequency_penalty": 0.15,
            "presence_penalty": 0.15
        }
    }
]