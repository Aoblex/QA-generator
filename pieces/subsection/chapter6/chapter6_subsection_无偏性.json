[
    {
        "strategy": "subsection",
        "source": "chapter6",
        "title": "无偏性",
        "content_length": 3524,
        "content": "Title: 无偏性\nContent:\n\\label{ssec:6.2.2} % P295 录入完毕，未检查\n\n相合性是大样本下估计量的评价标准, 对小样本而言, 需要一些其他的评价标准, 无偏性便是一个常用的评价标准.\n\n\\begin{definition}{}{6.2.2} % P295\n设 $\\hat{\\theta}_n=\\hat{\\theta}_n(x_1,\\cdots,x_n)$ 是 $\\theta$ 的一个估计, $\\theta$ 的参数空间为 $\\Theta$ ，若对任意的 $\\theta\\in\\Theta$, 有\n\\begin{equation}\\label{eq:6.2.4}\nE(\\hat{\\theta})=\\theta\n\\end{equation}\n则称 $\\hat\\theta$ 是 $\\theta$ 的{\\heiti 无偏估计}\\index{C!参数估计!无偏估计}, 否则称为{\\heiti 有偏估计}\\index{C!参数估计!有偏估计}.\n\\end{definition}\n\n无偏性要求可以改写为 $E(\\hat{\\theta}-\\theta)=0$, 这表示无偏估计没有系统偏差，当我们使用 $\\hat{\\theta}$ 估计 $\\theta$ 时, 由于样本的随机性, $\\hat{\\theta}$ 与 $\\theta$ 总是有偏差的, 这种偏差时而（对某些样本观测值）为正, 时而(对另一些样本观测值)为负, 时而大, 时而小. 无偏性表示, 把这些偏差平均起来其值为 0, 这就是无偏估计的含义. 而若估计不具有无偏性, 则无论使用多少次, 其平均也会与参数真值有一定的距离, 这个距离就是系统误差.\n\n\\begin{example}\\label{exam:6.2.4}\n对任一总体而言, 样本均值是总体均值的无偏估计. 当总体 $k$ 阶矩存在时, 样本 $k$ 阶原点矩 $a_k$ 是总体息 $k$ 阶原点矩 $\\mu_k$ 么的无偏估计. 但对 $k$ 阶中心矩则不一样, 譬如, 样本方差 $s^{*2}$ 就不是总体方差 $\\sigma^2$ 的无偏估计, 因在定理\\ref{thm:5.2.1}\n中已经指出:\n\\[E\\left(s^{* 2}\\right)=\\frac{n-1}{n} \\sigma^{2}\\]\n对此, 有如下两点说明：\n\\begin{enumerate}\n  \\item 当样本量趋于无穷时, 有 $E(s^{*2})\\to\\sigma^2$, 我们称 $s^{*2}$ 为 $\\sigma^2$ 的渐近无偏估计, 这表明当样本量较大时,  $s^{*2}$ 可近似看作 $\\sigma^2$ 的无偏估计.\n\n  \\item 若对 $s^{*2}$ 作如下修正:\n\\begin{equation}\\label{eq:6.2.5}\ns^{2}=\\frac{n s^{* 2}}{n-1}=\\frac{1}{n-1} \\sum_{i=1}^{n}\\left(x_{i}-\\overline{x}\\right)^{2}\n\\end{equation}\n则 $s^2$ 是总体方差的无偏估计.这种简单的修正方法在一些场合常被采用.\\eqref{eq:6.2.5}定义的 $s^2$ 也称为样本方差，它比 $s^{*2}$ 更常用.这是因为在 $n\\geqslant2$ 时，$s^{*2}<s^2$，因此用 $s^{*2}$ 估计 $\\sigma^2$ 有偏小的倾向，特别在小样本场合要使用 $s^2$ 估计 $\\sigma^2$.\n\\end{enumerate}\n\n无偏性不具有不变性. 即若 $\\hat{\\theta}$ 是 $\\theta$ 的无偏估计, 一般而言, $g(\\hat{\\theta})$ 不是 $g(\\theta)$ 的无偏估计, 除非 $g(\\theta)$ 是 $\\theta$ 的线性函数.譬如，$s^2$ 是 $\\sigma^2$ 的无偏估计, 但 $s$ 不是 $\\sigma$ 的无偏估计. 下而我们以正态分布为例加以说明.\n\\end{example}\n\n\\begin{example}\\label{exam:6.2.5}\n设总体为 $N(\\mu,\\sigma^{2}), x_{1}, \\cdots, x_{n}$ 是样本，我们已经指出 $s^2$ 是 $\\sigma^2$ 的无偏估计. 由定理\\ref{thm:5.3.1}, $Y=\\frac{(n-1) s^{2}}{\\sigma^{2}} \\sim \\chi^{2}(n-1)$, 其密度函数为\n\\[p(y)=\\frac{1}{2^{\\frac{n-1}{2}} \\Gamma(\\frac{n-1}{2})} y^{\\frac{n-1}{2}}\\ee^{-\\frac{y}{2}}, \\quad y>0\\]\n从而\n\\begin{align*}\nE(Y^{1/2})\n&=\\int_{0}^{+\\infty} y^{1 / 2} p(y)\\dd y \\\\ &=\\frac{1}{2^{\\frac{n-1}{2}} \\Gamma(\\frac{n-1}{2})} \\int_{0}^{\\infty} y^{\\frac{n}{2}-1} \\mathrm{e}^{-\\frac{y}{2}} \\dd y \\\\\n&=\\frac{2^{\\frac{n}{2}} \\Gamma(\\frac{n}{2})}{2^{\\frac{n-1}{2}} \\Gamma(\\frac{n-1}{2})}=\\sqrt{2} \\frac{\\Gamma(\\frac{n}{2})}{\\Gamma(\\frac{n-1}{2})}\n\\end{align*}\n由此, 我们有\n\\[E s=\\frac{\\sigma}{\\sqrt{n-1}} E(Y^{1 / 2})=\\sqrt{\\frac{2}{n-1}} \\cdot \\frac{\\Gamma(n / 2)}{\\Gamma((n-1) / 2)} \\cdot \\sigma \\equiv \\frac{\\sigma}{c_{n}}\\]\n这说明 $s$ 不是 $\\sigma$ 的无偏估计，利用修正技术可得 $c_n\\cdot s$ 是 $\\sigma$ 的无偏估计，其中 $c_n=\\sqrt{\\frac{n-1}{2}} \\cdot \\frac{\\Gamma((n-1) / 2)}{\\Gamma(n / 2)}$ 是修偏系数，表 \\ref{tab:6.2.1} 给出了 $c_n$ 的部分取值. 可以证明, 当 $n\\to+\\infty$ 时有 $c_n\\to1$, 这说明 $s$ 是 $\\sigma$ 的渐近无偏估计, 从而在样本容量较大时, 不经修正的 $s$ 也是 $\\sigma$ 的一个很好的估计.\n\\begin{table}[htbp]\n\\centering\n\\caption{正态标准差的修信系数表}\\label{tab:6.2.1}\n\\begin{tabular}{>{$}c<{$}*{4}{>{$}c<{$}||>{$}c<{$}}>{$}c<{$}}\n\\toprule\nn &   c_n  &  n &   c_n  &  n &   c_n  &  n &   c_n  &  n & c_n \\\\\n\\midrule\n  &        &  7 & 1.0424 & 13 & 1.0210 & 19 & 1.0140 & 25 & 1.0105\\\\\n2 & 1.2533 &  8 & 1.0362 & 14 & 1.0194 & 20 & 1.0132 & 26 & 1.0100\\\\\n3 & 1.1284 &  9 & 1.0317 & 15 & 1.0180 & 21 & 1.0126 & 27 & 1.0097\\\\\n4 & 1.0854 & 10 & 1.0281 & 16 & 1.0168 & 22 & 1.0120 & 28 & 1.0093\\\\\n5 & 1.0638 & 11 & 1.0253 & 17 & 1.0157 & 23 & 1.0114 & 29 & 1.0090\\\\\n6 & 1.0509 & 12 & 1.0230 & 18 & 1.0148 & 24 & 1.0109 & 30 & 1.0087\\\\\n\\bottomrule\n\\end{tabular}\n\\end{table}\n\\end{example}"
    },
    {
        "id": "chatcmpl-947TY4vnru9mAooiPgblg8MDBivff",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "logprobs": null,
                "message": {
                    "content": "{\n    \"问题1\": \"什么是无偏估计？\",\n    \"回答1\": \"无偏估计指的是对于参数 $\\theta$ 的估计量 $\\theta_n$，其期望等于真实参数值 $\\theta$，即 $E(\\theta_n)=\\theta$。这意味着无偏估计没有系统偏差，当使用 $\\theta_n$ 估计 $\\theta$ 时，由于样本的随机性，$\\theta_n$ 与 $\\theta$ 总是有偏差的，但这些偏差平均起来其值为 0。\",\n    \"问题2\": \"无偏性要求可以改写为什么形式？\",\n    \"回答2\": \"无偏性要求可以改写为 $E(\\theta_n-\\theta)=0$ 的形式。这表示无偏估计没有系统偏差，当使用 $\\theta_n$ 估计 $\\theta$ 时，由于样本的随机性，$\\theta_n$ 与 $\\theta$ 总是有偏差的，但这些偏差平均起来其值为 0。\",\n    \"问题3\": \"样本均值和样本方差分别是什么总体参数的无偏估计？\",\n    \"回答3\": \"样本均值是总体均值的无偏估计，而样本方差在进行修正后也可以成为总体方差的无偏估计。但需要注意，在一些特定情况下，样本方差可能存在偏小的倾向，因此需要进行修正以获得无偏估计。\",\n    \"问题4\": \"无偏性具有什么特点？\",\n    \"回答4\": \"无偏性不具有不变性。即若 $\\theta_n$ 是 $\\theta$ 的无偏估计，则一般而言，$g(\\theta_n)$ 不是 $g(\\theta)$ 的无偏估计，除非 $g(\\theta)$ 是 $\\theta$ 的线性函数。这意味着对于非线性函数而言，其无偏性不具有传递性。\",\n    \"问题5\": \"什么是渐近无偏估计？\",\n    \"回答5\": \"渐近无偏估计指的是当样本量趋于无穷时，估计量的期望逐渐趋近于真实参数值。在大样本情况下，该估计量可以近似看作是真实参数值的无偏估计。\",\n    \"问题6\": \"什么是修正系数？\",\n    \"回答6\": \"修正系数是用于修正原始估计量以获得无偏估计的系数。在一些情况下，原始估计量可能存在一定的偏差倾向，通过乘以修正系数可以获得更接近真实参数值的无偏估计。\",\n    \"问题7\": \"为什么需要对样本方差进行修正？\",\n    \"回答7\": \"在一些情况下，样本方差可能存在偏小的倾向，因此需要对其进行修正以获得总体方差的无偏估计。修正后的样本方差更加接近真实总体方差，并且在小样本情况下具有更好的性能。\",\n    \"问题8\": \"什么情况下修正后的样本方差可以成为总体方差的无偏估计？\",\n    \"回答8\": \"当对样本方差进行修正后得到修正样本方差时，即 $s^2=\\frac{n s^{* 2}}{n-1}$，则修正后的样本方差可以成为总体方差的无偏估计。这种简单的修正方法在一些场合常被采用。\",\n    \"问题9\": \"渐近无偏估计在何种情况下成立？\",\n    \"回答9\": \"渐近无偏估计在样本量趋于无穷时成立。当样本量较大时，原始估计量可以近似看作是真实参数值的无偏估计。\",\n    \"问题10\": \"修正系数在何种情况下趋于1？\",\n    \"回答10\": \"当样本量趋于无穷时，修正系数通常会趋于1。这说明在大样本情况下，原始估计量经过简单修正后也可以成为真实参数值的一个很好的估计。\"\n}",
                    "role": "assistant",
                    "function_call": null,
                    "tool_calls": null
                }
            }
        ],
        "created": 1710769076,
        "model": "gpt-3.5-turbo-1106",
        "object": "chat.completion",
        "system_fingerprint": "fp_4aaaf0dc94",
        "usage": {
            "completion_tokens": 1211,
            "prompt_tokens": 4839,
            "total_tokens": 6050
        },
        "parameters": {
            "model": "gpt-3.5-turbo-1106",
            "temperature": 0.2,
            "frequency_penalty": 0.15,
            "presence_penalty": 0.15
        }
    }
]