[
    {
        "strategy": "subsection",
        "source": "statistics",
        "title": "11.2.3 回归直线的拟合优度",
        "content_length": 4834,
        "content": "Title: 11.2.3 回归直线的拟合优度\nContent:\n回归直线 $\\hat{y}_{i}=\\hat{\\beta}_{0}+\\hat{\\beta}_{1} x_{i}$ 在一定程度上描述了变量 $x$ 与 $y$ 之间的数量关系, 根据这一方程, 可依据自变量 $x$ 的取值来佔计或预测因变量 $y$ 的取值。但估计或预测的精度如何将取决于回归直线对观测数据的拟合程度。可以想象, 如果各观测数据的散点都落在一条直线上, 那么这条直线就是对数据的完全拟合, 直线充分代表了各个点, 此时用 $x$ 来估计 $y$ 是没有误差的。各观测点越是紧密围绕直线, 说明直线对观测数据的拟合程度越好, 反之则越差。回归直线与各观测点的接近程度称为回归直线对数据的拟合优度 (goodness of fit)。为说明直线的拟合优度, 需要计算判定系数。\n\n\\section*{1. 判定系数}\n判定系数是对估计的回归方程拟合优度的度量。为说明它的含义, 需要对因变量 $y$ 取\\\\\n值的变差进行研究。\n\n因变量 $y$ 的取值是不同的, $y$ 取值的这种波动称为变差。变差的产生来自两个方面:一是由自变量 $x$ 的取值不同造成的; 二是除 $x$ 以外的其他因素（如 $x$ 对 $y$ 的非线性影响、\n\n\\begin{center}\n\\end{center}\n\n图 11-10 变差分解图测量误差等) 的影响。对一个具体的观测值来说, 变差的大小可以用实际观测值 $y$ 与其均值 $\\bar{y}$ 之差 $y-\\bar{y}$ 来表示。而 $n$ 次观测值的总变差可由这些离差的平方和来表示, 称为总平方和,记为 $S S T$, 即\n\n\n\\begin{equation*}\nS S T=\\sum\\left(y_{i}-\\bar{y}\\right)^{2} \\tag{11.10}\n\\end{equation*}\n\n\n从图 11-10 可以看出, 每个观测点的离差都可以分解为:\n\n\n\\begin{equation*}\ny-\\bar{y}=(y-\\hat{y})+(\\hat{y}-\\bar{y}) \\tag{11.11}\n\\end{equation*}\n\n\n将式 (11.11) 两边平方, 并对所有 $n$ 个点求和, 有\n\n\n\\begin{equation*}\n\\sum\\left(y_{i}-\\bar{y}\\right)^{2}=\\sum\\left(y_{i}-\\hat{y}_{i}\\right)^{2}+\\sum\\left(\\hat{y}_{i}-\\bar{y}\\right)^{2}+2 \\sum\\left(y_{i}-\\hat{y}_{i}\\right)\\left(\\hat{y}_{i}-\\bar{y}\\right) \\tag{11.12}\n\\end{equation*}\n\n\n可以证明, $\\sum\\left(y_{i}-\\hat{y}_{i}\\right)\\left(\\hat{y}_{i}-\\bar{y}\\right)=0$, 因此\n\n\n\\begin{equation*}\n\\sum\\left(y_{i}-\\bar{y}\\right)^{2}=\\sum\\left(y_{i}-\\hat{y}_{i}\\right)^{2}+\\sum\\left(\\hat{y}_{i}-\\bar{y}\\right)^{2} \\tag{11.13}\n\\end{equation*}\n\n\n式 (11.13) 的左边称为总平方和 $S S T$, 它可分解为两部分: $\\sum\\left(\\hat{y}_{i}-\\bar{y}\\right)^{2}$ 是回归值 $\\hat{y}_{i}$与均值 $\\bar{y}$ 的离差平方和, 根据估计的回归方程, 估计值 $\\hat{y}_{i}=\\hat{\\beta}_{0}+\\hat{\\beta}_{1} x_{i}$, 因此可以把 $\\hat{y}_{i}-\\bar{y}$看作由于自变量 $x$ 的变化引起的 $y$ 的变化, 而其平方和 $\\sum\\left(\\hat{y}_{i}-\\bar{y}\\right)^{2}$ 则反映了 $y$ 的总变差中由于 $x$ 与 $y$ 之间的线性关系引起的 $y$ 的变化部分, 它是可以由回归直线来解释的 $y_{i}$ 的变差部分, 称为回归平方和, 记为 $S S R ; \\sum\\left(y_{i}-\\hat{y}_{i}\\right)^{2}$ 是各实际观测点与回归值的残差 $y_{i}-\\hat{y}_{i}$ 平方和, 它是除了 $x$ 对 $y$ 的线性影响之外的其他因素引起的 $y$ 的变化部分, 是不能由回归直线来解释的 $y_{i}$ 的变差部分, 称为残差平方和或误差平方和, 记为 $S S E$ 。三个平方和的关系为:\n\n\n\\begin{equation*}\n\\text { 总平方和 }(S S T)=\\text { 回归平方和 }(S S R)+\\text { 残差平方和 }(S S E) \\tag{11.14}\n\\end{equation*}\n\n\n从图 11-10 可以直观地看出, 回归直线拟合的好坏取决于 $S S R$ 及 $S S E$ 的大小, 或者说取决于回归平方和 $S S R$ 占总平方和 $S S T$ 的比例 ( $S S R / S S T)$ 的大小。各观测点越是靠近直线, $S S R / S S T$ 则越大, 直线拟合得越好。回归平方和占总平方和的比例称为判定系数 (coefficient of determination), 记为 $R^{2}$, 其计算公式为:\n\n\n\\begin{equation*}\nR^{2}=\\frac{S S R}{S S T}=\\frac{\\sum\\left(\\hat{y}_{i}-\\bar{y}\\right)^{2}}{\\sum\\left(y_{i}-\\bar{y}\\right)^{2}}=1-\\frac{\\sum\\left(y_{i}-\\hat{y}_{i}\\right)^{2}}{\\sum\\left(y_{i}-\\bar{y}\\right)^{2}} \\tag{11.15}\n\\end{equation*}\n\n\n判定系数 $R^{2}$ 测度了回归直线对观测数据的拟合程度。若所有观测点都落在直线上,残差平方和 $S S E=0$, 则 $R^{2}=1$, 拟合是完全的; 如果 $y$ 的变化与 $x$ 无关, $x$ 完全无助于\\\\\n解释 $y$ 的变差, $\\hat{y}=\\bar{y}$, 则 $R^{2}=0$ 。可见 $R^{2}$ 的取值范围是 $[0,1] 。 R^{2}$ 越接近 1 , 表明回归平方和占总平方和的比例越大, 回归直线与各观测点越接近, 用 $x$ 的变化来解释 $y$ 值变差的部分就越多, 回归直线的拟合程度就越好; 反之, $R^{2}$ 越接近 0 , 回归直线的拟合程度就越差。\n\n在一元线性回归中, 相关系数 $r$ 实际上是判定系数的平方根。根据这一结论, 不仅可以由相关系数直接计算判定系数 $R^{2}$, 也可以进一步理解相关系数的意义。相关系数 $r$ 与回归系数 $\\hat{\\beta}_{1}$ 的正负号是相同的, 实际上, 相关系数 $r$ 从另一个角度说明了回归直线的拟合优度。 $|r|$ 越接近 1 , 表明回归直线对观测数据的拟合程度越好。但用 $r$ 说明回归直线的拟合优度要慎重, 因为 $r$ 的值总是大于 $R^{2}$ 的值（除非 $r=0$ 或 $|r|=1$ )。比如, 当 $r=0.5$时, 表面上看相关程度似乎接近一半, 但 $R^{2}=0.25$, 实际上这只能解释总变差的 $25 \\%$ 。 $r=0.7$ 才能解释近一半的变差, $r<0.3$ 意味着只有很少一部分变差可由回归直线来解释。\n\n\\section*{例 11.10}\n根据例 11.6 的数据, 计算不良贷款对贷款余额回归的判定系数, 并解释其意义。\n\n一解 根据表 11-4 Excel 输出的回归分析结果可知, 总平方和 $S S T=312.6504$; 回归平方和 $S S R=222.4860$; 残差平方和 $S S E=90.1644$ 。根据式（11.15）得:\n\n$$\nR^{2}=\\frac{S S R}{S S T}=\\frac{222.4860}{312.6504}=0.7116=71.16 \\%\n$$\n\n实际上，表 11-4 中直接给出了判定系数（R Square）为 0.711613 。\n\n判定系数的实际意义是: 在不良贷款取值的变差中, 有 $71.16 \\%$ 可以由不良贷款与贷款余额之间的线性关系来解释, 或者说, 在不良贷款取值的变动中, 有 $71.16 \\%$ 是由贷款余额决定的。不良贷款取值的差异有 $2 / 3$ 以上是由贷款余额决定的, 可见二者之间有较强的线性关系。\n\n\\section*{2. 估计标准误差}\n判定系数可用于度量回归直线的拟合程度, 相关系数也可以起到类似的作用。而残差平方和则可以说明实际观测值 $y_{i}$ 与回归估计值 $\\hat{y}_{i}$ 之间的差异程度。估计标准误差 (standard error of estimate) 就是度量各实际观测点在直线周围的散布状况的一个统计量,它是均方残差 (MSE) 的平方根, 用 $s_{e}$ 来表示, 其计算公式为:\n\n\n\\begin{equation*}\ns_{e}=\\sqrt{\\frac{\\sum\\left(y_{i}-\\hat{y}_{i}\\right)^{2}}{n-2}}=\\sqrt{\\frac{S S E}{n-2}}=\\sqrt{M S E} \\tag{11.16}\n\\end{equation*}\n\n\n估计标准误差是对误差项 $\\varepsilon$ 的标准差 $\\sigma$ 的估计, 它可以看作在排除了 $x$ 对 $y$ 的线性影响后, $y$ 随机波动大小的一个估计量。从估计标准误差的实际意义看, 它反映了用估计的回归方程预测因变量 $y$ 时预测误差的大小。各观测点越靠近直线, $s_{e}$ 越小, 回归直线对各观测点的代表性就越好, 根据估计的回归方程进行预测也就越准确。若各观测点全部落在\\\\\n直线上, 则 $s_{e}=0$, 此时用自变量来预测因变量是没有误差的。可见 $s_{e}$ 从另一个角度说明了回归直线的拟合优度。\n\n从式 (11.16) 容易看出, 回归直线是对 $n$ 个观测点拟合的所有直线中, 估计标准误差最小的一条直线, 因为回归直线是当 $\\sum\\left(y_{i}-\\hat{y}_{i}\\right)^{2}$ 最小时确定的。\n\n\\section*{例 11.11}\n根据例 11.9 的有关结果, 计算不良贷款对贷款余额回归的估计标准误差, 并解释其意义。\n\n・解 根据表 11-4 Excel 输出的回归分析结果可知, $S S E=90.1644$ 。根据式 (11.16) 得:\n\n$$\ns_{e}=\\sqrt{\\frac{\\operatorname{SSE}}{n-2}}=\\sqrt{\\frac{90.1644}{25-2}}=1.9799(\\text { 亿元) }\n$$\n\n实际上, 表 11-4 中直接给出了该值, 即标准误差=1.979 948。这就是说, 根据货款余额来估计不良贷款时, 平均的估计误差为 1.9799 亿元。"
    },
    {
        "id": "chatcmpl-93y7lCAdjm2rEn2E0gP3GEVE0etRp",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "logprobs": null,
                "message": {
                    "content": "{\n    \"问题1\": \"回归直线的拟合优度如何影响估计或预测的精度？\",\n    \"回答1\": \"回归直线的拟合优度决定了估计或预测的精度。如果各观测数据的散点都落在一条直线上，那么这条直线就是对数据的完全拟合，直线充分代表了各个点，此时用自变量 $x$ 来估计 $y$ 是没有误差的。各观测点越是紧密围绕直线，说明直线对观测数据的拟合程度越好，估计或预测的精度也就越高。\",\n    \"问题2\": \"判定系数是如何定义的？它对回归方程拟合优度有何作用？\",\n    \"回答2\": \"判定系数是对估计的回归方程拟合优度的度量。它反映了回归平方和占总平方和的比例，即回归直线与各观测点越接近，$R^{2}$ 就越接近 1，表明回归平方和占总平方和的比例越大，回归直线的拟合程度就越好；反之，$R^{2}$ 越接近 0，回归直线的拟合程度就越差。\",\n    \"问题3\": \"判定系数 $R^{2}$ 的取值范围是多少？它如何反映回归直线对观测数据的拟合程度？\",\n    \"回答3\": \"判定系数 $R^{2}$ 的取值范围是 $[0,1]$。$R^{2}$ 越接近 1，表明回归平方和占总平方和的比例越大，回归直线与各观测点越接近，用 $x$ 的变化来解释 $y$ 值变差的部分就越多，回归直线的拟合程度就越好；反之，$R^{2}$ 越接近 0，回归直线的拟合程度就越差。\",\n    \"问题4\": \"相关系数与判定系数之间有何关系？它们分别如何反映回归直线的拟合优度？\",\n    \"回答4\": \"在一元线性回归中，相关系数 $r$ 实际上是判定系数的平方根。相关系数 $r$ 与判定系数 $R^{2}$ 的正负号是相同的。$|r|$ 越接近 1，表明回归直线对观测数据的拟合程度越好；而判定系数 $R^{2}$ 越接近 1，则表示回归平方和占总平方和的比例越大，回归直线与各观测点越接近，拟合程度也就越好。\",\n    \"问题5\": \"估计标准误差是如何定义的？它如何反映回归直线对观测数据的拟合程度？\",\n    \"回答5\": \"估计标准误差是均方残差（MSE）的平方根，用 $s_{e}$ 表示。它反映了用估计的回归方程预测因变量 $y$ 时预测误差的大小。各观测点越靠近直线，$s_{e}$ 越小，表示回归直线对各观测点的代表性就越好，根据估计的回归方程进行预测也就越准确。\",\n    \"问题6\": \"判定系数和估计标准误差分别如何说明回归直线对观测数据的拟合程度？\",\n    \"回答6\": \"判定系数 $R^{2}$ 反映了回归平方和占总平方和的比例，即回归直线与各观测点越接近，$R^{2}$ 就越接近 1，表明回归平方和占总平方和的比例越大，回归直线的拟合程度就越好；而估计标准误差 $s_{e}$ 反映了用估计的回归方程预测因变量 $y$ 时预测误差的大小。各观测点越靠近直线，$s_{e}$ 越小，表示回归直线对各观测点的代表性就越好，根据估计的回归方程进行预测也就越准确。\",\n    \"问题7\": \"判定系数和估计标准误差在实际应用中有何意义？\",\n    \"回答7\": \"在实际应用中，判定系数 $R^{2}$ 可以帮助评价回归模型对观测数据的拟合程度，从而确定模型是否适合用于预测或解释数据。而估计标准误差 $s_{e}$ 则可以帮助评估使用估计的回归方程进行预测时可能产生的误差大小。这些指标能够帮助分析人员更好地理解和评价所建立的回归模型在实际应用中的效果。\",\n    \"问题8\": \"判定系数和相关系数之间有何关联？\",\n    \"回答8\": \"在一元线性回归中，相关系数 $r$ 实际上是判定系数 $R^{2}$ 的平方根。因此，在一元线性回归中，判定系数和相关系数之间存在着特定的关联。\",\n    \"问题9\": \"什么情况下判定系数为1？这代表什么意义？\",\n    \"回答9\": \"当所有观测点都落在直线上时，残差平方和为0，此时判定系数为1。这代表着模型对数据的完全拟合，即用自变量来预测因变量是没有误差的。\",\n    \"问题10\": \"判定系数和估计标准误差如何帮助解释建立的回归模型在实际应用中的效果？\",\n    \"回答10\": \"判定系数可以帮助评价建立的回归模型对观测数据的拟合程度，并确定模型是否适合用于预测或解释数据；而估计标准误差则可以帮助评估使用估计的回归方程进行预测时可能产生的误差大小。这些指标能够帮助分析人员更好地理解和评价所建立的回归模型在实际应用中产生效果。\"\n}",
                    "role": "assistant",
                    "function_call": null,
                    "tool_calls": null
                }
            }
        ],
        "created": 1710733129,
        "model": "gpt-3.5-turbo-1106",
        "object": "chat.completion",
        "system_fingerprint": "fp_4aaaf0dc94",
        "usage": {
            "completion_tokens": 1908,
            "prompt_tokens": 6291,
            "total_tokens": 8199
        },
        "parameters": {
            "model": "gpt-3.5-turbo-1106",
            "temperature": 0.2,
            "frequency_penalty": 0.15,
            "presence_penalty": 0.15
        }
    }
]