[
    {
        "strategy": "subsection",
        "source": "statistics",
        "title": "11.2.2 参数的最小二乘估计",
        "content_length": 4737,
        "content": "Title: 11.2.2 参数的最小二乘估计\nContent:\n对于第 $i$ 个 $x$ 值, 估计的回归方程可表示为:\n\n\n\\begin{equation*}\n\\hat{y}_{i}=\\hat{\\beta}_{0}+\\hat{\\beta}_{1} x_{i} \\tag{11.6}\n\\end{equation*}\n\n\n对于 $x$ 和 $y$ 的 $n$ 对观测值, 用于描述其关系的直线有多条, 究竟用哪条直线来代表两个变量之间的关系, 要有一个明确的原则。我们自然会想到距离各观测点最近的一条直线, 用它来代表 $x$与 $y$ 之间的关系与实际数据的误差比其他任何直线都小。卡尔 - 高斯 (Carl Gauss, 1777-1855)提出用最小化图 (见图 11-7) 中垂直方向的离差平方和来估计参数 $\\beta_{0}$ 和 $\\beta_{1}$, 根据这一方法确定模型参数 $\\beta_{0}$ 和 $\\beta_{1}$ 的方法称为最小二乘法, 也称最小平方法 (method of least squares), 它是通过使因变量的观测值 $y_{i}$ 与估计值 $\\hat{y}_{i}$ 之间的离差平方和达到最小来估计 $\\beta_{0}$ 和 $\\beta_{1}$ 的方法。\n\n最小二乘法的思想可用图 11-7 表示。\n\n\\begin{center}\n\\end{center}\n\n图 11-7 最小二乘法示意图\n\n用最小二乘法拟合的直线具有一些优良的性质。首先, 根据最小二乘法得到的回归直线能使离差平方和达到最小, 虽然这并不能保证它就是拟合数据的最佳直线(1), 但这毕竟是一条与数据拟合良好的直线应有的性质。其次, 由最小二乘法求得的回归直线可知 $\\beta_{0}$ 和 $\\beta_{1}$ 的估计量的抽样分布。最后, 在某些条件下, $\\beta_{0}$ 和 $\\beta_{1}$ 的最小二乘估计量同其他估计量相比,其抽样分布具有较小的标准差。正是基于上述性质，最小二乘法广泛用于回归模型参数的估计。\n\n根据最小二乘法，使\n\n\n\\begin{equation*}\n\\sum\\left(y_{i}-\\hat{y}_{i}\\right)^{2}=\\sum\\left(y_{i}-\\hat{\\beta}_{0}-\\hat{\\beta}_{1} x_{i}\\right)^{2} \\tag{11.7}\n\\end{equation*}\n\n\n最小。令 $Q=\\sum\\left(y_{i}-\\hat{y}_{i}\\right)^{2}$, 在给定样本数据后, $Q$ 是 $\\hat{\\beta}_{0}$ 和 $\\hat{\\beta}_{1}$ 的函数, 且最小值总是存在。根据微积分的极值定理, 对 $Q$ 求相应于 $\\hat{\\beta}_{0}$ 和 $\\hat{\\beta}_{1}$ 的偏导数, 令其等于 0 , 便可求出 $\\hat{\\beta}_{0}$ 和 $\\hat{\\beta}_{1}$, 即\n\n\\[\n\\left\\{\\begin{array}{l}\n\\left.\\frac{\\partial Q}{\\partial \\beta_{0}}\\right|_{\\beta_{0}=\\hat{\\beta}_{0}}=-2 \\sum_{i=1}^{n}\\left(y_{i}-\\hat{\\beta}_{0}-\\hat{\\beta}_{1} x_{i}\\right)=0  \\tag{11.8}\\\\\n\\left.\\frac{\\partial Q}{\\partial \\beta_{1}}\\right|_{\\beta_{1}=\\hat{\\beta}_{1}}=-2 \\sum_{i=1}^{n} x_{i}\\left(y_{i}-\\hat{\\beta}_{0}-\\hat{\\beta}_{1} x_{i}\\right)=0\n\\end{array}\\right.\n\\]\n\n解上述方程组得:\n\n\\[\n\\left\\{\\begin{array}{l}\n\\hat{\\beta}_{1}=\\frac{n \\sum_{i=1}^{n} x_{i} y_{i}-\\sum_{i=1}^{n} x_{i} \\sum_{i=1}^{n} y_{i}}{n \\sum_{i=1}^{n} x_{i}^{2}-\\left(\\sum_{i=1}^{n} x_{i}\\right)^{2}}  \\tag{11.9}\\\\\n\\hat{\\beta}_{0}=\\bar{y}-\\hat{\\beta}_{1} \\bar{x}\n\\end{array}\\right.\n\\]\n\\footnotetext{(1) 许多其他拟合直线也具有这种性质。\n}\n由式 (11.9) 可知, 当 $x=\\bar{x}$ 时, $\\hat{y}=\\bar{y}$, 即回归直线 $\\hat{y}_{i}=\\hat{\\beta}_{0}+\\hat{\\beta}_{1} x_{i}$ 通过点 $(\\bar{x}, \\bar{y})$,这是回归直线的重要特征之一。\n\n\\section*{例 11.9}\n根据例 11.6 的数据, 求不良贷款对贷款余额的估计方程。\n\n・・解 根据式 (11.9) 得:\n\n$$\n\\left\\{\\begin{array}{l}\n\\hat{\\beta}_{1}=\\frac{25 \\times 17080.14-3006.7 \\times 93.2}{25 \\times 516543.37-3006.7^{2}}=0.037895 \\\\\n\\hat{\\beta}_{0}=3.728-0.037895 \\times 120.268=-0.8295\n\\end{array}\\right.\n$$\n\n即不良贷款对贷款余额的估计方程为 $\\hat{y}=-0.8295+0.037895 x$ 。回归系数 $\\hat{\\beta}_{1}=0.037895$表示货款余额每增加 1 亿元, 不良贷款平均增加 0.037895 亿元。在回归分析中, 对截距 $\\hat{\\beta}_{0}$ 常常不能赋予任何真实意义，例如，在不良贷款与贷款余额的回归中, $\\hat{\\beta}_{0}=-0.8295$,如果要解释, 它是指当货款余额为 0 时, 不良贷款的平均值为 -0.8295 亿元。但是, 当贷款余额为 0 （没有货款）时，自然也就不会有不良货款，而在这里，它的值为一个负数，这就很难解释得通。因此, 在回归分析中, 对截距 $\\hat{\\beta}_{0}$ 通常不作实际意义上的解释。\n\n将 $x_{i}$ 的各个取值代入上述估计方程, 可以得到不良贷款的各个估计值 $\\hat{y}_{i}$ 。由图 11-8 可以看出散点图与回归直线的关系。\n\n\\begin{center}\n\\end{center}\n\n图 11-8 不良贷款对贷款余额的回归直线\n\n回归分析中的计算量较大, 特别是多元回归, 用手工计算几乎是不可能的。因此, 在实际分析中, 回归的计算完全依赖于计算机。除专门的统计软件外, 为大多数人所熟悉的 Excel 软件也有回归分析功能。下面将结合本例, 说明用 Excel 进行回归的具体步骤。\n\n首先, 将不良贷款与货款余额的数据输入 Excel 工作表中的 A2: B26 单元格。然后按下列步骤进行操作。\\\\\n$\\star$ 用 Excel 进行回归分析的操作步骤\n\n第 1 步: 点击【数据】, 并点击【数据分析】选项。\n\n第 2 步：在分析工具中选择【回归】, 点击【确定】。\n\n第 3 步: 当对话框出现时: 在【Y 值输入区域】方框内输入数据区域 $A 2: A 26$ 。在【X 值输入区\n\n域】方框内输入数据区域 B2:B26。在【置信度】选项中给出所需的数值（这里我们使用默认值 $95 \\%$ )。在【输出选项】中选择输出区域 (这里我们选新工作表组)。在【残差】中选择所需的选项 (这里我们暂时未选)。结果如图 11-9 所示。\n\n\\begin{center}\n\\end{center}\n\n图 11-9 用 Excel 进行回归的步骤\n\n点击【确定】后得到输出的结果。\n\n本例的 Excel 输出结果如表 11-4 所示。\n\n表 11-4 Excel 输出的回归分析结果\n\nSUMMARY OUTPUT\n\n回归统计\\\\\nMultiple R\\\\\n0. 843571\\\\\n$R$ Square\\\\\n0.711613\\\\\nAdjusted R Square\\\\\n0. 699074\\\\\n标准误差\n\n\\begin{enumerate}\n  \\item 979948\\\\\n观测值\\\\\n续表\n\\end{enumerate}\n\n\\begin{center}\n\\begin{tabular}{|c|c|c|c|c|c|c|}\n\\hline\n & df & SS & MS & F & Significance F &  \\\\\n\\hline\n回归 & 1 & 222.48598 & 222.48597956 & 6. 753844 & 1. $18349 \\mathrm{E}-07$ &  \\\\\n\\hline\n残差 & 23 & 90.164421 & 3. 920192 &  &  &  \\\\\n\\hline\n\\multirow[t]{2}{*}{总计} & 24 & 312.6504 &  &  &  &  \\\\\n\\hline\n & Coefficients & 标准误差 & t Stat & P-value & Lower $95 \\%$ & Upper $95 \\%$ \\\\\n\\hline\nIntercept & -0.829521 & 0.723043 & -1.147263 & 0.263068 & -2.325248 & 0.666206 \\\\\n\\hline\nX Variable 1 & 0.037895 & 0.005030 & 7.533515 & 0.000000 & 0.027489 & 0.048300 \\\\\n\\hline\n\\end{tabular}\n\\end{center}\n\nExcel 输出的回归结果包括以下几个部分:\n\n第一部分是 “回归统计”, 这部分给出了回归分析中的一些常用统计量, 包括相关系数 (Multiple R)、判定系数 (R Square)、调整的判定系数 (Adjusted R Square)、标准误差、观测值等。\n\n第二部分是 “方差分析”, 这部分给出的是回归分析的方差分析表, 包括回归和残差的自由度 (df)、总平方和 (SS)、均方 (MS) 、检验统计量 (F)、F 检验的显著性水平 (Significance F)。这部分的主要作用是对回归方程的线性关系进行显著性检验。下面将详细介绍。\n\n第三部分是回归参数估计的有关内容。包括回归方程的截距（Intercept）和斜率（X Variable 1) 的系数 (Coefficients)、标准误差、用于检验回归系数的 $t$ 统计量 (t Stat) 和 $P$ 值（P-value），以及截距和斜率的置信区间（Lower 95\\%和 Upper 95\\%) 等。\n\n此外, 还有 “残差分析” 部分, 这里暂时未给出其输出结果。对于本章内容所涉及的一些结果, 后面会陆续介绍。"
    },
    {
        "id": "chatcmpl-93y7SW8WYeDDJE5mkDKncxxQvbDtY",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "logprobs": null,
                "message": {
                    "content": "{\n    \"问题1\": \"最小二乘估计中的回归方程是如何表示的？\",\n    \"回答1\": \"对于第 $i$ 个 $x$ 值, 估计的回归方程可表示为 $\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ } \\\\\\text{hat}y_{i}=\\text{hat}{\\beta}_{0}+\\text{hat}{\\beta}_{1} x_{i}$。\",\n    \"问题2\": \"最小二乘法是如何确定模型参数 $\\beta_{0}$ 和 $\\beta_{1}$ 的方法？\",\n    \"回答2\": \"最小二乘法是通过使因变量的观测值 $y_{i}$ 与估计值 $\\text{hat}y_{i}$ 之间的离差平方和达到最小来估计 $\\beta_{0}$ 和 $\\beta_{1}$ 的方法。具体地，根据微积分的极值定理，对离差平方和求相应于 $\\text{hat}{\\beta}_{0}$ 和 $\\text{hat}{\\beta}_{1}$ 的偏导数，令其等于 0，便可求出 $\\text{hat}{\\beta}_{0}$ 和 $\\text{hat}{\\beta}_{1}$。\",\n    \"问题3\": \"最小二乘法得到的回归直线具有哪些优良的性质？\",\n    \"回答3\": \"根据最小二乘法得到的回归直线能使离差平方和达到最小，虽然这并不能保证它就是拟合数据的最佳直线，但这毕竟是一条与数据拟合良好的直线应有的性质。此外，由最小二乘法求得的回归直线还能使得 $\\beta_{0}$ 和 $\\beta_{1}$ 的估计量的抽样分布具有较小的标准差，在某些条件下。\",\n    \"问题4\": \"最小二乘估计量 $\\text{hat}{\\beta}_{0}$ 和 $\\text{hat}{\\beta}_{1}$ 的计算公式是什么？\",\n    \"回答4\": \"最小二乘估计量 $\\text{hat}{\\beta}_{1}=\\frac{n \\text{sum}_{i=1}^{n} x_{i} y_{i}-\\text{sum}_{i=1}^{n} x_{i} \\text{sum}_{i=1}^{n} y_{i}}{n \\text{sum}_{i=1}^{n} x_{i}^{2}-\\big(\\text{sum}_{i=1}^{n} x_{i}\\big)^{2}}$，$\\text{hat}{\\beta}_{0}=\\bar{y}-\\text{hat}{\\beta}_{1} \\bar{x}$。\",\n    \"问题5\": \"如何解释回归系数中的截距 $\\text{hat}{\\beta}_{0}$ 在实际意义上可能存在的问题？\",\n    \"回答5\": \"在回归分析中，对截距 $\\text{hat}{\\beta}_{0}$ 通常不能赋予任何真实意义。例如，在不良贷款与贷款余额的回归中，$\\text{hat}{\\beta}_{0}=-0.8295$，如果要解释，它是指当货款余额为 0 时，不良贷款的平均值为 -0.8295 亿元。但是，当贷款余额为 0 时，自然也就不会有不良货款，而在这里，它的值为一个负数，这就很难解释得通。\",\n    \"问题6\": \"在实际分析中，回归分析的计算依赖于哪些工具？\",\n    \"回答6\": \"在实际分析中，回归分析的计算完全依赖于计算机。除专门的统计软件外，一些常见软件如 Excel 也具有回归分析功能。\",\n    \"问题7\": \"如何在 Excel 中进行回归分析？\",\n    \"回答7\": \"在 Excel 中进行回归分析的操作步骤包括：点击【数据】并选择【数据分析】选项；在分析工具中选择【回归】；在对话框中输入数据区域并选择输出区域等步骤。\",\n    \"问题8\": \"Excel 输出的回归结果包括哪些部分？\",\n    \"回答8\": \"Excel 输出的回归结果包括 “回归统计” 部分、 “方差分析” 部分和 “回归参数估计” 部分等。其中，“回归统计” 部分给出了一些常用统计量；“方差分析” 部分给出了方差分析表；“回归参数估计” 部分给出了截距和斜率的系数、标准误差、$t$ 统计量和 $P$ 值等。\",\n    \"问题9\": \"Excel 中进行回归分析时需要注意哪些步骤？\",\n    \"回答9\": \"在 Excel 中进行回归分析时需要注意输入数据区域、选择输出区域、设置置信度等参数，并根据需要选择残差等选项。此外，在进行结果解释时也需要注意对各部分结果的理解和解释。\",\n    \"问题10\": \"在实际应用中，为什么需要依赖计算机进行回归分析？\",\n    \"回答10\": \"在实际应用中，尤其是多元回归等复杂情况下，进行手工计算几乎是不可能的。因此，依赖计算机进行回归分析可以大大提高效率，并且能够更好地处理大量数据和复杂模型。\"\n}",
                    "role": "assistant",
                    "function_call": null,
                    "tool_calls": null
                }
            }
        ],
        "created": 1710733110,
        "model": "gpt-3.5-turbo-1106",
        "object": "chat.completion",
        "system_fingerprint": "fp_4aaaf0dc94",
        "usage": {
            "completion_tokens": 1578,
            "prompt_tokens": 5768,
            "total_tokens": 7346
        },
        "parameters": {
            "model": "gpt-3.5-turbo-1106",
            "temperature": 0.2,
            "frequency_penalty": 0.15,
            "presence_penalty": 0.15
        }
    }
]