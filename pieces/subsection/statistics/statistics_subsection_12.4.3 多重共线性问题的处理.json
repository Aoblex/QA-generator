[
    {
        "strategy": "subsection",
        "source": "statistics",
        "title": "12.4.3 多重共线性问题的处理",
        "content_length": 5829,
        "content": "Title: 12.4.3 多重共线性问题的处理\nContent:\n一旦发现模型中存在多重共线性问题, 就应采取某种措施。至于采取什么样的方法来解决, 要看多重共线性的严重程度。下面给出多重共线性问题的一些解决办法。(1)\n\n（1）将一个或多个相关的自变量从模型中剔除, 使保留的自变量尽可能不相关。\n\n(2) 如果要在模型中保留所有的自变量, 就应该:\n\n\\begin{itemize}\n  \\item 避免根据 $t$ 统计量对单个参数 $\\beta$ 进行检验。\n  \\item 对因变量 $y$ 值的推断（估计或预测）限定在自变量样本值的范围内。\n\\end{itemize}\n\n\\section*{例 12.5}\n利用例 12.1 所建立的回归方程, 对多重共线性问题进行处理。\n\n-一解 首先, 考虑将一些相关的自变量从模型中剔除。从表 $12-3$ 的相关矩阵中可以看出, 货款余额与贷款项目个数的相关系数最高, 从定性角度看, 贷款余额与累计应收贷款之间也有很强的相关关系。因此将贷款项目个数和累计应收贷款这两个自变量剔除, 建立不良货款 $(y)$ 与贷款余额 $\\left(x_{1}\\right)$ 和固定资产投资额 $\\left(x_{2}\\right)$ 的线性模型。由 Excel 输出的结果如表 12-5 所示。\n\n表 12-5 Excel 输出的回归分析结果\n\nSUMMARY OUTPUT\n\n回归统计\n\nMultiple R\n\n0.872380\n\n$R$ Square\n\n0.761046\n\nAdjusted R Square\\\\\n0. 739323\n\n标准误差\n\n\\begin{enumerate}\n  \\item 842787\n\\end{enumerate}\n\n观测值 25\n\n(1) 处理多重共线性问题有更好的办法, 感兴趣的读者可参考有关回归方面的书籍。\\\\\n续表\n\n方差分析\n\n\\begin{center}\n\\begin{tabular}{|c|c|c|c|c|c|c|}\n\\hline\n & df & SS & MS & F & Significance F &  \\\\\n\\hline\n回归分析 & 2 & 237. 941432 & 118.970716 & 35.034023 & $1.45028 \\mathrm{E}-07$ &  \\\\\n\\hline\n残差 & 22 & 74.708968 & 3. 395862 &  &  &  \\\\\n\\hline\n\\multirow[t]{2}{*}{总计} & 24 & 312.6504 &  &  &  &  \\\\\n\\hline\n & Coefficients & 标准误差 & t Stat & P-value & Lower $95 \\%$ & Upper $95 \\%$ \\\\\n\\hline\nIntercept & -0.443424 & 0.696865 & -0.636312 & 0.531138 & -1.888634 & 1.001787 \\\\\n\\hline\nX Variable 1 & 0.050332 & 0.007477 & 6. 731607 & 0.000001 & 0.034826 & 0.065838 \\\\\n\\hline\n$\\mathrm{X}$ Variable 2 & -0.031903 & 0.014954 & -2.133368 & 0.044294 & -0.062916 & -0.000890 \\\\\n\\hline\n\\end{tabular}\n\\end{center}\n\n从表 $12-5$ 的输出结果中可以看出, 线性关系和各回归系数在 0.05 的显著性水平下是显著的，多重共线性问题不存在了。\n\n多重共线性问题带来的主要麻烦是对单个回归系数的解释和检验。在求因变量的置信区间和预测区间时一般不会受其影响, 但必须保证用于估计或预测的自变量的值是在样本数据的范围之内。因此, 如果仅仅是为了估计或预测, 可以将所有自变量都保留在模型中。\n\n最后需要提醒的是: 在建立多元线性回归模型时, 不要试图引人更多的自变量, 除非确实有必要。特别是在社会科学的研究中, 由于所使用的大多数数据都是非试验性质的,因此, 在某些情况下, 得到的结果往往并不令人满意, 但这不一定是因为选择的模型不合适, 而是数据的质量不好, 或者是引人的自变量不合适。\n\n\\section*{12.5 利用回归方程进行预测}\n在一元线性回归中, 我们曾介绍利用自变量来估计因变量的方法。对于多元线性回归, 同样可以利用给定的 $k$ 个自变量, 求出因变量 $y$ 的平均值的置信区间和个别值的预测区间。\n\n置信区间和预测区间的计算公式复杂, 超出了本书的范围, 这里不再介绍。多元回归问题的求解完全依赖于计算机, 已有的统计软件, 如 SAS, SPSS, MINITAB, STATISTICA 等都有现成的回归分析程序, 可以直接给出因变量的置信区间和预测区间。\n\n\\section*{例 12.6}\n沿用例 12.1 的数据。根据贷款余额 $x_{1}$ 、累计应收贷款 $x_{2}$ 、贷款项目个数 $x_{3}$ 和固定资产投资额 $x_{4}$ 建立不良贷款 $y$ 的 $95 \\%$ 的置信区间和预测区间。\n\n\\section*{太用 SPSS 进行回归分析的操作步骤}\n第 1 步: 选择【分析】 $\\rightarrow$ 【回归-线性】, 进入主对话框。\n\n第 2 步: 在主对话框中将因变量 (本例为不良贷款) 选入【因变量】, 将所有自变量 (本例为贷款余额、累计应收贷款、贷款项目个数、固定资产投资额）选入【自变量】，并在【方法】下选择【进入】。\n\n第 3 步：点击【保存】。在【预测值】下选择【非标准化】(输出点预测值)。在【预测区间】下选择【均值】和【单值】(输出置信区间和预测区间)。在【置信区间】中选择所要求的置信水平 (默认值为 $95 \\%$, 一般不用改变)。点击【继续】。点击【确定】。\n\n输出结果如表 12-6 所示。\n\n表 12-6 不良贷款的置信区间和预测区间\n\n\\begin{center}\n\\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}\n\\hline\n\\begin{tabular}{l}\n分行 \\\\\n编号 \\\\\n\\end{tabular} & \\begin{tabular}{l}\n不良 \\\\\n贷款 \\\\\n\\end{tabular} & \\begin{tabular}{l}\n贷款 \\\\\n余额 \\\\\n\\end{tabular} & \\begin{tabular}{l}\n累计应 \\\\\n收贷款 \\\\\n\\end{tabular} & \\begin{tabular}{l}\n贷款项 \\\\\n目个数 \\\\\n\\end{tabular} & \\begin{tabular}{c}\n固定资产 \\\\\n投资额 \\\\\n\\end{tabular} & PRE\\_ 1 & $\\mathrm{LMCI}_{-} 1$ & UMCI\\_ 1 & LICI\\_1 & $\\mathrm{LICI}_{-} 1$ \\\\\n\\hline\n1 & 0.9 & 67.3 & 6.8 & 5 & 51.9 & 1. 23718 & -0.18541 & 2.65976 & -2.73660 & 5.21095 \\\\\n\\hline\n2 & 1.1 & 111.3 & 19.8 & 16 & 90.9 & 3. 94465 & 1. 66643 & 6.22287 & -0.40937 & 8. 29867 \\\\\n\\hline\n3 & 4.8 & 173.0 & 7. 7 & 17 & 73.7 & 5.14051 & 3. 85596 & 6. 42507 & 1. 21403 & 9. 06699 \\\\\n\\hline\n4 & 3.2 & 80.8 & 7. 2 & 10 & 14.5 & 3.00138 & 1. 78174 & 4. 22102 & -0.90434 & 6.90711 \\\\\n\\hline\n5 & 7.8 & 199.7 & 16.5 & 19 & 63.2 & 7. 84785 & 6.43467 & 9. 26102 & 3. 877431 & 11.81827 \\\\\n\\hline\n6 & 2.7 & 16. 2 & 2.2 & 1 & 2.2 & -0.09702 & -1.62200 & 1. 42796 & -4.10860 & 3.91455 \\\\\n\\hline\n7 & 1.6 & 107.4 & 10. 7 & 17 & 20.2 & 4. 51985 & 3.01816 & 6.02155 & 0.51707 & 8. 52263 \\\\\n\\hline\n8 & 12.5 & 185.4 & 27.1 & 18 & 43.8 & 9. 39626 & 6.740061 & 12.05245 & 4. 833091 & 13. 95943 \\\\\n\\hline\n9 & 1.0 & 96.1 & 1. 7 & 10 & 55.9 & 1.59121 & 0.16342 & 3.01901 & -2.38443 & 5. 56686 \\\\\n\\hline\n10 & 2.6 & 72.8 & 9.1 & 14 & 64.3 & 1. 56664 & 0.32302 & 2.81027 & -2.34664 & 5.47992 \\\\\n\\hline\n11 & 0.3 & 64.2 & 2.1 & 11 & 42.7 & 0.77305 & -0.42179 & 1.96788 & -3.12500 & 4. 67109 \\\\\n\\hline\n12 & 4.0 & 132.2 & 11.2 & 23 & 76.7 & 4.02462 & 2.64760 & 5.40165 & 0.06693 & 7. 98232 \\\\\n\\hline\n13 & 0.8 & 58.6 & 6.0 & 14 & 22.8 & 1.75068 & 0.40366 & 3.09771 & -2.19667 & 5.69804 \\\\\n\\hline\n14 & 3.5 & 174.6 & 12.7 & 26 & 117.1 & 4.80854 & 3. 19196 & 6.42512 & 0.76126 & 8. 85582 \\\\\n\\hline\n15 & 10.2 & 263.5 & 15.8 & 34 & 146.7 & 8.04946 & 6.063031 & 10.03590 & 3. 840771 & 12. 25815 \\\\\n\\hline\n16 & 3.0 & 79.3 & 8.9 & 15 & 28.9 & 2.81606 & 1.62898 & 4.00313 & -1.07962 & 6.71173 \\\\\n\\hline\n17 & 0.2 & 14.8 & 0.6 & 2 & 42.1 & -1.54020 & -3.24509 & 0.16470 & -5.62356 & 2. 54316 \\\\\n\\hline\n18 & 0.4 & 73.5 & 5.9 & 11 & 25.3 & 2.21590 & 1. 18479 & 3.24701 & -1.63512 & 6.06691 \\\\\n\\hline\n19 & 1.0 & 24.7 & 5.0 & 4 & 13. 4 & 0.37443 & -0.87232 & 1. 62119 & -3.53984 & 4. 28871 \\\\\n\\hline\n20 & 6.8 & 139.4 & 7.2 & 28 & 64.3 & 4.15541 & 1. 94297 & 6.36785 & -0.16455 & 8. 47537 \\\\\n\\hline\n21 & 11.6 & 368.2 & 16.8 & 32 & 163.9 & 11.88805 & 9. 066561 & 14. 70954 & 7. 226721 & 16. 54938 \\\\\n\\hline\n22 & 1. 6 & 95.7 & 3. 8 & 10 & 44.5 & 2.21887 & 1. 03994 & 3. 39779 & -1.67434 & 6.11207 \\\\\n\\hline\n23 & 1. 2 & 109.6 & 10.3 & 14 & 67.9 & 3.11264 & 2.22239 & 4.00289 & -0.70308 & 6.92836 \\\\\n\\hline\n24 & 7.2 & 196.2 & 15.8 & 16 & 39.7 & 8. 24653 & 6. 330601 & 10.16246 & 4.070651 & 12. 42240 \\\\\n\\hline\n25 & 3.2 & 102.2 & 12.0 & 10 & 97.1 & 2. 15746 & 0.17604 & 4.13887 & -2.04887 & 6.36378 \\\\\n\\hline\n\\end{tabular}\n\\end{center}\n\n表 12-6 中的 PRE\\_1 是点估计（预测）值，LMCI\\_1 和 UMCI\\_1 是平均值的置信区间 (SPSS 称为均值的预测区间) 的下限和上限, LICI\\_1 和 UICI\\_1 是个别值的预测区间的下限和上限。\n\n\\section*{12.6 变量选择与逐步回归}\n根据多个自变量建立回归模型时, 若试图将所有的自变量都引人回归模型, 带来的问题往往让人无所适从, 或者是对所建立的模型不能进行有效的解释。比如, 在例 12.1 中,建立不良贷款与 4 个自变量的回归模型时, 得到的结果就很难解释。如果在建立模型之前能对所收集到的自变量进行一定的笁选, 去掉那些不必要的自变量, 不仅会使建立模型变得容易，而且使模型更具有可操作性，也更容易解释。"
    },
    {
        "id": "chatcmpl-93yPLddIAvkkeOlWO7HPLgmQq5FOs",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "logprobs": null,
                "message": {
                    "content": "{\n    \"问题1\": \"多重共线性问题的解决方法有哪些？\",\n    \"回答1\": \"多重共线性问题的解决方法包括剔除一个或多个相关的自变量使保留的自变量尽可能不相关，以及在模型中保留所有自变量但避免对单个参数进行检验，并限定因变量值的推断在自变量样本值的范围内。\",\n    \"问题2\": \"如何处理多重共线性问题以消除线性关系和使各回归系数显著？\",\n    \"回答2\": \"处理多重共线性问题可以考虑将一些相关的自变量从模型中剔除，从而消除线性关系。另外，对于剩余的自变量，可以通过适当的方法避免对单个参数进行检验，从而使各回归系数在显著性水平下显著。\",\n    \"问题3\": \"多重共线性问题会对回归系数的解释和检验产生什么影响？\",\n    \"回答3\": \"多重共线性问题会对单个回归系数的解释和检验产生主要影响。在求因变量的置信区间和预测区间时一般不会受其影响，但必须保证用于估计或预测的自变量的值是在样本数据的范围之内。\",\n    \"问题4\": \"为什么在建立多元线性回归模型时不应试图引入更多的自变量？\",\n    \"回答4\": \"在建立多元线性回归模型时，不应试图引入更多的自变量，除非确实有必要。特别是在社会科学研究中，由于所使用的大多数数据都是非试验性质的，因此，在某些情况下，得到的结果往往并不令人满意，但这不一定是因为选择的模型不合适，而是数据的质量不好或者引入的自变量不合适。\",\n    \"问题5\": \"如何利用给定的自变量求出因变量的平均值置信区间和个别值预测区间？\",\n    \"回答5\": \"利用给定的自变量求出因变量的平均值置信区间和个别值预测区间需要进行复杂的计算，通常依赖于计算机和统计软件。常用的统计软件如SAS、SPSS、MINITAB、STATISTICA等都有现成的回归分析程序，可以直接给出因变量的置信区间和预测区间。\",\n    \"问题6\": \"为什么在建立回归模型时需要进行变量选择和逐步回归？\",\n    \"回答6\": \"在建立回归模型时需要进行变量选择和逐步回归是因为根据多个自变量建立回归模型时，试图将所有自变量都引入模型会让人无所适从，难以解释。通过对收集到的自变量进行一定的筛选，去掉不必要的自变量，可以使建立模型更容易、更具可操作性，并且更容易解释。\"\n}",
                    "role": "assistant",
                    "function_call": null,
                    "tool_calls": null
                }
            }
        ],
        "created": 1710734219,
        "model": "gpt-3.5-turbo-1106",
        "object": "chat.completion",
        "system_fingerprint": "fp_4aaaf0dc94",
        "usage": {
            "completion_tokens": 901,
            "prompt_tokens": 6581,
            "total_tokens": 7482
        },
        "parameters": {
            "model": "gpt-3.5-turbo-1106",
            "temperature": 0.2,
            "frequency_penalty": 0.15,
            "presence_penalty": 0.15
        }
    }
]