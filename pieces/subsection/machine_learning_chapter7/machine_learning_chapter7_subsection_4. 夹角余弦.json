[
    {
        "strategy": "subsection",
        "source": "machine_learning_chapter7",
        "title": "4. 夹角余弦",
        "content_length": 2466,
        "content": "Title: 4. 夹角余弦\nContent:\n样本之间的相似度也可以用夹角余弦 (cosine) 来表示。夹角余弦越接近 1 , 表示样本越相似; 越接近 0 , 表示样本越不相似。\n\n定义 14.4 样本 $x_{i}$ 与样本 $x_{j}$ 之间的夹角余弦定义为\n\n\n\\begin{equation*}\ns_{i j}=\\frac{\\sum_{k=1}^{m} x_{k i} x_{k j}}{\\left(\\sum_{k=1}^{m} x_{k i}^{2} \\sum_{k=1}^{m} x_{k j}^{2}\\right)^{\\frac{1}{2}}} \\tag{14.9}\n\\end{equation*}\n\n\n由上述定义看出, 用距离度量相似度时, 距离越小, 样本越相似; 用相关系数时, 相关系数越大, 样本越相似。注意不同相似度度量得到的结果并不一定一致, 请参照图 14.1。\n\n\\begin{center}\n\\includegraphics[max width=\\textwidth]{2024_03_13_690a9c6ba63c19ff9106g-01}\n\\end{center}\n\n图 14.1 距离与相关系数的关系\n\n从图 14.1 可以看出, 如果从距离的角度看, A 和 B 比 A 和 C 更相似; 但从相关系数的角度看, $\\mathrm{A}$ 和 $\\mathrm{C}$ 比 $\\mathrm{A}$ 和 $\\mathrm{B}$ 更相似。所以, 进行聚类时, 选择适合的距离或相似度非常重要。\n\n\\section*{14.1 .2 类或簇}\n通过聚类得到的类或簇本质是样本的子集。如果一个聚类方法假定一个样本只能属于一个类或类的交集为空集, 那么该方法称为硬聚类 (hard clustering) 方法。否则, 如果一个样本可以属于多个类或类的交集不为空集，那么该方法称为软聚类 (soft clustering) 方法。本章只考虑硬聚类方法。\n\n用 $G$ 表示类或簇（cluster）, 用 $x_{i}, x_{j}$ 表示类中的样本, 用 $n_{G}$ 表示 $G$ 中样本的个数,用 $d_{i j}$ 表示样本 $x_{i}$ 与样本 $x_{j}$ 之间的距离。类或簇有多种定义, 下面给出几个常见的定义。\n\n定义 14.5 设 $T$ 为给定的正数, 若对于集合 $G$ 中任意两个样本 $x_{i}, x_{j}$, 有\n\n$$\nd_{i j} \\leqslant T\n$$\n\n则称 $G$ 为一个类或簇。\n\n定义 14.6 设 $T$ 为给定的正数, 若对集合 $G$ 的任意样本 $x_{i}$, 一定存在 $G$ 中的另一个样本 $x_{j}$, 使得\n\n$$\nd_{i j} \\leqslant T\n$$\n\n则称 $G$ 为一个类或簇。\n\n定义 14.7 设 $T$ 为给定的正数, 若对集合 $G$ 中任意一个样本 $x_{i}, G$ 中的另一个样本 $x_{j}$满足\n\n$$\n\\frac{1}{n_{G}-1} \\sum_{x_{j} \\in G} d_{i j} \\leqslant T\n$$\n\n其中 $n_{G}$ 为 $G$ 中样本的个数, 则称 $G$ 为一个类或簇。\n\n定义 14.8 设 $T$ 和 $V$ 为给定的两个正数, 如果集合 $G$ 中任意两个样本 $x_{i}, x_{j}$ 的距离 $d_{i j}$ 满足\n\n$$\n\\begin{aligned}\n& \\frac{1}{n_{G}\\left(n_{G}-1\\right)} \\sum_{x_{i} \\in G} \\sum_{x_{j} \\in G} d_{i j} \\leqslant T \\\\\n& d_{i j} \\leqslant V\n\\end{aligned}\n$$\n\n则称 $G$ 为一个类或簇。\n\n以上四个定义中, 第一个定义最常用, 并且由它可推出其他三个定义。\n\n类的特征可以通过不同角度来刻画, 常用的特征有下面三种:\n\n(1) 类的均值 $\\bar{x}_{G}$, 又称为类的中心\n\n\n\\begin{equation*}\n\\bar{x}_{G}=\\frac{1}{n_{G}} \\sum_{i=1}^{n_{G}} x_{i} \\tag{14.10}\n\\end{equation*}\n\n\n式中 $n_{G}$ 是类 $G$ 的样本个数。\n\n(2) 类的直径 (diameter) $D_{G}$\n\n类的直径 $D_{G}$ 是类中任意两个样本之间的最大距离, 即\n\n\n\\begin{equation*}\nD_{G}=\\max _{x_{i}, x_{j} \\in G} d_{i j} \\tag{14.11}\n\\end{equation*}\n\n\n(3) 类的样本散布矩阵 (scatter matrix) $A_{G}$ 与样本协方差矩阵 (covariance matrix) $S_{G}$类的样本散布矩阵 $A_{G}$ 为\n\n\n\\begin{equation*}\nA_{G}=\\sum_{i=1}^{n_{G}}\\left(x_{i}-\\bar{x}_{G}\\right)\\left(x_{i}-\\bar{x}_{G}\\right)^{\\mathrm{T}} \\tag{14.12}\n\\end{equation*}\n\n\n样本协方差矩阵 $S_{G}$ 为\n\n\n\\begin{align*}\nS_{G} & =\\frac{1}{n_{G}-1} A_{G} \\\\\n& =\\frac{1}{n_{G}-1} \\sum_{i=1}^{n_{G}}\\left(x_{i}-\\bar{x}_{G}\\right)\\left(x_{i}-\\bar{x}_{G}\\right)^{\\mathrm{T}} \\tag{14.13}\n\\end{align*}"
    },
    {
        "id": "chatcmpl-93yvwcvEKYiXAHsJ1riBIPTCVvSk2",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "logprobs": null,
                "message": {
                    "content": "{\n    \"问题1\": \"夹角余弦的定义是什么？\",\n    \"回答1\": \"样本 $x_{i}$ 与样本 $x_{j}$ 之间的夹角余弦定义为 $s_{i j}=\\frac{\\text{sum}_{k=1}^{m} x_{k i} x_{k j}}{\\big(\\text{sum}_{k=1}^{m} x_{k i}^{2} \\text{sum}_{k=1}^{m} x_{k j}^{2}\\big)^{\\frac{1}{2}}}$。\",\n    \"问题2\": \"夹角余弦的取值范围代表什么意义？\",\n    \"回答2\": \"夹角余弦越接近 1 , 表示样本越相似; 越接近 0 , 表示样本越不相似。\",\n    \"问题3\": \"在聚类中，硬聚类和软聚类的区别是什么？\",\n    \"回答3\": \"硬聚类方法假定一个样本只能属于一个类或类的交集为空集，而软聚类方法则允许一个样本属于多个类或类的交集不为空集。\",\n    \"问题4\": \"在聚类中，常用的类或簇的定义有哪些？\",\n    \"回答4\": \"常用的类或簇的定义包括距离阈值定义、相邻性定义、平均距离定义和直径与距离阈值定义等。\",\n    \"问题5\": \"如何计算类的均值 $\\bar{x}_{G}$？\",\n    \"回答5\": \"类的均值 $\\bar{x}_{G}$ 计算公式为 $\\bar{x}_{G}=\\frac{1}{n_{G}} \\text{sum}_{i=1}^{n_{G}} x_{i}$，其中 $n_{G}$ 是类 $G$ 的样本个数。\",\n    \"问题6\": \"什么是类的直径 $D_{G}$？\",\n    \"回答6\": \"类的直径 $D_{G}$ 是类中任意两个样本之间的最大距离，即 $D_{G}=\\text{max}_{x_{i}, x_{j} \\text{在} G} d_{i j}$。\",\n    \"问题7\": \"什么是类的样本散布矩阵 $A_{G}$ 和样本协方差矩阵 $S_{G}$？\",\n    \"回答7\": \"类的样本散布矩阵 $A_{G}$ 是指 $\\text{sum}_{i=1}^{n_{G}}\\big(x_{i}-\\bar{x}_{G}\\big)\\big(x_{i}-\\bar{x}_{G}\\big)^{\\text{T}}$，而样本协方差矩阵 $S_{G}$ 则是指 $\\frac{1}{n_{G}-1} A_{G}$ 或 $\\frac{1}{n_{G}-1} \\text{sum}_{i=1}^{n_{G}}\\big(x_{i}-\\bar{x}_{G}\\big)\\big(x_{i}-\\bar{x}_{G}\\big)^{\\text{T}}$。\",\n    \"问题8\": \"在聚类中，如何刻画类的特征？\",\n    \"回答8\": \"在聚类中，常用的刻画类的特征有三种：(1) 类的均值 $\\bar{x}_{G}$，又称为类的中心；(2) 类的直径 $D_{G}$；(3) 类的样本散布矩阵 $A_{G}$ 和样本协方差矩阵 $S_{G}$。\",\n    \"问题9\": \"为什么进行聚类时选择适合的距离或相似度非常重要？\",\n    \"回答9\": \"进行聚类时选择适合的距禈或相似度非常重要，因为不同距离或相似度度量得到的结果并不一定一致。选择合适的距离或相似度能够更准确地反映数据间的关系，从而影响最终聚类结果。\",\n    \"问题10\": \"夹角余弦和距离度量在相似度度量中有何区别？\",\n    \"回答10\": \"夹角余弦主要通过计算向量之间夹角余弦来衡量相似度，而距离度量则是通过计算向量之间的距离来衡量相似度。夹角余弦越接近 1 表示样本越相似，而距离越小表示样本越相似。\"\n}",
                    "role": "assistant",
                    "function_call": null,
                    "tool_calls": null
                }
            }
        ],
        "created": 1710736240,
        "model": "gpt-3.5-turbo-1106",
        "object": "chat.completion",
        "system_fingerprint": "fp_4aaaf0dc94",
        "usage": {
            "completion_tokens": 1216,
            "prompt_tokens": 4225,
            "total_tokens": 5441
        },
        "parameters": {
            "model": "gpt-3.5-turbo-1106",
            "temperature": 0.2,
            "frequency_penalty": 0.15,
            "presence_penalty": 0.15
        }
    }
]