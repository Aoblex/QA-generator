[
    {
        "strategy": "subsection",
        "source": "machine_learning_chapter7",
        "title": "15.1.2 紧奇异值分解与截断奇异值分解",
        "content_length": 3972,
        "content": "Title: 15.1.2 紧奇异值分解与截断奇异值分解\nContent:\n定理 15.1 给出的奇异值分解\n\n$$\n\\boldsymbol{A}=\\boldsymbol{U} \\boldsymbol{\\Sigma} \\boldsymbol{V}^{\\mathrm{T}}\n$$\n\n又称为矩阵的完全奇异值分解 (full singular value decomposition）。实际常用的是奇异值分\n\\footnotetext{(1) 参照附录 D。\n}\n解的紧凑形式和截断形式。紧奇异值分解是与原始矩阵等秩的奇异值分解, 截断奇异值分解是比原始矩阵低秩的奇异值分解。\n\n\\section*{1. 紧奇异值分解}\n定义 15.2 设有 $m \\times n$ 实矩阵 $\\boldsymbol{A}$, 其秩为 $\\operatorname{rank}(\\boldsymbol{A})=r, r \\leqslant \\min (m, n)$, 则称 $\\boldsymbol{U}_{r} \\boldsymbol{\\Sigma}_{r} \\boldsymbol{V}_{r}^{\\mathrm{T}}$为 $\\boldsymbol{A}$ 的紧奇异值分解 ( compact singular value decomposition), 即\n\n\n\\begin{equation*}\n\\boldsymbol{A}=\\boldsymbol{U}_{r} \\boldsymbol{\\Sigma}_{r} \\boldsymbol{V}_{r}^{\\mathrm{T}} \\tag{15.18}\n\\end{equation*}\n\n\n其中, $\\boldsymbol{U}_{r}$ 是 $m \\times r$ 矩阵, $\\boldsymbol{V}_{r}$ 是 $n \\times r$ 矩阵, $\\boldsymbol{\\Sigma}_{r}$ 是 $r$ 阶对角矩阵; 矩阵 $\\boldsymbol{U}_{r}$ 由完全奇异值分解中 $\\boldsymbol{U}$ 的前 $r$ 列、矩阵 $\\boldsymbol{V}_{r}$ 由 $\\boldsymbol{V}$ 的前 $r$ 列、矩阵 $\\boldsymbol{\\Sigma}_{r}$ 由 $\\boldsymbol{\\Sigma}$ 的前 $r$ 个对角线元素得到。紧奇异值分解的对角矩阵 $\\boldsymbol{\\Sigma}_{r}$ 的秩与原始矩阵 $\\boldsymbol{A}$ 的秩相等。\n\n例 15.2 由例 15.1 给出的矩阵 $\\boldsymbol{A}$ 的秩 $r=3$,\n\n$$\n\\boldsymbol{A}=\\left[\\begin{array}{llll}\n1 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 4 \\\\\n0 & 3 & 0 & 0 \\\\\n0 & 0 & 0 & 0 \\\\\n2 & 0 & 0 & 0\n\\end{array}\\right]\n$$\n\n$\\boldsymbol{A}$ 的紧奇异值分解是\n\n$$\n\\boldsymbol{A}=\\boldsymbol{U}_{r} \\boldsymbol{\\Sigma}_{r} \\boldsymbol{V}_{r}^{\\mathrm{T}}\n$$\n\n其中，\n\n$$\n\\boldsymbol{U}_{r}=\\left[\\begin{array}{ccc}\n0 & 0 & \\sqrt{0.2} \\\\\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 0 & 0 \\\\\n0 & 0 & \\sqrt{0.8}\n\\end{array}\\right], \\quad \\boldsymbol{\\Sigma}_{r}=\\left[\\begin{array}{ccc}\n4 & 0 & 0 \\\\\n0 & 3 & 0 \\\\\n0 & 0 & \\sqrt{5}\n\\end{array}\\right], \\quad \\boldsymbol{V}_{r}^{\\mathrm{T}}=\\left[\\begin{array}{cccc}\n0 & 0 & 0 & 1 \\\\\n0 & 1 & 0 & 0 \\\\\n1 & 0 & 0 & 0\n\\end{array}\\right]\n$$\n\n\\section*{2. 截断奇异值分解}\n在矩阵的奇异值分解中, 只取最大的 $k$ 个奇异值 ( $k<r, r$ 为矩阵的秩) 对应的部分,就得到矩阵的截断奇异值分解。实际应用中提到矩阵的奇异值分解时, 通常指截断奇异值分解。\n\n定义 15.3 设 $\\boldsymbol{A}$ 为 $m \\times n$ 实矩阵, 其秩 $\\operatorname{rank}(\\boldsymbol{A})=r$, 且 $0<k<r$, 则称 $\\boldsymbol{U}_{k} \\boldsymbol{\\Sigma}_{k} \\boldsymbol{V}_{k}^{\\mathrm{T}}$ 为矩阵 $\\boldsymbol{A}$ 的截断奇异值分解 (truncated singular value decomposition)，即\n\n\n\\begin{equation*}\n\\boldsymbol{A} \\approx \\boldsymbol{U}_{k} \\boldsymbol{\\Sigma}_{k} \\boldsymbol{V}_{k}^{\\mathrm{T}} \\tag{15.19}\n\\end{equation*}\n\n\n其中, $\\boldsymbol{U}_{k}$ 是 $m \\times k$ 矩阵, $\\boldsymbol{V}_{k}$ 是 $n \\times k$ 矩阵, $\\boldsymbol{\\Sigma}_{k}$ 是 $k$ 阶对角矩阵; 矩阵 $\\boldsymbol{U}_{k}$ 由完全奇异值分解中 $\\boldsymbol{U}$ 的前 $k$ 列、矩阵 $\\boldsymbol{V}_{k}$ 由 $\\boldsymbol{V}$ 的前 $k$ 列、矩阵 $\\boldsymbol{\\Sigma}_{k}$ 由 $\\boldsymbol{\\Sigma}$ 的前 $k$ 个对角线元素得到。对角矩阵 $\\Sigma_{k}$ 的秩比原始矩阵 $A$ 的秩低。\\\\\n例 15.3 由例 15.1 给出的矩阵 $\\boldsymbol{A}$\n\n$$\n\\boldsymbol{A}=\\left[\\begin{array}{llll}\n1 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 4 \\\\\n0 & 3 & 0 & 0 \\\\\n0 & 0 & 0 & 0 \\\\\n2 & 0 & 0 & 0\n\\end{array}\\right]\n$$\n\n的秩为 3 , 若取 $k=2$, 则其截断奇异值分解是\n\n$$\n\\boldsymbol{A} \\approx \\boldsymbol{A}_{2}=\\boldsymbol{U}_{2} \\boldsymbol{\\Sigma}_{2} \\boldsymbol{V}_{2}^{\\mathrm{T}}\n$$\n\n其中，\n\n$$\n\\begin{aligned}\n& \\boldsymbol{U}_{2}=\\left[\\begin{array}{ll}\n0 & 0 \\\\\n1 & 0 \\\\\n0 & 1 \\\\\n0 & 0 \\\\\n0 & 0\n\\end{array}\\right], \\quad \\boldsymbol{\\Sigma}_{2}=\\left[\\begin{array}{ll}\n4 & 0 \\\\\n0 & 3\n\\end{array}\\right], \\quad \\boldsymbol{V}_{2}^{\\mathrm{T}}=\\left[\\begin{array}{llll}\n0 & 0 & 0 & 1 \\\\\n0 & 1 & 0 & 0\n\\end{array}\\right], \\\\\n& \\boldsymbol{A}_{2}=\\boldsymbol{U}_{2} \\boldsymbol{\\Sigma}_{2} \\boldsymbol{V}_{2}^{\\mathrm{T}}=\\left[\\begin{array}{llll}\n0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 4 \\\\\n0 & 3 & 0 & 0 \\\\\n0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0\n\\end{array}\\right]\n\\end{aligned}\n$$\n\n这里的 $\\boldsymbol{U}_{2}, \\boldsymbol{V}_{2}$ 是例 15.1 的 $\\boldsymbol{U}$ 和 $\\boldsymbol{V}$ 的前两列, $\\boldsymbol{\\Sigma}_{2}$ 是 $\\boldsymbol{\\Sigma}$ 的前两行前两列。 $\\boldsymbol{A}_{2}$ 与 $\\boldsymbol{A}$ 相比, $\\boldsymbol{A}$的元素 1 和 2 在 $\\boldsymbol{A}_{2}$ 中均变成 0 。\n\n在实际应用中, 常常需要对矩阵的数据进行压缩, 将其近似表示, 奇异值分解提供了一种方法。后面将要叙述, 奇异值分解是在平方损失 (弗罗贝尼乌斯范数) 意义下对矩阵的最优近似。紧奇异值分解对应无损压缩，截断奇异值分解对应有损压缩。"
    },
    {
        "id": "chatcmpl-93z0gwnEfHWuCMElfk2wHOvT1wOYH",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "logprobs": null,
                "message": {
                    "content": "{\n    \"问题1\": \"紧奇异值分解和截断奇异值分解有什么区别？\",\n    \"回答1\": \"紧奇异值分解是与原始矩阵等秩的奇异值分解，而截断奇异值分解是比原始矩阵低秩的奇异值分解。在紧奇异值分解中，对角矩阵 $\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{}}}}}}}}}}}}}}}}}}}}}$ 的秩与原始矩阵 $\\boldsymbol{A}$ 的秩相等；而在截断奇异值分解中，对角矩阵 $\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{}}}}}}}}}}}}}}}}}$ 的秩比原始矩阵 $\\boldsymbol{A}$ 的秩低。\",\n    \"问题2\": \"紧奇异值分解的定义是什么？\",\n    \"回答2\": \"对于 $m \\times n$ 实矩阵 $\\boldsymbol{A}$，其秩为 $\\text{rank}(\\boldsymbol{A})=r, r \\text{ 为 } \\text{min}(m, n)$，则称 $\\boldsymbol{U}_{r} \\boldsymbol{\\boldmatrix}_{r} \\boldmatrix_{r}^T$ 为 $\\boldmatrix_{A}$ 的紧奇异值分解（compact singular value decomposition），即 $\\boldmatrix_{A}=\\boldmatrix_{U}_{r} \\boldmatrix_{\\boldmatrix}_{r} \\boldmatrix_{r}^T$。\",\n    \"问题3\": \"截断奇异值分解的定义是什么？\",\n    \"回答3\": \"对于 $m \\times n$ 实矩阵 $\\boldmatrix_{A}$，其秩 $\\text{rank}(\\boldmatrix_{A})=r$，且 $0<k<r$，则称 $\\boldmatrix_{U}_{k} \\boldmatrix_{\\boldmatrix}_{k} \\boldmatrix_{k}^T$ 为矩阵 $\\boldmatrix_{A}$ 的截断奇异值分解（truncated singular value decomposition），即 $\\boldmatrix_{A} \\text{约等于} \\boldmatrix_{U}_{k} \\boldmatrix_{\\boldmatrix}_{k} \\boldmatrix_{k}^T$。\",\n    \"问题4\": \"紧奇异值分解中的矩阵维度和性质是怎样的？\",\n    \"回答4\": \"在紧奇异值分解中，$\\boldmatrix_{U}_{r}$ 是 $m \\times r$ 矩阵，$\\boldmatrix_{V}_{r}$ 是 $n \\times r$ 矩阵，$\\boldmatrix_{\\boldmatrix}_{r}$ 是 $r$ 阶对角矩阵。其中，$\\boldmatrix_{U}_{r}$ 由完全奇异值分解中 $\\boldmatrix_{U}$ 的前 $r$ 列构成，$\\boldmatrix_{V}_{r}$ 由 $\\boldmatrix_{V}$ 的前 $r$ 列构成，$\\boldmatrix_{\\boldmatrix}_{r}$ 由 $\\boldmatrix_{\\bmatrix}$ 的前 $r$ 个对角线元素得到。紧奇异值分解的对角矩阵 $\\bmatrix_{\\bmatrix}_{r}$ 的秩与原始矩阵 $\\bmatrix_{A}$ 的秩相等。\",\n    \"问题5\": \"截断奇异值分解中的矩阵维度和性质是怎样的？\",\n    \"回答5\": \"在截断奇异值分解中，$\\bmatrix_{U}_{k}$ 是 $m \\times k$ 矩阵，$\\bmatrix_{V}_{k}$ 是 $n \\times k$ 矩阵，$\\bmatrix_{\\bmatrix}_{k}$ 是 $k$ 阶对角矩阵。其中，$\\bmatrix_{U}_{k}$ 由完全奇异值分解中 $\\bmatrix_{U}$ 的前 $k$ 列构成，$\\bmatrix_{V}_{k}$ 由 $\\bmatrix_{V}$ 的前 $k$ 列构成，$\\bmatrix_{\\bmatrix}_{k}$ 由 $\\bmatrix_{\\bmatrix}$ 的前 $k$ 个对角线元素得到。对角矩阵 $\\bmatrix_{\\bmatrix}_{k}$ 的秩比原始矩阵 $\\bmatrix_{A}$ 的秩低。\",\n    \"问题6\": \"紧奇异值分解和截断奇异值分解在实际应用中有何不同？\",\n    \"回答6\": \"在实际应用中提到矩阵的奇异值分解时，通常指截断奇异值分解。紧奇异值分解对应无损压缩，而截断奇异值分解对应有损压缩。因此，在实际应用中，通常会选择截断奇异值分解来对矩阵的数据进行压缩和近似表示。\",\n    \"问题7\": \"紧奇异值分解和截断奇异值分解如何影响矩阵的数据表示？\",\n    \"回答7\": \"紧奇异值分解提供了对原始矩阵的无损压缩表示，而截断奇异值分解提供了对原始矩阵的有损压缩表示。通过选择不同的奇异值个数进行截断，可以实现对原始数据的不同程度的近似表示，从而在实际应用中灵活地平衡数据表示的精度和存储成本。\",\n    \"问题8\": \"紧奇异值分解和截断奇异值分解如何影响数据压缩和存储？\",\n    \"回答8\": \"紧奇异值分解提供了无损压缩表示，适合需要精确还原原始数据的场景；而截断奇异值分解提供了有损压缩表示，适合在存储空间有限或对数据精度要求不高的场景。通过选择合适的截断方式和参数，可以在数据压缩和存储方面取得平衡。\",\n    \"问题9\": \"为什么在实际应用中常常需要对矩阵进行压缩和近似表示？\",\n    \"回答9\": \"在实际应用中，常常需要对大规模数据进行存储和处理。通过对矩阵进行压缩和近似表示，可以节省存储空间、降低计算成本，并且能够更高效地处理数据。因此，在实际应用中常常需要对矩阵进行压缩和近似表示来平衡存储成本和数据处理效率。\",\n    \"问题10\": \"紧奇异值分解和截断奇异值分解如何影响数据处理和计算成本？\",\n    \"回答10\": \"紧奇异值分解提供了无损压缩表示，在需要精确还原原始数据时计算成本较高；而截断奇异值分解提供了有损压缩表示，在存储空间有限或对数据精度要求不高时计算成本较低。因此，在数据处理和计算成本方面，选择合适的压缩方式能够更好地平衡存储需求和计算效率。\"\n}",
                    "role": "assistant",
                    "function_call": null,
                    "tool_calls": null
                }
            }
        ],
        "created": 1710736534,
        "model": "gpt-3.5-turbo-1106",
        "object": "chat.completion",
        "system_fingerprint": "fp_4aaaf0dc94",
        "usage": {
            "completion_tokens": 2027,
            "prompt_tokens": 4759,
            "total_tokens": 6786
        },
        "parameters": {
            "model": "gpt-3.5-turbo-1106",
            "temperature": 0.2,
            "frequency_penalty": 0.15,
            "presence_penalty": 0.15
        }
    }
]