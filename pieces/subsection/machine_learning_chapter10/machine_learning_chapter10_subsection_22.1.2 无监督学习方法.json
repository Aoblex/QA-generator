[
    {
        "strategy": "subsection",
        "source": "machine_learning_chapter10",
        "title": "22.1.2 无监督学习方法",
        "content_length": 1147,
        "content": "Title: 22.1.2 无监督学习方法\nContent:\n聚类有硬聚类和软聚类, 层次聚类与 $k$ 均值聚类是硬聚类方法, 高斯混合模型是软聚类方法。层次聚类基于启发式算法, $k$ 均值聚类基于迭代算法, 高斯混合模型学习通常基于 EM 算法。\n\n降维有线性降维和非线性降维, PCA 是线性降维方法。PCA 基于 SVD。\n\n话题分析兼有聚类和降维特点, 有非概率模型、概率模型。LSA 和 NMF 是非概率模型, PLSA 和 LDA 是概率模型。PLSA 不假设模型具有先验分布, 学习基于极大似然估计; LDA 假设模型具有先验分布, 学习基于贝叶斯学习, 具体地后验概率估计。LSA 的学习基于 SVD, NMF 可以直接用于话题分析。PLSA 的学习基于 EM 算法, LDA 的学习基于吉布斯抽样或变分推理。\n\n图分析的一个问题是链接分析, 即结点的重要度计算。PageRank 是链接分析的一个方法, 通常基于幂法。\n\n表 22.1 总结了无监督学习方法的模型、策略、算法。\n\n表 22.1 无监督学习方法的模型、策略和算法\n\n\\begin{center}\n\\begin{tabular}{l|l|l|l|l}\n\\hline\n\\multirow{4}{*}{聚类} & \\multicolumn{1}{|c|}{方法} & \\multicolumn{1}{c|}{模型} & \\multicolumn{1}{c}{策略} & \\multicolumn{1}{c}{算法} \\\\\n\\cline { 2 - 5 }\n & 层次聚类 & 聚类树 & 类内样本距离最小 & 启发式算法 \\\\\n\\cline { 2 - 5 }\n & $k$ 均值聚类 & $k$ 中心聚类 & 样本与类中心距离最小 & 迭代算法 \\\\\n\\cline { 2 - 5 }\n & 高斯混合模型 & 高斯混合模型 & 似然函数最大 & EM 算法 \\\\\n\\hline\n\\multirow{3}{*}{话题分析} & PCA & 低维正交空间 & 方差最大 & SVD \\\\\n\\cline { 2 - 5 }\n & LSA & 矩阵分解模型 & 平方损失最小 & SVD \\\\\n\\cline { 2 - 5 }\n & PLSA & 矩阵分解模型 & 平方损失最小 & 非负矩阵分解 \\\\\n\\cline { 2 - 5 }\n图分析 & PLSA 模型 & 似然函数最大 & EM 算法 &  \\\\\n\\hline\n\\multirow{2}{*}{PageRank} & LDA 模型 & 后验概率估计 & 吉布斯抽样, 变分推理 &  \\\\\n\\hline\n\\end{tabular}\n\\end{center}"
    },
    {
        "id": "chatcmpl-93zV2wu0X4WJFNrJVigzNuzL0eohf",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "logprobs": null,
                "message": {
                    "content": "{\n    \"问题1\": \"硬聚类和软聚类有何区别？\",\n    \"回答1\": \"硬聚类和软聚类的区别在于对样本的划分方式不同。硬聚类方法（如层次聚类和 $k$ 均值聚类）将每个样本划分到唯一的类别中，而软聚类方法（如高斯混合模型）允许样本以一定的概率分布属于不同的类别，从而更灵活地描述数据的分布。\",\n    \"问题2\": \"层次聚类和 $k$ 均值聚类分别基于什么算法？\",\n    \"回答2\": \"层次聚类基于启发式算法，而 $k$ 均值聚类基于迭代算法。这两种算法分别用于确定样本之间的距离或相似度，并根据距离或相似度进行样本的划分。\",\n    \"问题3\": \"高斯混合模型是如何学习的？\",\n    \"回答3\": \"高斯混合模型学习通常基于 EM 算法。EM 算法通过迭代优化似然函数，逐步调整高斯分布的参数，使得模型能够最大化拟合观测数据。\",\n    \"问题4\": \"PCA 是什么降维方法？它基于什么原理？\",\n    \"回答4\": \"PCA 是一种线性降维方法，基于奇异值分解（SVD）原理。它通过找到数据中方差最大的方向，将数据投影到这些方向上，从而实现降维。\",\n    \"问题5\": \"LSA 和 NMF 分别属于什么类型的话题分析模型？\",\n    \"回答5\": \"LSA 和 NMF 属于非概率模型。它们通过矩阵分解等方法来发现文本数据中的话题结构，但不涉及概率分布。\",\n    \"问题6\": \"PLSA 和 LDA 分别属于什么类型的话题分析模型？\",\n    \"回答6\": \"PLSA 属于非概率模型，不假设模型具有先验分布，学习基于极大似然估计；而 LDA 属于概率模型，假设模型具有先验分布，学习基于贝叶斯学习，具体地后验概率估计。\",\n    \"问题7\": \"LSA 的学习基于什么原理？\",\n    \"回答7\": \"LSA 的学习基于奇异值分解（SVD）原理。它通过对文档-词项矩阵进行奇异值分解，从而实现对文本数据中话题结构的发现。\",\n    \"问题8\": \"PageRank 是用于解决图分析中的什么问题？\",\n    \"回答8\": \"PageRank 是用于解决链接分析中节点的重要度计算问题。它通过考虑网络中节点之间的链接关系，计算每个节点的重要度，从而衡量节点在网络中的影响力。\",\n    \"问题9\": \"表 22.1 总结了无监督学习方法的哪些内容？\",\n    \"回答9\": \"表 22.1 总结了无监督学习方法的模型、策略和算法。其中包括了聚类、话题分析、图分析等无监督学习方法所涉及的具体模型、策略和算法。\",\n    \"问题10\": \"PLSA 的学习基于什么算法？\",\n    \"回答10\": \"PLSA 的学习基于非负矩阵分解算法。该算法通过迭代优化平方损失函数，逐步调整模型参数，以最小化观测数据与模型之间的差异。\"\n}",
                    "role": "assistant",
                    "function_call": null,
                    "tool_calls": null
                }
            }
        ],
        "created": 1710738416,
        "model": "gpt-3.5-turbo-1106",
        "object": "chat.completion",
        "system_fingerprint": "fp_4aaaf0dc94",
        "usage": {
            "completion_tokens": 1083,
            "prompt_tokens": 3462,
            "total_tokens": 4545
        },
        "parameters": {
            "model": "gpt-3.5-turbo-1106",
            "temperature": 0.2,
            "frequency_penalty": 0.15,
            "presence_penalty": 0.15
        }
    }
]