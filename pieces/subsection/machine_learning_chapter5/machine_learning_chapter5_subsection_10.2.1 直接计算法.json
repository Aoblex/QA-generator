[
    {
        "strategy": "subsection",
        "source": "machine_learning_chapter5",
        "title": "10.2.1 直接计算法",
        "content_length": 5440,
        "content": "Title: 10.2.1 直接计算法\nContent:\n给定模型 $\\lambda=(A, B, \\pi)$ 和观测序列 $O=\\left(o_{1}, o_{2}, \\cdots, o_{T}\\right)$, 计算观测序列 $O$ 出现的概率 $P(O \\mid \\lambda)$ 。最直接的方法是按概率公式直接计算。通过列举所有可能的长度为 $T$ 的状态序列 $I=\\left(i_{1}, i_{2}, \\cdots, i_{T}\\right)$, 求各个状态序列 $I$ 与观测序列 $O=\\left(o_{1}, o_{2}, \\cdots, o_{T}\\right)$ 的联合概率 $P(O, I \\mid \\lambda)$, 然后对所有可能的状态序列求和, 得到 $P(O \\mid \\lambda)$ 。\n\n状态序列 $I=\\left(i_{1}, i_{2}, \\cdots, i_{T}\\right)$ 的概率是\n\n\n\\begin{equation*}\nP(I \\mid \\lambda)=\\pi_{i_{1}} a_{i_{1} i_{2}} a_{i_{2} i_{3}} \\cdots a_{i_{T-1} i_{T}} \\tag{10.10}\n\\end{equation*}\n\n\n对固定的状态序列 $I=\\left(i_{1}, i_{2}, \\cdots, i_{T}\\right)$, 观测序列 $O=\\left(o_{1}, o_{2}, \\cdots, o_{T}\\right)$ 的概率是\n\n\n\\begin{equation*}\nP(O \\mid I, \\lambda)=b_{i_{1}}\\left(o_{1}\\right) b_{i_{2}}\\left(o_{2}\\right) \\cdots b_{i_{T}}\\left(o_{T}\\right) \\tag{10.11}\n\\end{equation*}\n\n\n$O$ 和 $I$ 同时出现的联合概率为\n\n\n\\begin{align*}\nP(O, I \\mid \\lambda) & =P(O \\mid I, \\lambda) P(I \\mid \\lambda) \\\\\n& =\\pi_{i_{1}} b_{i_{1}}\\left(o_{1}\\right) a_{i_{1} i_{2}} b_{i_{2}}\\left(o_{2}\\right) \\cdots a_{i_{T-1} i_{T}} b_{i_{T}}\\left(o_{T}\\right) \\tag{10.12}\n\\end{align*}\n\n\n然后, 对所有可能的状态序列 $I$ 求和, 得到观测序列 $O$ 的概率 $P(O \\mid \\lambda)$, 即\n\n\n\\begin{align*}\nP(O \\mid \\lambda) & =\\sum_{I} P(O \\mid I, \\lambda) P(I \\mid \\lambda) \\\\\n& =\\sum_{i_{1}, i_{2}, \\cdots, i_{T}} \\pi_{i_{1}} b_{i_{1}}\\left(o_{1}\\right) a_{i_{1} i_{2}} b_{i_{2}}\\left(o_{2}\\right) \\cdots a_{i_{T-1} i_{T}} b_{i_{T}}\\left(o_{T}\\right) \\tag{10.13}\n\\end{align*}\n\n\n但是, 利用公式 (10.13) 计算量很大, 是 $O\\left(T N^{\\mathrm{T}}\\right)$ 阶的, 这种算法不可行。\n\n下面介绍计算观测序列概率 $P(O \\mid \\lambda)$ 的有效算法——前向-后向算法 (forward-backward algorithm）。\n\n\\section*{10.2 .2 前向算法}\n首先定义前向概率。\n\n定义 10.2（前向概率） 给定隐马尔可夫模型 $\\lambda$, 定义到时刻 $t$ 部分观测序列为 $o_{1}, o_{2}, \\cdots, o_{t}$ 且状态为 $q_{i}$ 的概率为前向概率, 记作\n\n\n\\begin{equation*}\n\\alpha_{t}(i)=P\\left(o_{1}, o_{2}, \\cdots, o_{t}, i_{t}=q_{i} \\mid \\lambda\\right) \\tag{10.14}\n\\end{equation*}\n\n\n可以递推地求得前向概率 $\\alpha_{t}(i)$ 及观测序列概率 $P(O \\mid \\lambda)$ 。\n\n\\section*{算法 10.2 (观测序列概率的前向算法)}\n输入: 隐马尔可夫模型 $\\lambda$, 观测序列 $O$ 。\n\n输出: 观测序列概率 $P(O \\mid \\lambda)$ 。\n\n(1) 初值\n\n\n\\begin{equation*}\n\\alpha_{1}(i)=\\pi_{i} b_{i}\\left(o_{1}\\right), \\quad i=1,2, \\cdots, N \\tag{10.15}\n\\end{equation*}\n\n\n(2) 递推\n\n对 $t=1,2, \\cdots, T-1$, 有\n\n\n\\begin{equation*}\n\\alpha_{t+1}(i)=\\left[\\sum_{j=1}^{N} \\alpha_{t}(j) a_{j i}\\right] b_{i}\\left(o_{t+1}\\right), \\quad i=1,2, \\cdots, N \\tag{10.16}\n\\end{equation*}\n\n\n(3) 终止\n\n\n\\begin{equation*}\nP(O \\mid \\lambda)=\\sum_{i=1}^{N} \\alpha_{T}(i) \\tag{10.17}\n\\end{equation*}\n\n\n在前向算法中, 步骤 (1) 初始化前向概率, 是初始时刻的状态 $i_{1}=q_{i}$ 和观测 $o_{1}$ 的联合概率。步骤 (2) 是前向概率的递推公式, 计算到时刻 $t+1$ 部分观测序列为 $o_{1}, o_{2}, \\cdots, o_{t}, o_{t+1}$且在时刻 $t+1$ 处于状态 $q_{i}$ 的前向概率, 如图 10.1 所示。在式 (10.16) 的方括号里, 既然 $\\alpha_{t}(j)$ 是到时刻 $t$ 观测到 $o_{1}, o_{2}, \\cdots, o_{t}$ 并在时刻 $t$ 处于状态 $q_{j}$ 的前向概率, 那么乘积 $\\alpha_{t}(j) a_{j i}$就是到时刻 $t$ 观测到 $o_{1}, o_{2}, \\cdots, o_{t}$ 并在时刻 $t$ 处于状态 $q_{j}$ 而在时刻 $t+1$ 到达状态 $q_{i}$ 的联合概率。对这个乘积在时刻 $t$ 的所有可能的 $N$ 个状态 $q_{j}$ 求和, 其结果就是到时刻 $t$ 观测为 $o_{1}, o_{2}, \\cdots, o_{t}$ 并在时刻 $t+1$ 处于状态 $q_{i}$ 的联合概率。方括号里的值与观测概率 $b_{i}\\left(o_{t+1}\\right)$ 的乘积恰好是到时刻 $t+1$ 观测到 $o_{1}, o_{2}, \\cdots, o_{t}, o_{t+1}$ 并在时刻 $t+1$ 处于状态 $q_{i}$ 的前向概率 $\\alpha_{t+1}(i)$ 。步骤 (3) 给出 $P(O \\mid \\lambda)$ 的计算公式。因为\n\n$$\n\\alpha_{T}(i)=P\\left(o_{1}, o_{2}, \\cdots, o_{T}, i_{T}=q_{i} \\mid \\lambda\\right)\n$$\n\n所以\n\n$$\nP(O \\mid \\lambda)=\\sum_{i=1}^{N} \\alpha_{T}(i)\n$$\n\n\\begin{center}\n\\includegraphics[max width=\\textwidth]{2024_03_13_85ccebcbbc039fa5a6c0g-31(1)}\n\\end{center}\n\n图 10.1 前向概率的递推公式\n\n如图 10.2 所示, 前向算法实际是基于 “状态序列的路径结构” 递推计算 $P(O \\mid \\lambda)$ 的算法。前向算法高效的关键是其局部计算前向概率, 然后利用路径结构将前向概率 “递推” 到全局,得到 $P(O \\mid \\lambda)$ 。具体地, 在时刻 $t=1$, 计算 $\\alpha_{1}(i)$ 的 $N$ 个值 $(i=1,2, \\cdots, N)$; 在各个时刻 $t=1,2, \\cdots, T-1$, 计算 $\\alpha_{t+1}(i)$ 的 $N$ 个值 $(i=1,2, \\cdots, N)$, 而且每个 $\\alpha_{t+1}(i)$ 的计算利用前一时刻的 $N$ 个 $\\alpha_{t}(j)$ 。减少计算量的原因在于每一次计算直接引用前一个时刻的计算结果,避免重复计算。这样, 利用前向概率计算 $P(O \\mid \\lambda)$ 的计算量是 $O\\left(N^{2} T\\right)$ 阶的, 而不是直接计算的 $O\\left(T N^{T}\\right)$ 阶。\\\\\n\\includegraphics[max width=\\textwidth, center]{2024_03_13_85ccebcbbc039fa5a6c0g-31}\n\n图 10.2 观测序列路径结构\\\\\n例 10.2 考虑盒子和球模型 $\\lambda=(A, B, \\pi)$, 状态集合 $Q=\\{1,2,3\\}$, 观测集合 $V=$ \\{红, 白\\},\n\n$$\nA=\\left[\\begin{array}{lll}\n0.5 & 0.2 & 0.3 \\\\\n0.3 & 0.5 & 0.2 \\\\\n0.2 & 0.3 & 0.5\n\\end{array}\\right], \\quad B=\\left[\\begin{array}{cc}\n0.5 & 0.5 \\\\\n0.4 & 0.6 \\\\\n0.7 & 0.3\n\\end{array}\\right], \\quad \\pi=\\left[\\begin{array}{l}\n0.2 \\\\\n0.4 \\\\\n0.4\n\\end{array}\\right]\n$$\n\n设 $T=3, O=$ (红, 白, 红), 试用前向算法计算 $P(O \\mid \\lambda)$ 。\n\n解 按照算法 10.2:\n\n(1) 计算初值\n\n$$\n\\begin{aligned}\n& \\alpha_{1}(1)=\\pi_{1} b_{1}\\left(o_{1}\\right)=0.10 \\\\\n& \\alpha_{1}(2)=\\pi_{2} b_{2}\\left(o_{1}\\right)=0.16 \\\\\n& \\alpha_{1}(3)=\\pi_{3} b_{3}\\left(o_{1}\\right)=0.28\n\\end{aligned}\n$$\n\n(2) 递推计算\n\n$$\n\\begin{aligned}\n& \\alpha_{2}(1)=\\left[\\sum_{i=1}^{3} \\alpha_{1}(i) a_{i 1}\\right] b_{1}\\left(o_{2}\\right)=0.154 \\times 0.5=0.077 \\\\\n& \\alpha_{2}(2)=\\left[\\sum_{i=1}^{3} \\alpha_{1}(i) a_{i 2}\\right] b_{2}\\left(o_{2}\\right)=0.184 \\times 0.6=0.1104 \\\\\n& \\alpha_{2}(3)=\\left[\\sum_{i=1}^{3} \\alpha_{1}(i) a_{i 3}\\right] b_{3}\\left(o_{2}\\right)=0.202 \\times 0.3=0.0606 \\\\\n& \\alpha_{3}(1)=\\left[\\sum_{i=1}^{3} \\alpha_{2}(i) a_{i 1}\\right] b_{1}\\left(o_{3}\\right)=0.04187 \\\\\n& \\alpha_{3}(2)=\\left[\\sum_{i=1}^{3} \\alpha_{2}(i) a_{i 2}\\right] b_{2}\\left(o_{3}\\right)=0.03551 \\\\\n& \\alpha_{3}(3)=\\left[\\sum_{i=1}^{3} \\alpha_{2}(i) a_{i 3}\\right] b_{3}\\left(o_{3}\\right)=0.05284\n\\end{aligned}\n$$\n\n(3) 终止\n\n$$\nP(O \\mid \\lambda)=\\sum_{i=1}^{3} \\alpha_{3}(i)=0.13022\n$$"
    },
    {
        "id": "chatcmpl-948dVMYfjQywyIJZDhVWoyQ4asRK6",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "logprobs": null,
                "message": {
                    "content": "{\n    \"问题1\": \"直接计算法和前向-后向算法在计算观测序列概率方面有何区别？\",\n    \"回答1\": \"直接计算法是通过列举所有可能的长度为 $T$ 的状态序列 $I$，求各个状态序列 $I$ 与观测序列 $O$ 的联合概率 $P(O, I \\text{ 为 } \\boldsymbol{\\text{mid}} \\text{ 为 } \\boldsymbol{\\text{lambda}})$，然后对所有可能的状态序列求和，得到 $P(O \\text{ 为 } \\boldsymbol{\\text{mid}} \\text{ 为 } \\boldsymbol{\\text{lambda}})$。而前向-后向算法则是基于隐马尔可夫模型的前向概率和后向概率进行递推计算，最终得到观测序列概率 $P(O \\text{ 为 } \\boldsymbol{\\text{mid}} \\text{ 为 } \\boldsymbol{\\text{lambda}})$。因此，直接计算法和前向-后向算法在计算观测序列概率的方式上存在明显的区别。\",\n    \"问题2\": \"直接计算法中的联合概率是如何计算得到观测序列概率的？\",\n    \"回答2\": \"在直接计算法中，首先计算状态序列 $I$ 的概率 $P(I \\text{ 为 } \\boldsymbol{\\text{mid}} \\text{ 为 } \\boldsymbol{\\text{lambda}})$，然后计算观测序列 $O$ 和状态序列 $I$ 同时出现的联合概率 $P(O, I \\text{ 为 } \\boldsymbol{\\text{mid}} \\text{ 为 } \\boldsymbol{\\text{lambda}})$。最终通过对所有可能的状态序列 $I$ 求和，得到观测序列 $O$ 的概率 $P(O \\text{ 为 } \\boldsymbol{\\text{mid}} \\text{ 为 } \\boldsymbol{\\text{lambda}})$。\",\n    \"问题3\": \"前向-后向算法中的前向概率是如何定义的？\",\n    \"回答3\": \"在前向-后向算法中，定义到时刻 $t$ 部分观测序列为 $o_{1}, o_{2}, \\text{...}, o_{t}$ 且状态为 $q_{i}$ 的概率为前向概率，记作 $\\boldsymbol{\\text{alpha}}_{t}(i)=P\\big(o_{1}, o_{2}, \\text{...}, o_{t}, i_{t}=q_{i} \\text{ 为 } \\boldsymbol{\\text{mid}} \\text{ 为 } \\boldsymbol{\\text{lambda}}\\big)$。\",\n    \"问题4\": \"前向-后向算法中的递推公式是如何计算前向概率的？\",\n    \"回答4\": \"在前向-后向算法中，通过递推公式 $\\boldsymbol{\\text{alpha}}_{t+1}(i)=\\big[\\boldsymbol{\\text{sum}}_{j=1}^{N} \\boldsymbol{\\text{alpha}}_{t}(j) a_{j i}\\big] b_{i}\\big(o_{t+1}\\big)$ 计算到时刻 $t+1$ 部分观测序列为 $o_{1}, o_{2}, \\text{...}, o_{t}, o_{t+1}$ 且在时刻 $t+1$ 处于状态 $q_{i}$ 的前向概率。\",\n    \"问题5\": \"前向-后向算法中的终止步骤是如何计算观测序列概率的？\",\n    \"回答5\": \"在前向-后向算法中，通过终止步骤 $P(O \\text{ 为 } \\boldsymbol{\\text{mid}} \\text{ 为 } \\boldsymbol{\\text{lambda}})=\\boldsymbol{\\text{sum}}_{i=1}^{N} \\boldsymbol{\\text{alpha}}_{T}(i)$ 计算观测序列 $O$ 的概率。因为 $\\boldsymbol{\\text{alpha}}_{T}(i)=P\\big(o_{1}, o_{2}, \\text{...}, o_{T}, i_{T}=q_{i} \\text{ 为 } \\boldsymbol{\\text{mid}} \\text{ 为 } \\boldsymbol{\\text{lambda}}\\big)$，所以最终得到观测序列概率。\",\n    \"问题6\": \"直接计算法和前向-后向算法在计算效率上有何不同？\",\n    \"回答6\": \"直接计算法的计算量是 $O\\big(T N^T\\big)$ 阶的，而前向-后向算法的计算量是 $O\\big(N^2 T\\big)$ 阶的。因此，前向-后向算法相比直接计算法具有更高的计算效率。\",\n    \"问题7\": \"前向-后向算法中如何利用路径结构进行高效计算？\",\n    \"回答7\": \"在前向-后向算法中，利用路径结构将局部计算的前向概率递推到全局，从而实现了观测序列概率的高效计算。具体地，在每个时刻 $t=1,2, \\text{...}, T-1$，通过引用前一个时刻的计算结果来避免重复计算，从而减少了整体的计算量。\",\n    \"问题8\": \"直接计算法和前向-后向算法分别适用于什么样的隐马尔可夫模型？\",\n    \"回答8\": \"直接计算法适用于小规模、简单的隐马尔可夫模型，但对于大规模、复杂的模型会导致计算量巨大。而前向-后向算法则适用于各种规模和复杂度的隐马尔可夫模型，并且能够高效地计算观测序列概率。\",\n    \"问题9\": \"在给定隐马尔可夫模型 $\\boldsymbol{\\text{lambda}}$ 和观测序列 $\\boldsymbol{\\text{O}}$ 的情况下，如何使用前向-后向算法来求解观测序列概率？\",\n    \"回答9\": \"在给定隐马尔可夫模型 $\\boldsymbol{\\text{lambda}}$ 和观测序列 $\\boldsymbol{\\text{O}}$ 的情况下，可以通过前向-后向算法按照步骤 (1) 初值、(2) 递推和 (3) 终止来递推地求得前向概率 $\\boldsymbol{\\text{alpha}}_t(i)$ 及最终的观测序列概率 $P(O \\text{ 为 } \\boldsymbol{\\text{mid}} \\text{ 为 } \\boldsymbol{\\text{lambda}})$。\",\n    \"问题10\": \"请说明图中所示的路径结构对于理解前向-后向算法有何帮助？\",\n    \"回答10\": \"图中所示的路径结构有助于理解前向-后向算法是如何基于状态序列路径结构递推地计算观测序列概率的。它展示了如何通过局部计算前向概率，并利用路径结构将其递推到全局，从而实现了高效地求解观测序列概率。\"\n}",
                    "role": "assistant",
                    "function_call": null,
                    "tool_calls": null
                }
            }
        ],
        "created": 1710773537,
        "model": "gpt-3.5-turbo-1106",
        "object": "chat.completion",
        "system_fingerprint": "fp_4aaaf0dc94",
        "usage": {
            "completion_tokens": 1962,
            "prompt_tokens": 5840,
            "total_tokens": 7802
        },
        "parameters": {
            "model": "gpt-3.5-turbo-1106",
            "temperature": 0.2,
            "frequency_penalty": 0.15,
            "presence_penalty": 0.15
        }
    }
]