[
    {
        "strategy": "subsection",
        "source": "machine_learning_chapter5",
        "title": "10.2.3 后向算法",
        "content_length": 1650,
        "content": "Title: 10.2.3 后向算法\nContent:\n定义 10.3 (后向概率) 给定隐马尔可夫模型 $\\lambda$, 定义在时刻 $t$ 状态为 $q_{i}$ 的条件下, 从 $t+1$ 到 $T$ 的部分观测序列为 $o_{t+1}, o_{t+2}, \\cdots, o_{T}$ 的概率为后向概率, 记作\n\n\n\\begin{equation*}\n\\beta_{t}(i)=P\\left(o_{t+1}, o_{t+2}, \\cdots, o_{T} \\mid i_{t}=q_{i}, \\lambda\\right) \\tag{10.18}\n\\end{equation*}\n\n\n可以用递推的方法求得后向概率 $\\beta_{t}(i)$ 及观测序列概率 $P(O \\mid \\lambda)$ 。\n\n\\section*{算法 10.3 (观测序列概率的后向算法)}\n输入: 隐马尔可夫模型 $\\lambda$, 观测序列 $O$ 。\n\n输出: 观测序列概率 $P(O \\mid \\lambda)$ 。\n\n(1)\n\n\n\\begin{equation*}\n\\beta_{T}(i)=1, \\quad i=1,2, \\cdots, N \\tag{10.19}\n\\end{equation*}\n\n\n(2) 对 $t=T-1, T-2, \\cdots, 1$,\n\n\n\\begin{equation*}\n\\beta_{t}(i)=\\sum_{j=1}^{N} a_{i j} b_{j}\\left(o_{t+1}\\right) \\beta_{t+1}(j), \\quad i=1,2, \\cdots, N \\tag{10.20}\n\\end{equation*}\n\n\n(3)\n\n\n\\begin{equation*}\nP(O \\mid \\lambda)=\\sum_{i=1}^{N} \\pi_{i} b_{i}\\left(o_{1}\\right) \\beta_{1}(i) \\tag{10.21}\n\\end{equation*}\n\n\n步骤 (1) 初始化后向概率, 对最终时刻的所有状态 $q_{i}$ 规定 $\\beta_{T}(i)=1$ 。步骤 (2) 是后向概率的递推公式。如图 10.3 所示, 为了计算在时刻 $t$ 状态为 $q_{i}$ 条件下时刻 $t+1$ 之后的观测序列为 $o_{t+1}, o_{t+2}, \\cdots, o_{T}$ 的后向概率 $\\beta_{t}(i)$, 只需考虑在时刻 $t+1$ 所有可能的 $N$ 个状态 $q_{j}$ 的转移概率 (即 $a_{i j}$ 项), 以及在此状态下的观测 $o_{t+1}$ 的观测概率 (即 $b_{j}\\left(o_{t+1}\\right)$ 项), 然后考虑状态 $q_{j}$ 之后的观测序列的后向概率（即 $\\beta_{t+1}(j)$ 项）。步骤 (3) 求 $P(O \\mid \\lambda)$ 的思路与步骤 (2) 一致, 只是初始概率 $\\pi_{i}$ 代替转移概率。\n\n\\begin{center}\n\\includegraphics[max width=\\textwidth]{2024_03_13_85ccebcbbc039fa5a6c0g-33}\n\\end{center}\n\n图 10.3 后向概率递推公式\n\n利用前向概率和后向概率的定义可以将观测序列概率 $P(O \\mid \\lambda)$ 统一写成\n\n\n\\begin{equation*}\nP(O \\mid \\lambda)=\\sum_{i=1}^{N} \\sum_{j=1}^{N} \\alpha_{t}(i) a_{i j} b_{j}\\left(o_{t+1}\\right) \\beta_{t+1}(j), \\quad t=1,2, \\cdots, T-1 \\tag{10.22}\n\\end{equation*}"
    },
    {
        "id": "chatcmpl-948g0jV4s1RPxyfKSK9Eq8oQE9LO6",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "logprobs": null,
                "message": {
                    "content": "{\n    \"问题1\": \"什么是后向概率？\",\n    \"回答1\": \"后向概率是指在隐马尔可夫模型中，给定时刻 $t$ 状态为 $q_{i}$ 的条件下，从 $t+1$ 到 $T$ 的部分观测序列为 $o_{t+1}, o_{t+2}, \\text{...}, o_{T}$ 的概率，记作 $\\beta_{t}(i)$。\",\n    \"问题2\": \"如何通过递推的方法求得后向概率 $\\beta_{t}(i)$ 及观测序列概率 $P(O \\text{ 为 } \\boldsymbol{\\text{lambda}})$？\",\n    \"回答2\": \"可以通过递推的方法求得后向概率 $\\beta_{t}(i)$ 及观测序列概率 $P(O \\text{ 为 } \\boldsymbol{\\text{lambda}})$。首先初始化后向概率，对最终时刻的所有状态 $q_{i}$ 规定 $\\beta_{T}(i)=1$。然后利用递推公式 $\\beta_{t}(i)=\\text{sum}_{j=1}^{N} a_{i j} b_{j}\\big(o_{t+1}\\big) \\beta_{t+1}(j)$ 对 $t=T-1, T-2, \\text{...}, 1$ 进行计算。最终，观测序列概率 $P(O \\text{ 为 } \\boldsymbol{\\text{lambda}})$ 可以通过公式 $P(O \\text{ 为 } \\boldsymbol{\\text{lambda}})=\\text{sum}_{i=1}^{N} \\boldsymbol{\\text{pi}}_{i} b_{i}\\big(o_{1}\\big) \\beta_{1}(i)$ 求得。\",\n    \"问题3\": \"算法 10.3 (观测序列概率的后向算法)中的步骤 (1) 和步骤 (2) 分别是做什么的？\",\n    \"回答3\": \"算法 10.3 中的步骤 (1) 是初始化后向概率，对最终时刻的所有状态 $q_{i}$ 规定 $\\beta_{T}(i)=1$。而步骤 (2) 是利用递推公式 $\\beta_{t}(i)=\\text{sum}_{j=1}^{N} a_{i j} b_{j}\\big(o_{t+1}\\big) \\beta_{t+1}(j)$ 对 $t=T-1, T-2, \\text{...}, 1$ 进行计算，以求得后向概率 $\\beta_{t}(i)$。\",\n    \"问题4\": \"图 10.3 展示了什么内容？\",\n    \"回答4\": \"图 10.3 展示了后向概率的递推公式，即计算在时刻 $t$ 状态为 $q_{i}$ 条件下时刻 $t+1$ 之后的观测序列为 $o_{t+1}, o_{t+2}, \\text{...}, o_{T}$ 的后向概率 $\\beta_{t}(i)$ 的计算过程。\",\n    \"问题5\": \"利用前向概率和后向概率的定义，如何统一写出观测序列概率 $P(O \\text{ 为 } \\boldsymbol{\\text{lambda}})$？\",\n    \"回答5\": \"利用前向概率和后向概率的定义，可以将观测序列概率 $P(O \\text{ 为 } \\boldsymbol{\\text{lambda}})$ 统一写成公式 $P(O \\text{ 为 } \\boldsymbol{\\text{lambda}})=\\text{sum}_{i=1}^{N} \\text{sum}_{j=1}^{N} \\boldsymbol{\\text{alpha}}_{t}(i) a_{i j} b_{j}\\big(o_{t+1}\\big) \\beta_{t+1}(j), t=1,2, \\text{...}, T-1$。\",\n    \"问题6\": \"隐马尔可夫模型中的后向概率有什么作用？\",\n    \"回答6\": \"在隐马尔可夫模型中，后向概率可以用于计算给定模型和观测序列的情况下，某一特定时刻处于某一特定状态的概率。它是计算观测序列概率以及进行参数估计和模型训练的重要组成部分。\",\n    \"问题7\": \"在后向算法中，为什么需要初始化后向概率？\",\n    \"回答7\": \"在后向算法中，需要初始化后向概率是因为在递推计算中需要从最终时刻开始逐步计算得到每个时刻的后向概率。因此，需要对最终时刻的所有状态进行规定，以便进行递推计算。\",\n    \"问题8\": \"后向算法中的步骤 (2) 是如何计算后向概率 $\\beta_{t}(i)$ 的？\",\n    \"回答8\": \"在后向算法中的步骤 (2)，计算后向概率 $\\beta_{t}(i)$ 的过程是通过递推公式 $\\beta_{t}(i)=\\text{sum}_{j=1}^{N} a_{i j} b_{j}\\big(o_{t+1}\\big) \\beta_{t+1}(j)$ 进行的。这个公式考虑了在时刻 $t+1$ 所有可能的 $N$ 个状态 $q_{j}$ 的转移概率以及在此状态下的观测 $o_{t+1}$ 的观测概率，并结合了状态 $q_{j}$ 之后的观测序列的后向概率。\",\n    \"问题9\": \"隐马尔可夫模型中的前向概率和后向概率有何联系？\",\n    \"回答9\": \"利用前向概率和后向概率的定义，可以将观测序列概率统一写成一个公式。具体而言，观测序列概率可以通过前向概率、转移概率、观测概率和后向概率进行统一计算。这种联系使得前向和后向算法能够共同用于估计模型参数和进行预测。\",\n    \"问题10\": \"隐马尔可夫模型中的观测序列概率如何通过前向和后向算法进行计算？\",\n    \"回答10\": \"在隐马尔可夫模型中，利用前向和后向算法可以通过递推地计算前向和后向概率，并结合转移概率、观测概率来计算观测序列概率。具体而言，通过前向和后向算法可以统一计算出给定模型和观测序列情况下的观测序列概率。\"\n}",
                    "role": "assistant",
                    "function_call": null,
                    "tool_calls": null
                }
            }
        ],
        "created": 1710773692,
        "model": "gpt-3.5-turbo-1106",
        "object": "chat.completion",
        "system_fingerprint": "fp_4aaaf0dc94",
        "usage": {
            "completion_tokens": 1822,
            "prompt_tokens": 3608,
            "total_tokens": 5430
        },
        "parameters": {
            "model": "gpt-3.5-turbo-1106",
            "temperature": 0.2,
            "frequency_penalty": 0.15,
            "presence_penalty": 0.15
        }
    }
]