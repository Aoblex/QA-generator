[
    {
        "strategy": "subsection",
        "source": "machine_learning_chapter5",
        "title": "9.4.2 GEM 算法",
        "content_length": 5211,
        "content": "Title: 9.4.2 GEM 算法\nContent:\n\\section*{算法 9.3 (GEM 算法 1)}\n输入: 观测数据, $F$ 函数。\n\n输出: 模型参数。\n\n(1) 初始化参数 $\\theta^{(0)}$, 开始迭代;\n\n(2) 第 $i+1$ 次迭代, 第 1 步: 记 $\\theta^{(i)}$ 为参数 $\\theta$ 的估计值, $\\tilde{P}^{(i)}$ 为函数 $\\tilde{P}$ 的估计, 求 $\\tilde{P}^{(i+1)}$ 使 $\\tilde{P}$ 极大化 $F\\left(\\tilde{P}, \\theta^{(i)}\\right)$;\n\n(3) 第 2 步: 求 $\\theta^{(i+1)}$ 使 $F\\left(\\tilde{P}^{(i+1)}, \\theta\\right)$ 极大化;\n\n(4) 重复步骤 (2) 和步骤 (3), 直到收玫。\n\n在 GEM 算法 1 中, 有时求 $Q\\left(\\theta, \\theta^{(i)}\\right)$ 的极大化是很困难的。下面介绍的 GEM 算法 2 和 GEM 算法 3 并不是直接求 $\\theta^{(i+1)}$ 使 $Q\\left(\\theta, \\theta^{(i)}\\right)$ 达到极大的 $\\theta$, 而是找一个 $\\theta^{(i+1)}$ 使得 $Q\\left(\\theta^{(i+1)}, \\theta^{(i)}\\right)>Q\\left(\\theta^{(i)}, \\theta^{(i)}\\right)$ 。\n\n\\section*{算法 9.4 (GEM 算法 2)}\n输入: 观测数据, $Q$ 函数。\n\n输出: 模型参数。\n\n(1) 初始化参数 $\\theta^{(0)}$, 开始迭代;\n\n(2) 第 $i+1$ 次迭代, 第 1 步: 记 $\\theta^{(i)}$ 为参数 $\\theta$ 的估计值, 计算\n\n$$\n\\begin{aligned}\nQ\\left(\\theta, \\theta^{(i)}\\right) & =E_{Z}\\left[\\log P(Y, Z \\mid \\theta) \\mid Y, \\theta^{(i)}\\right] \\\\\n& =\\sum_{Z} P\\left(Z \\mid Y, \\theta^{(i)}\\right) \\log P(Y, Z \\mid \\theta)\n\\end{aligned}\n$$\n\n(3) 第 2 步: 求 $\\theta^{(i+1)}$ 使\n\n$$\nQ\\left(\\theta^{(i+1)}, \\theta^{(i)}\\right)>Q\\left(\\theta^{(i)}, \\theta^{(i)}\\right)\n$$\n\n(4) 重复步骤 (2) 和步骤 (3), 直到收玫。\n\n当参数 $\\theta$ 的维数为 $d(d \\geqslant 2)$ 时, 可采用一种特殊的 GEM 算法, 它将 EM 算法的 M 步分解为 $d$ 次条件极大化, 每次只改变参数向量的一个分量, 其余分量不改变。\n\n\\section*{算法 9.5 (GEM 算法 3)}\n输入: 观测数据, $Q$ 函数。\n\n输出: 模型参数。\n\n(1) 初始化参数 $\\theta^{(0)}=\\left(\\theta_{1}^{(0)}, \\theta_{2}^{(0)}, \\cdots, \\theta_{d}^{(0)}\\right)$, 开始迭代;\n\n(2) 第 $i+1$ 次迭代, 第 1 步: 记 $\\theta^{(i)}=\\left(\\theta_{1}^{(i)}, \\theta_{2}^{(i)}, \\cdots, \\theta_{d}^{(i)}\\right)$ 为参数 $\\theta=\\left(\\theta_{1}, \\theta_{2}, \\cdots, \\theta_{d}\\right)$ 的估计值, 计算\n\n$$\n\\begin{aligned}\nQ\\left(\\theta, \\theta^{(i)}\\right) & =E_{Z}\\left[\\log P(Y, Z \\mid \\theta) \\mid Y, \\theta^{(i)}\\right] \\\\\n& =\\sum_{Z} P\\left(Z \\mid y, \\theta^{(i)}\\right) \\log P(Y, Z \\mid \\theta)\n\\end{aligned}\n$$\n\n(3) 第 2 步: 进行 $d$ 次条件极大化: 首先, 在 $\\theta_{2}^{(i)}, \\cdots, \\theta_{d}^{(i)}$ 保持不变的条件下求使 $Q\\left(\\theta, \\theta^{(i)}\\right)$ 达到极大的 $\\theta_{1}^{(i+1)}$; 然后, 在 $\\theta_{1}=\\theta_{1}^{(i+1)}, \\theta_{j}=\\theta_{j}^{(i)}, j=3,4, \\cdots, d$ 的条件下求使 $Q\\left(\\theta, \\theta^{(i)}\\right)$ 达到极大的 $\\theta_{2}^{(i+1)}$; 如此继续, 经过 $d$ 次条件极大化, 得到 $\\theta^{(i+1)}=$ $\\left(\\theta_{1}^{(i+1)}, \\theta_{2}^{(i+1)}, \\cdots, \\theta_{d}^{(i+1)}\\right)$ 使得\n\n$$\nQ\\left(\\theta^{(i+1)}, \\theta^{(i)}\\right)>Q\\left(\\theta^{(i)}, \\theta^{(i)}\\right)\n$$\n\n(4) 重复步骤 (2) 和步骤 (3), 直到收玫。\n\n\\section*{本章概要}\n\\begin{enumerate}\n  \\item EM 算法是含有隐变量的概率模型极大似然估计或极大后验概率估计的迭代算法。含有隐变量的概率模型的数据表示为 $P(Y, Z \\mid \\theta)$ 。这里, $Y$ 是观测变量的数据, $Z$ 是隐变量的数据, $\\theta$ 是模型参数。 $\\mathrm{EM}$ 算法通过迭代求解观测数据的对数似然函数 $L(\\theta)=\\log P(Y \\mid \\theta)$的极大化, 实现极大似然估计。每次迭代包括两步: $\\mathrm{E}$ 步, 求期望, 即求 $\\log P(Y, Z \\mid \\theta)$ 关于 $P\\left(Z \\mid Y, \\theta^{(i)}\\right)$ 的期望:\n\\end{enumerate}\n\n$$\nQ\\left(\\theta, \\theta^{(i)}\\right)=\\sum_{Z} \\log P(Y, Z \\mid \\theta) P\\left(Z \\mid Y, \\theta^{(i)}\\right)\n$$\n\n称为 $Q$ 函数, 这里 $\\theta^{(i)}$ 是参数的现估计值; $\\mathrm{M}$ 步, 求极大, 即极大化 $Q$ 函数得到参数的新估计值:\n\n$$\n\\theta^{(i+1)}=\\arg \\max _{\\theta} Q\\left(\\theta, \\theta^{(i)}\\right)\n$$\n\n在构建具体的 EM 算法时, 重要的是定义 $Q$ 函数。每次迭代中, EM 算法通过极大化 $Q$函数来增大对数似然函数 $L(\\theta)$ 。\n\n\\begin{enumerate}\n  \\setcounter{enumi}{1}\n  \\item EM 算法在每次迭代后均提高观测数据的似然函数值, 即\n\\end{enumerate}\n\n$$\nP\\left(Y \\mid \\theta^{(i+1)}\\right) \\geqslant P\\left(Y \\mid \\theta^{(i)}\\right)\n$$\n\n在一般条件下 EM 算法是收玫的, 但不能保证收玫到全局最优。\n\n\\begin{enumerate}\n  \\setcounter{enumi}{2}\n  \\item EM 算法应用极其广泛, 主要应用于含有隐变量的概率模型的学习。高斯混合模型的参数估计是 EM 算法的一个重要应用, 第 10 章将要介绍的隐马尔可夫模型的无监督学习也是 EM 算法的一个重要应用。\n\n  \\item EM 算法还可以解释为 $F$ 函数的极大-极大算法。EM 算法有许多变形, 如 GEM 算法。GEM 算法的特点是每次迭代增加 $F$ 函数值 (并不一定是极大化 $F$ 函数), 从而增加似然函数值。\n\n\\end{enumerate}\n\n\\section*{继续阅 读}\nEM 算法由 Dempster 等人总结提出 ${ }^{[1]}$ 。类似的算法之前已被提出, 如 Baum-Welch 算法, 但是都没有 EM 算法那么广泛。EM 算法的介绍可参见文献 [2] 文献 [4]。EM 算法收玫性定理的有关证明见文献 [5]。GEM 是由 Neal 与 Hinton 提出的 ${ }^{[6]}$ 。\n\n\\section*{习 题}\n9.1 如例 9.1 的三硬币模型。假设观测数据不变, 试选择不同的初值, 例如, $\\pi^{(0)}=0.46$, $p^{(0)}=0.55, q^{(0)}=0.67$, 求模型参数 $\\theta=(\\pi, p, q)$ 的极大似然估计。\n\n9.2 证明引理 9.2 。\n\n9.3 已知观测数据 $-67,-48,6,8,14,16,23,24,28,29,41,49,56,60,75$, 试估计两个分量的高斯混合模型的 5 个参数。\n\n$9.4 \\mathrm{EM}$ 算法可以用到朴素贝叶斯法的无监督学习, 试写出其算法。\n\n\\section*{参考文献}\n[1] DEMPSTER A P, LAIRD N M, RUBIN D B. Maximum-likelihood from incomplete data via the EM algorithm[J]. Journal of the Royal Statistic Society (Series B), 1977, 39(1): 1-38.\n\n[2] HASTIE T, TIBSHIRANI R, FRIEDMAN J. The elements of statistical learning: data mining, inference, and prediction[M]. 范明, 柴玉梅, 旨红英, 等译. Springer, 2001.\n\n[3] MCLACHLAN G, KRISHNAN T. The EM algorithm and extensions[M]. New York: John Wiley \\& Sons, 1996.\n\n[4] 苏诗松, 王静龙, 幞晓龙. 高等数理统计 $[\\mathrm{M}]$. 北京: 高等教育出版社, 1998.\n\n[5] WU C F J. On the convergence properties of the EM algorithm[J]. The Annals of Statistics, 1983, 11: 95-103.\n\n[6] RADFORD N, GEOFFREY H, JORDAN M I. A view of the EM algorithm that justifies incremental, sparse, and other variants[C]//Learning in Graphical Models. Cambridge, MA: MIT Press, 1999: 355-368.\n\n\\section*{第 10 章隐马尔可夫模型}\n隐马尔可夫模型 (hidden Markov model, HMM) 是可用于标注问题的机器学习模型,描述由隐藏的马尔可夫链随机生成观测序列的过程, 属于生成模型。本章首先介绍隐马尔可夫模型的基本概念, 然后分别叙述隐马尔可夫模型的概率计算算法、学习算法以及预测算法。隐马尔可夫模型在语音识别、自然语言处理、生物信息、模式识别等领域有着广泛的应用。\n\n\\section*{10.1 隐马尔可夫模型的基本概念}"
    },
    {
        "id": "chatcmpl-948aYaCpWGsUi97cCr29vF2opYkD7",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "logprobs": null,
                "message": {
                    "content": "{\n    \"问题1\": \"GEM 算法 1 和 GEM 算法 2 的输入和输出有何不同？\",\n    \"回答1\": \"GEM 算法 1 的输入是观测数据和 $F$ 函数，输出是模型参数。而 GEM 算法 2 的输入是观测数据和 $Q$ 函数，输出也是模型参数。因此，两个算法的输入函数和输出结果存在明显的不同。\",\n    \"问题2\": \"GEM 算法 3 中的第 2 步是如何计算 $Q\\big(\\theta, \\theta^{(i)}\\big)$ 的？\",\n    \"回答2\": \"在 GEM 算法 3 中的第 2 步，计算 $Q\\big(\\theta, \\theta^{(i)}\\big)$ 的公式为 $Q\\big(\\theta, \\theta^{(i)}\\big) = E_{Z}\\big[\\text{log} P(Y, Z \\big| \\theta) \\big| Y, \\theta^{(i)}\\big] = \\text{∑}_{Z} P\\big(Z \\big| Y, \\theta^{(i)}\\big) \\text{log} P(Y, Z \\big| \\theta)$。\",\n    \"问题3\": \"GEM 算法中的 $Q$ 函数有什么作用？\",\n    \"回答3\": \"$Q$ 函数在 GEM 算法中起到了重要作用，它用于在每次迭代中极大化对数似然函数，从而实现参数的估计。每次迭代中，EM 算法通过极大化 $Q$ 函数来增大对数似然函数，从而提高观测数据的似然函数值。\",\n    \"问题4\": \"GEM 算法相比 EM 算法有哪些特点？\",\n    \"回答4\": \"GEM 算法是 EM 算法的一种变形，其特点是每次迭代增加 $F$ 函数值（并不一定是极大化 $F$ 函数），从而增加似然函数值。相比之下，EM 算法在每次迭代后均提高观测数据的似然函数值，但不能保证收敛到全局最优。因此，GEM 算法在某些情况下可能具有更好的收敛性能。\",\n    \"问题5\": \"为什么在 GEM 算法中有时求 $Q\\big(\\theta, \\theta^{(i)}\\big)$ 的极大化是很困难的？\",\n    \"回答5\": \"在 GEM 算法中有时求 $Q\\big(\\theta, \\theta^{(i)}\\big)$ 的极大化是很困难的，这可能是因为 $Q$ 函数的形式较为复杂或者存在多个局部最优解。这使得寻找使 $Q$ 函数达到极大值的参数 $\\theta^{(i+1)}$ 变得困难。\",\n    \"问题6\": \"GEM 算法中采用一种特殊的算法来处理参数 $\\theta$ 维数为 $d(d \\text{ 大于等于 } 2)$ 的情况，这种特殊算法是如何实现的？\",\n    \"回答6\": \"当参数 $\\theta$ 的维数为 $d(d \\text{ 大于等于 } 2)$ 时，可以采用一种特殊的 GEM 算法。它将 EM 算法的 M 步分解为 $d$ 次条件极大化，每次只改变参数向量的一个分量，其余分量不改变。这种特殊算法通过逐步更新参数向量的各个分量来实现对整体参数的估计。\",\n    \"问题7\": \"EM 算法和 GEM 算法在哪些领域有着广泛的应用？\",\n    \"回答7\": \"EM 算法主要应用于含有隐变量的概率模型的学习，如高斯混合模型的参数估计和隐马尔可夫模型的无监督学习。而 GEM 算法作为 EM 算法的变形，在类似领域也有着广泛的应用。\",\n    \"问题8\": \"GEM 算法中的收敛性如何？\",\n    \"回答8\": \"GEM 算法在每次迭代中增加 $F$ 函数值，并不一定是极大化 $F$ 函数，从而增加似然函数值。虽然一般情况下 GEM 算法是收敛的，但不能保证收敛到全局最优。因此，在实际应用中需要注意对算法收敛性进行评估。\",\n    \"问题9\": \"GEM 算法与 EM 算法之间存在怎样的关系？\",\n    \"回答9\": \"GEM 算法可以被解释为 $F$ 函数的极大-极大算法，并且是 EM 算法的一种变形。它通过增加 $F$ 函数值来增加似然函数值，相比之下具有一定程度上更好的收敛性能。\",\n    \"问题10\": \"GEM 算法中如何处理参数维数较大（$d \\text{ 大于等于 } 2$）的情况？\",\n    \"回答10\": \"当参数 $\\theta$ 的维数为 $d(d \\text{ 大于等于 } 2)$ 时，可以采用一种特殊的 GEM 算法。它将 EM 算法的 M 步分解为 $d$ 次条件极大化，每次只改变参数向量的一个分量，其余分量不改变。这种特殊算法通过逐步更新参数向量的各个分量来实现对整体参数的估计。\"\n}",
                    "role": "assistant",
                    "function_call": null,
                    "tool_calls": null
                }
            }
        ],
        "created": 1710773354,
        "model": "gpt-3.5-turbo-1106",
        "object": "chat.completion",
        "system_fingerprint": "fp_4aaaf0dc94",
        "usage": {
            "completion_tokens": 1562,
            "prompt_tokens": 5777,
            "total_tokens": 7339
        },
        "parameters": {
            "model": "gpt-3.5-turbo-1106",
            "temperature": 0.2,
            "frequency_penalty": 0.15,
            "presence_penalty": 0.15
        }
    }
]