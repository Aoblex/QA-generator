[
    {
        "strategy": "subsection",
        "source": "machine_learning_chapter2",
        "title": "4.1.1 基本方法",
        "content_length": 2497,
        "content": "Title: 4.1.1 基本方法\nContent:\n设输入空间 $\\mathcal{X} \\subseteq \\boldsymbol{R}^{n}$ 为 $n$ 维向量的集合, 输出空间为类标记集合 $\\mathcal{Y}=\\left\\{c_{1}, c_{2}, \\cdots, c_{K}\\right\\}$ 。输入为特征向量 $x \\in \\mathcal{X}$, 输出为类标记 (class label) $y \\in \\mathcal{Y} \\circ X$ 是定义在输入空间 $\\mathcal{X}$ 上的随机向量, $Y$ 是定义在输出空间 $\\mathcal{Y}$ 上的随机变量。 $P(X, Y)$ 是 $X$ 和 $Y$ 的联合概率分布。训练数据集\n\n$$\nT=\\left\\{\\left(x_{1}, y_{1}\\right),\\left(x_{2}, y_{2}\\right), \\cdots,\\left(x_{N}, y_{N}\\right)\\right\\}\n$$\n\n由 $P(X, Y)$ 独立同分布产生。\n\n朴素贝叶斯法通过训练数据集学习联合概率分布 $P(X, Y)$ 。具体地, 学习以下先验概率分布及条件概率分布。先验概率分布\n\n\n\\begin{equation*}\nP\\left(Y=c_{k}\\right), \\quad k=1,2, \\cdots, K \\tag{4.1}\n\\end{equation*}\n\n\n条件概率分布\n\n\n\\begin{equation*}\nP\\left(X=x \\mid Y=c_{k}\\right)=P\\left(X^{(1)}=x^{(1)}, \\cdots, X^{(n)}=x^{(n)} \\mid Y=c_{k}\\right), \\quad k=1,2, \\cdots, K \\tag{4.2}\n\\end{equation*}\n\n\n于是学习到联合概率分布 $P(X, Y)$ 。\n\n条件概率分布 $P\\left(X=x \\mid Y=c_{k}\\right)$ 有指数级数量的参数, 其估计实际是不可行的。事实上,假设 $x^{(j)}$ 可取值有 $S_{j}$ 个, $j=1,2, \\cdots, n, Y$ 可取值有 $K$ 个, 那么参数个数为 $K \\prod_{j=1}^{n} S_{j}$ 。\n\\footnotetext{(1) 注意: 朴素贝叶斯法与贝叶斯估计 (Bayesian estimation) 是不同的概念。\n}\n朴素贝叶斯法对条件概率分布作了条件独立性的假设。由于这是一个较强的假设, 朴素贝叶斯法也由此得名。具体地, 条件独立性假设是\n\n\n\\begin{align*}\nP\\left(X=x \\mid Y=c_{k}\\right) & =P\\left(X^{(1)}=x^{(1)}, \\cdots, X^{(n)}=x^{(n)} \\mid Y=c_{k}\\right) \\\\\n& =\\prod_{j=1}^{n} P\\left(X^{(j)}=x^{(j)} \\mid Y=c_{k}\\right) \\tag{4.3}\n\\end{align*}\n\n\n朴素贝叶斯法实际上学习到生成数据的机制, 所以属于生成模型。条件独立假设等于是说用于分类的特征在类确定的条件下都是条件独立的。这一假设使朴素贝叶斯法变得简单,但有时会牺牲一定的分类准确率。\n\n朴素贝叶斯法分类时, 对给定的输入 $x$, 通过学习到的模型计算后验概率分布 $P(Y=$ $\\left.c_{k} \\mid X=x\\right)$, 将后验概率最大的类作为 $x$ 的类输出。后验概率计算根据贝叶斯定理进行:\n\n\n\\begin{equation*}\nP\\left(Y=c_{k} \\mid X=x\\right)=\\frac{P\\left(X=x \\mid Y=c_{k}\\right) P\\left(Y=c_{k}\\right)}{\\sum_{k} P\\left(X=x \\mid Y=c_{k}\\right) P\\left(Y=c_{k}\\right)} \\tag{4.4}\n\\end{equation*}\n\n\n将式 (4.3) 代入式 (4.4), 有\n\n\n\\begin{equation*}\nP\\left(Y=c_{k} \\mid X=x\\right)=\\frac{P\\left(Y=c_{k}\\right) \\prod_{j} P\\left(X^{(j)}=x^{(j)} \\mid Y=c_{k}\\right)}{\\sum_{k} P\\left(Y=c_{k}\\right) \\prod_{j} P\\left(X^{(j)}=x^{(j)} \\mid Y=c_{k}\\right)}, \\quad k=1,2, \\cdots, K \\tag{4.5}\n\\end{equation*}\n\n\n这是朴素贝叶斯法分类的基本公式。于是, 朴素贝叶斯分类器可表示为\n\n\n\\begin{equation*}\ny=f(x)=\\arg \\max _{c_{k}} \\frac{P\\left(Y=c_{k}\\right) \\prod_{j} P\\left(X^{(j)}=x^{(j)} \\mid Y=c_{k}\\right)}{\\sum_{k} P\\left(Y=c_{k}\\right) \\prod_{j} P\\left(X^{(j)}=x^{(j)} \\mid Y=c_{k}\\right)} \\tag{4.6}\n\\end{equation*}\n\n\n注意到, 在式 (4.6) 中分母对所有 $c_{k}$ 都是相同的, 所以,\n\n\n\\begin{equation*}\ny=\\arg \\max _{c_{k}} P\\left(Y=c_{k}\\right) \\prod_{j} P\\left(X^{(j)}=x^{(j)} \\mid Y=c_{k}\\right) \\tag{4.7}\n\\end{equation*}"
    },
    {
        "id": "chatcmpl-9407fQSCXkxqds24aRVfyvciffNKI",
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "logprobs": null,
                "message": {
                    "content": "{\n    \"问题1\": \"朴素贝叶斯法中的输入空间和输出空间分别是什么？\",\n    \"回答1\": \"朴素贝叶斯法中，输入空间 $\\boldsymbol{X}$ 是 $n$ 维向量的集合，输出空间 $\\boldsymbol{Y}$ 是类标记集合 $\\big\\brace{c_{1}, c_{2}, \\text{...}, c_{K}\\big\\brace}$。\",\n    \"问题2\": \"朴素贝叶斯法中的训练数据集是如何产生的？\",\n    \"回答2\": \"朴素贝叶斯法中的训练数据集 $T$ 由联合概率分布 $P(X, Y)$ 独立同分布产生，即由随机向量 $X$ 和随机变量 $Y$ 按照联合概率分布 $P(X, Y)$ 产生。\",\n    \"问题3\": \"朴素贝叶斯法中的条件概率分布 $P\\big(X=x \\big| Y=c_{k}\\big)$ 为什么具有指数级数量的参数？\",\n    \"回答3\": \"条件概率分布 $P\\big(X=x \\big| Y=c_{k}\\big)$ 具有指数级数量的参数，因为假设特征可取值有 $S_{j}$ 个，$j=1,2, \\text{...}, n$，类别可取值有 $K$ 个，则参数个数为 $K \\times \\big(\\textstyle\\big\\brace\\textstyle\\brace_{j=1}^{n} S_{j}\\big)$。\",\n    \"问题4\": \"朴素贝叶斯法中的条件独立性假设是什么？\",\n    \"回答4\": \"朴素贝叶斯法中的条件独立性假设是指对于给定类别下的特征向量，各个特征之间是相互独立的，即 $P\\big(X=x \\big| Y=c_{k}\\big) = \\textstyle\\big\\brace\\textstyle\\brace_{j=1}^{n} P\\big(X^{(j)}=x^{(j)} \\big| Y=c_{k}\\big)$。\",\n    \"问题5\": \"朴素贝叶斯法属于什么类型的模型？\",\n    \"回答5\": \"朴素贝叶斯法属于生成模型，因为它实际上学习到生成数据的机制。它通过学习先验概率分布和条件概率分布来对联合概率分布进行建模。\",\n    \"问题6\": \"朴素贝叶斯法在分类时如何计算后验概率分布？\",\n    \"回答6\": \"在分类时，朴素贝叶斯法对给定的输入 $x$，通过学习到的模型计算后验概率分布 $P(Y=c_{k} \\big| X=x)$，然后将后验概率最大的类作为 $x$ 的类输出。\",\n    \"问题7\": \"朴素贝叶斯法分类器的基本公式是什么？\",\n    \"回答7\": \"朴素贝叶斯法分类器的基本公式为 $y=f(x)=\\text{argmax}_{c_{k}} \\frac{P(Y=c_{k}) \\times \\textstyle\\big\\brace\\textstyle\\brace_{j} P(X^{(j)}=x^{(j)} \\big| Y=c_{k})}{\\textstyle\\big\\brace\\textstyle\\brace_{k} P(Y=c_{k}) \\times \\textstyle\\big\\brace\\textstyle\\brace_{j} P(X^{(j)}=x^{(j)} \\big| Y=c_{k})}$。\",\n    \"问题8\": \"在朴素贝叶斯法分类器的基本公式中，为什么分母对所有 $c_{k}$ 都是相同的？\",\n    \"回答8\": \"在朴素贝叶斯法分类器的基本公式中，分母对所有 $c_{k}$ 都是相同的，因为在计算最大后验概率时，分母对于不同类别是相同的，所以可以简化为只计算分子部分。\",\n    \"问题9\": \"朴素贝叶斯法中的条件独立性假设会带来什么影响？\",\n    \"回答9\": \"朴素贝叶斯法中的条件独立性假设使得模型变得简单，但有时会牺牲一定的分类准确率。这是因为该假设过于强大，在实际情况下可能并不成立，导致模型对数据关联性的捕捉能力有限。\",\n    \"问题10\": \"朴素贝叶斯法中的训练数据集是如何用于学习先验概率和条件概率分布的？\",\n    \"回答10\": \"朴素贝叶斯法通过训练数据集学习先验概率分布和条件概率分布。具体地，通过统计训练数据集中各个类别出现的频次以及特征在各个类别下出现的频次来估计先验概率和条件概率分布。\"\n}",
                    "role": "assistant",
                    "function_call": null,
                    "tool_calls": null
                }
            }
        ],
        "created": 1710740811,
        "model": "gpt-3.5-turbo-1106",
        "object": "chat.completion",
        "system_fingerprint": "fp_4aaaf0dc94",
        "usage": {
            "completion_tokens": 1404,
            "prompt_tokens": 4109,
            "total_tokens": 5513
        },
        "parameters": {
            "model": "gpt-3.5-turbo-1106",
            "temperature": 0.2,
            "frequency_penalty": 0.15,
            "presence_penalty": 0.15
        }
    }
]