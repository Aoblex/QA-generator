[
    {
        "strategy": "section",
        "source": "978-3-319-52452-8",
        "level": 3,
        "title": "Smoothing in the Time Series Context",
        "content_length": 8621,
        "content": "Title: Smoothing in the Time Series Context\nContent: In Sect. 1.2, we introduced the concept of filtering or smoothing a time series, and in Example 1.9, we discussed using a moving average to smooth white noise. This method is useful in discovering certain traits in a time series, such as long-term trend and seasonal components. In particular, if \\(x_{t}\\) represents the observations, then\n\n\\[m_{t}=\\sum_{j=-k}^{k}a_{j}x_{t-j}, \\tag{2.37}\\]\n\nwhere \\(a_{j}=a_{-j}\\geq 0\\) and \\(\\sum_{j=-k}^{k}a_{j}=1\\) is a symmetric moving average of the data.\n\n**Example 2.11**: **Moving Average Smoother**\n\nFor example, Fig. 2.12 shows the monthly SOI series discussed in Example 1.5 smoothed using (2.37) with weights \\(a_{0}=a_{\\pm 1}=\\cdots=a_{\\pm 5}=1/12\\), and \\(a_{\\pm 6}=1/24\\); \\(k=6\\). This particular method removes (filters out) the obvious annual temperature cycle and helps emphasize the El Nino cycle. To reproduce Fig. 2.12 in R:\n\n```\nwgts=c(.5,rep(1,11),.5)/12soif=filter(soi,sides=2,filter=wgts)plot(soi)lines(soif,lwd=2,col=4)par(fig=c(.65,1,.65,1),new=TRUE)#theinsertnwgts=c(rep(@,20),wgts,rep(0,20))plot(mwgts,type=\"l\",ylim=c(-.02,.1),xart='n',yart='n',ann=FALSE)\n```\n\nAlthough the moving average smoother does a good job in highlighting the El Nino effect, it might be considered too choppy. We can obtain a smoother fit using the normal distribution for the weights, instead of boxcar-type weights of (2.37).\n\nFigure 2.11: Data generated by (2.35) [_top_] and the fitted line superimposed on the data [_bottom_]\n\n**Example 2.12**: **Kernel Smoothing**\n\nKernel smoothing is a moving average smoother that uses a weight function, or kernel, to average the observations. Figure 2.13 shows kernel smoothing of the SOI series, where \\(m_{t}\\) is now\n\n\\[m_{t}=\\sum_{i=1}^{n}w_{i}(t)x_{i}, \\tag{2.38}\\]\n\nwhere\n\n\\[w_{i}(t)=K\\left(\\frac{t-i}{b}\\right)\\Bigm{/}\\sum_{j=1}^{n}K\\left(\\frac{t-j}{b}\\right) \\tag{2.39}\\]\n\nare the weights and \\(K(\\cdot)\\) is a kernel function. This estimator, which was originally explored by Parzen [148] and Rosenblatt [170], is often called the Nadaraya-Watson estimator (Watson [207]). In this example, and typically, the normal kernel, \\(K(z)=\\frac{1}{\\sqrt{2\\pi}}\\exp(-z^{2}/2)\\), is used.\n\nFigure 2.12: Moving average smoother of SOI. The insert shows the shape of the moving average (“boxcar”) kernel [not drawn to scale] described in (2.39)\n\nFigure 2.13: Kernel smoother of SOI. The insert shows the shape of the normal kernel [not drawn to scale]To implement this in R, use the ksmooth function where a bandwidth can be chosen. The wider the bandwidth, \\(b\\), the smoother the result. From the R ksmooth help file: The kernels are scaled so that their quartiles (viewed as probability densities) are at \\(\\pm\\) 0.25*bandwidth. For the standard normal distribution, the quartiles are \\(\\pm\\).674. In our case, we are smoothing over time, which is of the form \\(t/12\\) for the SOI time series. In Fig. 13, we used the value of \\(b=1\\) to correspond to approximately smoothing a little over one year. Figure 13 can be reproduced in R as follows.\n\nplot(soi) lines(ksmooth(time(soi), soi, \"normal\", bandwidth=1), lwd=2, col=4) par(fig = c(.65, 1,.65, 1), new = TRUE) # the insert gauss = function(x) { 1/sqrt(2*pi) * exp(-(x^2)/2) } x = seq(from = -3, to = 3, by = 0.001) plot(x, gauss(x), type =\"l\", ylim=c(-.02,.45), xat='n', yat='n', ann=FALSE)\n\n**Example 2.13**: **Lowess**\n\nAnother approach to smoothing a time plot is nearest neighbor regression. The technique is based on \\(k\\)-nearest neighbors regression, wherein one uses only the data \\(\\{x_{t-k/2},\\ldots,x_{t},\\ldots,x_{t+k/2}\\}\\) to predict \\(x_{t}\\) via regression, and then sets \\(m_{t}=\\hat{x}_{t}\\).\n\nLowess is a method of smoothing that is rather complex, but the basic idea is close to nearest neighbor regression. Figure 14 shows smoothing of SOI using the R function lowess (see Cleveland [42]). First, a certain proportion of nearest neighbors to \\(x_{t}\\) are included in a weighting scheme; values closer to \\(x_{t}\\) in time get more weight. Then, a robust weighted regression is used to predict \\(x_{t}\\) and obtain the smoothed values \\(m_{t}\\). The larger the fraction of nearest neighbors included, the smoother the fit will be. In Fig. 14, one smoother uses 5% of the data to obtain an estimate of the EI Nino cycle of the data.\n\nIn addition, a (negative) trend in SOI would indicate the long-term warming of the Pacific Ocean. To investigate this, we used lowess with the default smoother span of f=2/3 of the data. Figure 14 can be reproduced in R as follows.\n\nplot(soi) lines(lowess(soi, f=.05), lwd=2, col=4) # EI Nino cycle lines(lowess(soi), lty=2, lwd=2, col=2) # trend (with default span)\n\nFigure 14: Locally weighted scatterplot smoothers (lowess) of the SOI series\n\n**Example 2.14**: **Smoothing Splines**\n\nAn obvious way to smooth data would be to fit a polynomial regression in terms of time. For example, a cubic polynomial would have \\(x_{t}=m_{t}+w_{t}\\) where\n\n\\[m_{t}=\\beta_{0}+\\beta_{1}t+\\beta_{2}t^{2}+\\beta_{3}t^{3}.\\]\n\nWe could then fit \\(m_{t}\\) via ordinary least squares.\n\nAn extension of polynomial regression is to first divide time \\(t=1,\\ldots,n\\), into \\(k\\) intervals, \\([t_{0}=1,t_{1}]\\), \\([t_{1}+1,t_{2}]\\),..., \\([t_{k-1}+1,t_{k}=n]\\); the values \\(t_{0},t_{1},\\ldots,t_{k}\\) are called _knots_. Then, in each interval, one fits a polynomial regression, typically the order is 3, and this is called _cubic splines_.\n\nA related method is _smoothing splines_, which minimizes a compromise between the fit and the degree of smoothness given by\n\n\\[\\sum_{t=1}^{n}\\left[x_{t}-m_{t}\\right]^{2}+\\lambda\\int\\left(m_{t}^{\\prime \\prime}\\right)^{2}dt, \\tag{2.40}\\]\n\nwhere \\(m_{t}\\) is a cubic spline with a knot at each \\(t\\) and primes denote differentiation. The degree of smoothness is controlled by \\(\\lambda>0\\).\n\nThink of taking a long drive where \\(m_{t}\\) is the position of your car at time \\(t\\). In this case, \\(m_{t}^{\\prime\\prime}\\) is instantaneous acceleration/deceleration, and \\(\\int(m_{t}^{\\prime\\prime})^{2}dt\\) is a measure of the total amount of acceleration and deceleration on your trip. A smooth drive would be one where a constant velocity, is maintained (i.e., \\(m_{t}^{\\prime\\prime}=0\\)). A choppy ride would be when the driver is constantly accelerating and decelerating, such as beginning drivers tend to do.\n\nIf \\(\\lambda=0\\), we don't care how choppy the ride is, and this leads to \\(m_{t}=x_{t}\\), the data, which are not smooth. If \\(\\lambda=\\infty\\), we insist on no acceleration or deceleration (\\(m_{t}^{\\prime\\prime}=0\\)); in this case, our drive must be at constant velocity, \\(m_{t}=c+vt\\), and\n\nFigure 2.15: Smoothing splines fit to the SOI seriesconsequently very smooth. Thus, \\(\\lambda\\) is seen as a trade-off between linear regression (completely smooth) and the data itself (no smoothness). The larger the value of \\(\\lambda\\), the smoother the fit.\n\nIn R, the smoothing parameter is called spar and it is monotonically related to \\(\\lambda\\); type?smooth.spline to view the help file for details. Figure 15 shows smoothing spline fits on the SOI series using spar=.5 to emphasize the El Nino cycle, and spar=1 to emphasize the trend. The figure can be reproduced in R as follows.\n\nplot(soi) lines(smooth.spline(time(soi), soi, spar=.5), lwd=2, col=4) lines(smooth.spline(time(soi), soi, spar= 1), lty=2, lwd=2, col=2)\n\n**Example 2.15**: **Smoothing One Series as a Function of Another**\n\nIn addition to smoothing time plots, smoothing techniques can be applied to smoothing a time series as a function of another time series. We have already seen this idea used in Example 2.8 when we used lowess to visualize the nonlinear relationship between Recruitment and SOI at various lags. In this example, we smooth the scatterplot of two contemporaneously measured time series, mortality as a function of temperature. In Example 2.2, we discovered a nonlinear relationship between mortality and temperature. Continuing along these lines, Fig. 16 show a scatterplot of mortality, \\(M_{t}\\), and temperature, \\(T_{t}\\), along with \\(M_{t}\\) smoothed as a function of \\(T_{t}\\) using lowess. Note that mortality increases at extreme temperatures, but in an asymmetric way; mortality is higher at colder temperatures than at hotter temperatures. The minimum mortality rate seems to occur at approximately \\(83^{\\circ}\\) F.\n\nFigure 16 can be reproduced in R as follows using the defaults.\n\nplot(tempr, cmort, xlab=\"Temperature\", ylab=\"Mortality\") lines(lowess(tempr, cmort))\n\nFigure 16: Smooth of mortality as a function of temperature using lowess"
    },
    {
        "raw_response": "{\n  \"问题1\": \"什么是时间序列中的滤波或平滑的概念？\",\n  \"回答1\": \"在时间序列中，滤波或平滑的概念是指通过一定的加权方式对观测数据进行平滑处理，以揭示数据中的长期趋势和季节性成分。滤波方法可以有助于减少数据的噪音，使数据更易于分析，同时也有助于突出数据中的周期性和趋势性变化。\",\n  \"问题2\": \"什么是对称移动平均？\",\n  \"回答2\": \"对称移动平均是一种通过对数据进行加权平均来平滑时间序列的方法。在对称移动平均中，通过对过去和未来一定时间范围内的数据进行加权平均来得到平滑后的数值。这种方法可以帮助去除季节性的变化，突出时间序列中的某些特定特征。\",\n  \"问题3\": \"在指数平滑中，移动平均平滑器如何影响数据的特征？\",\n  \"回答3\": \"在指数平滑中，移动平均平滑器通过对一定时间范围内的数据进行加权平均来平滑数据。这种平滑器能够减少数据的波动，突出数据的趋势和季节性成分，有助于更清晰地观察数据的长期趋势和季节性变化。\",\n  \"问题4\": \"什么是核平滑？\",\n  \"回答4\": \"核平滑是一种移动平均平滑方法，它使用权重函数或核函数对观测数据进行加权平均。通过核平滑，可以更加灵活地平滑数据，突出其中的特定特征。在核平滑中，常用的核函数是正态核函数，它可以帮助去除噪音，突出数据的特定模式。\",\n  \"问题5\": \"什么是Lowess方法？\",\n  \"回答5\": \"Lowess方法是一种复杂的平滑技术，其基本思想类似于最近邻回归。通过Lowess方法，可以通过加权回归预测来对数据进行平滑处理，以突出数据中的特定特征。Lowess方法可以通过引入不同比例的最近邻数据来调节拟合的平滑度，从而得到更加灵活的平滑结果。\",\n  \"问题6\": \"什么是平滑样条？\",\n  \"回答6\": \"平滑样条是一种用于平滑数据的方法，它通过将时间等间隔划分成多个区间，并在每个区间内进行多项式回归来实现数据的平滑处理。平滑样条可以帮助减少数据的波动，突出数据的长期趋势和季节性变化，对于分析时间序列数据具有重要作用。\",\n  \"问题7\": \"什么是阻尼参数在平滑样条中的作用？\",\n  \"回答7\": \"在平滑样条中，阻尼参数用于调节平滑样条的平滑度。阻尼参数越大，平滑样条的平滑度越高，数据的波动被进一步减少，长期趋势更加显著；而阻尼参数越小，平滑样条的平滑度越低，更多地保留了数据的波动特征。\",\n  \"问题8\": \"在统计学中，平滑样条如何平衡拟合和平滑度？\",\n  \"回答8\": \"在统计学中，平滑样条通过最小化拟合误差和平滑度的权衡方式来实现拟合和平滑度的平衡。平滑样条的核心思想是在保持对数据的良好拟合的同时，尽可能减少数据的波动，以突出数据的长期趋势和季节性变化。\",\n  \"问题9\": \"在时间序列中，为什么需要平滑技术？\",\n  \"回答9\": \"在时间序列中，平滑技术能够帮助去除数据中的噪音和随机波动，更清晰地揭示数据的长期趋势和季节性变化。通过平滑技术，可以更好地理解时间序列数据的特征，为进一步分析和预测提供更准确的基础。\",\n  \"问题10\": \"平滑技术在统计学中的应用有哪些？\",\n  \"回答10\": \"平滑技术在统计学中有广泛的应用，例如用于处理时间序列数据、回归分析中的拟合和预测、图像处理中的噪音去除等。通过不同的平滑技术，可以更好地分析和理解数据的特征，为统计学研究和实际应用提供有力的工具支持。\"\n}"
    }
]