\documentclass[10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{CJKutf8}
\usepackage{graphicx}
\usepackage[export]{adjustbox}
\graphicspath{ {./images/} }
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage[version=4]{mhchem}
\usepackage{stmaryrd}
\usepackage{hyperref}
\hypersetup{colorlinks=true, linkcolor=blue, filecolor=magenta, urlcolor=cyan,}
\urlstyle{same}

\title{机器学习方法 }


\author{李航著}
\date{}


\begin{document}
\begin{CJK*}{UTF8}{bsmi}
\maketitle
\begin{center}
\includegraphics[max width=\textwidth]{2024_03_13_bea450f13c914fcf9c21g-01}
\end{center}

请革大掌出版社

请草大尊出版社

北京

\section*{内容简介}
机器学习是以概率论、统计学、信息论、最优化理论、计算理论等为基础的计算机应用理论学科,也是人工智能、数据挖掘等领域的基础学科。本书全面系统地介绍了机器学习的主要方法, 共分 3 篇。第 1 篇介绍监督学习的主要方法, 包括感知机、 $k$ 近邻法、朴素贝叶斯法、决策树、逻辑斯谛回归与最大熵模型、支持向量机、Boosting、EM 算法、隐马尔可夫模型、条件随机场等; 第 2 篇介绍无监督学习的主要方法, 包括聚类、奇异值分解、主成分分析、潜在语义分析、概率潜在语义分析、马尔可夫链蒙特卡罗法、潜在狄利克雷分配、PageRank 算法等; 第 3 篇介绍深度学习的主要方法, 包括前馈神经网络、卷积神经网络、循环神经网络、序列到序列模型、预训练语言模型、生成对抗网络等。书中每章介绍一两种机器学习方法。详细叙述各个方法的模型、策略和算法。从具体例子入手, 由浅入深, 帮助读者直观地理解基本思路, 同时从理论角度出发, 给出严格的数学推导, 严谨详实, 让读者更好地掌握基本原理和概念。目的是使读者能学会和使用这些机器学习的基本技术。为满足读者进一步学习的需要, 书中还对各个方法的要点进行了总结, 给出了一些习题, 并列出了主要参考文献。

本书是机器学习及相关课程的教学参考书, 适合人工智能、数据挖掘等专业的本科生、研究生使用,也可供计算机各个领域的专业研发人员参考。

本书封面贴有清华大学出版社防伪标签, 无标签者不得销售。

版权所有, 侵权必究。举报: 010-62782989, \href{mailto:beiqinquan@tup.tsinghua.edu.cn}{beiqinquan@tup.tsinghua.edu.cn}。

\section*{图书在版编目(CIP)数据}
机器学习方法/李航著—北京: 清华大学出版社, 2022.1

ISBN 978-7-302-59730-8

I. (1)机 ‥ II . (1)李 ‥ III. (1)机器学习 IV. (1)TP181

中国版本图书馆 CIP 数据核字(2021)第 277513 号

责任编辑: 王 倩

封面设计: 李祥榕

责任校对: 王淑云

责任印制：丛怀宇

出版发行: 清华大学出版社

网 址: \href{http://www.tup.com.cn}{http://www.tup.com.cn}, \href{http://www.wqbook.com}{http://www.wqbook.com}

地 址: 北京清华大学学研大厦 $\mathrm{A}$ 座邮 编: 100084

社 总机: 010-83470000 邮 购: 010-62786544

投稿与读者服务: 010-62776969, \href{mailto:c-service@tup.tsinghua.edu.cn}{c-service@tup.tsinghua.edu.cn}

质量反馈: 010-62772015, \href{mailto:zhiliang@tup.tsinghua.edu.cn}{zhiliang@tup.tsinghua.edu.cn}

印 装 者: 三河市东方印刷有限公司

经 销: 全国新华书店

开 本: $185 \mathrm{~mm} \times 260 \mathrm{~mm}$ 印 张: 35.75 插 页: 4 字 数: 880 千字

版次: 2022 年 3 月第 1 版

印次: 2022 年 3 月第 1 次印刷

定价: 138.00 元

产品编号：093532-01\\
献给我的母亲

\section*{序言}
2012 年《统计学习方法 (第 1 版)》出版, 内容涵盖监督学习的主要方法, 2019 年第 2 版出版, 增加了无监督学习的主要方法, 都属于传统机器学习。在这段时间里, 机器学习领域发生了巨大变化, 深度学习在人工智能各个应用方向取得了巨大突破, 成为机器学习的主流技术, 彻底改变了机器学习的面貌。有些读者希望能看到与之前风格相同的讲解深度学习的书籍, 这也触发了作者在原来《统计学习方法》的基础上增加深度学习内容的想法 (计划今后再增加强化学习)。从 2018 年开始, 历时 3 年左右, 完成了深度学习的写作。

考虑到内容的变化, 现将书名更改为《机器学习方法》。第 1 篇监督学习和第 2 篇无监督学习基本为原来的内容, 增加第 3 篇深度学习, 希望对读者有所裨益。传统机器学习是深度学习的基础, 所以将这些内容放在一本书里讲述也有其合理之处。虽然深度学习目前是大家关注的重点, 但传统机器学习仍然有其不容忽视的地位。事实上, 传统机器学习和深度学习各自有更适合的应用场景, 比如, 深度学习长于大数据、复杂问题的预测, 特别是人工智能的应用; 传统机器学习善于小数据、相对简单问题的预测。

本书的定位是讲解机器学习的基本内容, 并不完全是入门书。介绍的内容都是最基本的,在这种意义上适合初学者。但主旨是把最重要的原理和方法做系统的总结, 方便大家经常阅读和复习。在写第 3 篇的时候也接受大家对第 1 篇和第 2 篇的反馈意见, 在力求文字简练清晰的同时, 也确保叙述的详尽明了, 以方便读者理解。在各章方法的导入部分适当增加了背景和动机的介绍。

第 3 篇中使用的数学符号与第 1 篇和第 2 篇有一定的对应关系, 但由于深度学习的特点也有一些改变, 也都能自成体系。将符号完全统一于一个框架内还需要做大量的工作, 希望在增加第 4 篇强化学习之后再做处理。

对第 3 篇的原稿, 郑诗源、张新松等帮助做了校阅, 对一些章节的内容提出了宝贵的意见。责任编辑王倩也为本书的出版做了大量工作。在此对他们表示衰心的感谢。

\section*{《统计学习方法 (第 2 版)》序言}
《统计学习方法 (第 1 版)》于 2012 年出版, 讲述了统计机器学习方法, 主要是一些常用的监督学习方法。第 2 版增加了一些常用的无监督学习方法, 由此本书涵盖了传统统计机器学习方法的主要内容。

在撰写《统计学习方法》伊始, 对全书内容做了初步规划。第 1 版出版之后, 即着手无监督学习方法的写作。由于写作是在业余时间进行, 常常被主要工作打断, 历经 6 年多时间才使这部分工作得以完成。但犹未能加入深度学习和强化学习等重要内容, 希望今后能够增补,完成整本书的写作计划。

《统计学习方法 (第 1 版)》的出版正值大数据和人工智能的热潮, 生逢其时, 截至 2019 年 4 月本书共印刷 25 次, 152000 册, 得到了广大读者的欢迎和支持。有许多读者指出本书对学习和掌握机器学习技术有极大的帮助, 也有许多读者通过电子邮件、微博等指出书中的错误, 提出改进的建议和意见。一些高校将本书作为机器学习课程的教材或参考书。有的同学在网上发表了读书笔记, 有的同学将本书介绍的方法在计算机上实现。清华大学深圳研究生院袁春老师精心制作了第 1 版 12 章的课件, 在网上公布, 为大家提供教学之便。众多老师、同学、读者的支持和鼓励, 让作者深受感动和鼓舞。在这里向所有的老师、同学、读者致以诚挚的谢意!

能为中国的计算机科学、人工智能领域做出一点微薄的贡献, 感到由衷的欣慰, 同时也感受到作为知识传播者的重大责任, 让作者决意把本书写好。也希望大家今后不吝指教, 多提宝贵意见, 以帮助继续提高本书的质量。在写作中作者也深切体会到教学相长的道理, 经常发现自己对基础知识的掌握不够扎实, 通过写作得以对相关知识进行深入的学习, 受益匪浅。

本书是一部机器学习的基本读物, 要求读者拥有高等数学、线性代数和概率统计的基础知识。书中主要讲述统计机器学习的方法, 力求系统全面又简明扼要地阐述这些方法的理论、算法和应用, 使读者能对这些机器学习的基本技术有很好的掌握。针对每个方法, 详细介绍其基本原理、基础理论、实际算法, 给出细致的数学推导和具体实例, 既帮助读者理解, 也便于日后复习。

第 2 版增加的无监督学习方法, 王泉、陈嘉怡、柴琛林、赵程绮等帮助做了认真细致的校阅, 提出了许多宝贵意见, 在此谨对他们表示衷心的感谢。清华大学出版社的薛慧编辑一直对本书的写作给予非常专业的指导和帮助, 在此对她表示衷心的感谢!

由于本人水平有限, 本书一定存在不少错误, 恳请各位专家、老师和同学批评指正。

\section*{《统计学习方法 (第 1 版)》序言}
计算机与网络已经融入人们的日常学习、工作和生活之中, 成为人们不可或缺的助手和伙伴。计算机与网络的飞速发展完全改变了人们的学习、工作和生活方式。智能化是计算机研究与开发的一个主要目标。近几十年来的实践表明, 统计机器学习方法是实现这一目标的最有效手段, 尽管它还存在着一定的局限性。

本人一直从事利用统计学习方法对文本数据进行各种智能性处理的研究, 包括自然语言处理、信息检索、文本数据挖掘。近 20 年来, 这些领域发展之快, 应用之广, 实在令人惊叹! 可以说, 统计机器学习是这些领域的核心技术, 在这些领域的发展及应用中起着决定性的作用。

本人在日常的研究工作中经常指导学生, 并在国内外一些大学及讲习班上多次做过关于统计学习的报告和演讲。在这一过程中, 同学们学习热情很高, 希望得到指导, 这使作者产生了撰写本书的想法。

国内外已出版了多本关于统计机器学习的书籍, 比如, Hastie 等人的《统计学习基础》,该书对统计学习的诸多问题有非常精辟的论述, 但对初学者来说显得有些深奥。统计学习范围甚广, 一两本书很难覆盖所有问题。本书主要是面向将统计学习方法作为工具的科研人员与学生, 特别是从事信息检索、自然语言处理、文本数据挖掘及相关领域的研究与开发的科研人员与学生。

本书力求系统而详细地介绍统计学习的方法。在内容选取上, 侧重介绍那些最重要、最常用的方法, 特别是关于分类与标注问题的方法。对其他问题及方法, 如聚类等, 计划在今后的写作中再加以介绍。在叙述方式上, 每一章讲述一种方法, 各章内容相对独立、完整; 同时力图用统一框架来论述所有方法, 使全书整体不失系统性, 读者可以从头到尾通读, 也可以选择单个章节细读。对每一种方法的讲述力求深入浅出, 给出必要的推导证明, 提供简单的实例, 使初学者易于掌握该方法的基本内容, 领会方法的本质, 并准确地使用方法。对相关的深层理论, 则予以简述。在每章后面, 给出一些习题, 介绍一些相关的研究动向和阅读材料,列出参考文献, 以满足读者进一步学习的需求。本书第 1 章简要叙述统计学习方法的基本概念, 最后一章对统计学习方法进行比较与总结。此外, 在附录中简要介绍一些共用的最优化理论与方法。

本书可以作为统计机器学习及相关课程的教学参考书, 适用于信息检索及自然语言处理等专业的大学生、研究生。

本书初稿完成后, 田飞、王佳磊、武威、陈凯、伍浩铖、曹正、陶宇等人分别审阅了全部\\
或部分章节, 提出了许多宝贵意见, 对本书质量的提高有很大帮助, 在此向他们表示衷心的感谢。在本书的写作和出版过程中, 清华大学出版社的责任编辑薛慧给予了很多帮助, 在此特向她致谢。

由于本人水平所限, 书中难免有错误和不当之处, 欢迎各位专家和读者给予批评指正。

李 航

2011 年 4 月 23 日

\section*{目录}
第 1 章 机器学习及监督学习概论 ..... 3\\
1.1 机器学习 ..... 3\\
1.2 机器学习的分类 ..... 5\\
1.2.1 基本分类 ..... 5\\
1.2.2 按模型分类 ..... 10\\
1.2.3 按算法分类 ..... 11\\
1.2.4 按技巧分类 ..... 12\\
1.3 机器学习方法三要素 ..... 13\\
1.3.1 模型 ..... 13\\
1.3.2 策略 ..... 14\\
1.3.3 算法 ..... 16\\
1.4 模型评估与模型选择 ..... 17\\
1.4.1 训练误差与测试误差 ..... 17\\
1.4.2 过拟合与模型选择 ..... 18\\
1.5 正则化与交叉验证 ..... 20\\
1.5.1 正则化 ..... 20\\
1.5.2 交叉验证 ..... 20\\
1.6 泛化能力 ..... 21\\
1.6.1 泛化误差 ..... 21\\
1.6.2 泛化误差上界 ..... 22\\
1.7 生成模型与判别模型 ..... 24\\
1.8 监督学习应用 ..... 24\\
1.8.1 分类问题 ..... 24\\
1.8.2 标注问题 ..... 26\\
1.8.3 回归问题 ..... 27\\
本章概要 ..... 28\\
继续阅读 ..... 29\\
习题 ..... 29\\
参考文献 ..... 29\\
第 2 章 感知机 ..... 30\\
2.1 感知机模型 ..... 30\\
2.2 感知机学习策略 ..... 31\\
2.2 .1 数据集的线性可分性 ..... 31\\
2.2 .2 感知机学习策略 ..... 31\\
2.3 感知机学习算法 ..... 32\\
2.3 .1 感知机学习算法的原始形式 ..... 33\\
2.3.2 算法的收玫性 ..... 35\\
2.3.3 感知机学习算法的对偶形式 ..... 37\\
本章概要 ..... 39\\
继续阅读 ..... 40\\
习题 ..... 40\\
参考文献 ..... 40\\
第 3 章 $k$ 近邻法 ..... 41\\
$3.1 k$ 近邻算法 ..... 41\\
$3.2 k$ 近邻模型 ..... 42\\
3.2.1 模型 ..... 42\\
3.2 .2 距离度量 ..... 42\\
$3.2 .3 k$ 值的选择 ..... 43\\
3.2.4 分类决策规则 ..... 44\\
$3.3 k$ 近邻法的实现: $k d$ 树 ..... 44\\
3.3.1 构造 $k d$ 树 ..... 45\\
3.3.2 搜索 $k d$ 树 ..... 46\\
本章概要 ..... 48\\
继续阅读 ..... 48\\
习题 ..... 48\\
参考文献 ..... 49\\
第 4 章朴素贝叶斯法 ..... 50\\
4.1 朴素贝叶斯法的学习与分类 ..... 50\\
4.1.1 基本方法 ..... 50\\
4.1.2 后验概率最大化的含义 ..... 51\\
4.2 朴素贝叶斯法的参数估计 ..... 52\\
4.2.1 极大似然估计 ..... 52\\
4.2 .2 学习与分类算法 ..... 53\\
4.2.3 贝叶斯估计 ..... 54\\
本章概要 ..... 55\\
继续阅读 ..... 56\\
习题 ..... 56\\
参考文献 ..... 56\\
第 5 章 决策树。 ..... 57\\
5.1 决策树模型与学习 ..... 57\\
5.1.1 决策树模型 ..... 57\\
5.1.2 决策树与 if-then 规则 ..... 58\\
5.1.3 决策树与条件概率分布 ..... 58\\
5.1.4 决策树学习 ..... 58\\
5.2 特征选择 ..... 60\\
5.2.1 特征选择问题 ..... 60\\
5.2 .2 信息增益 ..... 61\\
5.2 .3 信息增益比 ..... 64\\
5.3 决策树的生成 ..... 64\\
5.3.1 ID3 算法 ..... 65\\
$5.3 .2 \mathrm{C} 4.5$ 的生成算法 ..... 66\\
5.4 决策树的剪枝 ..... 66\\
5.5 CART 算法 ..... 68\\
5.5.1 CART 生成 ..... 69\\
5.5.2 CART 剪枝 ..... 72\\
本章概要 ..... 74\\
继续阅读 ..... 75\\
习题 ..... 75\\
参考文献 ..... 75\\
第 6 章 逻辑斯谛回归与最大熵模型 ..... 77\\
6.1 逻辑斯谛回归模型 ..... 77\\
6.1.1 逻辑斯谛分布 ..... 77\\
6.1.2 二项逻辑斯谛回归模型 ..... 78\\
6.1.3 模型参数估计 ..... 79\\
6.1.4 多项逻辑斯谛回归 ..... 79\\
6.2 最大熵模型 ..... 80\\
6.2 .1 最大熵原理 ..... 80\\
6.2.2 最大熵模型的定义 ..... 82\\
6.2 .3 最大熵模型的学习 ..... 83\\
6.2.4 极大似然估计 ..... 86\\
6.3 模型学习的最优化算法 ..... 87\\
6.3.1 改进的迭代尺度法 ..... 87\\
6.3.2 拟牛顿法 ..... 90\\
本章概要 ..... 91\\
继续阅读 ..... 92\\
习题 ..... 92\\
参考文献 ..... 93\\
第 7 章 支持向量机 ..... 94\\
7.1 线性可分支持向量机与硬间隔最大化 ..... 94\\
7.1.1 线性可分支持向量机 ..... 94\\
7.1.2 函数间隔和几何间隔 ..... 96\\
7.1.3 间隔最大化 ..... 97\\
7.1.4 学习的对偶算法 ..... 101\\
7.2 线性支持向量机与软间隔最大化 ..... 106\\
7.2.1 线性支持向量机 ..... 106\\
7.2 .2 学习的对偶算法 ..... 107\\
7.2 .3 支持向量 ..... 110\\
7.2 .4 合页损失函数 ..... 111\\
7.3 非线性支持向量机与核函数 ..... 112\\
7.3.1 核技巧 ..... 112\\
7.3 .2 正定核 ..... 115\\
7.3.3 常用核函数 ..... 118\\
7.3.4 非线性支持向量分类机 ..... 120\\
7.4 序列最小最优化算法 ..... 121\\
7.4.1 两个变量二次规划的求解方法 ..... 122\\
7.4.2 变量的选择方法 ..... 124\\
7.4.3 SMO 算法 ..... 126\\
本章概要 ..... 127\\
继续阅读 ..... 129\\
习题 ..... 129\\
参考文献 ..... 129\\
第 8 章 Boosting ..... 131\\
8.1 AdaBoost 算法 ..... 131\\
8.1.1 Boosting 的基本思路 ..... 131\\
8.1.2 AdaBoost 算法 ..... 132\\
8.1.3 AdaBoost 的例子 ..... 134\\
8.2 AdaBoost 算法的训练误差分析 ..... 135\\
8.3 AdaBoost 算法的解释 ..... 137\\
8.3.1 前向分步算法 ..... 137\\
8.3.2 前向分步算法与 AdaBoost ..... 138\\
8.4 提升树 ..... 140\\
8.4.1 提升树模型 ..... 140\\
8.4.2 提升树算法 ..... 140\\
8.4.3 梯度提升 ..... 144\\
本章概要 ..... 145\\
继续阅读 ..... 146\\
习题 ..... 146\\
参考文献 ..... 146\\
第 9 章 $\mathrm{EM}$ 算法及其推广 ..... 148\\
$9.1 \mathrm{EM}$ 算法的引入 ..... 148\\
9.1.1 EM 算法 ..... 148\\
9.1.2 EM 算法的导出 ..... 151\\
9.1.3 EM 算法在无监督学习中的应用 ..... 153\\
$9.2 \mathrm{EM}$ 算法的收玫性 ..... 153\\
9.3 EM 算法在高斯混合模型学习中的应用 ..... 154\\
9.3.1 高斯混合模型 ..... 155\\
9.3.2 高斯混合模型参数估计的 EM 算法 ..... 155\\
$9.4 \mathrm{EM}$ 算法的推广 ..... 158\\
9.4.1 $F$ 函数的极大-极大算法 ..... 158\\
9.4.2 GEM 算法 ..... 160\\
本章概要 ..... 161\\
继续阅读 ..... 162\\
习题 ..... 162\\
参考文献 ..... 162\\
第 10 章隐马尔可夫模型 ..... 163\\
10.1 隐马尔可夫模型的基本概念 ..... 163\\
10.1.1 隐马尔可夫模型的定义 ..... 163\\
10.1.2 观测序列的生成过程 ..... 166\\
10.1.3 隐马尔可夫模型的 3 个基本问题 ..... 166\\
10.2 概率计算算法 ..... 166\\
10.2.1 直接计算法 ..... 166\\
10.2 .2 前向算法 ..... 167\\
10.2.3 后向算法 ..... 169\\
10.2.4 一些概率与期望值的计算 ..... 170\\
10.3 学习算法 ..... 172\\
10.3.1 监督学习方法 ..... 172\\
10.3.2 Baum-Welch 算法 ..... 172\\
10.3.3 Baum-Welch 模型参数估计公式 ..... 174\\
10.4 预测算法 ..... 175\\
10.4.1 近似算法 ..... 175\\
10.4.2 维特比算法 ..... 176\\
本章概要 ..... 179\\
继续阅读 ..... 179\\
习题 ..... 180\\
参考文献 ..... 180\\
第 11 章 条件随机场 ..... 181\\
11.1 概率无向图模型 ..... 181\\
11.1.1 模型定义 ..... 181\\
11.1.2 概率无向图模型的因子分解 ..... 183\\
11.2 条件随机场的定义与形式 ..... 184\\
11.2.1 条件随机场的定义 ..... 184\\
11.2.2 条件随机场的参数化形式 ..... 185\\
11.2.3 条件随机场的简化形式 ..... 186\\
11.2.4 条件随机场的矩阵形式 ..... 187\\
11.3 条件随机场的概率计算问题 ..... 189\\
11.3.1 前向-后向算法 ..... 189\\
11.3.2 概率计算 ..... 189\\
11.3 .3 期望值的计算 ..... 190\\
11.4 条件随机场的学习算法 ..... 191\\
11.4.1 改进的迭代尺度法 ..... 191\\
11.4.2 拟牛顿法 ..... 194\\
11.5 条件随机场的预测算法 ..... 195\\
本章概要 ..... 197\\
继续阅读 ..... 198\\
习题 ..... 198\\
参考文献 ..... 199\\
第 12 章 监督学习方法总结 ..... 200\\
第 2 稐 天监督学习\\
第 13 章 无监督学习概论. ..... 207\\
13.1 无监督学习基本原理 ..... 207\\
13.2 基本问题 ..... 208\\
13.3 机器学习三要素 ..... 210\\
13.4 无监督学习方法 ..... 210\\
本章概要 ..... 214\\
继续阅读 ..... 215\\
参考文献 ..... 215\\
第 14 章 聚类方法 ..... 216\\
14.1 聚类的基本概念 ..... 216\\
14.1.1 相似度或距离 ..... 216\\
14.1.2 类或簇 ..... 219\\
14.1.3 类与类之间的距离 ..... 220\\
14.2 层次聚类 ..... 220\\
$14.3 k$ 均值聚类 ..... 222\\
14.3 .1 模型 ..... 222\\
14.3.2 策略 ..... 223\\
14.3.3 算法 ..... 224\\
14.3.4 算法特性 ..... 225\\
本章概要 ..... 226\\
继续阅读 ..... 227\\
习题 ..... 227\\
参考文献 ..... 227\\
第 15 章 奇异值分解 ..... 229\\
15.1 奇异值分解的定义与性质 ..... 229\\
15.1.1 定义与定理 ..... 229\\
15.1.2 紧奇异值分解与截断奇异值分解 ..... 233\\
15.1.3 几何解释 ..... 235\\
15.1.4 主要性质 ..... 237\\
15.2 奇异值分解的计算 ..... 238\\
15.3 奇异值分解与矩阵近似 ..... 241\\
15.3.1 弗罗贝尼乌斯范数 ..... 241\\
15.3.2 矩阵的最优近似 ..... 242\\
15.3.3 矩阵的外积展开式 ..... 245\\
本章概要 ..... 247\\
继续阅读 ..... 248\\
习题 ..... 248\\
参考文献 ..... 249\\
第 16 章 主成分分析 ..... 250\\
16.1 总体主成分分析 ..... 250\\
16.1.1 基本想法 ..... 250\\
16.1.2 定义和导出 ..... 252\\
16.1.3 主要性质 ..... 253\\
16.1.4 主成分的个数 ..... 257\\
16.1.5 规范化变量的总体主成分 ..... 260\\
16.2 样本主成分分析 ..... 260\\
16.2.1 样本主成分的定义和性质 ..... 261\\
16.2.2 相关矩阵的特征值分解算法 ..... 263\\
16.2.3 数据矩阵的奇异值分解算法 ..... 265\\
本章概要 ..... 267\\
继续阅读 ..... 269\\
习题 ..... 269\\
参考文献 ..... 269\\
第 17 章 潜在语义分析 ..... 271\\
17.1 单词向量空间与话题向量空间 ..... 271\\
17.1.1 单词向量空间 ..... 271\\
17.1.2 话题向量空间 ..... 273\\
17.2 潜在语义分析算法 ..... 276\\
17.2.1 矩阵奇异值分解算法 ..... 276\\
17.2.2 例子 ..... 278\\
17.3 非负矩阵分解算法 ..... 279\\
17.3.1 非负矩阵分解 ..... 279\\
17.3.2 潜在语义分析模型 ..... 280\\
17.3.3 非负矩阵分解的形式化 ..... 280\\
17.3.4 算法 ..... 281\\
本章概要 ..... 283\\
继续阅读 ..... 284\\
习题 ..... 284\\
参考文献 ..... 285\\
第 18 章 概率潜在语义分析 ..... 286\\
18.1 概率潜在语义分析模型 ..... 286\\
18.1.1 基本想法 ..... 286\\
18.1.2 生成模型 ..... 287\\
18.1.3 共现模型 ..... 288\\
18.1.4 模型性质 ..... 289\\
18.2 概率潜在语义分析的算法 ..... 291\\
本章概要 ..... 293\\
继续阅读 ..... 294\\
习题 ..... 294\\
参考文献 ..... 295\\
第 19 章 马尔可夫链蒙特卡罗法. ..... 296\\
19.1 蒙特卡罗法 ..... 296\\
19.1.1 随机抽样 ..... 296\\
19.1.2 数学期望估计 ..... 297\\
19.1.3 积分计算 ..... 298\\
19.2 马尔可夫链 ..... 299\\
19.2.1 基本定义 ..... 299\\
19.2.2 离散状态马尔可夫链 ..... 300\\
19.2.3 连续状态马尔可夫链 ..... 305\\
19.2.4 马尔可夫链的性质 ..... 306\\
19.3 马尔可夫链蒙特卡罗法 ..... 310\\
19.3.1 基本想法 ..... 310\\
19.3.2 基本步骤 ..... 311\\
19.3.3 马尔可夫链蒙特卡罗法与统计学习 ..... 311\\
19.4 Metropolis-Hastings 算法 ..... 312\\
19.4.1 基本原理 ..... 312\\
19.4.2 Metropolis-Hastings 算法 ..... 315\\
19.4.3 单分量 Metropolis-Hastings 算法 ..... 315\\
19.5 吉布斯抽样 ..... 316\\
19.5.1 基本原理 ..... 316\\
19.5.2 吉布斯抽样算法 ..... 318\\
19.5.3 抽样计算 ..... 319\\
本章概要 ..... 320\\
继续阅读 ..... 321\\
习题 ..... 321\\
参考文献 ..... 322\\
第 20 章 潜在狄利克雷分配 ..... 324\\
20.1 狄利克雷分布 ..... 324\\
20.1.1 分布定义 ..... 324\\
20.1.2 共轭先验 ..... 327\\
20.2 潜在狄利克雷分配模型 ..... 328\\
20.2.1 基本想法 ..... 328\\
20.2.2 模型定义 ..... 329\\
20.2.3 概率图模型 ..... 331\\
20.2.4 随机变量序列的可交换性 ..... 332\\
20.2.5 概率公式 ..... 332\\
20.3 LDA 的吉布斯抽样算法 ..... 333\\
20.3.1 基本想法 ..... 333\\
20.3.2 算法的主要部分 ..... 334\\
20.3.3 算法的后处理 ..... 336\\
20.3.4 算法 ..... 337\\
20.4 LDA 的变分 EM 算法 ..... 338\\
20.4 .1 变分推理 ..... 338\\
20.4.2 变分 EM 算法 ..... 339\\
20.4.3 算法推导 ..... 340\\
20.4.4 算法总结 ..... 346\\
本章概要 ..... 346\\
继续阅读 ..... 348\\
习题 ..... 348\\
参考文献 ..... 348\\
第 21 章 PageRank 算法 ..... 349\\
21.1 PageRank 的定义 ..... 349\\
21.1.1 基本想法 ..... 349\\
21.1.2 有向图和随机游走模型 ..... 350\\
21.1.3 PageRank 的基本定义 ..... 352\\
21.1.4 PageRank 的一般定义 ..... 354\\
21.2 PageRank 的计算 ..... 355\\
21.2.1 迭代算法 ..... 355\\
21.2 .2 幂法 ..... 357\\
21.2 .3 代数算法 ..... 361\\
本章概要 ..... 362\\
继续阅读 ..... 363\\
习题 ..... 363\\
参考文献 ..... 364\\
第 22 章无监督学习方法总结 ..... 365\\
22.1 无监督学习方法的关系和特点 ..... 365\\
22.1.1 各种方法之间的关系 ..... 365\\
22.1.2 无监督学习方法 ..... 366\\
22.1.3 基础机器学习方法 ..... 366\\
22.2 话题模型之间的关系和特点 ..... 367\\
参考文献 ..... 368

\section*{第 3 篇深度学}
第 23 章前馈神经网络 ..... 371\\
23.1 前馈神经网络的模型 ..... 371\\
23.1.1 前馈神经网络定义 ..... 372\\
23.1.2 前馈神经网络的例子 ..... 381\\
23.1.3 前馈神经网络的表示能力 ..... 386\\
23.2 前馈神经网络的学习算法 ..... 389\\
23.2.1 前馈神经网络学习 ..... 389\\
23.2.2 前馈神经网络学习的优化算法 ..... 391\\
23.2.3 反向传播算法 ..... 393\\
23.2.4 在计算图上的实现 ..... 397\\
23.2.5 算法的实现技巧 ..... 401\\
23.3 前馈神经网络学习的正则化 ..... 406\\
23.3.1 深度学习中的正则化 ..... 406\\
23.3.2 早停法 ..... 406\\
23.3.3 暂退法 ..... 408\\
本章概要 ..... 410\\
继续阅读 ..... 413\\
习题 ..... 413\\
参考文献 ..... 414\\
第 24 章 卷积神经网络 ..... 415\\
24.1 卷积神经网络的模型 ..... 415\\
24.1.1 背景 ..... 415\\
24.1.2 卷积 ..... 416\\
24.1.3 汇聚 ..... 424\\
24.1.4 卷积神经网络 ..... 427\\
24.1.5 卷积神经网络性质 ..... 430\\
24.2 卷积神经网络的学习算法 ..... 432\\
24.2.1 卷积导数 ..... 432\\
24.2 .2 反向传播算法 ..... 433\\
24.3 图像分类中的应用 ..... 436\\
24.3.1 AlexNet. ..... 436\\
24.3.2 残差网络 ..... 437\\
本章概要 ..... 441\\
继续阅读 ..... 443\\
习题 ..... 443\\
参考文献 ..... 445\\
第 25 章循环神经网络 ..... 447\\
25.1 简单循环神经网络 ..... 447\\
25.1.1 模型 ..... 447\\
25.1.2 学习算法 ..... 450\\
25.2 常用循环神经网络 ..... 454\\
25.2.1 长短期记忆网络 ..... 454\\
25.2.2 门控循环单元网络 ..... 457\\
25.2.3 深度循环神经网络 ..... 458\\
25.2.4 双向循环神经网络 ..... 459\\
25.3 自然语言生成中的应用 ..... 460\\
25.3.1 词向量 ..... 460\\
25.3.2 语言模型与语言生成 ..... 463\\
本章概要 ..... 465\\
继续阅读 ..... 467\\
习题 ..... 467\\
参考文献 ..... 468\\
第 26 章 序列到序列模型 ..... 469\\
26.1 序列到序列基本模型 ..... 469\\
26.1.1 序列到序列学习 ..... 469\\
26.1.2 基本模型 ..... 471\\
26.2 RNN Search 模型 ..... 472\\
26.2 .1 注意力 ..... 472\\
26.2.2 模型定义 ..... 474\\
26.2 .3 模型特点 ..... 475\\
26.3 Transformer 模型 ..... 475\\
26.3.1 模型架构 ..... 476\\
26.3.2 模型特点 ..... 482\\
本章概要 ..... 483\\
继续阅读 ..... 486\\
习题 ..... 486\\
参考文献 ..... 486\\
第 27 章 预训练语言模型 ..... 488\\
27.1 GPT 模型 ..... 488\\
27.1.1 预训练语言模型 ..... 488\\
27.1.2 模型和学习 ..... 490\\
27.2 BERT 模型 ..... 493\\
27.2.1 去噪自动编码器 ..... 493\\
27.2 .2 模型和学习 ..... 495\\
27.2 .3 模型特点 ..... 499\\
本章概要 ..... 500\\
继续阅读 ..... 502\\
习题 ..... 502\\
参考文献 ..... 502\\
第 28 章 生成对抗网络 ..... 504\\
28.1 GAN 基本模型 ..... 504\\
28.1.1 模型 ..... 504\\
28.1.2 学习算法 ..... 506\\
28.1.3 理论分析 ..... 507\\
28.2 图像生成中的应用 ..... 508\\
28.2.1 转置卷积 ..... 509\\
28.2.2 DCGAN ..... 511\\
本章概要 ..... 513\\
继续阅读 ..... 514\\
习题 ..... 514\\
参考文献 ..... 515\\
第 29 章 深度学习方法总结 ..... 516\\
29.1 深度学习的模型 ..... 516\\
29.2 深度学习的方法 ..... 518\\
29.3 深度学习的优化算法 ..... 520\\
29.4 深度学习的优缺点 ..... 522\\
参考文献 ..... 523\\
附录 A 梯度下降法 ..... 524\\
附录 B 牛顿法和拟牛顿法 ..... 526\\
附录 C 拉格朗日对偶性 ..... 531\\
附录 D 矩阵的基本子空间 ..... 534\\
附录 E KL 散度的定义和狄利克雷分布的性质 ..... 537\\
附录 $\mathbf{F}$ 软最大化函数的偏导数和交叉嫡损失函数的偏导数 ..... 539\\
索引 ..... 541\\
第 1 斒 监督学习

\section*{第 1 章机器学习及监督学习概论}
本书第 1 篇讲述监督学习方法。监督学习是从标注数据中学习模型的机器学习问题, 是机器学习的重要组成部分。

本章简要叙述机器学习及监督学习的一些基本概念, 使读者对机器学习及监督学习有初步了解。1.1 节叙述机器学习或统计机器学习的定义、研究对象与方法; 1.2 节叙述机器学习的分类, 基本分类是监督学习、无监督学习、强化学习; 1.3 节叙述机器学习方法的三要素:模型、策略和算法; 1.4 节至 1.7 节相继介绍监督学习的几个重要概念, 包括模型评估与模型选择、正则化与交叉验证、学习的泛化能力、生成模型与判别模型; 最后 1.8 节介绍监督学习的应用: 分类问题、标注问题与回归问题。

\section*{1.1 机器 学习}
\section*{1. 机器学习的特点}
机器学习 (machine learning) 是关于计算机基于数据构建概率统计模型并运用模型对数据进行预测与分析的一门学科。机器学习也称为统计机器学习 (statistical machine learning）。

机器学习的主要特点是: (1)机器学习以计算机及网络为平台, 是建立在计算机及网络上的; (2)机器学习以数据为研究对象, 是数据驱动的学科; (3)机器学习的目的是对数据进行预测与分析; (4)机器学习以方法为中心, 机器学习方法构建模型并应用模型进行预测与分析; (5)机器学习是概率论、统计学、信息论、计算理论、最优化理论及计算机科学等多个领域的交叉学科, 并且在发展中逐步形成独自的理论体系与方法论。

赫尔伯特・西蒙 (Herbert A. Simon) 曾对 “学习”给出以下定义: “如果一个系统能够通过执行某个过程改进它的性能, 这就是学习。” 按照这一观点, 机器学习就是计算机系统通过运用数据及统计方法提高系统性能的学习。

\section*{2. 机器学习的对象}
机器学习研究的对象是数据 (data)。它从数据出发, 提取数据的特征, 抽象出数据的模型, 发现数据中的知识, 又回到对数据的分析与预测中去。作为机器学习的对象, 数据是多样的, 包括存在于计算机及网络上的各种数字、文字、图像、视频、音频数据以及它们的组合。

机器学习关于数据的基本假设是同类数据具有一定的统计规律性, 这是机器学习的前\\
提。这里的同类数据是指具有某种共同性质的数据, 例如英文文章、互联网网页、数据库中的数据等。由于它们具有统计规律性, 所以可以用概率统计方法处理它们。比如, 可以用随机变量描述数据中的特征, 用概率分布描述数据的统计规律。在机器学习中, 以变量或变量组表示数据。数据分为由连续变量和离散变量表示的类型。本书以讨论离散变量的方法为主。另外, 本书只涉及利用数据构建模型及利用模型对数据进行分析与预测, 对数据的观测和收集等问题不作讨论。

\section*{3. 机器学习的目的}
机器学习用于对数据的预测与分析, 特别是对未知新数据的预测与分析。对数据的预测可以使计算机更加智能化, 或者说使计算机的某些性能得到提高; 对数据的分析可以让人们获取新的知识, 给人们带来新的发现。

对数据的预测与分析是通过构建概率统计模型实现的。机器学习总的目标就是考虑学习什么样的模型和如何学习模型, 以使模型能对数据进行准确的预测与分析, 同时也要考虑尽可能地提高学习效率。

\section*{4. 机器学习的方法}
机器学习的方法是基于数据构建概率统计模型从而对数据进行预测与分析。机器学习由监督学习 (supervised learning) 、无监督学习 (unsupervised learning) 和强化学习 (reinforcement learning) 等组成。

本书第 1 篇讲述监督学习, 第 2 篇讲述无监督学习。可以说监督学习、无监督学习方法是最主要的机器学习方法。第 3 篇讲述深度学习, 既可以用于监督学习, 也可以用于无监督学习。

机器学习方法可以概括如下: 从给定的、有限的、用于学习的训练数据 (training data)集合出发, 假设数据是独立同分布产生的; 并且假设要学习的模型属于某个函数的集合, 称为假设空间 (hypothesis space) ; 应用某个评价准则 (evaluation criterion), 从假设空间中选取一个最优模型, 使它对已知的训练数据及未知的测试数据 (test data) 在给定的评价准则下有最优的预测; 最优模型的选取由算法实现。这样, 机器学习方法包括模型的假设空间、模型选择的准则以及模型学习的算法, 称为机器学习方法的三要素, 简称为模型 (model) 、策略（strategy）和算法（algorithm）。

实现机器学习方法的步骤如下:

(1) 得到一个有限的训练数据集合;

(2) 确定包含所有可能的模型的假设空间, 即学习模型的集合;

(3) 确定模型选择的准则, 即学习的策略;

(4) 实现求解最优模型的算法, 即学习的算法;

(5) 通过学习方法选择最优模型;

(6) 利用学习的最优模型对新数据进行预测或分析。

本书第 1 篇介绍监督学习方法, 主要包括用于分类、标注与回归问题的方法。这些方法在自然语言处理、信息检索、文本数据挖掘等领域中有着极其广泛的应用。

\section*{5. 机器学习的研究}
机器学习研究一般包括机器学习方法、机器学习理论及机器学习应用三个方面。机器学\\
习方法的研究旨在开发新的学习方法; 机器学习理论的研究在于探求机器学习方法的有效性与效率, 以及机器学习的基本理论问题; 机器学习应用的研究主要考虑将机器学习方法应用到实际问题中去, 解决实际问题。

\section*{6. 机器学习的重要性}
近几十年来, 机器学习无论是在理论还是在应用方面都得到了巨大的发展, 有许多重大突破, 机器学习已被成功地应用到人工智能、模式识别、数据挖掘、自然语言处理、语音处理、计算视觉、信息检索、生物信息等许多计算机应用领域中, 并且成为这些领域的核心技术。人们确信, 机器学习将会在今后的科学发展和技术应用中发挥越来越大的作用。

机器学习学科在科学技术中的重要性主要体现在以下几个方面:

(1) 机器学习是处理海量数据的有效方法。我们处于一个信息爆炸的时代, 海量数据的处理与利用是人们必然的需求。现实中的数据不但规模大, 而且常常具有不确定性, 机器学习往往是处理这类数据最强有力的工具。

（2）机器学习是计算机智能化的有效手段。智能化是计算机发展的必然趋势, 也是计算机技术研究与开发的主要目标。近几十年来, 人工智能等领域的研究证明, 利用机器学习模仿人类智能的方法虽有一定的局限性，但是还是实现这一目标的最有效手段。

(3) 机器学习是计算机科学发展的一个重要组成部分。可以认为计算机科学由三维组成: 系统、计算、信息。机器学习主要属于信息这一维, 并在其中起着核心作用。

\section*{1.2 机器学习的分类}
机器学习或统计机器学习是一个范围宽阔、内容繁多、应用广泛的领域, 并不存在 (至少现在不存在）一个统一的理论体系涵盖所有内容。下面从几个角度对机器学习方法进行分类。

\subsection*{1.2.1 基本分类}
机器学习一般包括监督学习、无监督学习、强化学习。有时还包括半监督学习、主动学习。

\section*{1. 监督学习}
监督学习 (supervised learning) 是指从标注数据中学习预测模型的机器学习问题。标注数据表示输入输出的对应关系, 预测模型对给定的输入产生相应的输出。监督学习的本质是学习输入到输出的映射的统计规律。

(1) 输入空间、特征空间和输出空间

在监督学习中, 将输入与输出所有可能取值的集合分别称为输入空间 (input space) 与输出空间 (output space)。输入空间与输出空间可以是有限元素的集合, 也可以是整个欧氏空间。输入空间与输出空间可以是同一个空间, 也可以是不同的空间, 但通常输出空间远远小于输入空间。

每个具体的输入是一个实例 (instance), 通常由特征向量（feature vector）表示。这时,\\
所有特征向量存在的空间称为特征空间（feature space）。特征空间的每一维对应一个特征。有时假设输入空间与特征空间为相同的空间，对它们不予区分; 有时假设输入空间与特征空间为不同的空间，将实例从输入空间映射到特征空间。模型实际上都是定义在特征空间上的。

在监督学习中, 将输入与输出看作是定义在输入 (特征) 空间与输出空间上的随机变量的取值。输入输出变量用大写字母表示, 习惯上输入变量写作 $X$, 输出变量写作 $Y$ 。输入输出变量的取值用小写字母表示, 输入变量的取值写作 $x$, 输出变量的取值写作 $y$ 。变量可以是标量或向量, 都用相同类型字母表示。除特别声明外, 本书中向量均为列向量。输入实例 $x$ 的特征向量记作

$$
x=\left(x^{(1)}, x^{(2)}, \cdots, x^{(i)}, \cdots, x^{(n)}\right)^{\mathrm{T}}
$$

其中, $x^{(i)}$ 表示 $x$ 的第 $i$ 个特征。注意 $x^{(i)}$ 与 $x_{i}$ 不同, 本书通常用 $x_{i}$ 表示多个输入变量中的第 $i$ 个变量, 即

$$
x_{i}=\left(x_{i}^{(1)}, x_{i}^{(2)}, \cdots, x_{i}^{(n)}\right)^{\mathrm{T}}
$$

监督学习从训练数据 (training data) 集合中学习模型, 对测试数据 (test data) 进行预测。训练数据由输入 (或特征向量) 与输出对组成, 训练集通常表示为

$$
T=\left\{\left(x_{1}, y_{1}\right),\left(x_{2}, y_{2}\right), \cdots,\left(x_{N}, y_{N}\right)\right\}
$$

测试数据也由输入与输出对组成。输入与输出对又称为样本 (sample) 或样本点。

输入变量 $X$ 和输出变量 $Y$ 有不同的类型, 可以是连续的, 也可以是离散的。人们根据输入输出变量的不同类型, 对预测任务给予不同的名称: 输入变量与输出变量均为连续变量的预测问题称为回归问题; 输出变量为有限个离散变量的预测问题称为分类问题; 输入变量与输出变量均为变量序列的预测问题称为标注问题。

(2) 联合概率分布

监督学习假设输入与输出的随机变量 $X$ 和 $Y$ 遵循联合概率分布 $P(X, Y) \circ P(X, Y)$ 表示分布函数或分布密度函数。注意在学习过程中, 假定这一联合概率分布存在, 但对学习系统来说, 联合概率分布的具体定义是未知的。训练数据与测试数据被看作是依联合概率分布 $P(X, Y)$ 独立同分布产生的。机器学习假设数据存在一定的统计规律, $X$ 和 $Y$ 具有联合概率分布就是监督学习关于数据的基本假设。

(3) 假设空间

监督学习的目的在于学习一个由输入到输出的映射, 这一映射由模型来表示。换句话说,学习的目的就在于找到最好的这样的模型。模型属于由输入空间到输出空间的映射的集合,这个集合就是假设空间 (hypothesis space)。假设空间的确定意味着学习的范围的确定。

监督学习的模型可以是概率模型或非概率模型, 由条件概率分布 $P(Y \mid X)$ 或决策函数 (decision function) $Y=f(X)$ 表示, 随具体学习方法而定。对具体的输入进行相应的输出预测时, 写作 $P(y \mid x)$ 或 $y=f(x)$ 。

(4) 问题的形式化

监督学习利用训练数据集学习一个模型, 再用模型对测试样本集进行预测。由于在这个\\
过程中需要标注训练数据集, 而标注的训练数据集往往是人工给出的, 所以称为监督学习。监督学习分为学习和预测两个过程, 由学习系统与预测系统完成, 可用图 1.1 来描述。

\begin{center}
\includegraphics[max width=\textwidth]{2024_03_13_bea450f13c914fcf9c21g-30}
\end{center}

图 1.1 监督学习

首先给定一个训练数据集

$$
T=\left\{\left(x_{1}, y_{1}\right),\left(x_{2}, y_{2}\right), \cdots,\left(x_{N}, y_{N}\right)\right\}
$$

其中 $\left(x_{i}, y_{i}\right), i=1,2, \cdots, N$, 称为样本或样本点。 $x_{i} \in \mathcal{X} \subseteq \boldsymbol{R}^{n}$ 是输入的观测值, 也称为输入或实例, $y_{i} \in \mathcal{Y}$ 是输出的观测值, 也称为输出。

监督学习分为学习和预测两个过程, 由学习系统与预测系统完成。在学习过程中, 学习系统利用给定的训练数据集, 通过学习 (或训练) 得到一个模型, 表示为条件概率分布 $\hat{P}(Y \mid X)$或决策函数 $Y=\hat{f}(X)$ 。条件概率分布 $\hat{P}(Y \mid X)$ 或决策函数 $Y=\hat{f}(X)$ 描述输入与输出随机变量之间的映射关系。在预测过程中, 预测系统对于给定的测试样本集中的输入 $x_{N+1}$, 由模型 $y_{N+1}=\arg \max _{y} \hat{P}\left(y \mid x_{N+1}\right)$ 或 $y_{N+1}=\hat{f}\left(x_{N+1}\right)$ 给出相应的输出 $y_{N+1}$ 。

在监督学习中, 假设训练数据与测试数据是依联合概率分布 $P(X, Y)$ 独立同分布产生的。

学习系统 (也就是学习算法) 试图通过训练数据集中的样本 $\left(x_{i}, y_{i}\right)$ 带来的信息学习模型。具体地说, 对输入 $x_{i}$, 一个具体的模型 $y=f(x)$ 可以产生一个输出 $f\left(x_{i}\right)$, 而训练数据集中对应的输出是 $y_{i}$ 。如果这个模型有很好的预测能力, 训练样本输出 $y_{i}$ 和模型输出 $f\left(x_{i}\right)$ 之间的差就应该足够小。学习系统通过不断地尝试, 选取最好的模型, 以便对训练数据集有足够好的预测, 同时对未知的测试数据集的预测也有尽可能好的推广。

\section*{2. 无监督学习}
无监督学习 (1) (unsupervised learning) 是指从无标注数据中学习预测模型的机器学习问题。无标注数据是自然得到的数据, 预测模型表示数据的类别、转换或概率。无监督学习的本质是学习数据中的统计规律或潜在结构。

模型的输入与输出的所有可能取值的集合分别称为输入空间与输出空间。输入空间与输出空间可以是有限元素集合, 也可以是欧氏空间。每个输入是一个实例, 由特征向量表示。每一个输出是对输入的分析结果, 由输入的类别、转换或概率表示。模型可以实现对数据的聚类、降维或概率估计。

假设 $\mathcal{X}$ 是输入空间, $\mathcal{Z}$ 是隐式结构空间。要学习的模型可以表示为函数 $z=g(x)$ 、条件

(1) 也译作非监督学习。\\
概率分布 $P(z \mid x)$ 或者条件概率分布 $P(x \mid z)$ 的形式, 其中 $x \in \mathcal{X}$ 是输入, $z \in \mathcal{Z}$ 是输出。包含所有可能的模型的集合称为假设空间。无监督学习旨在从假设空间中选出在给定评价标准下的最优模型。

无监督学习通常使用大量的无标注数据学习或训练, 每一个样本是一个实例。训练数据表示为 $U=\left\{x_{1}, x_{2}, \cdots, x_{N}\right\}$, 其中 $x_{i}, i=1,2, \cdots, N$, 是样本。

无监督学习可以用于对已有数据的分析, 也可以用于对未来数据的预测。分析时使用学习得到的模型, 即函数 $z=\hat{g}(x)$ 、条件概率分布 $\hat{P}(z \mid x)$ 或者条件概率分布 $\hat{P}(x \mid z)$ 。预测时, 和监督学习有类似的流程。由学习系统与预测系统完成, 如图 1.2 所示。在学习过程中, 学习系统从训练数据集学习, 得到一个最优模型, 表示为函数 $z=\hat{g}(x)$ 、条件概率分布 $\hat{P}(z \mid x)$ 或者条件概率分布 $\hat{P}(x \mid z)$ 。在预测过程中, 预测系统对于给定的输入 $x_{N+1}$, 由模型 $z_{N+1}=\hat{g}\left(x_{N+1}\right)$ 或 $z_{N+1}=\arg \max _{z} \hat{P}\left(z \mid x_{N+1}\right)$ 给出相应的输出 $z_{N+1}$, 进行聚类或降维, 或者由模型 $\hat{P}(x \mid z)$ 给出输入的概率 $\hat{P}\left(x_{N+1} \mid z_{N+1}\right)$, 进行概率估计。

\begin{center}
\includegraphics[max width=\textwidth]{2024_03_13_bea450f13c914fcf9c21g-31(1)}
\end{center}

图 1.2 无监督学习

\section*{3. 强化学习}
强化学习 (reinforcement learning) 是指智能系统在与环境的连续互动中学习最优行为策略的机器学习问题。假设智能系统与环境的互动基于马尔可夫决策过程 (Markov decision process), 智能系统能观测到的是与环境互动得到的数据序列。强化学习的本质是学习最优的序贯决策。

智能系统与环境的互动如图 1.3 所示。在每一步 $t$, 智能系统从环境中观测到一个状态 (state) $s_{t}$ 与一个奖励 (reward) $r_{t}$, 采取一个动作 (action) $a_{t}$ 。环境根据智能系统选择的

\begin{center}
\includegraphics[max width=\textwidth]{2024_03_13_bea450f13c914fcf9c21g-31}
\end{center}

图 1.3 智能系统与环境的互动\\
动作, 决定下一步 $t+1$ 的状态 $s_{t+1}$ 与奖励 $r_{t+1}$ 。要学习的策略表示为给定的状态下采取的动作。智能系统的目标不是短期奖励的最大化, 而是长期累积奖励的最大化。强化学习过程中, 系统不断地试错（trial and error）, 以达到学习最优策略的目的。

强化学习的马尔可夫决策过程是状态、奖励、动作序列上的随机过程, 由四元组 $\langle S, A, P, r\rangle$ 组成。

\begin{itemize}
  \item $S$ 是有限状态 (state) 的集合。
  \item $A$ 是有限动作 (action) 的集合。
  \item $P$ 是状态转移概率 (transition probability) 函数:
\end{itemize}

$$
P\left(s^{\prime} \mid s, a\right)=P\left(s_{t+1}=s^{\prime} \mid s_{t}=s, a_{t}=a\right)
$$

\begin{itemize}
  \item $r$ 是奖励函数 (reward function) : $r(s, a)=E\left(r_{t+1} \mid s_{t}=s, a_{t}=a\right)$ 。
\end{itemize}

马尔可夫决策过程具有马尔可夫性, 下一个状态只依赖于前一个状态与动作, 由状态转移概率函数 $P\left(s^{\prime} \mid s, a\right)$ 表示。下一个奖励依赖于前一个状态与动作, 由奖励函数 $r(s, a)$ 表示。

策略 $\pi$ 定义为给定状态下动作的函数 $a=f(s)$ 或者条件概率分布 $P(a \mid s)$ 。给定一个策略 $\pi$, 智能系统与环境互动的行为就已确定 (或者是确定性的或者是随机性的)。

价值函数（value function）或状态价值函数（state value function）定义为策略 $\pi$ 从某一个状态 $s$ 开始的长期累积奖励的数学期望:


\begin{equation*}
v_{\pi}(s)=E_{\pi}\left[r_{t+1}+\gamma r_{t+2}+\gamma^{2} r_{t+3}+\cdots \mid s_{t}=s\right] \tag{1.1}
\end{equation*}


动作价值函数 (action value function) 定义为策略 $\pi$ 从某一个状态 $s$ 和动作 $a$ 开始的长期累积奖励的数学期望:


\begin{equation*}
q_{\pi}(s, a)=E_{\pi}\left[r_{t+1}+\gamma r_{t+2}+\gamma^{2} r_{t+3}+\cdots \mid s_{t}=s, a_{t}=a\right] \tag{1.2}
\end{equation*}


强化学习的目标就是在所有可能的策略中选出价值函数最大的策略 $\pi^{*}$, 而在实际学习中往往从具体的策略出发, 不断优化已有策略。这里 $\gamma$ 是折扣率, 表示未来的奖励会有衰减。

强化学习方法中有基于策略的（policy-based）、基于价值的（value-based）, 这两者属于无模型的 (model-free) 方法, 还有有模型的 (model-based) 方法。

有模型的方法试图直接学习马尔可夫决策过程的模型, 包括转移概率函数 $P\left(s^{\prime} \mid s, a\right)$ 和奖励函数 $r(s, a)$ 。这样可以通过模型对环境的反馈进行预测, 求出价值函数最大的策略 $\pi^{*}$ 。

无模型的、基于策略的方法不直接学习模型, 而是试图求解最优策略 $\pi^{*}$, 表示为函数 $a=f^{*}(s)$ 或者是条件概率分布 $P^{*}(a \mid s)$, 这样也能达到在环境中做出最优决策的目的。学习通常从一个具体策略开始, 通过搜索更优的策略进行。

无模型的、基于价值的方法也不直接学习模型, 而是试图求解最优价值函数, 特别是最优动作价值函数 $q^{*}(s, a)$ 。这样可以间接地学到最优策略, 根据该策略在给定的状态下做出相应的动作。学习通常从一个具体价值函数开始, 通过搜索更优的价值函数进行。

\section*{4. 半监督学习与主动学习}
半监督学习 (semi-supervised learning) 是指利用标注数据和未标注数据学习预测模型的机器学习问题。通常有少量标注数据、大量未标注数据, 因为标注数据的构建往往需要人\\
工, 成本较高, 未标注数据的收集不需太多成本。半监督学习旨在利用未标注数据中的信息,辅助标注数据, 进行监督学习, 以较低的成本达到较好的学习效果。

主动学习 (active learning) 是指机器不断主动给出实例让教师进行标注, 然后利用标注数据学习预测模型的机器学习问题。通常的监督学习使用给定的标注数据, 往往是随机得到的, 可以看作是 “被动学习”, 主动学习的目标是找出对学习最有帮助的实例让教师标注, 以较小的标注代价达到较好的学习效果。

半监督学习和主动学习更接近监督学习。

\section*{1.2 .2 按模型分类}
机器学习或统计机器学习方法可以根据其模型的种类进行分类。

\section*{1. 概率模型与非概率模型}
机器学习的模型可以分为概率模型 (probabilistic model) 和非概率模型 (non-probabilistic model）或者确定性模型（deterministic model）。在监督学习中, 概率模型取条件概率分布形式 $P(y \mid x)$, 非概率模型取函数形式 $y=f(x)$, 其中 $x$ 是输入, $y$ 是输出。在无监督学习中, 概率模型取条件概率分布形式 $P(z \mid x)$ 或 $P(x \mid z)$, 非概率模型取函数形式 $z=g(x)$, 其中 $x$ 是输入, $z$ 是输出。

本书介绍的决策树、朴素贝叶斯、隐马尔可夫模型、条件随机场、概率潜在语义分析、潜在狄利克雷分配、高斯混合模型是概率模型。感知机、支持向量机、 $k$ 近邻、AdaBoost、 $k$ 均值、潜在语义分析, 以及神经网络是非概率模型。逻辑斯谛回归既可看作是概率模型, 又可看作是非概率模型。

条件概率分布 $P(y \mid x)$ 和函数 $y=f(x)$ 可以相互转化 (条件概率分布 $P(z \mid x)$ 和函数 $z=g(x)$ 同样可以)。具体地, 条件概率分布最大化后得到函数, 函数归一化后得到条件概率分布。所以, 概率模型和非概率模型的区别不在于输入与输出之间的映射关系, 而在于模型的内在结构。概率模型通常可以表示为联合概率分布的形式, 其中的变量表示输入、输出、隐变量甚至参数。而非概率模型不一定存在这样的联合概率分布。

概率模型的代表是概率图模型（probabilistic graphical model）, 概率图模型是联合概率分布由有向图或者无向图表示的概率模型, 而联合概率分布可以根据图的结构分解为因子乘积的形式。贝叶斯网络、马尔可夫随机场、条件随机场是概率图模型。无论模型如何复杂, 均可以用最基本的加法规则和乘法规则（参照图 1.4）进行概率推理。

加法规则 : $P(x)=\sum_{y} P(x, y)$

乘法规则 : $P(x, y)=P(x) P(y \mid x)$

其中 $x$ 和 $y$ 是随机变量

图 1.4 基本概率公式

\section*{2. 线性模型与非线性模型}
机器学习模型, 特别是非概率模型, 可以分为线性模型 (linear model) 和非线性模型（non-linear model）。如果函数 $y=f(x)$ 或 $z=g(x)$ 是线性函数, 则称模型是线性模型,否则称模型是非线性模型。

本书介绍的感知机、线性支持向量机、 $k$ 近邻、 $k$ 均值、潜在语义分析是线性模型, 核函数支持向量机、AdaBoost、神经网络是非线性模型。

深度学习 (deep learning) 实际是复杂神经网络的学习, 也就是复杂的非线性模型的学习。

\section*{3. 参数化模型与非参数化模型}
机器学习模型又可以分为参数化模型 (parametric model) 和非参数化模型 (nonparametric model）。参数化模型假设模型参数的维度固定, 模型可以由有限维参数完全刻画; 非参数化模型假设模型参数的维度不固定或者说无穷大, 随着训练数据量的增加而不断增大。

本书介绍的感知机、朴素贝叶斯、逻辑斯谛回归、 $k$ 均值、高斯混合模型、潜在语义分析、概率潜在语义分析、潜在狄利克雷分配是参数化模型, 决策树、支持向量机、AdaBoost、 $k$ 近邻是非参数化模型。

参数化模型适合问题简单的情况, 现实中问题往往比较复杂, 非参数化模型更加有效。

\subsection*{1.2.3 按算法分类}
机器学习根据算法, 可以分为在线学习 (online learning) 与批量学习 (batch learning)。在线学习是指每次接受一个样本, 进行预测, 之后学习模型, 并不断重复该操作的机器学习。与之对应, 批量学习一次接受所有数据, 学习模型, 之后进行预测。有些实际应用的场景要求学习必须是在线的。比如, 数据依次达到无法存储, 系统需要及时做出处理; 数据规模很大,不可能一次处理所有数据; 数据的模式随时间动态变化, 需要算法快速适应新的模式 (不满足独立同分布假设）。

在线学习可以是监督学习, 也可以是无监督学习, 强化学习本身就拥有在线学习的特点。以下只考虑在线的监督学习。

学习和预测在一个系统, 每次接受一个输入 $x_{t}$, 用已有模型给出预测 $\hat{f}\left(x_{t}\right)$, 之后得到相应的反馈, 即该输入对应的输出 $y_{t}$; 系统用损失函数计算两者的差异, 更新模型, 并不断重复以上操作, 如图 1.5 所示。

\begin{center}
\includegraphics[max width=\textwidth]{2024_03_13_bea450f13c914fcf9c21g-34}
\end{center}

图 1.5 在线学习

利用随机梯度下降的感知机学习算法就是在线学习算法。\\
在线学习通常比批量学习更难, 很难学到预测精确率更高的模型, 因为每次模型更新中,可利用的数据有限。

\subsection*{1.2.4 按技巧分类}
机器学习方法可以根据其使用的技巧进行分类。

\section*{1. 贝叶斯学习}
贝叶斯学习 (Bayesian learning) 又称为贝叶斯推理 (Bayesian inference), 是统计学、机器学习中重要的方法。其主要想法是: 在概率模型的学习和推理中, 利用贝叶斯定理, 计算在给定数据条件下模型的条件概率, 即后验概率, 并应用这个原理进行模型的估计, 以及对数据的预测。将模型、未观测要素及其参数用变量表示, 使用模型的先验分布是贝叶斯学习的特点。贝叶斯学习中也使用基本概率公式 (图 1.4)。

本书介绍的朴素贝叶斯、潜在狄利克雷分配的学习属于贝叶斯学习。

假设随机变量 $D$ 表示数据, 随机变量 $\theta$ 表示模型参数。根据贝叶斯定理, 可以用以下公式计算后验概率 $P(\theta \mid D):$


\begin{equation*}
P(\theta \mid D)=\frac{P(\theta) P(D \mid \theta)}{P(D)} \tag{1.3}
\end{equation*}


其中, $P(\theta)$ 是先验概率, $P(D \mid \theta)$ 是似然函数。

模型估计时, 估计整个后验概率分布 $P(\theta \mid D)$ 。如果需要给出一个模型, 通常取后验概率最大的模型。

预测时，计算数据对后验概率分布的期望值:


\begin{equation*}
P(x \mid D)=\int P(x \mid \theta, D) P(\theta \mid D) \mathrm{d} \theta \tag{1.4}
\end{equation*}


这里 $x$ 是新样本。

贝叶斯估计与极大似然估计在思想上有很大的不同, 代表着统计学中贝叶斯学派和频率学派对统计的不同认识。其实, 可以简单地把两者联系起来, 假设先验分布是均匀分布, 取后验概率最大, 就能从贝叶斯估计得到极大似然估计。图 1.6 对贝叶斯估计和极大似然估计进行比较。

$$
\begin{aligned}
& D \xrightarrow{\text { 极大似然估计 }} \hat{\theta}=\arg \max _{\theta} P(D \mid \theta) \\
& D \xrightarrow{\text { 贝叶斯估计 }} \hat{P}(\theta \mid D)=\frac{P(\theta) P(D \mid \theta)}{P(D)}
\end{aligned}
$$

\begin{center}
\includegraphics[max width=\textwidth]{2024_03_13_bea450f13c914fcf9c21g-35}
\end{center}

图 1.6 贝叶斯估计与极大似然估计

\section*{2. 核方法}
核方法 (kernel method) 是使用核函数表示和学习非线性模型的一种机器学习方法, 可以用于监督学习和无监督学习。有一些线性模型的学习方法基于相似度计算, 更具体地, 向量内积计算。核方法可以把它们扩展到非线性模型的学习, 使其应用范围更广泛。

本书介绍的核函数支持向量机，以及核 PCA、核 $k$ 均值属于核方法。

把线性模型扩展到非线性模型, 直接的做法是显式地定义从输入空间（低维空间）到特征空间（高维空间）的映射，在特征空间中进行内积计算。比如支持向量机，把输入空间的线性不可分问题转化为特征空问的线性可分问题，如图 1.7 所示。核方法的技巧在于不显式地定义这个映射, 而是直接定义核函数, 即映射之后在特征空间的内积。这样可以简化计算, 达到同样的效果。

\begin{center}
\includegraphics[max width=\textwidth]{2024_03_13_bea450f13c914fcf9c21g-36(1)}
\end{center}

图 1.7 输入空间到特征空间的映射

假设 $x_{1}$ 和 $x_{2}$ 是输入空间的任意两个实例 (向量), 其内积是 $\left\langle x_{1}, x_{2}\right\rangle$ 。假设从输入空间到特征空间的映射是 $\varphi$, 于是 $x_{1}$ 和 $x_{2}$ 在特征空间的映像是 $\varphi\left(x_{1}\right)$ 和 $\varphi\left(x_{2}\right)$, 其内积

\includegraphics[max width=\textwidth, center]{2024_03_13_bea450f13c914fcf9c21g-36}\\
$\left\langle\varphi\left(x_{1}\right), \varphi\left(x_{2}\right)\right\rangle$ 。表示定理给出核函数技巧成立的充要条件。

\section*{1.3 机器学习方法三要素}
机器学习方法都是由模型、策略和算法构成的, 即机器学习方法由三要素构成, 可以简单地表示为

$$
\text { 方法 }=\text { 模型 }+ \text { 策略 }+ \text { 算法 }
$$

下面论述监督学习中的机器学习三要素。非监督学习也同样拥有这三要素。可以说构建一种机器学习方法就是确定具体的机器学习三要素。

\subsection*{1.3.1 模型}
机器学习首要考虑的问题是学习什么样的模型。在监督学习过程中, 模型就是所要学习的条件概率分布或决策函数。模型的假设空间 (hypothesis space) 包含所有可能的条件概率分布或决策函数。例如, 假设决策函数是输入变量的线性函数, 那么模型的假设空间就是所有这些线性函数构成的函数集合。假设空间中的模型一般有无穷多个。\\
假设空间用 $\mathcal{F}$ 表示, 可以定义为决策函数的集合:


\begin{equation*}
\mathcal{F}=\{f \mid Y=f(X)\} \tag{1.5}
\end{equation*}


其中, $X$ 和 $Y$ 是定义在输入空间 $\mathcal{X}$ 和输出空间 $\mathcal{Y}$ 上的变量。这时 $\mathcal{F}$ 通常是由一个参数向量决定的函数族:


\begin{equation*}
\mathcal{F}=\left\{f \mid Y=f_{\theta}(X), \theta \in \boldsymbol{R}^{n}\right\} \tag{1.6}
\end{equation*}


参数向量 $\theta$ 取值于 $n$ 维欧氏空间 $\boldsymbol{R}^{n}$, 称为参数空间（parameter space）。

假设空间也可以定义为条件概率的集合:


\begin{equation*}
\mathcal{F}=\{P \mid P(Y \mid X)\} \tag{1.7}
\end{equation*}


其中, $X$ 和 $Y$ 是定义在输入空间 $\mathcal{X}$ 和输出空间 $\mathcal{Y}$ 上的随机变量。这时 $\mathcal{F}$ 通常是由一个参数向量决定的条件概率分布族:


\begin{equation*}
\mathcal{F}=\left\{P \mid P_{\theta}(Y \mid X), \theta \in \boldsymbol{R}^{n}\right\} \tag{1.8}
\end{equation*}


参数向量 $\theta$ 取值于 $n$ 维欧氏空间 $\boldsymbol{R}^{n}$ ，也称为参数空间。

本书中称由决策函数表示的模型为非概率模型, 由条件概率表示的模型为概率模型。为了简便起见, 当论及模型时, 有时只用其中一种模型。

\subsection*{1.3.2 策略}
有了模型的假设空间, 机器学习接着需要考虑的是按照什么样的准则学习或选择最优的模型。机器学习的目标在于从假设空间中选取最优模型。

首先引入损失函数与风险函数的概念。损失函数度量模型一次预测的好坏, 风险函数度量平均意义下模型预测的好坏。

\section*{1. 损失函数和风险函数}
监督学习问题是在假设空间 $\mathcal{F}$ 中选取模型 $f$ 作为决策函数, 对于给定的输入 $X$, 由 $f(X)$ 给出相应的输出 $Y$, 这个输出的预测值 $f(X)$ 与真实值 $Y$ 可能一致也可能不一致, 用一个损失函数 (loss function) 或代价函数 (cost function) 来度量预测错误的程度。损失函数是 $f(X)$ 和 $Y$ 的非负实值函数, 记作 $L(Y, f(X))$ 。

机器学习常用的损失函数有以下几种:

(1) 0-1 损失函数 (0-1 loss function)

\[
L(Y, f(X))= \begin{cases}1, & Y \neq f(X)  \tag{1.9}\\ 0, & Y=f(X)\end{cases}
\]

(2) 平方损失函数 (quadratic loss function)


\begin{equation*}
L(Y, f(X))=(Y-f(X))^{2} \tag{1.10}
\end{equation*}


(3) 绝对损失函数 (absolute loss function)


\begin{equation*}
L(Y, f(X))=|Y-f(X)| \tag{1.11}
\end{equation*}


(4) 对数损失函数（logarithmic loss function）或对数似然损失函数（log-likelihood loss function)


\begin{equation*}
L(Y, P(Y \mid X))=-\log P(Y \mid X) \tag{1.12}
\end{equation*}


损失函数值越小, 模型就越好。由于模型的输入、输出 $(X, Y)$ 是随机变量, 遵循联合分布 $P(X, Y)$, 所以损失函数的期望是


\begin{align*}
R_{\exp }(f) & =E_{P}[L(Y, f(X))] \\
& =\int_{\mathcal{X} \times \mathcal{Y}} L(y, f(x)) P(x, y) \mathrm{d} x \mathrm{~d} y \tag{1.13}
\end{align*}


这是理论上模型 $f(X)$ 关于联合分布 $P(X, Y)$ 的平均意义下的损失, 称为风险函数（risk function）或期望损失（expected loss）。

学习的目标就是选择期望风险最小的模型。由于联合分布 $P(X, Y)$ 是未知的, $R_{\exp }(f)$不能直接计算。实际上, 如果知道联合分布 $P(X, Y)$, 可以从联合分布直接求出条件概率分布 $P(Y \mid X)$, 也就不需要学习了。正因为不知道联合概率分布, 所以才需要进行学习。这样一来, 一方面根据期望风险最小学习模型要用到联合分布, 另一方面联合分布又是未知的, 所以监督学习就成为一个病态问题（ill-formed problem）。

给定一个训练数据集

$$
T=\left\{\left(x_{1}, y_{1}\right),\left(x_{2}, y_{2}\right), \cdots,\left(x_{N}, y_{N}\right)\right\}
$$

模型 $f(X)$ 关于训练数据集的平均损失称为经验风险 (empirical risk) 或经验损失 (empirical loss ), 记作 $R_{\text {emp }}$ :


\begin{equation*}
R_{\mathrm{emp}}(f)=\frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, f\left(x_{i}\right)\right) \tag{1.14}
\end{equation*}


期望风险 $R_{\exp }(f)$ 是模型关于联合分布的期望损失, 经验风险 $R_{\mathrm{emp}}(f)$ 是模型关于训练样本集的平均损失。根据大数定律, 当样本容量 $N$ 趋于无穷时, 经验风险 $R_{\mathrm{emp}}(f)$ 趋于期望风险 $R_{\exp }(f)$ 。所以一个很自然的想法是用经验风险估计期望风险。但是, 由于现实中训练样本数目有限, 甚至很小, 所以用经验风险估计期望风险常常并不理想, 要对经验风险进行一定的矫正。这就关系到监督学习的两个基本策略: 经验风险最小化和结构风险最小化。

\section*{2. 经验风险最小化与结构风险最小化}
在假设空间、损失函数以及训练数据集确定的情况下，经验风险函数式 (1.14) 就可以确定。经验风险最小化 (empirical risk minimization, ERM) 的策略认为, 经验风险最小的模型是最优的模型。根据这一策略, 按照经验风险最小化求最优模型就是求解最优化问题:


\begin{equation*}
\min _{f \in \mathcal{F}} \frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, f\left(x_{i}\right)\right) \tag{1.15}
\end{equation*}


其中, $\mathcal{F}$ 是假设空间。

当样本容量足够大时, 经验风险最小化能保证有很好的学习效果, 在现实中被广泛采用。比如, 极大似然估计 (maximum likelihood estimation) 就是经验风险最小化的一个例子。当模型是条件概率分布、损失函数是对数损失函数时, 经验风险最小化就等价于极大似然估计。但是, 当样本容量很小时, 经验风险最小化学习的效果就未必很好, 会产生 “过拟合” (over-fitting) 现象。

结构风险最小化 (structural risk minimization, SRM) 是为了防止过拟合而提出来的策略。结构风险最小化等价于正则化 (regularization)。结构风险在经验风险上加上表示模型复杂度的正则化项 (regularizer) 或罚项 (penalty term)。在假设空间、损失函数以及训练数据集确定的情况下，结构风险的定义是


\begin{equation*}
R_{\mathrm{srm}}(f)=\frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, f\left(x_{i}\right)\right)+\lambda J(f) \tag{1.16}
\end{equation*}


其中, $J(f)$ 为模型的复杂度, 是定义在假设空间 $\mathcal{F}$ 上的泛函。模型 $f$ 越复杂, 复杂度 $J(f)$就越大; 反之, 模型 $f$ 越简单, 复杂度 $J(f)$ 就越小。也就是说, 复杂度表示了对复杂模型的惩罚。 $\lambda \geqslant 0$ 是系数, 用以权衡经验风险和模型复杂度。结构风险小需要经验风险与模型复杂度同时小。结构风险小的模型往往对训练数据以及未知的测试数据都有较好的预测。

比如, 贝叶斯估计中的最大后验概率估计 (maximum posterior probability estimation, MAP) 就是结构风险最小化的一个例子。当模型是条件概率分布、损失函数是对数损失函数、模型复杂度由模型的先验概率表示时, 结构风险最小化就等价于最大后验概率估计。

结构风险最小化的策略认为结构风险最小的模型是最优的模型, 所以求最优模型就是求解最优化问题:


\begin{equation*}
\min _{f \in \mathcal{F}} \frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, f\left(x_{i}\right)\right)+\lambda J(f) \tag{1.17}
\end{equation*}


这样, 监督学习问题就变成了经验风险或结构风险函数的最优化问题 (1.15) 和 (1.17)。这时经验或结构风险函数是最优化的目标函数。

\subsection*{1.3.3 算法}
算法是指学习模型的具体计算方法。机器学习基于训练数据集, 根据学习策略, 从假设空间中选择最优模型, 最后需要考虑用什么样的计算方法求解最优模型。这时, 机器学习问题归结为最优化问题, 机器学习的算法成为求解最优化问题的算法。如果最优化问题有显式的解析解, 这个最优化问题就比较简单。但通常解析解不存在, 这就需要用数值计算的方法求解。如何保证找到全局最优解, 并使求解的过程非常高效, 就成为一个重要问题。机器学习可以利用已有的最优化算法, 有时也需要开发独自的最优化算法。

机器学习方法之间的不同主要来自其模型、策略、算法的不同。确定了模型、策略、算法, 机器学习的方法也就确定了。这就是将其称为机器学习方法三要素的原因。以下介绍监督学习的几个重要概念。

\section*{1.4 模型评估与模型选择}
\subsection*{1.4.1 训练误差与测试误差}
机器学习的目的是使学到的模型不仅对已知数据而且对未知数据都能有很好的预测能力。不同的学习方法会给出不同的模型。当损失函数给定时, 基于损失函数的模型的训练误差 (training error) 和模型的测试误差 (test error) 就自然成为学习方法评估的标准。注意,机器学习方法具体采用的损失函数未必是评估时使用的损失函数。当然, 让两者一致是比较理想的。

假设学习到的模型是 $Y=\hat{f}(X)$, 训练误差是模型 $Y=\hat{f}(X)$ 关于训练数据集的平均损失:


\begin{equation*}
R_{\mathrm{emp}}(\hat{f})=\frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, \hat{f}\left(x_{i}\right)\right) \tag{1.18}
\end{equation*}


其中, $N$ 是训练样本容量。

测试误差是模型 $Y=\hat{f}(X)$ 关于测试数据集的平均损失:


\begin{equation*}
e_{\text {test }}=\frac{1}{N^{\prime}} \sum_{i=1}^{N^{\prime}} L\left(y_{i}, \hat{f}\left(x_{i}\right)\right) \tag{1.19}
\end{equation*}


其中, $N^{\prime}$ 是测试样本容量。

例如, 当损失函数是 0-1 损失时, 测试误差就变成了常见的测试数据集上的误差率 (error rate):


\begin{equation*}
e_{\text {test }}=\frac{1}{N^{\prime}} \sum_{i=1}^{N^{\prime}} I\left(y_{i} \neq \hat{f}\left(x_{i}\right)\right) \tag{1.20}
\end{equation*}


这里 $I$ 是指示函数 (indicator function), 即 $y \neq \hat{f}(x)$ 时为 1 , 否则为 0 。

相应地, 常见的测试数据集上的精确率 (accuracy) 为


\begin{equation*}
r_{\text {test }}=\frac{1}{N^{\prime}} \sum_{i=1}^{N^{\prime}} I\left(y_{i}=\hat{f}\left(x_{i}\right)\right) \tag{1.21}
\end{equation*}


显然，

$$
r_{\text {test }}+e_{\text {test }}=1
$$

训练误差的大小对判断给定的问题是不是一个容易学习的问题是有意义的, 但本质上不重要。测试误差反映了学习方法对未知的测试数据集的预测能力, 是学习中的重要概念。显然, 给定两种学习方法, 测试误差小的方法具有更好的预测能力, 是更有效的方法。通常将学习方法对未知数据的预测能力称为泛化能力 (generalization ability), 这个问题将在 1.6 节继续论述。


\end{CJK*}
\end{document}